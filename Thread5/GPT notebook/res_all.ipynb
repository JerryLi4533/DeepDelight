{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 50000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 2\n",
    "ff_dropout = 0.2\n",
    "attn_dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('./input/tinyshakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(ff_dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class FlexibleBlock(nn.Module):\n",
    "    \"\"\"A Transformer block that can adapt between single and double layer configurations.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_embd, n_head, res1_dropout, res2_dropout, res4_dropout=None, use_double_layers=False):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.use_double_layers = use_double_layers\n",
    "        # Store dropout rates as instance attributes\n",
    "        self.res1_dropout = res1_dropout\n",
    "        self.res2_dropout = res2_dropout\n",
    "        self.res4_dropout = res4_dropout if res4_dropout is not None else 0  # Ensure there's a default value\n",
    "        \n",
    "        self.sa1 = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd1 = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "        self.dropout1 = nn.Dropout(res1_dropout)\n",
    "        self.dropout2 = nn.Dropout(res2_dropout)\n",
    "        \n",
    "        if self.use_double_layers:\n",
    "            self.sa2 = MultiHeadAttention(n_head, head_size)\n",
    "            self.ffwd2 = FeedFoward(n_embd)\n",
    "            self.ln3 = nn.LayerNorm(n_embd)\n",
    "            self.ln4 = nn.LayerNorm(n_embd)\n",
    "            self.res4_dropout = res4_dropout\n",
    "            self.dropout4 = nn.Dropout(res4_dropout) if res4_dropout is not None else None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.ln1(x)\n",
    "        y = self.dropout1(x) * (1 - self.res1_dropout) + self.sa1(x)\n",
    "        \n",
    "        y = self.ln2(y)\n",
    "        z = self.dropout2(x) * (1 - self.res2_dropout) + self.dropout1(y) * (1 - self.res1_dropout) + self.ffwd1(y)\n",
    "        \n",
    "        if self.use_double_layers:\n",
    "            z = self.ln3(z)\n",
    "            a = self.dropout1(z) * (1 - self.res1_dropout) + self.sa2(z)\n",
    "            a = self.ln4(a)\n",
    "            z = self.dropout4(x) * (1 - self.res4_dropout) + self.dropout2(z) * (1 - self.res2_dropout) + self.dropout1(a) * (1 - self.res1_dropout) + self.ffwd2(a)\n",
    "        \n",
    "        return z\n",
    "\n",
    "\n",
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, res1_dropout=0.0, res2_dropout=0.0, res4_dropout=0.0, use_double_layers=False):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        self.block_size = block_size\n",
    "        self.device = device\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        \n",
    "        # 使用 FlexibleBlock 而不是 Block\n",
    "        self.blocks = nn.Sequential(*[FlexibleBlock(n_embd, n_head, res1_dropout, res2_dropout, res4_dropout, use_double_layers) for _ in range(n_layer)])\n",
    "        \n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx)  # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=self.device))  # (T,C)\n",
    "        x = tok_emb + pos_emb  # (B,T,C)\n",
    "        x = self.blocks(x)  # (B,T,C)\n",
    "        x = self.ln_f(x)  # (B,T,C)\n",
    "        logits = self.lm_head(x)  # (B,T,vocab_size)\n",
    "\n",
    "        if targets is not None:\n",
    "            logits = logits.view(-1, self.vocab_size)  # (B*T, vocab_size)\n",
    "            targets = targets.view(-1)  # (B*T,)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # Assuming idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -self.block_size:]  # Crop idx to the last block_size tokens\n",
    "            logits, _ = self(idx_cond)  # Get the predictions\n",
    "            logits = logits[:, -1, :]  # Focus only on the last time step\n",
    "            probs = F.softmax(logits, dim=-1)  # Apply softmax to get probabilities\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # Sample from the distribution\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # Append sampled index to the running sequence\n",
    "        return idx\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with configuration: {'res1_dropout': 0.025, 'res2_dropout': 0.99, 'res4_dropout': 0.0, 'use_double_layers': False}\n",
      "step 0: train loss 4.2832, val loss 4.2867\n",
      "step 100: train loss 2.7362, val loss 2.7493\n",
      "step 200: train loss 2.5569, val loss 2.5523\n",
      "step 300: train loss 2.4906, val loss 2.4914\n",
      "step 400: train loss 2.4569, val loss 2.4551\n",
      "step 500: train loss 2.4077, val loss 2.4069\n",
      "step 600: train loss 2.3587, val loss 2.3591\n",
      "step 700: train loss 2.3319, val loss 2.3434\n",
      "step 800: train loss 2.2903, val loss 2.2880\n",
      "step 900: train loss 2.2484, val loss 2.2661\n",
      "step 1000: train loss 2.2245, val loss 2.2431\n",
      "step 1100: train loss 2.1999, val loss 2.2226\n",
      "step 1200: train loss 2.1899, val loss 2.2038\n",
      "step 1300: train loss 2.1658, val loss 2.1954\n",
      "step 1400: train loss 2.1449, val loss 2.1741\n",
      "step 1500: train loss 2.1357, val loss 2.1655\n",
      "step 1600: train loss 2.1262, val loss 2.1481\n",
      "step 1700: train loss 2.1004, val loss 2.1294\n",
      "step 1800: train loss 2.0863, val loss 2.1175\n",
      "step 1900: train loss 2.0823, val loss 2.1098\n",
      "step 2000: train loss 2.0600, val loss 2.0962\n",
      "step 2100: train loss 2.0556, val loss 2.0913\n",
      "step 2200: train loss 2.0385, val loss 2.0959\n",
      "step 2300: train loss 2.0291, val loss 2.0712\n",
      "step 2400: train loss 2.0230, val loss 2.0715\n",
      "step 2500: train loss 2.0085, val loss 2.0668\n",
      "step 2600: train loss 2.0110, val loss 2.0663\n",
      "step 2700: train loss 2.0032, val loss 2.0566\n",
      "step 2800: train loss 1.9829, val loss 2.0450\n",
      "step 2900: train loss 1.9904, val loss 2.0545\n",
      "step 3000: train loss 1.9710, val loss 2.0301\n",
      "step 3100: train loss 1.9620, val loss 2.0446\n",
      "step 3200: train loss 1.9636, val loss 2.0249\n",
      "step 3300: train loss 1.9524, val loss 2.0215\n",
      "step 3400: train loss 1.9463, val loss 2.0278\n",
      "step 3500: train loss 1.9400, val loss 2.0142\n",
      "step 3600: train loss 1.9299, val loss 2.0047\n",
      "step 3700: train loss 1.9320, val loss 2.0039\n",
      "step 3800: train loss 1.9236, val loss 2.0058\n",
      "step 3900: train loss 1.9100, val loss 1.9882\n",
      "step 4000: train loss 1.9141, val loss 2.0119\n",
      "step 4100: train loss 1.9037, val loss 1.9908\n",
      "step 4200: train loss 1.9030, val loss 1.9807\n",
      "step 4300: train loss 1.8906, val loss 1.9888\n",
      "step 4400: train loss 1.8867, val loss 1.9787\n",
      "step 4500: train loss 1.8796, val loss 1.9836\n",
      "step 4600: train loss 1.8924, val loss 1.9741\n",
      "step 4700: train loss 1.8782, val loss 1.9760\n",
      "step 4800: train loss 1.8800, val loss 1.9889\n",
      "step 4900: train loss 1.8667, val loss 1.9584\n",
      "step 5000: train loss 1.8641, val loss 1.9639\n",
      "step 5100: train loss 1.8755, val loss 1.9678\n",
      "step 5200: train loss 1.8576, val loss 1.9614\n",
      "step 5300: train loss 1.8496, val loss 1.9533\n",
      "step 5400: train loss 1.8634, val loss 1.9652\n",
      "step 5500: train loss 1.8517, val loss 1.9713\n",
      "step 5600: train loss 1.8519, val loss 1.9577\n",
      "step 5700: train loss 1.8481, val loss 1.9537\n",
      "step 5800: train loss 1.8345, val loss 1.9354\n",
      "step 5900: train loss 1.8354, val loss 1.9498\n",
      "step 6000: train loss 1.8402, val loss 1.9500\n",
      "step 6100: train loss 1.8498, val loss 1.9559\n",
      "step 6200: train loss 1.8314, val loss 1.9406\n",
      "step 6300: train loss 1.8310, val loss 1.9396\n",
      "step 6400: train loss 1.8325, val loss 1.9373\n",
      "step 6500: train loss 1.8209, val loss 1.9376\n",
      "step 6600: train loss 1.8202, val loss 1.9490\n",
      "step 6700: train loss 1.8232, val loss 1.9371\n",
      "step 6800: train loss 1.8120, val loss 1.9303\n",
      "step 6900: train loss 1.8189, val loss 1.9254\n",
      "step 7000: train loss 1.8258, val loss 1.9474\n",
      "step 7100: train loss 1.8077, val loss 1.9444\n",
      "step 7200: train loss 1.8103, val loss 1.9450\n",
      "step 7300: train loss 1.8109, val loss 1.9237\n",
      "step 7400: train loss 1.8103, val loss 1.9431\n",
      "step 7500: train loss 1.8100, val loss 1.9426\n",
      "step 7600: train loss 1.8084, val loss 1.9349\n",
      "step 7700: train loss 1.8058, val loss 1.9117\n",
      "step 7800: train loss 1.7972, val loss 1.9221\n",
      "step 7900: train loss 1.7930, val loss 1.9427\n",
      "step 8000: train loss 1.7987, val loss 1.9411\n",
      "step 8100: train loss 1.7902, val loss 1.9165\n",
      "step 8200: train loss 1.7875, val loss 1.9127\n",
      "step 8300: train loss 1.8029, val loss 1.9249\n",
      "step 8400: train loss 1.7781, val loss 1.9066\n",
      "step 8500: train loss 1.7875, val loss 1.9263\n",
      "step 8600: train loss 1.7885, val loss 1.9151\n",
      "step 8700: train loss 1.7796, val loss 1.9157\n",
      "step 8800: train loss 1.7850, val loss 1.9106\n",
      "step 8900: train loss 1.7855, val loss 1.9093\n",
      "step 9000: train loss 1.7883, val loss 1.9118\n",
      "step 9100: train loss 1.7846, val loss 1.9181\n",
      "step 9200: train loss 1.7805, val loss 1.9119\n",
      "step 9300: train loss 1.7707, val loss 1.8987\n",
      "step 9400: train loss 1.7709, val loss 1.8990\n",
      "step 9500: train loss 1.7766, val loss 1.9053\n",
      "step 9600: train loss 1.7722, val loss 1.9125\n",
      "step 9700: train loss 1.7763, val loss 1.9085\n",
      "step 9800: train loss 1.7680, val loss 1.9042\n",
      "step 9900: train loss 1.7739, val loss 1.8960\n",
      "step 10000: train loss 1.7698, val loss 1.9077\n",
      "step 10100: train loss 1.7715, val loss 1.9135\n",
      "step 10200: train loss 1.7750, val loss 1.9112\n",
      "step 10300: train loss 1.7554, val loss 1.8841\n",
      "step 10400: train loss 1.7590, val loss 1.9002\n",
      "step 10500: train loss 1.7574, val loss 1.9116\n",
      "step 10600: train loss 1.7654, val loss 1.9005\n",
      "step 10700: train loss 1.7571, val loss 1.8939\n",
      "step 10800: train loss 1.7605, val loss 1.8949\n",
      "step 10900: train loss 1.7586, val loss 1.9113\n",
      "step 11000: train loss 1.7516, val loss 1.8970\n",
      "step 11100: train loss 1.7509, val loss 1.8930\n",
      "step 11200: train loss 1.7535, val loss 1.8924\n",
      "step 11300: train loss 1.7498, val loss 1.8966\n",
      "step 11400: train loss 1.7548, val loss 1.9041\n",
      "step 11500: train loss 1.7439, val loss 1.9022\n",
      "step 11600: train loss 1.7487, val loss 1.8866\n",
      "step 11700: train loss 1.7577, val loss 1.8766\n",
      "step 11800: train loss 1.7516, val loss 1.8834\n",
      "step 11900: train loss 1.7479, val loss 1.8758\n",
      "step 12000: train loss 1.7400, val loss 1.8664\n",
      "step 12100: train loss 1.7324, val loss 1.8800\n",
      "step 12200: train loss 1.7347, val loss 1.8826\n",
      "step 12300: train loss 1.7459, val loss 1.8649\n",
      "step 12400: train loss 1.7392, val loss 1.8643\n",
      "step 12500: train loss 1.7443, val loss 1.8685\n",
      "step 12600: train loss 1.7480, val loss 1.8820\n",
      "step 12700: train loss 1.7460, val loss 1.8725\n",
      "step 12800: train loss 1.7406, val loss 1.8842\n",
      "step 12900: train loss 1.7469, val loss 1.8828\n",
      "step 13000: train loss 1.7329, val loss 1.8771\n",
      "step 13100: train loss 1.7243, val loss 1.8639\n",
      "step 13200: train loss 1.7304, val loss 1.8803\n",
      "step 13300: train loss 1.7412, val loss 1.8855\n",
      "step 13400: train loss 1.7254, val loss 1.8761\n",
      "step 13500: train loss 1.7297, val loss 1.8816\n",
      "step 13600: train loss 1.7277, val loss 1.9000\n",
      "step 13700: train loss 1.7335, val loss 1.8682\n",
      "step 13800: train loss 1.7356, val loss 1.8819\n",
      "step 13900: train loss 1.7172, val loss 1.8800\n",
      "step 14000: train loss 1.7220, val loss 1.8733\n",
      "step 14100: train loss 1.7275, val loss 1.8648\n",
      "step 14200: train loss 1.7264, val loss 1.8797\n",
      "step 14300: train loss 1.7243, val loss 1.8690\n",
      "step 14400: train loss 1.7322, val loss 1.8676\n",
      "step 14500: train loss 1.7265, val loss 1.8648\n",
      "step 14600: train loss 1.7285, val loss 1.8880\n",
      "step 14700: train loss 1.7204, val loss 1.8685\n",
      "step 14800: train loss 1.7242, val loss 1.8631\n",
      "step 14900: train loss 1.7266, val loss 1.8395\n",
      "step 15000: train loss 1.7202, val loss 1.8615\n",
      "step 15100: train loss 1.7167, val loss 1.8660\n",
      "step 15200: train loss 1.7150, val loss 1.8710\n",
      "step 15300: train loss 1.7159, val loss 1.8620\n",
      "step 15400: train loss 1.7240, val loss 1.8610\n",
      "step 15500: train loss 1.7210, val loss 1.8600\n",
      "step 15600: train loss 1.7131, val loss 1.8686\n",
      "step 15700: train loss 1.7144, val loss 1.8677\n",
      "step 15800: train loss 1.7298, val loss 1.8641\n",
      "step 15900: train loss 1.7112, val loss 1.8507\n",
      "step 16000: train loss 1.7166, val loss 1.8567\n",
      "step 16100: train loss 1.7272, val loss 1.8627\n",
      "step 16200: train loss 1.7151, val loss 1.8592\n",
      "step 16300: train loss 1.7146, val loss 1.8506\n",
      "step 16400: train loss 1.7087, val loss 1.8499\n",
      "step 16500: train loss 1.6994, val loss 1.8578\n",
      "step 16600: train loss 1.7085, val loss 1.8511\n",
      "step 16700: train loss 1.7011, val loss 1.8538\n",
      "step 16800: train loss 1.7085, val loss 1.8705\n",
      "step 16900: train loss 1.7081, val loss 1.8584\n",
      "step 17000: train loss 1.7143, val loss 1.8591\n",
      "step 17100: train loss 1.7028, val loss 1.8699\n",
      "step 17200: train loss 1.7109, val loss 1.8642\n",
      "step 17300: train loss 1.6953, val loss 1.8529\n",
      "step 17400: train loss 1.7076, val loss 1.8660\n",
      "step 17500: train loss 1.7013, val loss 1.8530\n",
      "step 17600: train loss 1.6948, val loss 1.8488\n",
      "step 17700: train loss 1.7036, val loss 1.8485\n",
      "step 17800: train loss 1.7159, val loss 1.8626\n",
      "step 17900: train loss 1.7072, val loss 1.8673\n",
      "step 18000: train loss 1.7047, val loss 1.8721\n",
      "step 18100: train loss 1.7104, val loss 1.8573\n",
      "step 18200: train loss 1.7094, val loss 1.8426\n",
      "step 18300: train loss 1.7066, val loss 1.8704\n",
      "step 18400: train loss 1.7002, val loss 1.8549\n",
      "step 18500: train loss 1.6984, val loss 1.8451\n",
      "step 18600: train loss 1.7022, val loss 1.8496\n",
      "step 18700: train loss 1.7064, val loss 1.8557\n",
      "step 18800: train loss 1.7005, val loss 1.8381\n",
      "step 18900: train loss 1.6940, val loss 1.8542\n",
      "step 19000: train loss 1.7001, val loss 1.8455\n",
      "step 19100: train loss 1.7016, val loss 1.8743\n",
      "step 19200: train loss 1.7072, val loss 1.8509\n",
      "step 19300: train loss 1.6987, val loss 1.8508\n",
      "step 19400: train loss 1.6938, val loss 1.8612\n",
      "step 19500: train loss 1.7039, val loss 1.8513\n",
      "step 19600: train loss 1.6893, val loss 1.8538\n",
      "step 19700: train loss 1.7042, val loss 1.8564\n",
      "step 19800: train loss 1.6964, val loss 1.8501\n",
      "step 19900: train loss 1.6983, val loss 1.8430\n",
      "step 20000: train loss 1.7014, val loss 1.8407\n",
      "step 20100: train loss 1.6933, val loss 1.8393\n",
      "step 20200: train loss 1.6982, val loss 1.8357\n",
      "step 20300: train loss 1.7037, val loss 1.8519\n",
      "step 20400: train loss 1.6883, val loss 1.8439\n",
      "step 20500: train loss 1.6881, val loss 1.8345\n",
      "step 20600: train loss 1.6900, val loss 1.8528\n",
      "step 20700: train loss 1.6921, val loss 1.8465\n",
      "step 20800: train loss 1.6918, val loss 1.8390\n",
      "step 20900: train loss 1.6842, val loss 1.8565\n",
      "step 21000: train loss 1.6924, val loss 1.8450\n",
      "step 21100: train loss 1.6988, val loss 1.8538\n",
      "step 21200: train loss 1.6903, val loss 1.8443\n",
      "step 21300: train loss 1.7030, val loss 1.8446\n",
      "step 21400: train loss 1.6961, val loss 1.8405\n",
      "step 21500: train loss 1.6937, val loss 1.8482\n",
      "step 21600: train loss 1.6873, val loss 1.8287\n",
      "step 21700: train loss 1.6853, val loss 1.8316\n",
      "step 21800: train loss 1.6893, val loss 1.8383\n",
      "step 21900: train loss 1.6881, val loss 1.8383\n",
      "step 22000: train loss 1.6927, val loss 1.8368\n",
      "step 22100: train loss 1.7014, val loss 1.8489\n",
      "step 22200: train loss 1.6817, val loss 1.8374\n",
      "step 22300: train loss 1.6993, val loss 1.8455\n",
      "step 22400: train loss 1.6891, val loss 1.8312\n",
      "step 22500: train loss 1.6849, val loss 1.8412\n",
      "step 22600: train loss 1.6712, val loss 1.8367\n",
      "step 22700: train loss 1.6829, val loss 1.8414\n",
      "step 22800: train loss 1.6941, val loss 1.8350\n",
      "step 22900: train loss 1.6943, val loss 1.8435\n",
      "step 23000: train loss 1.6872, val loss 1.8315\n",
      "step 23100: train loss 1.6836, val loss 1.8455\n",
      "step 23200: train loss 1.6802, val loss 1.8431\n",
      "step 23300: train loss 1.6835, val loss 1.8434\n",
      "step 23400: train loss 1.6798, val loss 1.8422\n",
      "step 23500: train loss 1.6889, val loss 1.8371\n",
      "step 23600: train loss 1.6776, val loss 1.8375\n",
      "step 23700: train loss 1.6775, val loss 1.8409\n",
      "step 23800: train loss 1.6881, val loss 1.8355\n",
      "step 23900: train loss 1.6874, val loss 1.8472\n",
      "step 24000: train loss 1.6730, val loss 1.8290\n",
      "step 24100: train loss 1.6817, val loss 1.8270\n",
      "step 24200: train loss 1.6806, val loss 1.8380\n",
      "step 24300: train loss 1.6761, val loss 1.8342\n",
      "step 24400: train loss 1.6917, val loss 1.8209\n",
      "step 24500: train loss 1.6808, val loss 1.8360\n",
      "step 24600: train loss 1.6808, val loss 1.8322\n",
      "step 24700: train loss 1.6769, val loss 1.8385\n",
      "step 24800: train loss 1.6746, val loss 1.8261\n",
      "step 24900: train loss 1.6759, val loss 1.8361\n",
      "step 25000: train loss 1.6777, val loss 1.8276\n",
      "step 25100: train loss 1.6832, val loss 1.8226\n",
      "step 25200: train loss 1.6729, val loss 1.8312\n",
      "step 25300: train loss 1.6881, val loss 1.8326\n",
      "step 25400: train loss 1.6754, val loss 1.8274\n",
      "step 25500: train loss 1.6751, val loss 1.8243\n",
      "step 25600: train loss 1.6796, val loss 1.8326\n",
      "step 25700: train loss 1.6720, val loss 1.8340\n",
      "step 25800: train loss 1.6663, val loss 1.8359\n",
      "step 25900: train loss 1.6817, val loss 1.8236\n",
      "step 26000: train loss 1.6773, val loss 1.8328\n",
      "step 26100: train loss 1.6836, val loss 1.8363\n",
      "step 26200: train loss 1.6700, val loss 1.8303\n",
      "step 26300: train loss 1.6788, val loss 1.8421\n",
      "step 26400: train loss 1.6829, val loss 1.8460\n",
      "step 26500: train loss 1.6699, val loss 1.8343\n",
      "step 26600: train loss 1.6688, val loss 1.8458\n",
      "step 26700: train loss 1.6702, val loss 1.8385\n",
      "step 26800: train loss 1.6706, val loss 1.8172\n",
      "step 26900: train loss 1.6707, val loss 1.8292\n",
      "step 27000: train loss 1.6783, val loss 1.8294\n",
      "step 27100: train loss 1.6732, val loss 1.8341\n",
      "step 27200: train loss 1.6796, val loss 1.8403\n",
      "step 27300: train loss 1.6773, val loss 1.8222\n",
      "step 27400: train loss 1.6603, val loss 1.8187\n",
      "step 27500: train loss 1.6752, val loss 1.8305\n",
      "step 27600: train loss 1.6600, val loss 1.8232\n",
      "step 27700: train loss 1.6701, val loss 1.8270\n",
      "step 27800: train loss 1.6595, val loss 1.8178\n",
      "step 27900: train loss 1.6722, val loss 1.8390\n",
      "step 28000: train loss 1.6730, val loss 1.8256\n",
      "step 28100: train loss 1.6625, val loss 1.8248\n",
      "step 28200: train loss 1.6662, val loss 1.8327\n",
      "step 28300: train loss 1.6673, val loss 1.8284\n",
      "step 28400: train loss 1.6490, val loss 1.8282\n",
      "step 28500: train loss 1.6716, val loss 1.8305\n",
      "step 28600: train loss 1.6717, val loss 1.8376\n",
      "step 28700: train loss 1.6655, val loss 1.8376\n",
      "step 28800: train loss 1.6755, val loss 1.8203\n",
      "step 28900: train loss 1.6758, val loss 1.8233\n",
      "step 29000: train loss 1.6612, val loss 1.8182\n",
      "step 29100: train loss 1.6729, val loss 1.8321\n",
      "step 29200: train loss 1.6636, val loss 1.8249\n",
      "step 29300: train loss 1.6710, val loss 1.8274\n",
      "step 29400: train loss 1.6638, val loss 1.8113\n",
      "step 29500: train loss 1.6591, val loss 1.8371\n",
      "step 29600: train loss 1.6695, val loss 1.8370\n",
      "step 29700: train loss 1.6702, val loss 1.8356\n",
      "step 29800: train loss 1.6646, val loss 1.8124\n",
      "step 29900: train loss 1.6581, val loss 1.8355\n",
      "step 30000: train loss 1.6724, val loss 1.8212\n",
      "step 30100: train loss 1.6616, val loss 1.8268\n",
      "step 30200: train loss 1.6606, val loss 1.8368\n",
      "step 30300: train loss 1.6696, val loss 1.8149\n",
      "step 30400: train loss 1.6711, val loss 1.8169\n",
      "step 30500: train loss 1.6585, val loss 1.8191\n",
      "step 30600: train loss 1.6696, val loss 1.8241\n",
      "step 30700: train loss 1.6595, val loss 1.8220\n",
      "step 30800: train loss 1.6604, val loss 1.8063\n",
      "step 30900: train loss 1.6577, val loss 1.8242\n",
      "step 31000: train loss 1.6651, val loss 1.8234\n",
      "step 31100: train loss 1.6616, val loss 1.8093\n",
      "step 31200: train loss 1.6687, val loss 1.8125\n",
      "step 31300: train loss 1.6630, val loss 1.8125\n",
      "step 31400: train loss 1.6620, val loss 1.8181\n",
      "step 31500: train loss 1.6598, val loss 1.8246\n",
      "step 31600: train loss 1.6666, val loss 1.8207\n",
      "step 31700: train loss 1.6613, val loss 1.8170\n",
      "step 31800: train loss 1.6652, val loss 1.8166\n",
      "step 31900: train loss 1.6599, val loss 1.8181\n",
      "step 32000: train loss 1.6628, val loss 1.8111\n",
      "step 32100: train loss 1.6635, val loss 1.8163\n",
      "step 32200: train loss 1.6667, val loss 1.8077\n",
      "step 32300: train loss 1.6513, val loss 1.8080\n",
      "step 32400: train loss 1.6572, val loss 1.8208\n",
      "step 32500: train loss 1.6675, val loss 1.8166\n",
      "step 32600: train loss 1.6693, val loss 1.8115\n",
      "step 32700: train loss 1.6565, val loss 1.8131\n",
      "step 32800: train loss 1.6650, val loss 1.8182\n",
      "step 32900: train loss 1.6534, val loss 1.8108\n",
      "step 33000: train loss 1.6628, val loss 1.8068\n",
      "step 33100: train loss 1.6586, val loss 1.8065\n",
      "step 33200: train loss 1.6568, val loss 1.8105\n",
      "step 33300: train loss 1.6627, val loss 1.8143\n",
      "step 33400: train loss 1.6625, val loss 1.8117\n",
      "step 33500: train loss 1.6629, val loss 1.8130\n",
      "step 33600: train loss 1.6625, val loss 1.8144\n",
      "step 33700: train loss 1.6489, val loss 1.8119\n",
      "step 33800: train loss 1.6575, val loss 1.8194\n",
      "step 33900: train loss 1.6674, val loss 1.8012\n",
      "step 34000: train loss 1.6580, val loss 1.8170\n",
      "step 34100: train loss 1.6485, val loss 1.8149\n",
      "step 34200: train loss 1.6559, val loss 1.8189\n",
      "step 34300: train loss 1.6553, val loss 1.8064\n",
      "step 34400: train loss 1.6652, val loss 1.8216\n",
      "step 34500: train loss 1.6552, val loss 1.7970\n",
      "step 34600: train loss 1.6561, val loss 1.8078\n",
      "step 34700: train loss 1.6572, val loss 1.8112\n",
      "step 34800: train loss 1.6644, val loss 1.8085\n",
      "step 34900: train loss 1.6538, val loss 1.8124\n",
      "step 35000: train loss 1.6678, val loss 1.8198\n",
      "step 35100: train loss 1.6573, val loss 1.8071\n",
      "step 35200: train loss 1.6582, val loss 1.8116\n",
      "step 35300: train loss 1.6514, val loss 1.8120\n",
      "step 35400: train loss 1.6527, val loss 1.8139\n",
      "step 35500: train loss 1.6579, val loss 1.8152\n",
      "step 35600: train loss 1.6549, val loss 1.8084\n",
      "step 35700: train loss 1.6580, val loss 1.8111\n",
      "step 35800: train loss 1.6555, val loss 1.8213\n",
      "step 35900: train loss 1.6557, val loss 1.8115\n",
      "step 36000: train loss 1.6557, val loss 1.8355\n",
      "step 36100: train loss 1.6544, val loss 1.8304\n",
      "step 36200: train loss 1.6532, val loss 1.8017\n",
      "step 36300: train loss 1.6571, val loss 1.7994\n",
      "step 36400: train loss 1.6604, val loss 1.8119\n",
      "step 36500: train loss 1.6525, val loss 1.8094\n",
      "step 36600: train loss 1.6543, val loss 1.8112\n",
      "step 36700: train loss 1.6493, val loss 1.8012\n",
      "step 36800: train loss 1.6509, val loss 1.8018\n",
      "step 36900: train loss 1.6473, val loss 1.8122\n",
      "step 37000: train loss 1.6504, val loss 1.8069\n",
      "step 37100: train loss 1.6577, val loss 1.8109\n",
      "step 37200: train loss 1.6491, val loss 1.8032\n",
      "step 37300: train loss 1.6590, val loss 1.8119\n",
      "step 37400: train loss 1.6563, val loss 1.8098\n",
      "step 37500: train loss 1.6429, val loss 1.8107\n",
      "step 37600: train loss 1.6464, val loss 1.8078\n",
      "step 37700: train loss 1.6495, val loss 1.8107\n",
      "step 37800: train loss 1.6580, val loss 1.8131\n",
      "step 37900: train loss 1.6649, val loss 1.8075\n",
      "step 38000: train loss 1.6475, val loss 1.7958\n",
      "step 38100: train loss 1.6473, val loss 1.8187\n",
      "step 38200: train loss 1.6653, val loss 1.8249\n",
      "step 38300: train loss 1.6543, val loss 1.8162\n",
      "step 38400: train loss 1.6471, val loss 1.8002\n",
      "step 38500: train loss 1.6472, val loss 1.8107\n",
      "step 38600: train loss 1.6523, val loss 1.7859\n",
      "step 38700: train loss 1.6476, val loss 1.8165\n",
      "step 38800: train loss 1.6512, val loss 1.8152\n",
      "step 38900: train loss 1.6522, val loss 1.8039\n",
      "step 39000: train loss 1.6473, val loss 1.8073\n",
      "step 39100: train loss 1.6503, val loss 1.7965\n",
      "step 39200: train loss 1.6381, val loss 1.8020\n",
      "step 39300: train loss 1.6369, val loss 1.8074\n",
      "step 39400: train loss 1.6484, val loss 1.8173\n",
      "step 39500: train loss 1.6519, val loss 1.8217\n",
      "step 39600: train loss 1.6380, val loss 1.8036\n",
      "step 39700: train loss 1.6453, val loss 1.8008\n",
      "step 39800: train loss 1.6374, val loss 1.7956\n",
      "step 39900: train loss 1.6478, val loss 1.8007\n",
      "step 40000: train loss 1.6349, val loss 1.7915\n",
      "step 40100: train loss 1.6465, val loss 1.8127\n",
      "step 40200: train loss 1.6527, val loss 1.8036\n",
      "step 40300: train loss 1.6436, val loss 1.7931\n",
      "step 40400: train loss 1.6440, val loss 1.7976\n",
      "step 40500: train loss 1.6462, val loss 1.7956\n",
      "step 40600: train loss 1.6539, val loss 1.8011\n",
      "step 40700: train loss 1.6502, val loss 1.8048\n",
      "step 40800: train loss 1.6499, val loss 1.7930\n",
      "step 40900: train loss 1.6550, val loss 1.8184\n",
      "step 41000: train loss 1.6593, val loss 1.8213\n",
      "step 41100: train loss 1.6520, val loss 1.8127\n",
      "step 41200: train loss 1.6456, val loss 1.8046\n",
      "step 41300: train loss 1.6487, val loss 1.8058\n",
      "step 41400: train loss 1.6620, val loss 1.8039\n",
      "step 41500: train loss 1.6443, val loss 1.8032\n",
      "step 41600: train loss 1.6444, val loss 1.8086\n",
      "step 41700: train loss 1.6382, val loss 1.8088\n",
      "step 41800: train loss 1.6469, val loss 1.8041\n",
      "step 41900: train loss 1.6540, val loss 1.8075\n",
      "step 42000: train loss 1.6384, val loss 1.8026\n",
      "step 42100: train loss 1.6542, val loss 1.8068\n",
      "step 42200: train loss 1.6431, val loss 1.7916\n",
      "step 42300: train loss 1.6452, val loss 1.7937\n",
      "step 42400: train loss 1.6373, val loss 1.8029\n",
      "step 42500: train loss 1.6501, val loss 1.7952\n",
      "step 42600: train loss 1.6442, val loss 1.7899\n",
      "step 42700: train loss 1.6458, val loss 1.7873\n",
      "step 42800: train loss 1.6393, val loss 1.8057\n",
      "step 42900: train loss 1.6378, val loss 1.8011\n",
      "step 43000: train loss 1.6455, val loss 1.8124\n",
      "step 43100: train loss 1.6554, val loss 1.8097\n",
      "step 43200: train loss 1.6447, val loss 1.8032\n",
      "step 43300: train loss 1.6364, val loss 1.8039\n",
      "step 43400: train loss 1.6483, val loss 1.7965\n",
      "step 43500: train loss 1.6429, val loss 1.8032\n",
      "step 43600: train loss 1.6480, val loss 1.8011\n",
      "step 43700: train loss 1.6347, val loss 1.8027\n",
      "step 43800: train loss 1.6396, val loss 1.7933\n",
      "step 43900: train loss 1.6413, val loss 1.7986\n",
      "step 44000: train loss 1.6425, val loss 1.8046\n",
      "step 44100: train loss 1.6459, val loss 1.8090\n",
      "step 44200: train loss 1.6556, val loss 1.7983\n",
      "step 44300: train loss 1.6359, val loss 1.8019\n",
      "step 44400: train loss 1.6443, val loss 1.7998\n",
      "step 44500: train loss 1.6378, val loss 1.8038\n",
      "step 44600: train loss 1.6364, val loss 1.8123\n",
      "step 44700: train loss 1.6440, val loss 1.7935\n",
      "step 44800: train loss 1.6489, val loss 1.8002\n",
      "step 44900: train loss 1.6409, val loss 1.8016\n",
      "step 45000: train loss 1.6429, val loss 1.8097\n",
      "step 45100: train loss 1.6308, val loss 1.8048\n",
      "step 45200: train loss 1.6431, val loss 1.8210\n",
      "step 45300: train loss 1.6468, val loss 1.8050\n",
      "step 45400: train loss 1.6438, val loss 1.8089\n",
      "step 45500: train loss 1.6510, val loss 1.7962\n",
      "step 45600: train loss 1.6439, val loss 1.8078\n",
      "step 45700: train loss 1.6371, val loss 1.8031\n",
      "step 45800: train loss 1.6417, val loss 1.8044\n",
      "step 45900: train loss 1.6475, val loss 1.7920\n",
      "step 46000: train loss 1.6440, val loss 1.7972\n",
      "step 46100: train loss 1.6300, val loss 1.8181\n",
      "step 46200: train loss 1.6399, val loss 1.8050\n",
      "step 46300: train loss 1.6432, val loss 1.7914\n",
      "step 46400: train loss 1.6404, val loss 1.7966\n",
      "step 46500: train loss 1.6427, val loss 1.8040\n",
      "step 46600: train loss 1.6466, val loss 1.8014\n",
      "step 46700: train loss 1.6383, val loss 1.7822\n",
      "step 46800: train loss 1.6512, val loss 1.8002\n",
      "step 46900: train loss 1.6459, val loss 1.8000\n",
      "step 47000: train loss 1.6277, val loss 1.7963\n",
      "step 47100: train loss 1.6343, val loss 1.8100\n",
      "step 47200: train loss 1.6408, val loss 1.7871\n",
      "step 47300: train loss 1.6508, val loss 1.7953\n",
      "step 47400: train loss 1.6378, val loss 1.7956\n",
      "step 47500: train loss 1.6460, val loss 1.8046\n",
      "step 47600: train loss 1.6374, val loss 1.8037\n",
      "step 47700: train loss 1.6375, val loss 1.8065\n",
      "step 47800: train loss 1.6313, val loss 1.7895\n",
      "step 47900: train loss 1.6410, val loss 1.7943\n",
      "step 48000: train loss 1.6455, val loss 1.7941\n",
      "step 48100: train loss 1.6384, val loss 1.7911\n",
      "step 48200: train loss 1.6454, val loss 1.8007\n",
      "step 48300: train loss 1.6437, val loss 1.8090\n",
      "step 48400: train loss 1.6464, val loss 1.8045\n",
      "step 48500: train loss 1.6450, val loss 1.8054\n",
      "step 48600: train loss 1.6404, val loss 1.8049\n",
      "step 48700: train loss 1.6356, val loss 1.7850\n",
      "step 48800: train loss 1.6395, val loss 1.7874\n",
      "step 48900: train loss 1.6244, val loss 1.7858\n",
      "step 49000: train loss 1.6379, val loss 1.7974\n",
      "step 49100: train loss 1.6416, val loss 1.7964\n",
      "step 49200: train loss 1.6327, val loss 1.7922\n",
      "step 49300: train loss 1.6461, val loss 1.7910\n",
      "step 49400: train loss 1.6294, val loss 1.7926\n",
      "step 49500: train loss 1.6470, val loss 1.7980\n",
      "step 49600: train loss 1.6381, val loss 1.8048\n",
      "step 49700: train loss 1.6431, val loss 1.8020\n",
      "step 49800: train loss 1.6330, val loss 1.7880\n",
      "step 49900: train loss 1.6386, val loss 1.7988\n",
      "step 49999: train loss 1.6354, val loss 1.7901\n",
      "Results for configuration res1_dropout=0.025_res2_dropout=0.99_res4_dropout=0.0_use_double_layers=False saved.\n",
      "Training model with configuration: {'res1_dropout': 0.1, 'res2_dropout': 0.99, 'res4_dropout': 0.0, 'use_double_layers': False}\n",
      "step 0: train loss 4.3775, val loss 4.3786\n",
      "step 100: train loss 2.7469, val loss 2.7615\n",
      "step 200: train loss 2.5819, val loss 2.5746\n",
      "step 300: train loss 2.5121, val loss 2.5133\n",
      "step 400: train loss 2.4686, val loss 2.4547\n",
      "step 500: train loss 2.4214, val loss 2.4259\n",
      "step 600: train loss 2.3900, val loss 2.3996\n",
      "step 700: train loss 2.3767, val loss 2.3677\n",
      "step 800: train loss 2.3276, val loss 2.3304\n",
      "step 900: train loss 2.2945, val loss 2.3042\n",
      "step 1000: train loss 2.2727, val loss 2.2867\n",
      "step 1100: train loss 2.2544, val loss 2.2603\n",
      "step 1200: train loss 2.2379, val loss 2.2421\n",
      "step 1300: train loss 2.2251, val loss 2.2404\n",
      "step 1400: train loss 2.1993, val loss 2.2312\n",
      "step 1500: train loss 2.1933, val loss 2.2072\n",
      "step 1600: train loss 2.1774, val loss 2.1893\n",
      "step 1700: train loss 2.1684, val loss 2.1877\n",
      "step 1800: train loss 2.1566, val loss 2.1816\n",
      "step 1900: train loss 2.1438, val loss 2.1573\n",
      "step 2000: train loss 2.1292, val loss 2.1520\n",
      "step 2100: train loss 2.1156, val loss 2.1446\n",
      "step 2200: train loss 2.1083, val loss 2.1377\n",
      "step 2300: train loss 2.0912, val loss 2.1439\n",
      "step 2400: train loss 2.0801, val loss 2.1179\n",
      "step 2500: train loss 2.0729, val loss 2.1157\n",
      "step 2600: train loss 2.0720, val loss 2.1228\n",
      "step 2700: train loss 2.0708, val loss 2.1120\n",
      "step 2800: train loss 2.0584, val loss 2.1038\n",
      "step 2900: train loss 2.0524, val loss 2.0923\n",
      "step 3000: train loss 2.0419, val loss 2.0916\n",
      "step 3100: train loss 2.0308, val loss 2.0824\n",
      "step 3200: train loss 2.0245, val loss 2.0859\n",
      "step 3300: train loss 2.0283, val loss 2.0695\n",
      "step 3400: train loss 2.0038, val loss 2.0646\n",
      "step 3500: train loss 2.0016, val loss 2.0666\n",
      "step 3600: train loss 1.9990, val loss 2.0516\n",
      "step 3700: train loss 1.9995, val loss 2.0596\n",
      "step 3800: train loss 1.9843, val loss 2.0630\n",
      "step 3900: train loss 1.9919, val loss 2.0475\n",
      "step 4000: train loss 1.9824, val loss 2.0411\n",
      "step 4100: train loss 1.9644, val loss 2.0322\n",
      "step 4200: train loss 1.9739, val loss 2.0462\n",
      "step 4300: train loss 1.9549, val loss 2.0374\n",
      "step 4400: train loss 1.9584, val loss 2.0269\n",
      "step 4500: train loss 1.9467, val loss 2.0195\n",
      "step 4600: train loss 1.9423, val loss 2.0153\n",
      "step 4700: train loss 1.9433, val loss 2.0279\n",
      "step 4800: train loss 1.9505, val loss 2.0115\n",
      "step 4900: train loss 1.9288, val loss 2.0221\n",
      "step 5000: train loss 1.9297, val loss 2.0171\n",
      "step 5100: train loss 1.9316, val loss 2.0122\n",
      "step 5200: train loss 1.9235, val loss 2.0090\n",
      "step 5300: train loss 1.9138, val loss 2.0085\n",
      "step 5400: train loss 1.9276, val loss 1.9967\n",
      "step 5500: train loss 1.9257, val loss 1.9995\n",
      "step 5600: train loss 1.9171, val loss 2.0042\n",
      "step 5700: train loss 1.8953, val loss 2.0030\n",
      "step 5800: train loss 1.9157, val loss 1.9989\n",
      "step 5900: train loss 1.9153, val loss 1.9968\n",
      "step 6000: train loss 1.9062, val loss 1.9905\n",
      "step 6100: train loss 1.9062, val loss 1.9899\n",
      "step 6200: train loss 1.8955, val loss 1.9806\n",
      "step 6300: train loss 1.8976, val loss 1.9957\n",
      "step 6400: train loss 1.8866, val loss 1.9937\n",
      "step 6500: train loss 1.8798, val loss 1.9927\n",
      "step 6600: train loss 1.8734, val loss 1.9872\n",
      "step 6700: train loss 1.8729, val loss 1.9776\n",
      "step 6800: train loss 1.8883, val loss 1.9624\n",
      "step 6900: train loss 1.8729, val loss 1.9859\n",
      "step 7000: train loss 1.8668, val loss 1.9811\n",
      "step 7100: train loss 1.8675, val loss 1.9893\n",
      "step 7200: train loss 1.8654, val loss 1.9772\n",
      "step 7300: train loss 1.8677, val loss 1.9763\n",
      "step 7400: train loss 1.8652, val loss 1.9734\n",
      "step 7500: train loss 1.8646, val loss 1.9722\n",
      "step 7600: train loss 1.8545, val loss 1.9683\n",
      "step 7700: train loss 1.8459, val loss 1.9591\n",
      "step 7800: train loss 1.8621, val loss 1.9770\n",
      "step 7900: train loss 1.8597, val loss 1.9774\n",
      "step 8000: train loss 1.8426, val loss 1.9710\n",
      "step 8100: train loss 1.8540, val loss 1.9710\n",
      "step 8200: train loss 1.8547, val loss 1.9601\n",
      "step 8300: train loss 1.8383, val loss 1.9515\n",
      "step 8400: train loss 1.8555, val loss 1.9644\n",
      "step 8500: train loss 1.8391, val loss 1.9675\n",
      "step 8600: train loss 1.8487, val loss 1.9715\n",
      "step 8700: train loss 1.8368, val loss 1.9781\n",
      "step 8800: train loss 1.8406, val loss 1.9596\n",
      "step 8900: train loss 1.8299, val loss 1.9458\n",
      "step 9000: train loss 1.8336, val loss 1.9554\n",
      "step 9100: train loss 1.8367, val loss 1.9615\n",
      "step 9200: train loss 1.8287, val loss 1.9532\n",
      "step 9300: train loss 1.8278, val loss 1.9526\n",
      "step 9400: train loss 1.8332, val loss 1.9465\n",
      "step 9500: train loss 1.8286, val loss 1.9599\n",
      "step 9600: train loss 1.8218, val loss 1.9604\n",
      "step 9700: train loss 1.8315, val loss 1.9578\n",
      "step 9800: train loss 1.8181, val loss 1.9546\n",
      "step 9900: train loss 1.8232, val loss 1.9538\n",
      "step 10000: train loss 1.8206, val loss 1.9543\n",
      "step 10100: train loss 1.8115, val loss 1.9464\n",
      "step 10200: train loss 1.8106, val loss 1.9494\n",
      "step 10300: train loss 1.8085, val loss 1.9395\n",
      "step 10400: train loss 1.8093, val loss 1.9430\n",
      "step 10500: train loss 1.8132, val loss 1.9527\n",
      "step 10600: train loss 1.8136, val loss 1.9431\n",
      "step 10700: train loss 1.8191, val loss 1.9586\n",
      "step 10800: train loss 1.8102, val loss 1.9374\n",
      "step 10900: train loss 1.8035, val loss 1.9362\n",
      "step 11000: train loss 1.8126, val loss 1.9354\n",
      "step 11100: train loss 1.8125, val loss 1.9470\n",
      "step 11200: train loss 1.8034, val loss 1.9359\n",
      "step 11300: train loss 1.8174, val loss 1.9486\n",
      "step 11400: train loss 1.8081, val loss 1.9311\n",
      "step 11500: train loss 1.8069, val loss 1.9379\n",
      "step 11600: train loss 1.8067, val loss 1.9363\n",
      "step 11700: train loss 1.8010, val loss 1.9270\n",
      "step 11800: train loss 1.7919, val loss 1.9360\n",
      "step 11900: train loss 1.7956, val loss 1.9423\n",
      "step 12000: train loss 1.8020, val loss 1.9305\n",
      "step 12100: train loss 1.7951, val loss 1.9268\n",
      "step 12200: train loss 1.7980, val loss 1.9287\n",
      "step 12300: train loss 1.7992, val loss 1.9394\n",
      "step 12400: train loss 1.7857, val loss 1.9239\n",
      "step 12500: train loss 1.8053, val loss 1.9373\n",
      "step 12600: train loss 1.7818, val loss 1.9367\n",
      "step 12700: train loss 1.7858, val loss 1.9282\n",
      "step 12800: train loss 1.7962, val loss 1.9328\n",
      "step 12900: train loss 1.7922, val loss 1.9466\n",
      "step 13000: train loss 1.7848, val loss 1.9355\n",
      "step 13100: train loss 1.7879, val loss 1.9317\n",
      "step 13200: train loss 1.7933, val loss 1.9205\n",
      "step 13300: train loss 1.7913, val loss 1.9384\n",
      "step 13400: train loss 1.7833, val loss 1.9341\n",
      "step 13500: train loss 1.7859, val loss 1.9214\n",
      "step 13600: train loss 1.7808, val loss 1.9354\n",
      "step 13700: train loss 1.7817, val loss 1.9275\n",
      "step 13800: train loss 1.7794, val loss 1.9302\n",
      "step 13900: train loss 1.7732, val loss 1.9259\n",
      "step 14000: train loss 1.7752, val loss 1.9279\n",
      "step 14100: train loss 1.7827, val loss 1.9207\n",
      "step 14200: train loss 1.7716, val loss 1.9341\n",
      "step 14300: train loss 1.7820, val loss 1.9237\n",
      "step 14400: train loss 1.7849, val loss 1.9282\n",
      "step 14500: train loss 1.7703, val loss 1.9157\n",
      "step 14600: train loss 1.7786, val loss 1.9109\n",
      "step 14700: train loss 1.7886, val loss 1.9308\n",
      "step 14800: train loss 1.7810, val loss 1.9227\n",
      "step 14900: train loss 1.7681, val loss 1.9270\n",
      "step 15000: train loss 1.7697, val loss 1.9167\n",
      "step 15100: train loss 1.7829, val loss 1.9177\n",
      "step 15200: train loss 1.7653, val loss 1.9181\n",
      "step 15300: train loss 1.7792, val loss 1.9307\n",
      "step 15400: train loss 1.7662, val loss 1.9168\n",
      "step 15500: train loss 1.7667, val loss 1.9176\n",
      "step 15600: train loss 1.7694, val loss 1.9204\n",
      "step 15700: train loss 1.7784, val loss 1.9140\n",
      "step 15800: train loss 1.7706, val loss 1.9186\n",
      "step 15900: train loss 1.7660, val loss 1.9129\n",
      "step 16000: train loss 1.7744, val loss 1.9189\n",
      "step 16100: train loss 1.7715, val loss 1.9236\n",
      "step 16200: train loss 1.7588, val loss 1.9266\n",
      "step 16300: train loss 1.7698, val loss 1.9246\n",
      "step 16400: train loss 1.7571, val loss 1.9179\n",
      "step 16500: train loss 1.7560, val loss 1.9015\n",
      "step 16600: train loss 1.7600, val loss 1.9220\n",
      "step 16700: train loss 1.7543, val loss 1.9042\n",
      "step 16800: train loss 1.7640, val loss 1.9121\n",
      "step 16900: train loss 1.7569, val loss 1.9031\n",
      "step 17000: train loss 1.7603, val loss 1.9173\n",
      "step 17100: train loss 1.7685, val loss 1.9112\n",
      "step 17200: train loss 1.7638, val loss 1.9187\n",
      "step 17300: train loss 1.7560, val loss 1.9089\n",
      "step 17400: train loss 1.7670, val loss 1.9126\n",
      "step 17500: train loss 1.7554, val loss 1.9150\n",
      "step 17600: train loss 1.7576, val loss 1.9127\n",
      "step 17700: train loss 1.7531, val loss 1.9121\n",
      "step 17800: train loss 1.7614, val loss 1.9134\n",
      "step 17900: train loss 1.7560, val loss 1.9077\n",
      "step 18000: train loss 1.7429, val loss 1.8941\n",
      "step 18100: train loss 1.7586, val loss 1.8977\n",
      "step 18200: train loss 1.7512, val loss 1.9040\n",
      "step 18300: train loss 1.7486, val loss 1.9159\n",
      "step 18400: train loss 1.7590, val loss 1.9148\n",
      "step 18500: train loss 1.7546, val loss 1.9067\n",
      "step 18600: train loss 1.7572, val loss 1.9081\n",
      "step 18700: train loss 1.7488, val loss 1.9072\n",
      "step 18800: train loss 1.7506, val loss 1.9073\n",
      "step 18900: train loss 1.7545, val loss 1.9068\n",
      "step 19000: train loss 1.7581, val loss 1.9077\n",
      "step 19100: train loss 1.7456, val loss 1.9002\n",
      "step 19200: train loss 1.7513, val loss 1.9153\n",
      "step 19300: train loss 1.7466, val loss 1.9002\n",
      "step 19400: train loss 1.7486, val loss 1.9095\n",
      "step 19500: train loss 1.7474, val loss 1.9000\n",
      "step 19600: train loss 1.7447, val loss 1.9074\n",
      "step 19700: train loss 1.7418, val loss 1.9045\n",
      "step 19800: train loss 1.7482, val loss 1.9171\n",
      "step 19900: train loss 1.7503, val loss 1.9041\n",
      "step 20000: train loss 1.7441, val loss 1.9073\n",
      "step 20100: train loss 1.7450, val loss 1.9034\n",
      "step 20200: train loss 1.7408, val loss 1.8964\n",
      "step 20300: train loss 1.7420, val loss 1.8946\n",
      "step 20400: train loss 1.7483, val loss 1.8900\n",
      "step 20500: train loss 1.7436, val loss 1.9017\n",
      "step 20600: train loss 1.7393, val loss 1.9140\n",
      "step 20700: train loss 1.7489, val loss 1.8919\n",
      "step 20800: train loss 1.7427, val loss 1.8870\n",
      "step 20900: train loss 1.7502, val loss 1.8969\n",
      "step 21000: train loss 1.7353, val loss 1.9047\n",
      "step 21100: train loss 1.7403, val loss 1.9070\n",
      "step 21200: train loss 1.7359, val loss 1.9004\n",
      "step 21300: train loss 1.7472, val loss 1.8977\n",
      "step 21400: train loss 1.7227, val loss 1.8967\n",
      "step 21500: train loss 1.7328, val loss 1.8890\n",
      "step 21600: train loss 1.7370, val loss 1.9091\n",
      "step 21700: train loss 1.7384, val loss 1.8977\n",
      "step 21800: train loss 1.7364, val loss 1.8992\n",
      "step 21900: train loss 1.7419, val loss 1.8994\n",
      "step 22000: train loss 1.7350, val loss 1.8912\n",
      "step 22100: train loss 1.7356, val loss 1.8891\n",
      "step 22200: train loss 1.7317, val loss 1.8939\n",
      "step 22300: train loss 1.7324, val loss 1.8903\n",
      "step 22400: train loss 1.7396, val loss 1.8925\n",
      "step 22500: train loss 1.7217, val loss 1.8973\n",
      "step 22600: train loss 1.7374, val loss 1.8880\n",
      "step 22700: train loss 1.7380, val loss 1.8965\n",
      "step 22800: train loss 1.7272, val loss 1.8862\n",
      "step 22900: train loss 1.7379, val loss 1.8855\n",
      "step 23000: train loss 1.7299, val loss 1.8785\n",
      "step 23100: train loss 1.7261, val loss 1.8908\n",
      "step 23200: train loss 1.7319, val loss 1.8825\n",
      "step 23300: train loss 1.7354, val loss 1.9075\n",
      "step 23400: train loss 1.7264, val loss 1.8933\n",
      "step 23500: train loss 1.7247, val loss 1.8944\n",
      "step 23600: train loss 1.7351, val loss 1.8995\n",
      "step 23700: train loss 1.7196, val loss 1.8833\n",
      "step 23800: train loss 1.7265, val loss 1.8822\n",
      "step 23900: train loss 1.7270, val loss 1.8933\n",
      "step 24000: train loss 1.7274, val loss 1.8845\n",
      "step 24100: train loss 1.7290, val loss 1.8861\n",
      "step 24200: train loss 1.7220, val loss 1.8828\n",
      "step 24300: train loss 1.7244, val loss 1.8844\n",
      "step 24400: train loss 1.7226, val loss 1.8870\n",
      "step 24500: train loss 1.7257, val loss 1.8762\n",
      "step 24600: train loss 1.7228, val loss 1.8709\n",
      "step 24700: train loss 1.7323, val loss 1.8909\n",
      "step 24800: train loss 1.7296, val loss 1.8848\n",
      "step 24900: train loss 1.7304, val loss 1.8845\n",
      "step 25000: train loss 1.7245, val loss 1.8825\n",
      "step 25100: train loss 1.7199, val loss 1.8750\n",
      "step 25200: train loss 1.7289, val loss 1.8821\n",
      "step 25300: train loss 1.7157, val loss 1.8899\n",
      "step 25400: train loss 1.7279, val loss 1.8933\n",
      "step 25500: train loss 1.7259, val loss 1.8830\n",
      "step 25600: train loss 1.7282, val loss 1.8772\n",
      "step 25700: train loss 1.7278, val loss 1.8857\n",
      "step 25800: train loss 1.7332, val loss 1.8935\n",
      "step 25900: train loss 1.7295, val loss 1.8801\n",
      "step 26000: train loss 1.7228, val loss 1.8899\n",
      "step 26100: train loss 1.7239, val loss 1.8654\n",
      "step 26200: train loss 1.7222, val loss 1.8824\n",
      "step 26300: train loss 1.7270, val loss 1.8939\n",
      "step 26400: train loss 1.7265, val loss 1.8845\n",
      "step 26500: train loss 1.7268, val loss 1.8777\n",
      "step 26600: train loss 1.7209, val loss 1.8804\n",
      "step 26700: train loss 1.7238, val loss 1.8786\n",
      "step 26800: train loss 1.7119, val loss 1.8825\n",
      "step 26900: train loss 1.7225, val loss 1.8888\n",
      "step 27000: train loss 1.7268, val loss 1.8978\n",
      "step 27100: train loss 1.7217, val loss 1.8783\n",
      "step 27200: train loss 1.7299, val loss 1.8871\n",
      "step 27300: train loss 1.7244, val loss 1.8907\n",
      "step 27400: train loss 1.7208, val loss 1.8912\n",
      "step 27500: train loss 1.7222, val loss 1.8709\n",
      "step 27600: train loss 1.7133, val loss 1.8865\n",
      "step 27700: train loss 1.7133, val loss 1.8939\n",
      "step 27800: train loss 1.7137, val loss 1.8741\n",
      "step 27900: train loss 1.7158, val loss 1.8748\n",
      "step 28000: train loss 1.7083, val loss 1.8721\n",
      "step 28100: train loss 1.7227, val loss 1.8712\n",
      "step 28200: train loss 1.7205, val loss 1.8860\n",
      "step 28300: train loss 1.7103, val loss 1.8734\n",
      "step 28400: train loss 1.7105, val loss 1.8713\n",
      "step 28500: train loss 1.7150, val loss 1.8711\n",
      "step 28600: train loss 1.7145, val loss 1.8774\n",
      "step 28700: train loss 1.7218, val loss 1.8788\n",
      "step 28800: train loss 1.7208, val loss 1.8874\n",
      "step 28900: train loss 1.7070, val loss 1.8876\n",
      "step 29000: train loss 1.7149, val loss 1.8737\n",
      "step 29100: train loss 1.7162, val loss 1.8736\n",
      "step 29200: train loss 1.7166, val loss 1.8834\n",
      "step 29300: train loss 1.7191, val loss 1.8655\n",
      "step 29400: train loss 1.7127, val loss 1.8804\n",
      "step 29500: train loss 1.7113, val loss 1.8742\n",
      "step 29600: train loss 1.7072, val loss 1.8682\n",
      "step 29700: train loss 1.7034, val loss 1.8806\n",
      "step 29800: train loss 1.7080, val loss 1.8609\n",
      "step 29900: train loss 1.7057, val loss 1.8639\n",
      "step 30000: train loss 1.7141, val loss 1.8761\n",
      "step 30100: train loss 1.7084, val loss 1.8783\n",
      "step 30200: train loss 1.7205, val loss 1.8603\n",
      "step 30300: train loss 1.7089, val loss 1.8753\n",
      "step 30400: train loss 1.7146, val loss 1.8698\n",
      "step 30500: train loss 1.7156, val loss 1.8701\n",
      "step 30600: train loss 1.7125, val loss 1.8800\n",
      "step 30700: train loss 1.7084, val loss 1.8769\n",
      "step 30800: train loss 1.7103, val loss 1.8776\n",
      "step 30900: train loss 1.7050, val loss 1.8716\n",
      "step 31000: train loss 1.7130, val loss 1.8828\n",
      "step 31100: train loss 1.7015, val loss 1.8708\n",
      "step 31200: train loss 1.7082, val loss 1.8615\n",
      "step 31300: train loss 1.7025, val loss 1.8841\n",
      "step 31400: train loss 1.7147, val loss 1.8745\n",
      "step 31500: train loss 1.7224, val loss 1.8732\n",
      "step 31600: train loss 1.7034, val loss 1.8723\n",
      "step 31700: train loss 1.7049, val loss 1.8611\n",
      "step 31800: train loss 1.7077, val loss 1.8712\n",
      "step 31900: train loss 1.6962, val loss 1.8657\n",
      "step 32000: train loss 1.7030, val loss 1.8832\n",
      "step 32100: train loss 1.7104, val loss 1.8602\n",
      "step 32200: train loss 1.7043, val loss 1.8698\n",
      "step 32300: train loss 1.7066, val loss 1.8717\n",
      "step 32400: train loss 1.7151, val loss 1.8697\n",
      "step 32500: train loss 1.7203, val loss 1.8670\n",
      "step 32600: train loss 1.7143, val loss 1.8698\n",
      "step 32700: train loss 1.7126, val loss 1.8691\n",
      "step 32800: train loss 1.6998, val loss 1.8745\n",
      "step 32900: train loss 1.7118, val loss 1.8527\n",
      "step 33000: train loss 1.7001, val loss 1.8641\n",
      "step 33100: train loss 1.7103, val loss 1.8748\n",
      "step 33200: train loss 1.7041, val loss 1.8764\n",
      "step 33300: train loss 1.6938, val loss 1.8640\n",
      "step 33400: train loss 1.7084, val loss 1.8722\n",
      "step 33500: train loss 1.7171, val loss 1.8719\n",
      "step 33600: train loss 1.6986, val loss 1.8561\n",
      "step 33700: train loss 1.7063, val loss 1.8687\n",
      "step 33800: train loss 1.6999, val loss 1.8713\n",
      "step 33900: train loss 1.7187, val loss 1.8872\n",
      "step 34000: train loss 1.7112, val loss 1.8803\n",
      "step 34100: train loss 1.7037, val loss 1.8718\n",
      "step 34200: train loss 1.6945, val loss 1.8705\n",
      "step 34300: train loss 1.7027, val loss 1.8722\n",
      "step 34400: train loss 1.7045, val loss 1.8766\n",
      "step 34500: train loss 1.7021, val loss 1.8836\n",
      "step 34600: train loss 1.7069, val loss 1.8674\n",
      "step 34700: train loss 1.7012, val loss 1.8757\n",
      "step 34800: train loss 1.7116, val loss 1.8698\n",
      "step 34900: train loss 1.6974, val loss 1.8818\n",
      "step 35000: train loss 1.7023, val loss 1.8751\n",
      "step 35100: train loss 1.6957, val loss 1.8671\n",
      "step 35200: train loss 1.7039, val loss 1.8626\n",
      "step 35300: train loss 1.6996, val loss 1.8645\n",
      "step 35400: train loss 1.6964, val loss 1.8662\n",
      "step 35500: train loss 1.6997, val loss 1.8682\n",
      "step 35600: train loss 1.6911, val loss 1.8644\n",
      "step 35700: train loss 1.6930, val loss 1.8615\n",
      "step 35800: train loss 1.6939, val loss 1.8506\n",
      "step 35900: train loss 1.6909, val loss 1.8564\n",
      "step 36000: train loss 1.7090, val loss 1.8611\n",
      "step 36100: train loss 1.6938, val loss 1.8811\n",
      "step 36200: train loss 1.7001, val loss 1.8630\n",
      "step 36300: train loss 1.7024, val loss 1.8709\n",
      "step 36400: train loss 1.7024, val loss 1.8491\n",
      "step 36500: train loss 1.7091, val loss 1.8743\n",
      "step 36600: train loss 1.6944, val loss 1.8604\n",
      "step 36700: train loss 1.6868, val loss 1.8765\n",
      "step 36800: train loss 1.6900, val loss 1.8567\n",
      "step 36900: train loss 1.7064, val loss 1.8649\n",
      "step 37000: train loss 1.6931, val loss 1.8619\n",
      "step 37100: train loss 1.7000, val loss 1.8691\n",
      "step 37200: train loss 1.7021, val loss 1.8656\n",
      "step 37300: train loss 1.6959, val loss 1.8590\n",
      "step 37400: train loss 1.6933, val loss 1.8643\n",
      "step 37500: train loss 1.6992, val loss 1.8682\n",
      "step 37600: train loss 1.7058, val loss 1.8716\n",
      "step 37700: train loss 1.7023, val loss 1.8669\n",
      "step 37800: train loss 1.7026, val loss 1.8690\n",
      "step 37900: train loss 1.6983, val loss 1.8591\n",
      "step 38000: train loss 1.6960, val loss 1.8592\n",
      "step 38100: train loss 1.6843, val loss 1.8589\n",
      "step 38200: train loss 1.6860, val loss 1.8694\n",
      "step 38300: train loss 1.6953, val loss 1.8562\n",
      "step 38400: train loss 1.6953, val loss 1.8662\n",
      "step 38500: train loss 1.6920, val loss 1.8663\n",
      "step 38600: train loss 1.6971, val loss 1.8544\n",
      "step 38700: train loss 1.6811, val loss 1.8549\n",
      "step 38800: train loss 1.6908, val loss 1.8661\n",
      "step 38900: train loss 1.7084, val loss 1.8442\n",
      "step 39000: train loss 1.6830, val loss 1.8616\n",
      "step 39100: train loss 1.6927, val loss 1.8377\n",
      "step 39200: train loss 1.6949, val loss 1.8582\n",
      "step 39300: train loss 1.6919, val loss 1.8531\n",
      "step 39400: train loss 1.6937, val loss 1.8676\n",
      "step 39500: train loss 1.7016, val loss 1.8543\n",
      "step 39600: train loss 1.6919, val loss 1.8646\n",
      "step 39700: train loss 1.6805, val loss 1.8565\n",
      "step 39800: train loss 1.6931, val loss 1.8658\n",
      "step 39900: train loss 1.6903, val loss 1.8547\n",
      "step 40000: train loss 1.6913, val loss 1.8635\n",
      "step 40100: train loss 1.6774, val loss 1.8651\n",
      "step 40200: train loss 1.6923, val loss 1.8639\n",
      "step 40300: train loss 1.6919, val loss 1.8561\n",
      "step 40400: train loss 1.7004, val loss 1.8687\n",
      "step 40500: train loss 1.6913, val loss 1.8655\n",
      "step 40600: train loss 1.6980, val loss 1.8529\n",
      "step 40700: train loss 1.6967, val loss 1.8516\n",
      "step 40800: train loss 1.6937, val loss 1.8739\n",
      "step 40900: train loss 1.6854, val loss 1.8683\n",
      "step 41000: train loss 1.6889, val loss 1.8756\n",
      "step 41100: train loss 1.6887, val loss 1.8583\n",
      "step 41200: train loss 1.6866, val loss 1.8594\n",
      "step 41300: train loss 1.6963, val loss 1.8553\n",
      "step 41400: train loss 1.6933, val loss 1.8677\n",
      "step 41500: train loss 1.6950, val loss 1.8582\n",
      "step 41600: train loss 1.6819, val loss 1.8516\n",
      "step 41700: train loss 1.6933, val loss 1.8577\n",
      "step 41800: train loss 1.6883, val loss 1.8435\n",
      "step 41900: train loss 1.6909, val loss 1.8499\n",
      "step 42000: train loss 1.6904, val loss 1.8692\n",
      "step 42100: train loss 1.6912, val loss 1.8733\n",
      "step 42200: train loss 1.6907, val loss 1.8644\n",
      "step 42300: train loss 1.6856, val loss 1.8392\n",
      "step 42400: train loss 1.6780, val loss 1.8512\n",
      "step 42500: train loss 1.6941, val loss 1.8629\n",
      "step 42600: train loss 1.6970, val loss 1.8703\n",
      "step 42700: train loss 1.6901, val loss 1.8615\n",
      "step 42800: train loss 1.6883, val loss 1.8543\n",
      "step 42900: train loss 1.6873, val loss 1.8449\n",
      "step 43000: train loss 1.6922, val loss 1.8455\n",
      "step 43100: train loss 1.6845, val loss 1.8476\n",
      "step 43200: train loss 1.6981, val loss 1.8489\n",
      "step 43300: train loss 1.6799, val loss 1.8448\n",
      "step 43400: train loss 1.6960, val loss 1.8622\n",
      "step 43500: train loss 1.6976, val loss 1.8582\n",
      "step 43600: train loss 1.6825, val loss 1.8488\n",
      "step 43700: train loss 1.6915, val loss 1.8661\n",
      "step 43800: train loss 1.6933, val loss 1.8427\n",
      "step 43900: train loss 1.6780, val loss 1.8516\n",
      "step 44000: train loss 1.6965, val loss 1.8626\n",
      "step 44100: train loss 1.6825, val loss 1.8556\n",
      "step 44200: train loss 1.6823, val loss 1.8658\n",
      "step 44300: train loss 1.6926, val loss 1.8629\n",
      "step 44400: train loss 1.6924, val loss 1.8568\n",
      "step 44500: train loss 1.6763, val loss 1.8591\n",
      "step 44600: train loss 1.7026, val loss 1.8667\n",
      "step 44700: train loss 1.6879, val loss 1.8681\n",
      "step 44800: train loss 1.6873, val loss 1.8640\n",
      "step 44900: train loss 1.6749, val loss 1.8746\n",
      "step 45000: train loss 1.6825, val loss 1.8554\n",
      "step 45100: train loss 1.6858, val loss 1.8578\n",
      "step 45200: train loss 1.6787, val loss 1.8505\n",
      "step 45300: train loss 1.6785, val loss 1.8608\n",
      "step 45400: train loss 1.6843, val loss 1.8709\n",
      "step 45500: train loss 1.6788, val loss 1.8570\n",
      "step 45600: train loss 1.6849, val loss 1.8649\n",
      "step 45700: train loss 1.6896, val loss 1.8634\n",
      "step 45800: train loss 1.6768, val loss 1.8492\n",
      "step 45900: train loss 1.6900, val loss 1.8569\n",
      "step 46000: train loss 1.6825, val loss 1.8552\n",
      "step 46100: train loss 1.6851, val loss 1.8611\n",
      "step 46200: train loss 1.6887, val loss 1.8581\n",
      "step 46300: train loss 1.6869, val loss 1.8576\n",
      "step 46400: train loss 1.6857, val loss 1.8571\n",
      "step 46500: train loss 1.6712, val loss 1.8515\n",
      "step 46600: train loss 1.6868, val loss 1.8473\n",
      "step 46700: train loss 1.6823, val loss 1.8584\n",
      "step 46800: train loss 1.6850, val loss 1.8367\n",
      "step 46900: train loss 1.6772, val loss 1.8474\n",
      "step 47000: train loss 1.6868, val loss 1.8436\n",
      "step 47100: train loss 1.6886, val loss 1.8514\n",
      "step 47200: train loss 1.6832, val loss 1.8508\n",
      "step 47300: train loss 1.6842, val loss 1.8595\n",
      "step 47400: train loss 1.6818, val loss 1.8504\n",
      "step 47500: train loss 1.6772, val loss 1.8488\n",
      "step 47600: train loss 1.6886, val loss 1.8498\n",
      "step 47700: train loss 1.6888, val loss 1.8582\n",
      "step 47800: train loss 1.6864, val loss 1.8502\n",
      "step 47900: train loss 1.6884, val loss 1.8562\n",
      "step 48000: train loss 1.6833, val loss 1.8522\n",
      "step 48100: train loss 1.6741, val loss 1.8521\n",
      "step 48200: train loss 1.6886, val loss 1.8541\n",
      "step 48300: train loss 1.6683, val loss 1.8520\n",
      "step 48400: train loss 1.6810, val loss 1.8469\n",
      "step 48500: train loss 1.6774, val loss 1.8439\n",
      "step 48600: train loss 1.6797, val loss 1.8461\n",
      "step 48700: train loss 1.6727, val loss 1.8419\n",
      "step 48800: train loss 1.6811, val loss 1.8624\n",
      "step 48900: train loss 1.6845, val loss 1.8647\n",
      "step 49000: train loss 1.6748, val loss 1.8407\n",
      "step 49100: train loss 1.6910, val loss 1.8516\n",
      "step 49200: train loss 1.6926, val loss 1.8676\n",
      "step 49300: train loss 1.6850, val loss 1.8634\n",
      "step 49400: train loss 1.6811, val loss 1.8508\n",
      "step 49500: train loss 1.6725, val loss 1.8540\n",
      "step 49600: train loss 1.6790, val loss 1.8664\n",
      "step 49700: train loss 1.6769, val loss 1.8437\n",
      "step 49800: train loss 1.6865, val loss 1.8527\n",
      "step 49900: train loss 1.6853, val loss 1.8373\n",
      "step 49999: train loss 1.6802, val loss 1.8410\n",
      "Results for configuration res1_dropout=0.1_res2_dropout=0.99_res4_dropout=0.0_use_double_layers=False saved.\n",
      "Training model with configuration: {'res1_dropout': 0.2, 'res2_dropout': 0.99, 'res4_dropout': 0.0, 'use_double_layers': False}\n",
      "step 0: train loss 4.4331, val loss 4.4360\n",
      "step 100: train loss 2.8209, val loss 2.8388\n",
      "step 200: train loss 2.6224, val loss 2.6317\n",
      "step 300: train loss 2.5426, val loss 2.5533\n",
      "step 400: train loss 2.5149, val loss 2.5161\n",
      "step 500: train loss 2.4659, val loss 2.4674\n",
      "step 600: train loss 2.4308, val loss 2.4444\n",
      "step 700: train loss 2.4108, val loss 2.4047\n",
      "step 800: train loss 2.3854, val loss 2.3834\n",
      "step 900: train loss 2.3636, val loss 2.3718\n",
      "step 1000: train loss 2.3322, val loss 2.3246\n",
      "step 1100: train loss 2.3188, val loss 2.3302\n",
      "step 1200: train loss 2.3037, val loss 2.3054\n",
      "step 1300: train loss 2.2946, val loss 2.3056\n",
      "step 1400: train loss 2.2638, val loss 2.2770\n",
      "step 1500: train loss 2.2486, val loss 2.2730\n",
      "step 1600: train loss 2.2365, val loss 2.2543\n",
      "step 1700: train loss 2.2347, val loss 2.2559\n",
      "step 1800: train loss 2.2226, val loss 2.2442\n",
      "step 1900: train loss 2.1979, val loss 2.2205\n",
      "step 2000: train loss 2.1891, val loss 2.2065\n",
      "step 2100: train loss 2.1809, val loss 2.2154\n",
      "step 2200: train loss 2.1523, val loss 2.1912\n",
      "step 2300: train loss 2.1589, val loss 2.1815\n",
      "step 2400: train loss 2.1619, val loss 2.1816\n",
      "step 2500: train loss 2.1473, val loss 2.1656\n",
      "step 2600: train loss 2.1462, val loss 2.1546\n",
      "step 2700: train loss 2.1319, val loss 2.1694\n",
      "step 2800: train loss 2.1214, val loss 2.1542\n",
      "step 2900: train loss 2.1203, val loss 2.1384\n",
      "step 3000: train loss 2.0957, val loss 2.1387\n",
      "step 3100: train loss 2.1086, val loss 2.1327\n",
      "step 3200: train loss 2.0936, val loss 2.1327\n",
      "step 3300: train loss 2.0908, val loss 2.1299\n",
      "step 3400: train loss 2.0735, val loss 2.1184\n",
      "step 3500: train loss 2.0683, val loss 2.1134\n",
      "step 3600: train loss 2.0634, val loss 2.1085\n",
      "step 3700: train loss 2.0634, val loss 2.1184\n",
      "step 3800: train loss 2.0468, val loss 2.0978\n",
      "step 3900: train loss 2.0588, val loss 2.0910\n",
      "step 4000: train loss 2.0434, val loss 2.0813\n",
      "step 4100: train loss 2.0370, val loss 2.0898\n",
      "step 4200: train loss 2.0333, val loss 2.0776\n",
      "step 4300: train loss 2.0431, val loss 2.0877\n",
      "step 4400: train loss 2.0249, val loss 2.0910\n",
      "step 4500: train loss 2.0269, val loss 2.0721\n",
      "step 4600: train loss 2.0143, val loss 2.0779\n",
      "step 4700: train loss 2.0109, val loss 2.0661\n",
      "step 4800: train loss 2.0063, val loss 2.0734\n",
      "step 4900: train loss 2.0102, val loss 2.0701\n",
      "step 5000: train loss 2.0127, val loss 2.0703\n",
      "step 5100: train loss 2.0002, val loss 2.0607\n",
      "step 5200: train loss 1.9937, val loss 2.0492\n",
      "step 5300: train loss 1.9912, val loss 2.0640\n",
      "step 5400: train loss 1.9832, val loss 2.0524\n",
      "step 5500: train loss 1.9878, val loss 2.0601\n",
      "step 5600: train loss 1.9834, val loss 2.0542\n",
      "step 5700: train loss 1.9794, val loss 2.0383\n",
      "step 5800: train loss 1.9680, val loss 2.0442\n",
      "step 5900: train loss 1.9672, val loss 2.0360\n",
      "step 6000: train loss 1.9739, val loss 2.0529\n",
      "step 6100: train loss 1.9542, val loss 2.0431\n",
      "step 6200: train loss 1.9687, val loss 2.0453\n",
      "step 6300: train loss 1.9675, val loss 2.0219\n",
      "step 6400: train loss 1.9681, val loss 2.0447\n",
      "step 6500: train loss 1.9452, val loss 2.0262\n",
      "step 6600: train loss 1.9546, val loss 2.0210\n",
      "step 6700: train loss 1.9619, val loss 2.0456\n",
      "step 6800: train loss 1.9478, val loss 2.0211\n",
      "step 6900: train loss 1.9442, val loss 2.0217\n",
      "step 7000: train loss 1.9422, val loss 2.0205\n",
      "step 7100: train loss 1.9466, val loss 2.0251\n",
      "step 7200: train loss 1.9384, val loss 2.0331\n",
      "step 7300: train loss 1.9385, val loss 2.0129\n",
      "step 7400: train loss 1.9371, val loss 2.0296\n",
      "step 7500: train loss 1.9268, val loss 2.0082\n",
      "step 7600: train loss 1.9241, val loss 2.0352\n",
      "step 7700: train loss 1.9228, val loss 2.0254\n",
      "step 7800: train loss 1.9198, val loss 2.0213\n",
      "step 7900: train loss 1.9292, val loss 2.0230\n",
      "step 8000: train loss 1.9189, val loss 2.0154\n",
      "step 8100: train loss 1.9210, val loss 2.0202\n",
      "step 8200: train loss 1.9121, val loss 2.0168\n",
      "step 8300: train loss 1.9061, val loss 2.0142\n",
      "step 8400: train loss 1.9119, val loss 2.0075\n",
      "step 8500: train loss 1.9116, val loss 1.9990\n",
      "step 8600: train loss 1.9064, val loss 1.9991\n",
      "step 8700: train loss 1.8954, val loss 2.0014\n",
      "step 8800: train loss 1.8941, val loss 1.9985\n",
      "step 8900: train loss 1.8922, val loss 1.9966\n",
      "step 9000: train loss 1.8992, val loss 2.0062\n",
      "step 9100: train loss 1.8934, val loss 2.0063\n",
      "step 9200: train loss 1.8886, val loss 1.9981\n",
      "step 9300: train loss 1.9001, val loss 2.0066\n",
      "step 9400: train loss 1.8921, val loss 1.9947\n",
      "step 9500: train loss 1.8890, val loss 1.9927\n",
      "step 9600: train loss 1.9048, val loss 2.0073\n",
      "step 9700: train loss 1.8843, val loss 2.0082\n",
      "step 9800: train loss 1.8912, val loss 2.0006\n",
      "step 9900: train loss 1.8946, val loss 2.0109\n",
      "step 10000: train loss 1.8861, val loss 1.9971\n",
      "step 10100: train loss 1.8805, val loss 1.9831\n",
      "step 10200: train loss 1.8776, val loss 1.9938\n",
      "step 10300: train loss 1.8712, val loss 1.9922\n",
      "step 10400: train loss 1.8729, val loss 1.9915\n",
      "step 10500: train loss 1.8808, val loss 2.0047\n",
      "step 10600: train loss 1.8673, val loss 1.9886\n",
      "step 10700: train loss 1.8745, val loss 2.0020\n",
      "step 10800: train loss 1.8653, val loss 2.0010\n",
      "step 10900: train loss 1.8743, val loss 1.9967\n",
      "step 11000: train loss 1.8732, val loss 1.9944\n",
      "step 11100: train loss 1.8625, val loss 1.9713\n",
      "step 11200: train loss 1.8628, val loss 1.9790\n",
      "step 11300: train loss 1.8705, val loss 1.9885\n",
      "step 11400: train loss 1.8632, val loss 1.9858\n",
      "step 11500: train loss 1.8691, val loss 1.9874\n",
      "step 11600: train loss 1.8689, val loss 1.9798\n",
      "step 11700: train loss 1.8587, val loss 1.9810\n",
      "step 11800: train loss 1.8663, val loss 1.9784\n",
      "step 11900: train loss 1.8538, val loss 1.9808\n",
      "step 12000: train loss 1.8456, val loss 1.9712\n",
      "step 12100: train loss 1.8667, val loss 1.9937\n",
      "step 12200: train loss 1.8544, val loss 1.9640\n",
      "step 12300: train loss 1.8646, val loss 1.9759\n",
      "step 12400: train loss 1.8510, val loss 1.9655\n",
      "step 12500: train loss 1.8511, val loss 1.9722\n",
      "step 12600: train loss 1.8583, val loss 1.9737\n",
      "step 12700: train loss 1.8441, val loss 1.9688\n",
      "step 12800: train loss 1.8420, val loss 1.9721\n",
      "step 12900: train loss 1.8522, val loss 1.9666\n",
      "step 13000: train loss 1.8552, val loss 1.9721\n",
      "step 13100: train loss 1.8392, val loss 1.9573\n",
      "step 13200: train loss 1.8317, val loss 1.9692\n",
      "step 13300: train loss 1.8519, val loss 1.9639\n",
      "step 13400: train loss 1.8528, val loss 1.9710\n",
      "step 13500: train loss 1.8365, val loss 1.9800\n",
      "step 13600: train loss 1.8443, val loss 1.9742\n",
      "step 13700: train loss 1.8389, val loss 1.9681\n",
      "step 13800: train loss 1.8428, val loss 1.9715\n",
      "step 13900: train loss 1.8319, val loss 1.9743\n",
      "step 14000: train loss 1.8363, val loss 1.9801\n",
      "step 14100: train loss 1.8332, val loss 1.9681\n",
      "step 14200: train loss 1.8334, val loss 1.9705\n",
      "step 14300: train loss 1.8317, val loss 1.9648\n",
      "step 14400: train loss 1.8256, val loss 1.9502\n",
      "step 14500: train loss 1.8328, val loss 1.9657\n",
      "step 14600: train loss 1.8275, val loss 1.9655\n",
      "step 14700: train loss 1.8407, val loss 1.9690\n",
      "step 14800: train loss 1.8284, val loss 1.9509\n",
      "step 14900: train loss 1.8364, val loss 1.9494\n",
      "step 15000: train loss 1.8246, val loss 1.9429\n",
      "step 15100: train loss 1.8164, val loss 1.9546\n",
      "step 15200: train loss 1.8303, val loss 1.9533\n",
      "step 15300: train loss 1.8163, val loss 1.9495\n",
      "step 15400: train loss 1.8419, val loss 1.9533\n",
      "step 15500: train loss 1.8307, val loss 1.9617\n",
      "step 15600: train loss 1.8182, val loss 1.9565\n",
      "step 15700: train loss 1.8189, val loss 1.9495\n",
      "step 15800: train loss 1.8243, val loss 1.9559\n",
      "step 15900: train loss 1.8204, val loss 1.9640\n",
      "step 16000: train loss 1.8187, val loss 1.9471\n",
      "step 16100: train loss 1.8298, val loss 1.9559\n",
      "step 16200: train loss 1.8254, val loss 1.9451\n",
      "step 16300: train loss 1.8135, val loss 1.9530\n",
      "step 16400: train loss 1.8196, val loss 1.9472\n",
      "step 16500: train loss 1.8178, val loss 1.9424\n",
      "step 16600: train loss 1.8083, val loss 1.9524\n",
      "step 16700: train loss 1.8170, val loss 1.9456\n",
      "step 16800: train loss 1.8076, val loss 1.9601\n",
      "step 16900: train loss 1.8217, val loss 1.9363\n",
      "step 17000: train loss 1.8175, val loss 1.9531\n",
      "step 17100: train loss 1.8150, val loss 1.9456\n",
      "step 17200: train loss 1.8174, val loss 1.9467\n",
      "step 17300: train loss 1.8162, val loss 1.9374\n",
      "step 17400: train loss 1.8090, val loss 1.9275\n",
      "step 17500: train loss 1.8095, val loss 1.9396\n",
      "step 17600: train loss 1.7944, val loss 1.9393\n",
      "step 17700: train loss 1.8107, val loss 1.9338\n",
      "step 17800: train loss 1.8130, val loss 1.9407\n",
      "step 17900: train loss 1.8008, val loss 1.9571\n",
      "step 18000: train loss 1.8009, val loss 1.9431\n",
      "step 18100: train loss 1.8000, val loss 1.9336\n",
      "step 18200: train loss 1.8007, val loss 1.9352\n",
      "step 18300: train loss 1.8043, val loss 1.9484\n",
      "step 18400: train loss 1.7938, val loss 1.9318\n",
      "step 18500: train loss 1.8073, val loss 1.9286\n",
      "step 18600: train loss 1.8008, val loss 1.9385\n",
      "step 18700: train loss 1.8008, val loss 1.9372\n",
      "step 18800: train loss 1.8063, val loss 1.9323\n",
      "step 18900: train loss 1.7969, val loss 1.9290\n",
      "step 19000: train loss 1.7865, val loss 1.9318\n",
      "step 19100: train loss 1.7996, val loss 1.9367\n",
      "step 19200: train loss 1.7997, val loss 1.9275\n",
      "step 19300: train loss 1.7982, val loss 1.9347\n",
      "step 19400: train loss 1.7946, val loss 1.9265\n",
      "step 19500: train loss 1.7944, val loss 1.9173\n",
      "step 19600: train loss 1.7987, val loss 1.9269\n",
      "step 19700: train loss 1.7917, val loss 1.9176\n",
      "step 19800: train loss 1.7878, val loss 1.9316\n",
      "step 19900: train loss 1.7913, val loss 1.9388\n",
      "step 20000: train loss 1.8118, val loss 1.9328\n",
      "step 20100: train loss 1.7844, val loss 1.9334\n",
      "step 20200: train loss 1.7849, val loss 1.9268\n",
      "step 20300: train loss 1.7820, val loss 1.9264\n",
      "step 20400: train loss 1.7862, val loss 1.9244\n",
      "step 20500: train loss 1.7788, val loss 1.9348\n",
      "step 20600: train loss 1.7981, val loss 1.9264\n",
      "step 20700: train loss 1.7897, val loss 1.9112\n",
      "step 20800: train loss 1.7839, val loss 1.9306\n",
      "step 20900: train loss 1.7883, val loss 1.9305\n",
      "step 21000: train loss 1.7833, val loss 1.9289\n",
      "step 21100: train loss 1.7813, val loss 1.9095\n",
      "step 21200: train loss 1.7904, val loss 1.9397\n",
      "step 21300: train loss 1.7908, val loss 1.9281\n",
      "step 21400: train loss 1.7851, val loss 1.9318\n",
      "step 21500: train loss 1.7907, val loss 1.9259\n",
      "step 21600: train loss 1.7839, val loss 1.9227\n",
      "step 21700: train loss 1.7974, val loss 1.9443\n",
      "step 21800: train loss 1.7847, val loss 1.9239\n",
      "step 21900: train loss 1.7858, val loss 1.9307\n",
      "step 22000: train loss 1.7724, val loss 1.9308\n",
      "step 22100: train loss 1.7877, val loss 1.9348\n",
      "step 22200: train loss 1.7744, val loss 1.9318\n",
      "step 22300: train loss 1.7830, val loss 1.9223\n",
      "step 22400: train loss 1.7940, val loss 1.9334\n",
      "step 22500: train loss 1.7741, val loss 1.9298\n",
      "step 22600: train loss 1.7841, val loss 1.9410\n",
      "step 22700: train loss 1.7829, val loss 1.9206\n",
      "step 22800: train loss 1.7833, val loss 1.9350\n",
      "step 22900: train loss 1.7754, val loss 1.9206\n",
      "step 23000: train loss 1.7685, val loss 1.9276\n",
      "step 23100: train loss 1.7662, val loss 1.9227\n",
      "step 23200: train loss 1.7804, val loss 1.9187\n",
      "step 23300: train loss 1.7813, val loss 1.9229\n",
      "step 23400: train loss 1.7727, val loss 1.9142\n",
      "step 23500: train loss 1.7754, val loss 1.9321\n",
      "step 23600: train loss 1.7831, val loss 1.9148\n",
      "step 23700: train loss 1.7784, val loss 1.9198\n",
      "step 23800: train loss 1.7847, val loss 1.9313\n",
      "step 23900: train loss 1.7784, val loss 1.9070\n",
      "step 24000: train loss 1.7802, val loss 1.9166\n",
      "step 24100: train loss 1.7740, val loss 1.9330\n",
      "step 24200: train loss 1.7787, val loss 1.9158\n",
      "step 24300: train loss 1.7794, val loss 1.9148\n",
      "step 24400: train loss 1.7669, val loss 1.9085\n",
      "step 24500: train loss 1.7766, val loss 1.9177\n",
      "step 24600: train loss 1.7747, val loss 1.9206\n",
      "step 24700: train loss 1.7660, val loss 1.9191\n",
      "step 24800: train loss 1.7789, val loss 1.9333\n",
      "step 24900: train loss 1.7843, val loss 1.9274\n",
      "step 25000: train loss 1.7802, val loss 1.9164\n",
      "step 25100: train loss 1.7849, val loss 1.9204\n",
      "step 25200: train loss 1.7705, val loss 1.9199\n",
      "step 25300: train loss 1.7730, val loss 1.9199\n",
      "step 25400: train loss 1.7692, val loss 1.9178\n",
      "step 25500: train loss 1.7791, val loss 1.9228\n",
      "step 25600: train loss 1.7778, val loss 1.9378\n",
      "step 25700: train loss 1.7760, val loss 1.9215\n",
      "step 25800: train loss 1.7697, val loss 1.9133\n",
      "step 25900: train loss 1.7580, val loss 1.9141\n",
      "step 26000: train loss 1.7557, val loss 1.9137\n",
      "step 26100: train loss 1.7628, val loss 1.9235\n",
      "step 26200: train loss 1.7786, val loss 1.9127\n",
      "step 26300: train loss 1.7538, val loss 1.9036\n",
      "step 26400: train loss 1.7725, val loss 1.9271\n",
      "step 26500: train loss 1.7648, val loss 1.9150\n",
      "step 26600: train loss 1.7795, val loss 1.9442\n",
      "step 26700: train loss 1.7688, val loss 1.9255\n",
      "step 26800: train loss 1.7675, val loss 1.9272\n",
      "step 26900: train loss 1.7654, val loss 1.9193\n",
      "step 27000: train loss 1.7542, val loss 1.9264\n",
      "step 27100: train loss 1.7662, val loss 1.9240\n",
      "step 27200: train loss 1.7592, val loss 1.9162\n",
      "step 27300: train loss 1.7708, val loss 1.9085\n",
      "step 27400: train loss 1.7780, val loss 1.9109\n",
      "step 27500: train loss 1.7815, val loss 1.9067\n",
      "step 27600: train loss 1.7564, val loss 1.9166\n",
      "step 27700: train loss 1.7665, val loss 1.9207\n",
      "step 27800: train loss 1.7741, val loss 1.8948\n",
      "step 27900: train loss 1.7539, val loss 1.9072\n",
      "step 28000: train loss 1.7587, val loss 1.9028\n",
      "step 28100: train loss 1.7609, val loss 1.9174\n",
      "step 28200: train loss 1.7601, val loss 1.9168\n",
      "step 28300: train loss 1.7701, val loss 1.9032\n",
      "step 28400: train loss 1.7843, val loss 1.9171\n",
      "step 28500: train loss 1.7565, val loss 1.9014\n",
      "step 28600: train loss 1.7681, val loss 1.9193\n",
      "step 28700: train loss 1.7537, val loss 1.9100\n",
      "step 28800: train loss 1.7676, val loss 1.9043\n",
      "step 28900: train loss 1.7506, val loss 1.9053\n",
      "step 29000: train loss 1.7596, val loss 1.9107\n",
      "step 29100: train loss 1.7554, val loss 1.9045\n",
      "step 29200: train loss 1.7528, val loss 1.9078\n",
      "step 29300: train loss 1.7564, val loss 1.9134\n",
      "step 29400: train loss 1.7539, val loss 1.9182\n",
      "step 29500: train loss 1.7589, val loss 1.8986\n",
      "step 29600: train loss 1.7671, val loss 1.9054\n",
      "step 29700: train loss 1.7551, val loss 1.9136\n",
      "step 29800: train loss 1.7545, val loss 1.9050\n",
      "step 29900: train loss 1.7486, val loss 1.9012\n",
      "step 30000: train loss 1.7482, val loss 1.8998\n",
      "step 30100: train loss 1.7486, val loss 1.9021\n",
      "step 30200: train loss 1.7598, val loss 1.9039\n",
      "step 30300: train loss 1.7542, val loss 1.8934\n",
      "step 30400: train loss 1.7512, val loss 1.8998\n",
      "step 30500: train loss 1.7604, val loss 1.8979\n",
      "step 30600: train loss 1.7523, val loss 1.9015\n",
      "step 30700: train loss 1.7595, val loss 1.9012\n",
      "step 30800: train loss 1.7467, val loss 1.8956\n",
      "step 30900: train loss 1.7465, val loss 1.8764\n",
      "step 31000: train loss 1.7464, val loss 1.9025\n",
      "step 31100: train loss 1.7489, val loss 1.8911\n",
      "step 31200: train loss 1.7526, val loss 1.9037\n",
      "step 31300: train loss 1.7537, val loss 1.9133\n",
      "step 31400: train loss 1.7416, val loss 1.9012\n",
      "step 31500: train loss 1.7537, val loss 1.9059\n",
      "step 31600: train loss 1.7558, val loss 1.8989\n",
      "step 31700: train loss 1.7453, val loss 1.8856\n",
      "step 31800: train loss 1.7520, val loss 1.9018\n",
      "step 31900: train loss 1.7568, val loss 1.8925\n",
      "step 32000: train loss 1.7562, val loss 1.9083\n",
      "step 32100: train loss 1.7661, val loss 1.9011\n",
      "step 32200: train loss 1.7519, val loss 1.8989\n",
      "step 32300: train loss 1.7511, val loss 1.8915\n",
      "step 32400: train loss 1.7556, val loss 1.9053\n",
      "step 32500: train loss 1.7553, val loss 1.9076\n",
      "step 32600: train loss 1.7412, val loss 1.8933\n",
      "step 32700: train loss 1.7394, val loss 1.8897\n",
      "step 32800: train loss 1.7472, val loss 1.8986\n",
      "step 32900: train loss 1.7481, val loss 1.8977\n",
      "step 33000: train loss 1.7442, val loss 1.8952\n",
      "step 33100: train loss 1.7417, val loss 1.9006\n",
      "step 33200: train loss 1.7350, val loss 1.9011\n",
      "step 33300: train loss 1.7438, val loss 1.9103\n",
      "step 33400: train loss 1.7368, val loss 1.8977\n",
      "step 33500: train loss 1.7478, val loss 1.8908\n",
      "step 33600: train loss 1.7496, val loss 1.8935\n",
      "step 33700: train loss 1.7455, val loss 1.8911\n",
      "step 33800: train loss 1.7574, val loss 1.9045\n",
      "step 33900: train loss 1.7477, val loss 1.9063\n",
      "step 34000: train loss 1.7370, val loss 1.8909\n",
      "step 34100: train loss 1.7544, val loss 1.8909\n",
      "step 34200: train loss 1.7460, val loss 1.9003\n",
      "step 34300: train loss 1.7564, val loss 1.9107\n",
      "step 34400: train loss 1.7402, val loss 1.9049\n",
      "step 34500: train loss 1.7455, val loss 1.8852\n",
      "step 34600: train loss 1.7450, val loss 1.8946\n",
      "step 34700: train loss 1.7478, val loss 1.8989\n",
      "step 34800: train loss 1.7403, val loss 1.8868\n",
      "step 34900: train loss 1.7442, val loss 1.8924\n",
      "step 35000: train loss 1.7421, val loss 1.8988\n",
      "step 35100: train loss 1.7391, val loss 1.9086\n",
      "step 35200: train loss 1.7352, val loss 1.9020\n",
      "step 35300: train loss 1.7485, val loss 1.8930\n",
      "step 35400: train loss 1.7385, val loss 1.8827\n",
      "step 35500: train loss 1.7347, val loss 1.8872\n",
      "step 35600: train loss 1.7445, val loss 1.8932\n",
      "step 35700: train loss 1.7490, val loss 1.8952\n",
      "step 35800: train loss 1.7477, val loss 1.8976\n",
      "step 35900: train loss 1.7494, val loss 1.9018\n",
      "step 36000: train loss 1.7488, val loss 1.8992\n",
      "step 36100: train loss 1.7400, val loss 1.8930\n",
      "step 36200: train loss 1.7355, val loss 1.8858\n",
      "step 36300: train loss 1.7383, val loss 1.8900\n",
      "step 36400: train loss 1.7420, val loss 1.8895\n",
      "step 36500: train loss 1.7450, val loss 1.8914\n",
      "step 36600: train loss 1.7434, val loss 1.8903\n",
      "step 36700: train loss 1.7380, val loss 1.8903\n",
      "step 36800: train loss 1.7362, val loss 1.8931\n",
      "step 36900: train loss 1.7238, val loss 1.9033\n",
      "step 37000: train loss 1.7378, val loss 1.9126\n",
      "step 37100: train loss 1.7325, val loss 1.9053\n",
      "step 37200: train loss 1.7401, val loss 1.9003\n",
      "step 37300: train loss 1.7363, val loss 1.8932\n",
      "step 37400: train loss 1.7472, val loss 1.8868\n",
      "step 37500: train loss 1.7462, val loss 1.8843\n",
      "step 37600: train loss 1.7343, val loss 1.9005\n",
      "step 37700: train loss 1.7436, val loss 1.8953\n",
      "step 37800: train loss 1.7395, val loss 1.8925\n",
      "step 37900: train loss 1.7360, val loss 1.8871\n",
      "step 38000: train loss 1.7374, val loss 1.8851\n",
      "step 38100: train loss 1.7423, val loss 1.8972\n",
      "step 38200: train loss 1.7165, val loss 1.8911\n",
      "step 38300: train loss 1.7400, val loss 1.8925\n",
      "step 38400: train loss 1.7428, val loss 1.8840\n",
      "step 38500: train loss 1.7401, val loss 1.8831\n",
      "step 38600: train loss 1.7385, val loss 1.8891\n",
      "step 38700: train loss 1.7403, val loss 1.8998\n",
      "step 38800: train loss 1.7357, val loss 1.8875\n",
      "step 38900: train loss 1.7376, val loss 1.8763\n",
      "step 39000: train loss 1.7442, val loss 1.8935\n",
      "step 39100: train loss 1.7327, val loss 1.8926\n",
      "step 39200: train loss 1.7360, val loss 1.8874\n",
      "step 39300: train loss 1.7337, val loss 1.8895\n",
      "step 39400: train loss 1.7364, val loss 1.9034\n",
      "step 39500: train loss 1.7388, val loss 1.8892\n",
      "step 39600: train loss 1.7351, val loss 1.8869\n",
      "step 39700: train loss 1.7441, val loss 1.9048\n",
      "step 39800: train loss 1.7349, val loss 1.9042\n",
      "step 39900: train loss 1.7320, val loss 1.9036\n",
      "step 40000: train loss 1.7261, val loss 1.8904\n",
      "step 40100: train loss 1.7356, val loss 1.8908\n",
      "step 40200: train loss 1.7313, val loss 1.8785\n",
      "step 40300: train loss 1.7250, val loss 1.8876\n",
      "step 40400: train loss 1.7316, val loss 1.8638\n",
      "step 40500: train loss 1.7277, val loss 1.8853\n",
      "step 40600: train loss 1.7346, val loss 1.8826\n",
      "step 40700: train loss 1.7328, val loss 1.8856\n",
      "step 40800: train loss 1.7264, val loss 1.8926\n",
      "step 40900: train loss 1.7321, val loss 1.8782\n",
      "step 41000: train loss 1.7233, val loss 1.8871\n",
      "step 41100: train loss 1.7272, val loss 1.8967\n",
      "step 41200: train loss 1.7312, val loss 1.8851\n",
      "step 41300: train loss 1.7275, val loss 1.8874\n",
      "step 41400: train loss 1.7324, val loss 1.8980\n",
      "step 41500: train loss 1.7377, val loss 1.8902\n",
      "step 41600: train loss 1.7293, val loss 1.8944\n",
      "step 41700: train loss 1.7435, val loss 1.8916\n",
      "step 41800: train loss 1.7287, val loss 1.8991\n",
      "step 41900: train loss 1.7317, val loss 1.8918\n",
      "step 42000: train loss 1.7308, val loss 1.8965\n",
      "step 42100: train loss 1.7299, val loss 1.9014\n",
      "step 42200: train loss 1.7328, val loss 1.8940\n",
      "step 42300: train loss 1.7356, val loss 1.9073\n",
      "step 42400: train loss 1.7315, val loss 1.9013\n",
      "step 42500: train loss 1.7276, val loss 1.8879\n",
      "step 42600: train loss 1.7249, val loss 1.8828\n",
      "step 42700: train loss 1.7212, val loss 1.8965\n",
      "step 42800: train loss 1.7257, val loss 1.8878\n",
      "step 42900: train loss 1.7313, val loss 1.8829\n",
      "step 43000: train loss 1.7294, val loss 1.8930\n",
      "step 43100: train loss 1.7184, val loss 1.8758\n",
      "step 43200: train loss 1.7298, val loss 1.8849\n",
      "step 43300: train loss 1.7195, val loss 1.8828\n",
      "step 43400: train loss 1.7273, val loss 1.8859\n",
      "step 43500: train loss 1.7164, val loss 1.8796\n",
      "step 43600: train loss 1.7385, val loss 1.8737\n",
      "step 43700: train loss 1.7286, val loss 1.8889\n",
      "step 43800: train loss 1.7232, val loss 1.8844\n",
      "step 43900: train loss 1.7265, val loss 1.8953\n",
      "step 44000: train loss 1.7318, val loss 1.8942\n",
      "step 44100: train loss 1.7192, val loss 1.8824\n",
      "step 44200: train loss 1.7290, val loss 1.8804\n",
      "step 44300: train loss 1.7174, val loss 1.8940\n",
      "step 44400: train loss 1.7230, val loss 1.8999\n",
      "step 44500: train loss 1.7225, val loss 1.8937\n",
      "step 44600: train loss 1.7176, val loss 1.8835\n",
      "step 44700: train loss 1.7327, val loss 1.8740\n",
      "step 44800: train loss 1.7164, val loss 1.8968\n",
      "step 44900: train loss 1.7271, val loss 1.8785\n",
      "step 45000: train loss 1.7295, val loss 1.8895\n",
      "step 45100: train loss 1.7176, val loss 1.8895\n",
      "step 45200: train loss 1.7218, val loss 1.8783\n",
      "step 45300: train loss 1.7331, val loss 1.8725\n",
      "step 45400: train loss 1.7280, val loss 1.8916\n",
      "step 45500: train loss 1.7209, val loss 1.8947\n",
      "step 45600: train loss 1.7256, val loss 1.8934\n",
      "step 45700: train loss 1.7117, val loss 1.8879\n",
      "step 45800: train loss 1.7266, val loss 1.8806\n",
      "step 45900: train loss 1.7165, val loss 1.8869\n",
      "step 46000: train loss 1.7321, val loss 1.8639\n",
      "step 46100: train loss 1.7140, val loss 1.8767\n",
      "step 46200: train loss 1.7165, val loss 1.8780\n",
      "step 46300: train loss 1.7151, val loss 1.8696\n",
      "step 46400: train loss 1.7362, val loss 1.8838\n",
      "step 46500: train loss 1.7198, val loss 1.8805\n",
      "step 46600: train loss 1.7151, val loss 1.8848\n",
      "step 46700: train loss 1.7202, val loss 1.8780\n",
      "step 46800: train loss 1.7230, val loss 1.8824\n",
      "step 46900: train loss 1.7286, val loss 1.8650\n",
      "step 47000: train loss 1.7257, val loss 1.8752\n",
      "step 47100: train loss 1.7261, val loss 1.8919\n",
      "step 47200: train loss 1.7231, val loss 1.8838\n",
      "step 47300: train loss 1.7286, val loss 1.8774\n",
      "step 47400: train loss 1.7215, val loss 1.8744\n",
      "step 47500: train loss 1.7181, val loss 1.8800\n",
      "step 47600: train loss 1.7182, val loss 1.8813\n",
      "step 47700: train loss 1.7216, val loss 1.8824\n",
      "step 47800: train loss 1.7198, val loss 1.8745\n",
      "step 47900: train loss 1.7197, val loss 1.8774\n",
      "step 48000: train loss 1.7315, val loss 1.8823\n",
      "step 48100: train loss 1.7090, val loss 1.8760\n",
      "step 48200: train loss 1.7180, val loss 1.8758\n",
      "step 48300: train loss 1.7149, val loss 1.8761\n",
      "step 48400: train loss 1.7170, val loss 1.8824\n",
      "step 48500: train loss 1.7107, val loss 1.8840\n",
      "step 48600: train loss 1.7211, val loss 1.8859\n",
      "step 48700: train loss 1.7252, val loss 1.8924\n",
      "step 48800: train loss 1.7110, val loss 1.8929\n",
      "step 48900: train loss 1.7055, val loss 1.8962\n",
      "step 49000: train loss 1.7102, val loss 1.8798\n",
      "step 49100: train loss 1.7268, val loss 1.8865\n",
      "step 49200: train loss 1.7185, val loss 1.8874\n",
      "step 49300: train loss 1.7117, val loss 1.8903\n",
      "step 49400: train loss 1.7180, val loss 1.8796\n",
      "step 49500: train loss 1.7162, val loss 1.8953\n",
      "step 49600: train loss 1.7236, val loss 1.8675\n",
      "step 49700: train loss 1.7219, val loss 1.8865\n",
      "step 49800: train loss 1.7197, val loss 1.8746\n",
      "step 49900: train loss 1.7227, val loss 1.8902\n",
      "step 49999: train loss 1.7195, val loss 1.8847\n",
      "Results for configuration res1_dropout=0.2_res2_dropout=0.99_res4_dropout=0.0_use_double_layers=False saved.\n",
      "Training model with configuration: {'res1_dropout': 0.5, 'res2_dropout': 0.99, 'res4_dropout': 0.0, 'use_double_layers': False}\n",
      "step 0: train loss 4.3369, val loss 4.3341\n",
      "step 100: train loss 3.2677, val loss 3.3188\n",
      "step 200: train loss 2.8340, val loss 2.8511\n",
      "step 300: train loss 2.7019, val loss 2.7027\n",
      "step 400: train loss 2.6468, val loss 2.6396\n",
      "step 500: train loss 2.6053, val loss 2.6136\n",
      "step 600: train loss 2.5790, val loss 2.5673\n",
      "step 700: train loss 2.5611, val loss 2.5503\n",
      "step 800: train loss 2.5373, val loss 2.5398\n",
      "step 900: train loss 2.5222, val loss 2.5231\n",
      "step 1000: train loss 2.5006, val loss 2.5035\n",
      "step 1100: train loss 2.4821, val loss 2.4756\n",
      "step 1200: train loss 2.4619, val loss 2.4564\n",
      "step 1300: train loss 2.4394, val loss 2.4332\n",
      "step 1400: train loss 2.4355, val loss 2.4161\n",
      "step 1500: train loss 2.4156, val loss 2.4051\n",
      "step 1600: train loss 2.4111, val loss 2.3946\n",
      "step 1700: train loss 2.3994, val loss 2.3785\n",
      "step 1800: train loss 2.3809, val loss 2.3722\n",
      "step 1900: train loss 2.3737, val loss 2.3582\n",
      "step 2000: train loss 2.3618, val loss 2.3528\n",
      "step 2100: train loss 2.3499, val loss 2.3430\n",
      "step 2200: train loss 2.3360, val loss 2.3371\n",
      "step 2300: train loss 2.3345, val loss 2.3130\n",
      "step 2400: train loss 2.3319, val loss 2.3240\n",
      "step 2500: train loss 2.3075, val loss 2.3089\n",
      "step 2600: train loss 2.3005, val loss 2.2914\n",
      "step 2700: train loss 2.2952, val loss 2.2961\n",
      "step 2800: train loss 2.2952, val loss 2.2960\n",
      "step 2900: train loss 2.2870, val loss 2.2908\n",
      "step 3000: train loss 2.2766, val loss 2.2790\n",
      "step 3100: train loss 2.2683, val loss 2.2743\n",
      "step 3200: train loss 2.2548, val loss 2.2694\n",
      "step 3300: train loss 2.2567, val loss 2.2510\n",
      "step 3400: train loss 2.2537, val loss 2.2516\n",
      "step 3500: train loss 2.2441, val loss 2.2421\n",
      "step 3600: train loss 2.2422, val loss 2.2426\n",
      "step 3700: train loss 2.2460, val loss 2.2470\n",
      "step 3800: train loss 2.2184, val loss 2.2422\n",
      "step 3900: train loss 2.2211, val loss 2.2269\n",
      "step 4000: train loss 2.2069, val loss 2.2155\n",
      "step 4100: train loss 2.2128, val loss 2.2243\n",
      "step 4200: train loss 2.1940, val loss 2.2043\n",
      "step 4300: train loss 2.2018, val loss 2.2078\n",
      "step 4400: train loss 2.1916, val loss 2.2025\n",
      "step 4500: train loss 2.1897, val loss 2.2011\n",
      "step 4600: train loss 2.1830, val loss 2.2001\n",
      "step 4700: train loss 2.1758, val loss 2.1847\n",
      "step 4800: train loss 2.1710, val loss 2.1948\n",
      "step 4900: train loss 2.1627, val loss 2.1877\n",
      "step 5000: train loss 2.1560, val loss 2.1789\n",
      "step 5100: train loss 2.1587, val loss 2.1798\n",
      "step 5200: train loss 2.1555, val loss 2.1766\n",
      "step 5300: train loss 2.1597, val loss 2.1782\n",
      "step 5400: train loss 2.1514, val loss 2.1863\n",
      "step 5500: train loss 2.1465, val loss 2.1619\n",
      "step 5600: train loss 2.1361, val loss 2.1657\n",
      "step 5700: train loss 2.1394, val loss 2.1574\n",
      "step 5800: train loss 2.1292, val loss 2.1651\n",
      "step 5900: train loss 2.1437, val loss 2.1629\n",
      "step 6000: train loss 2.1294, val loss 2.1462\n",
      "step 6100: train loss 2.1312, val loss 2.1595\n",
      "step 6200: train loss 2.1282, val loss 2.1420\n",
      "step 6300: train loss 2.1240, val loss 2.1544\n",
      "step 6400: train loss 2.1186, val loss 2.1488\n",
      "step 6500: train loss 2.1110, val loss 2.1388\n",
      "step 6600: train loss 2.1114, val loss 2.1434\n",
      "step 6700: train loss 2.1060, val loss 2.1451\n",
      "step 6800: train loss 2.1123, val loss 2.1476\n",
      "step 6900: train loss 2.0952, val loss 2.1418\n",
      "step 7000: train loss 2.1030, val loss 2.1303\n",
      "step 7100: train loss 2.0961, val loss 2.1324\n",
      "step 7200: train loss 2.0946, val loss 2.1229\n",
      "step 7300: train loss 2.0944, val loss 2.1365\n",
      "step 7400: train loss 2.0867, val loss 2.1349\n",
      "step 7500: train loss 2.0864, val loss 2.1218\n",
      "step 7600: train loss 2.0992, val loss 2.1290\n",
      "step 7700: train loss 2.0884, val loss 2.1210\n",
      "step 7800: train loss 2.0756, val loss 2.1102\n",
      "step 7900: train loss 2.0739, val loss 2.1245\n",
      "step 8000: train loss 2.0780, val loss 2.1100\n",
      "step 8100: train loss 2.0707, val loss 2.1073\n",
      "step 8200: train loss 2.0869, val loss 2.1131\n",
      "step 8300: train loss 2.0604, val loss 2.1143\n",
      "step 8400: train loss 2.0687, val loss 2.1095\n",
      "step 8500: train loss 2.0619, val loss 2.1111\n",
      "step 8600: train loss 2.0549, val loss 2.1051\n",
      "step 8700: train loss 2.0570, val loss 2.1124\n",
      "step 8800: train loss 2.0614, val loss 2.1123\n",
      "step 8900: train loss 2.0585, val loss 2.1033\n",
      "step 9000: train loss 2.0540, val loss 2.1101\n",
      "step 9100: train loss 2.0643, val loss 2.0994\n",
      "step 9200: train loss 2.0557, val loss 2.1060\n",
      "step 9300: train loss 2.0543, val loss 2.1036\n",
      "step 9400: train loss 2.0472, val loss 2.1012\n",
      "step 9500: train loss 2.0518, val loss 2.0941\n",
      "step 9600: train loss 2.0442, val loss 2.1024\n",
      "step 9700: train loss 2.0476, val loss 2.1156\n",
      "step 9800: train loss 2.0427, val loss 2.0917\n",
      "step 9900: train loss 2.0422, val loss 2.0978\n",
      "step 10000: train loss 2.0466, val loss 2.0912\n",
      "step 10100: train loss 2.0377, val loss 2.0971\n",
      "step 10200: train loss 2.0298, val loss 2.0972\n",
      "step 10300: train loss 2.0440, val loss 2.0955\n",
      "step 10400: train loss 2.0376, val loss 2.0955\n",
      "step 10500: train loss 2.0268, val loss 2.0963\n",
      "step 10600: train loss 2.0223, val loss 2.0782\n",
      "step 10700: train loss 2.0298, val loss 2.0789\n",
      "step 10800: train loss 2.0294, val loss 2.0871\n",
      "step 10900: train loss 2.0440, val loss 2.1045\n",
      "step 11000: train loss 2.0256, val loss 2.0804\n",
      "step 11100: train loss 2.0260, val loss 2.0828\n",
      "step 11200: train loss 2.0290, val loss 2.0942\n",
      "step 11300: train loss 2.0245, val loss 2.0749\n",
      "step 11400: train loss 2.0299, val loss 2.0740\n",
      "step 11500: train loss 2.0315, val loss 2.0854\n",
      "step 11600: train loss 2.0108, val loss 2.0762\n",
      "step 11700: train loss 2.0109, val loss 2.0804\n",
      "step 11800: train loss 2.0074, val loss 2.0830\n",
      "step 11900: train loss 2.0249, val loss 2.0905\n",
      "step 12000: train loss 2.0108, val loss 2.0760\n",
      "step 12100: train loss 2.0172, val loss 2.0734\n",
      "step 12200: train loss 2.0063, val loss 2.0868\n",
      "step 12300: train loss 2.0058, val loss 2.0686\n",
      "step 12400: train loss 2.0090, val loss 2.0619\n",
      "step 12500: train loss 2.0110, val loss 2.0835\n",
      "step 12600: train loss 2.0077, val loss 2.0716\n",
      "step 12700: train loss 2.0060, val loss 2.0810\n",
      "step 12800: train loss 2.0117, val loss 2.0754\n",
      "step 12900: train loss 1.9966, val loss 2.0665\n",
      "step 13000: train loss 2.0035, val loss 2.0752\n",
      "step 13100: train loss 2.0038, val loss 2.0846\n",
      "step 13200: train loss 1.9973, val loss 2.0763\n",
      "step 13300: train loss 2.0003, val loss 2.0787\n",
      "step 13400: train loss 1.9966, val loss 2.0741\n",
      "step 13500: train loss 1.9931, val loss 2.0722\n",
      "step 13600: train loss 2.0087, val loss 2.0703\n",
      "step 13700: train loss 1.9929, val loss 2.0741\n",
      "step 13800: train loss 1.9850, val loss 2.0556\n",
      "step 13900: train loss 1.9893, val loss 2.0621\n",
      "step 14000: train loss 1.9875, val loss 2.0624\n",
      "step 14100: train loss 1.9906, val loss 2.0597\n",
      "step 14200: train loss 1.9841, val loss 2.0734\n",
      "step 14300: train loss 1.9798, val loss 2.0741\n",
      "step 14400: train loss 1.9815, val loss 2.0751\n",
      "step 14500: train loss 1.9777, val loss 2.0610\n",
      "step 14600: train loss 1.9897, val loss 2.0625\n",
      "step 14700: train loss 1.9810, val loss 2.0654\n",
      "step 14800: train loss 1.9793, val loss 2.0635\n",
      "step 14900: train loss 1.9841, val loss 2.0551\n",
      "step 15000: train loss 1.9756, val loss 2.0586\n",
      "step 15100: train loss 1.9809, val loss 2.0638\n",
      "step 15200: train loss 1.9686, val loss 2.0536\n",
      "step 15300: train loss 1.9695, val loss 2.0570\n",
      "step 15400: train loss 1.9728, val loss 2.0614\n",
      "step 15500: train loss 1.9543, val loss 2.0622\n",
      "step 15600: train loss 1.9699, val loss 2.0614\n",
      "step 15700: train loss 1.9687, val loss 2.0609\n",
      "step 15800: train loss 1.9752, val loss 2.0603\n",
      "step 15900: train loss 1.9695, val loss 2.0557\n",
      "step 16000: train loss 1.9697, val loss 2.0510\n",
      "step 16100: train loss 1.9694, val loss 2.0503\n",
      "step 16200: train loss 1.9708, val loss 2.0624\n",
      "step 16300: train loss 1.9696, val loss 2.0417\n",
      "step 16400: train loss 1.9669, val loss 2.0490\n",
      "step 16500: train loss 1.9662, val loss 2.0450\n",
      "step 16600: train loss 1.9655, val loss 2.0479\n",
      "step 16700: train loss 1.9656, val loss 2.0358\n",
      "step 16800: train loss 1.9653, val loss 2.0500\n",
      "step 16900: train loss 1.9593, val loss 2.0444\n",
      "step 17000: train loss 1.9613, val loss 2.0579\n",
      "step 17100: train loss 1.9596, val loss 2.0546\n",
      "step 17200: train loss 1.9628, val loss 2.0466\n",
      "step 17300: train loss 1.9644, val loss 2.0476\n",
      "step 17400: train loss 1.9601, val loss 2.0604\n",
      "step 17500: train loss 1.9692, val loss 2.0519\n",
      "step 17600: train loss 1.9589, val loss 2.0462\n",
      "step 17700: train loss 1.9536, val loss 2.0436\n",
      "step 17800: train loss 1.9611, val loss 2.0426\n",
      "step 17900: train loss 1.9528, val loss 2.0491\n",
      "step 18000: train loss 1.9466, val loss 2.0278\n",
      "step 18100: train loss 1.9519, val loss 2.0480\n",
      "step 18200: train loss 1.9481, val loss 2.0464\n",
      "step 18300: train loss 1.9528, val loss 2.0281\n",
      "step 18400: train loss 1.9381, val loss 2.0346\n",
      "step 18500: train loss 1.9383, val loss 2.0417\n",
      "step 18600: train loss 1.9459, val loss 2.0400\n",
      "step 18700: train loss 1.9503, val loss 2.0325\n",
      "step 18800: train loss 1.9507, val loss 2.0415\n",
      "step 18900: train loss 1.9416, val loss 2.0286\n",
      "step 19000: train loss 1.9464, val loss 2.0331\n",
      "step 19100: train loss 1.9443, val loss 2.0264\n",
      "step 19200: train loss 1.9376, val loss 2.0334\n",
      "step 19300: train loss 1.9473, val loss 2.0345\n",
      "step 19400: train loss 1.9432, val loss 2.0290\n",
      "step 19500: train loss 1.9483, val loss 2.0373\n",
      "step 19600: train loss 1.9432, val loss 2.0289\n",
      "step 19700: train loss 1.9368, val loss 2.0241\n",
      "step 19800: train loss 1.9389, val loss 2.0291\n",
      "step 19900: train loss 1.9475, val loss 2.0365\n",
      "step 20000: train loss 1.9432, val loss 2.0301\n",
      "step 20100: train loss 1.9377, val loss 2.0241\n",
      "step 20200: train loss 1.9351, val loss 2.0335\n",
      "step 20300: train loss 1.9223, val loss 2.0285\n",
      "step 20400: train loss 1.9419, val loss 2.0340\n",
      "step 20500: train loss 1.9357, val loss 2.0308\n",
      "step 20600: train loss 1.9359, val loss 2.0332\n",
      "step 20700: train loss 1.9265, val loss 2.0392\n",
      "step 20800: train loss 1.9348, val loss 2.0243\n",
      "step 20900: train loss 1.9282, val loss 2.0388\n",
      "step 21000: train loss 1.9341, val loss 2.0309\n",
      "step 21100: train loss 1.9280, val loss 2.0160\n",
      "step 21200: train loss 1.9291, val loss 2.0317\n",
      "step 21300: train loss 1.9277, val loss 2.0217\n",
      "step 21400: train loss 1.9305, val loss 2.0160\n",
      "step 21500: train loss 1.9207, val loss 2.0196\n",
      "step 21600: train loss 1.9201, val loss 2.0079\n",
      "step 21700: train loss 1.9269, val loss 2.0271\n",
      "step 21800: train loss 1.9311, val loss 2.0316\n",
      "step 21900: train loss 1.9137, val loss 2.0101\n",
      "step 22000: train loss 1.9230, val loss 2.0207\n",
      "step 22100: train loss 1.9173, val loss 2.0179\n",
      "step 22200: train loss 1.9301, val loss 2.0204\n",
      "step 22300: train loss 1.9195, val loss 2.0379\n",
      "step 22400: train loss 1.9162, val loss 2.0344\n",
      "step 22500: train loss 1.9126, val loss 2.0105\n",
      "step 22600: train loss 1.9263, val loss 2.0126\n",
      "step 22700: train loss 1.9139, val loss 2.0156\n",
      "step 22800: train loss 1.9148, val loss 2.0144\n",
      "step 22900: train loss 1.9156, val loss 2.0119\n",
      "step 23000: train loss 1.9160, val loss 2.0304\n",
      "step 23100: train loss 1.9133, val loss 2.0196\n",
      "step 23200: train loss 1.9125, val loss 2.0209\n",
      "step 23300: train loss 1.9070, val loss 2.0187\n",
      "step 23400: train loss 1.9084, val loss 2.0129\n",
      "step 23500: train loss 1.9251, val loss 2.0208\n",
      "step 23600: train loss 1.9129, val loss 2.0030\n",
      "step 23700: train loss 1.9154, val loss 2.0216\n",
      "step 23800: train loss 1.9075, val loss 2.0080\n",
      "step 23900: train loss 1.9109, val loss 2.0219\n",
      "step 24000: train loss 1.8978, val loss 2.0122\n",
      "step 24100: train loss 1.9210, val loss 2.0200\n",
      "step 24200: train loss 1.9120, val loss 1.9997\n",
      "step 24300: train loss 1.9192, val loss 2.0090\n",
      "step 24400: train loss 1.9159, val loss 1.9942\n",
      "step 24500: train loss 1.9185, val loss 2.0076\n",
      "step 24600: train loss 1.9133, val loss 2.0014\n",
      "step 24700: train loss 1.9140, val loss 2.0148\n",
      "step 24800: train loss 1.9009, val loss 2.0190\n",
      "step 24900: train loss 1.8989, val loss 2.0052\n",
      "step 25000: train loss 1.9099, val loss 2.0130\n",
      "step 25100: train loss 1.9069, val loss 2.0113\n",
      "step 25200: train loss 1.9027, val loss 2.0077\n",
      "step 25300: train loss 1.8989, val loss 2.0030\n",
      "step 25400: train loss 1.9191, val loss 2.0161\n",
      "step 25500: train loss 1.8997, val loss 1.9906\n",
      "step 25600: train loss 1.9032, val loss 2.0199\n",
      "step 25700: train loss 1.9044, val loss 2.0075\n",
      "step 25800: train loss 1.8957, val loss 1.9974\n",
      "step 25900: train loss 1.9121, val loss 2.0120\n",
      "step 26000: train loss 1.9031, val loss 2.0080\n",
      "step 26100: train loss 1.8977, val loss 2.0161\n",
      "step 26200: train loss 1.8934, val loss 2.0065\n",
      "step 26300: train loss 1.8987, val loss 2.0018\n",
      "step 26400: train loss 1.9050, val loss 2.0055\n",
      "step 26500: train loss 1.8991, val loss 2.0128\n",
      "step 26600: train loss 1.8869, val loss 2.0140\n",
      "step 26700: train loss 1.8888, val loss 1.9939\n",
      "step 26800: train loss 1.8937, val loss 1.9995\n",
      "step 26900: train loss 1.8954, val loss 1.9967\n",
      "step 27000: train loss 1.8904, val loss 2.0112\n",
      "step 27100: train loss 1.8905, val loss 2.0037\n",
      "step 27200: train loss 1.8871, val loss 2.0012\n",
      "step 27300: train loss 1.8888, val loss 1.9935\n",
      "step 27400: train loss 1.8963, val loss 2.0020\n",
      "step 27500: train loss 1.8836, val loss 2.0053\n",
      "step 27600: train loss 1.8889, val loss 2.0075\n",
      "step 27700: train loss 1.8852, val loss 2.0051\n",
      "step 27800: train loss 1.8915, val loss 1.9993\n",
      "step 27900: train loss 1.8968, val loss 2.0013\n",
      "step 28000: train loss 1.8798, val loss 2.0045\n",
      "step 28100: train loss 1.8869, val loss 1.9973\n",
      "step 28200: train loss 1.8909, val loss 2.0005\n",
      "step 28300: train loss 1.8708, val loss 1.9900\n",
      "step 28400: train loss 1.8849, val loss 1.9971\n",
      "step 28500: train loss 1.8833, val loss 1.9829\n",
      "step 28600: train loss 1.8810, val loss 1.9898\n",
      "step 28700: train loss 1.8974, val loss 2.0087\n",
      "step 28800: train loss 1.8797, val loss 1.9937\n",
      "step 28900: train loss 1.8859, val loss 1.9973\n",
      "step 29000: train loss 1.8848, val loss 1.9895\n",
      "step 29100: train loss 1.8810, val loss 1.9999\n",
      "step 29200: train loss 1.8796, val loss 1.9907\n",
      "step 29300: train loss 1.8853, val loss 1.9985\n",
      "step 29400: train loss 1.8742, val loss 1.9941\n",
      "step 29500: train loss 1.8885, val loss 1.9969\n",
      "step 29600: train loss 1.8835, val loss 1.9920\n",
      "step 29700: train loss 1.8794, val loss 1.9801\n",
      "step 29800: train loss 1.8741, val loss 1.9878\n",
      "step 29900: train loss 1.8798, val loss 1.9853\n",
      "step 30000: train loss 1.8892, val loss 1.9942\n",
      "step 30100: train loss 1.8748, val loss 1.9917\n",
      "step 30200: train loss 1.8823, val loss 2.0034\n",
      "step 30300: train loss 1.8780, val loss 1.9864\n",
      "step 30400: train loss 1.8824, val loss 2.0040\n",
      "step 30500: train loss 1.8860, val loss 1.9914\n",
      "step 30600: train loss 1.8851, val loss 1.9896\n",
      "step 30700: train loss 1.8745, val loss 1.9966\n",
      "step 30800: train loss 1.8699, val loss 1.9946\n",
      "step 30900: train loss 1.8796, val loss 1.9910\n",
      "step 31000: train loss 1.8585, val loss 2.0012\n",
      "step 31100: train loss 1.8716, val loss 1.9817\n",
      "step 31200: train loss 1.8770, val loss 1.9770\n",
      "step 31300: train loss 1.8783, val loss 1.9884\n",
      "step 31400: train loss 1.8656, val loss 1.9852\n",
      "step 31500: train loss 1.8570, val loss 1.9637\n",
      "step 31600: train loss 1.8749, val loss 1.9848\n",
      "step 31700: train loss 1.8858, val loss 1.9825\n",
      "step 31800: train loss 1.8665, val loss 1.9978\n",
      "step 31900: train loss 1.8734, val loss 1.9998\n",
      "step 32000: train loss 1.8702, val loss 2.0019\n",
      "step 32100: train loss 1.8759, val loss 2.0068\n",
      "step 32200: train loss 1.8725, val loss 1.9970\n",
      "step 32300: train loss 1.8645, val loss 1.9938\n",
      "step 32400: train loss 1.8706, val loss 1.9829\n",
      "step 32500: train loss 1.8771, val loss 1.9914\n",
      "step 32600: train loss 1.8619, val loss 1.9933\n",
      "step 32700: train loss 1.8720, val loss 1.9876\n",
      "step 32800: train loss 1.8785, val loss 1.9814\n",
      "step 32900: train loss 1.8689, val loss 1.9908\n",
      "step 33000: train loss 1.8637, val loss 1.9882\n",
      "step 33100: train loss 1.8641, val loss 1.9821\n",
      "step 33200: train loss 1.8768, val loss 1.9927\n",
      "step 33300: train loss 1.8750, val loss 1.9930\n",
      "step 33400: train loss 1.8759, val loss 1.9927\n",
      "step 33500: train loss 1.8691, val loss 2.0015\n",
      "step 33600: train loss 1.8622, val loss 1.9777\n",
      "step 33700: train loss 1.8635, val loss 1.9849\n",
      "step 33800: train loss 1.8604, val loss 1.9946\n",
      "step 33900: train loss 1.8572, val loss 1.9767\n",
      "step 34000: train loss 1.8723, val loss 1.9896\n",
      "step 34100: train loss 1.8602, val loss 1.9920\n",
      "step 34200: train loss 1.8718, val loss 1.9882\n",
      "step 34300: train loss 1.8670, val loss 1.9932\n",
      "step 34400: train loss 1.8671, val loss 1.9736\n",
      "step 34500: train loss 1.8665, val loss 1.9926\n",
      "step 34600: train loss 1.8582, val loss 1.9760\n",
      "step 34700: train loss 1.8656, val loss 1.9957\n",
      "step 34800: train loss 1.8621, val loss 1.9795\n",
      "step 34900: train loss 1.8524, val loss 1.9748\n",
      "step 35000: train loss 1.8530, val loss 1.9793\n",
      "step 35100: train loss 1.8650, val loss 1.9768\n",
      "step 35200: train loss 1.8599, val loss 1.9849\n",
      "step 35300: train loss 1.8574, val loss 1.9837\n",
      "step 35400: train loss 1.8602, val loss 1.9794\n",
      "step 35500: train loss 1.8498, val loss 1.9714\n",
      "step 35600: train loss 1.8555, val loss 1.9712\n",
      "step 35700: train loss 1.8583, val loss 1.9744\n",
      "step 35800: train loss 1.8532, val loss 1.9864\n",
      "step 35900: train loss 1.8628, val loss 1.9868\n",
      "step 36000: train loss 1.8556, val loss 1.9804\n",
      "step 36100: train loss 1.8587, val loss 1.9791\n",
      "step 36200: train loss 1.8590, val loss 1.9759\n",
      "step 36300: train loss 1.8481, val loss 1.9830\n",
      "step 36400: train loss 1.8546, val loss 1.9793\n",
      "step 36500: train loss 1.8574, val loss 1.9898\n",
      "step 36600: train loss 1.8643, val loss 1.9809\n",
      "step 36700: train loss 1.8513, val loss 1.9922\n",
      "step 36800: train loss 1.8533, val loss 1.9810\n",
      "step 36900: train loss 1.8533, val loss 1.9802\n",
      "step 37000: train loss 1.8496, val loss 1.9806\n",
      "step 37100: train loss 1.8559, val loss 1.9744\n",
      "step 37200: train loss 1.8471, val loss 1.9785\n",
      "step 37300: train loss 1.8599, val loss 1.9717\n",
      "step 37400: train loss 1.8693, val loss 1.9889\n",
      "step 37500: train loss 1.8600, val loss 1.9864\n",
      "step 37600: train loss 1.8514, val loss 1.9722\n",
      "step 37700: train loss 1.8497, val loss 1.9736\n",
      "step 37800: train loss 1.8528, val loss 1.9900\n",
      "step 37900: train loss 1.8468, val loss 1.9703\n",
      "step 38000: train loss 1.8454, val loss 1.9784\n",
      "step 38100: train loss 1.8314, val loss 1.9603\n",
      "step 38200: train loss 1.8443, val loss 1.9707\n",
      "step 38300: train loss 1.8491, val loss 1.9632\n",
      "step 38400: train loss 1.8558, val loss 1.9766\n",
      "step 38500: train loss 1.8587, val loss 1.9777\n",
      "step 38600: train loss 1.8481, val loss 1.9598\n",
      "step 38700: train loss 1.8549, val loss 1.9798\n",
      "step 38800: train loss 1.8488, val loss 1.9741\n",
      "step 38900: train loss 1.8489, val loss 1.9607\n",
      "step 39000: train loss 1.8393, val loss 1.9649\n",
      "step 39100: train loss 1.8512, val loss 1.9815\n",
      "step 39200: train loss 1.8429, val loss 1.9652\n",
      "step 39300: train loss 1.8436, val loss 1.9736\n",
      "step 39400: train loss 1.8485, val loss 1.9850\n",
      "step 39500: train loss 1.8446, val loss 1.9633\n",
      "step 39600: train loss 1.8440, val loss 1.9721\n",
      "step 39700: train loss 1.8450, val loss 1.9623\n",
      "step 39800: train loss 1.8456, val loss 1.9836\n",
      "step 39900: train loss 1.8346, val loss 1.9735\n",
      "step 40000: train loss 1.8509, val loss 1.9568\n",
      "step 40100: train loss 1.8392, val loss 1.9717\n",
      "step 40200: train loss 1.8406, val loss 1.9684\n",
      "step 40300: train loss 1.8510, val loss 1.9694\n",
      "step 40400: train loss 1.8473, val loss 1.9610\n",
      "step 40500: train loss 1.8414, val loss 1.9680\n",
      "step 40600: train loss 1.8405, val loss 1.9582\n",
      "step 40700: train loss 1.8434, val loss 1.9648\n",
      "step 40800: train loss 1.8435, val loss 1.9718\n",
      "step 40900: train loss 1.8449, val loss 1.9592\n",
      "step 41000: train loss 1.8499, val loss 1.9657\n",
      "step 41100: train loss 1.8412, val loss 1.9541\n",
      "step 41200: train loss 1.8448, val loss 1.9436\n",
      "step 41300: train loss 1.8479, val loss 1.9584\n",
      "step 41400: train loss 1.8468, val loss 1.9783\n",
      "step 41500: train loss 1.8335, val loss 1.9600\n",
      "step 41600: train loss 1.8564, val loss 1.9673\n",
      "step 41700: train loss 1.8358, val loss 1.9714\n",
      "step 41800: train loss 1.8418, val loss 1.9719\n",
      "step 41900: train loss 1.8370, val loss 1.9740\n",
      "step 42000: train loss 1.8383, val loss 1.9589\n",
      "step 42100: train loss 1.8398, val loss 1.9741\n",
      "step 42200: train loss 1.8451, val loss 1.9781\n",
      "step 42300: train loss 1.8520, val loss 1.9773\n",
      "step 42400: train loss 1.8339, val loss 1.9677\n",
      "step 42500: train loss 1.8490, val loss 1.9679\n",
      "step 42600: train loss 1.8368, val loss 1.9672\n",
      "step 42700: train loss 1.8393, val loss 1.9553\n",
      "step 42800: train loss 1.8456, val loss 1.9656\n",
      "step 42900: train loss 1.8361, val loss 1.9482\n",
      "step 43000: train loss 1.8500, val loss 1.9692\n",
      "step 43100: train loss 1.8293, val loss 1.9609\n",
      "step 43200: train loss 1.8383, val loss 1.9693\n",
      "step 43300: train loss 1.8303, val loss 1.9748\n",
      "step 43400: train loss 1.8383, val loss 1.9656\n",
      "step 43500: train loss 1.8318, val loss 1.9578\n",
      "step 43600: train loss 1.8283, val loss 1.9739\n",
      "step 43700: train loss 1.8448, val loss 1.9538\n",
      "step 43800: train loss 1.8431, val loss 1.9703\n",
      "step 43900: train loss 1.8401, val loss 1.9831\n",
      "step 44000: train loss 1.8380, val loss 1.9623\n",
      "step 44100: train loss 1.8381, val loss 1.9569\n",
      "step 44200: train loss 1.8401, val loss 1.9561\n",
      "step 44300: train loss 1.8373, val loss 1.9644\n",
      "step 44400: train loss 1.8415, val loss 1.9670\n",
      "step 44500: train loss 1.8251, val loss 1.9613\n",
      "step 44600: train loss 1.8218, val loss 1.9660\n",
      "step 44700: train loss 1.8276, val loss 1.9642\n",
      "step 44800: train loss 1.8325, val loss 1.9588\n",
      "step 44900: train loss 1.8301, val loss 1.9685\n",
      "step 45000: train loss 1.8326, val loss 1.9752\n",
      "step 45100: train loss 1.8417, val loss 1.9718\n",
      "step 45200: train loss 1.8295, val loss 1.9657\n",
      "step 45300: train loss 1.8307, val loss 1.9704\n",
      "step 45400: train loss 1.8248, val loss 1.9628\n",
      "step 45500: train loss 1.8351, val loss 1.9621\n",
      "step 45600: train loss 1.8331, val loss 1.9569\n",
      "step 45700: train loss 1.8228, val loss 1.9642\n",
      "step 45800: train loss 1.8342, val loss 1.9610\n",
      "step 45900: train loss 1.8449, val loss 1.9653\n",
      "step 46000: train loss 1.8213, val loss 1.9624\n",
      "step 46100: train loss 1.8184, val loss 1.9541\n",
      "step 46200: train loss 1.8271, val loss 1.9565\n",
      "step 46300: train loss 1.8311, val loss 1.9694\n",
      "step 46400: train loss 1.8256, val loss 1.9639\n",
      "step 46500: train loss 1.8211, val loss 1.9672\n",
      "step 46600: train loss 1.8307, val loss 1.9618\n",
      "step 46700: train loss 1.8263, val loss 1.9477\n",
      "step 46800: train loss 1.8424, val loss 1.9716\n",
      "step 46900: train loss 1.8251, val loss 1.9581\n",
      "step 47000: train loss 1.8201, val loss 1.9527\n",
      "step 47100: train loss 1.8303, val loss 1.9662\n",
      "step 47200: train loss 1.8240, val loss 1.9656\n",
      "step 47300: train loss 1.8370, val loss 1.9694\n",
      "step 47400: train loss 1.8148, val loss 1.9721\n",
      "step 47500: train loss 1.8234, val loss 1.9585\n",
      "step 47600: train loss 1.8329, val loss 1.9661\n",
      "step 47700: train loss 1.8209, val loss 1.9543\n",
      "step 47800: train loss 1.8331, val loss 1.9613\n",
      "step 47900: train loss 1.8162, val loss 1.9580\n",
      "step 48000: train loss 1.8395, val loss 1.9592\n",
      "step 48100: train loss 1.8319, val loss 1.9587\n",
      "step 48200: train loss 1.8294, val loss 1.9711\n",
      "step 48300: train loss 1.8342, val loss 1.9536\n",
      "step 48400: train loss 1.8168, val loss 1.9546\n",
      "step 48500: train loss 1.8269, val loss 1.9482\n",
      "step 48600: train loss 1.8333, val loss 1.9615\n",
      "step 48700: train loss 1.8279, val loss 1.9572\n",
      "step 48800: train loss 1.8241, val loss 1.9536\n",
      "step 48900: train loss 1.8152, val loss 1.9557\n",
      "step 49000: train loss 1.8352, val loss 1.9637\n",
      "step 49100: train loss 1.8150, val loss 1.9550\n",
      "step 49200: train loss 1.8168, val loss 1.9614\n",
      "step 49300: train loss 1.8213, val loss 1.9653\n",
      "step 49400: train loss 1.8221, val loss 1.9548\n",
      "step 49500: train loss 1.8216, val loss 1.9389\n",
      "step 49600: train loss 1.8119, val loss 1.9585\n",
      "step 49700: train loss 1.8370, val loss 1.9588\n",
      "step 49800: train loss 1.8260, val loss 1.9644\n",
      "step 49900: train loss 1.8242, val loss 1.9475\n",
      "step 49999: train loss 1.8183, val loss 1.9599\n",
      "Results for configuration res1_dropout=0.5_res2_dropout=0.99_res4_dropout=0.0_use_double_layers=False saved.\n",
      "Training model with configuration: {'res1_dropout': 0.025, 'res2_dropout': 0.1, 'res4_dropout': 0.0, 'use_double_layers': False}\n",
      "step 0: train loss 4.4326, val loss 4.4304\n",
      "step 100: train loss 2.7721, val loss 2.7840\n",
      "step 200: train loss 2.5685, val loss 2.5824\n",
      "step 300: train loss 2.4972, val loss 2.5030\n",
      "step 400: train loss 2.4584, val loss 2.4614\n",
      "step 500: train loss 2.4101, val loss 2.4226\n",
      "step 600: train loss 2.3658, val loss 2.3746\n",
      "step 700: train loss 2.3328, val loss 2.3356\n",
      "step 800: train loss 2.3048, val loss 2.3188\n",
      "step 900: train loss 2.2864, val loss 2.2896\n",
      "step 1000: train loss 2.2531, val loss 2.2670\n",
      "step 1100: train loss 2.2247, val loss 2.2357\n",
      "step 1200: train loss 2.2051, val loss 2.2258\n",
      "step 1300: train loss 2.1825, val loss 2.2089\n",
      "step 1400: train loss 2.1701, val loss 2.1951\n",
      "step 1500: train loss 2.1437, val loss 2.1819\n",
      "step 1600: train loss 2.1286, val loss 2.1507\n",
      "step 1700: train loss 2.1147, val loss 2.1432\n",
      "step 1800: train loss 2.1046, val loss 2.1449\n",
      "step 1900: train loss 2.1060, val loss 2.1327\n",
      "step 2000: train loss 2.0770, val loss 2.1148\n",
      "step 2100: train loss 2.0681, val loss 2.1116\n",
      "step 2200: train loss 2.0676, val loss 2.0967\n",
      "step 2300: train loss 2.0506, val loss 2.1002\n",
      "step 2400: train loss 2.0405, val loss 2.0950\n",
      "step 2500: train loss 2.0238, val loss 2.0781\n",
      "step 2600: train loss 2.0224, val loss 2.0721\n",
      "step 2700: train loss 2.0243, val loss 2.0606\n",
      "step 2800: train loss 2.0131, val loss 2.0579\n",
      "step 2900: train loss 2.0033, val loss 2.0549\n",
      "step 3000: train loss 1.9867, val loss 2.0417\n",
      "step 3100: train loss 1.9884, val loss 2.0525\n",
      "step 3200: train loss 1.9901, val loss 2.0455\n",
      "step 3300: train loss 1.9748, val loss 2.0469\n",
      "step 3400: train loss 1.9619, val loss 2.0239\n",
      "step 3500: train loss 1.9494, val loss 2.0286\n",
      "step 3600: train loss 1.9640, val loss 2.0197\n",
      "step 3700: train loss 1.9475, val loss 2.0165\n",
      "step 3800: train loss 1.9490, val loss 2.0074\n",
      "step 3900: train loss 1.9313, val loss 2.0139\n",
      "step 4000: train loss 1.9431, val loss 2.0185\n",
      "step 4100: train loss 1.9292, val loss 2.0021\n",
      "step 4200: train loss 1.9229, val loss 2.0055\n",
      "step 4300: train loss 1.9202, val loss 1.9917\n",
      "step 4400: train loss 1.9251, val loss 2.0091\n",
      "step 4500: train loss 1.9314, val loss 2.0120\n",
      "step 4600: train loss 1.8996, val loss 1.9860\n",
      "step 4700: train loss 1.9098, val loss 1.9945\n",
      "step 4800: train loss 1.9010, val loss 1.9970\n",
      "step 4900: train loss 1.8928, val loss 1.9861\n",
      "step 5000: train loss 1.8965, val loss 1.9832\n",
      "step 5100: train loss 1.8810, val loss 1.9897\n",
      "step 5200: train loss 1.8778, val loss 1.9832\n",
      "step 5300: train loss 1.8828, val loss 1.9803\n",
      "step 5400: train loss 1.8765, val loss 1.9796\n",
      "step 5500: train loss 1.8712, val loss 1.9773\n",
      "step 5600: train loss 1.8674, val loss 1.9758\n",
      "step 5700: train loss 1.8599, val loss 1.9728\n",
      "step 5800: train loss 1.8684, val loss 1.9600\n",
      "step 5900: train loss 1.8615, val loss 1.9711\n",
      "step 6000: train loss 1.8606, val loss 1.9691\n",
      "step 6100: train loss 1.8507, val loss 1.9550\n",
      "step 6200: train loss 1.8566, val loss 1.9601\n",
      "step 6300: train loss 1.8487, val loss 1.9523\n",
      "step 6400: train loss 1.8415, val loss 1.9457\n",
      "step 6500: train loss 1.8498, val loss 1.9535\n",
      "step 6600: train loss 1.8388, val loss 1.9494\n",
      "step 6700: train loss 1.8382, val loss 1.9417\n",
      "step 6800: train loss 1.8415, val loss 1.9453\n",
      "step 6900: train loss 1.8269, val loss 1.9588\n",
      "step 7000: train loss 1.8403, val loss 1.9575\n",
      "step 7100: train loss 1.8266, val loss 1.9442\n",
      "step 7200: train loss 1.8235, val loss 1.9415\n",
      "step 7300: train loss 1.8202, val loss 1.9542\n",
      "step 7400: train loss 1.8092, val loss 1.9328\n",
      "step 7500: train loss 1.8243, val loss 1.9352\n",
      "step 7600: train loss 1.8258, val loss 1.9365\n",
      "step 7700: train loss 1.8110, val loss 1.9383\n",
      "step 7800: train loss 1.8094, val loss 1.9303\n",
      "step 7900: train loss 1.8107, val loss 1.9227\n",
      "step 8000: train loss 1.8156, val loss 1.9440\n",
      "step 8100: train loss 1.8085, val loss 1.9215\n",
      "step 8200: train loss 1.8112, val loss 1.9196\n",
      "step 8300: train loss 1.8017, val loss 1.9235\n",
      "step 8400: train loss 1.8013, val loss 1.9379\n",
      "step 8500: train loss 1.7933, val loss 1.9301\n",
      "step 8600: train loss 1.7972, val loss 1.9339\n",
      "step 8700: train loss 1.7856, val loss 1.9366\n",
      "step 8800: train loss 1.7979, val loss 1.9326\n",
      "step 8900: train loss 1.7834, val loss 1.9204\n",
      "step 9000: train loss 1.7906, val loss 1.9405\n",
      "step 9100: train loss 1.7849, val loss 1.9120\n",
      "step 9200: train loss 1.7819, val loss 1.9173\n",
      "step 9300: train loss 1.7814, val loss 1.9279\n",
      "step 9400: train loss 1.7875, val loss 1.9041\n",
      "step 9500: train loss 1.7804, val loss 1.9213\n",
      "step 9600: train loss 1.7756, val loss 1.9168\n",
      "step 9700: train loss 1.7882, val loss 1.9340\n",
      "step 9800: train loss 1.7765, val loss 1.9189\n",
      "step 9900: train loss 1.7801, val loss 1.9197\n",
      "step 10000: train loss 1.7703, val loss 1.9177\n",
      "step 10100: train loss 1.7810, val loss 1.9120\n",
      "step 10200: train loss 1.7755, val loss 1.9141\n",
      "step 10300: train loss 1.7796, val loss 1.9118\n",
      "step 10400: train loss 1.7787, val loss 1.9119\n",
      "step 10500: train loss 1.7635, val loss 1.9115\n",
      "step 10600: train loss 1.7768, val loss 1.9128\n",
      "step 10700: train loss 1.7570, val loss 1.9041\n",
      "step 10800: train loss 1.7596, val loss 1.9057\n",
      "step 10900: train loss 1.7532, val loss 1.9100\n",
      "step 11000: train loss 1.7672, val loss 1.9147\n",
      "step 11100: train loss 1.7644, val loss 1.9002\n",
      "step 11200: train loss 1.7619, val loss 1.9025\n",
      "step 11300: train loss 1.7540, val loss 1.8977\n",
      "step 11400: train loss 1.7585, val loss 1.9025\n",
      "step 11500: train loss 1.7459, val loss 1.9004\n",
      "step 11600: train loss 1.7600, val loss 1.8894\n",
      "step 11700: train loss 1.7507, val loss 1.8843\n",
      "step 11800: train loss 1.7568, val loss 1.9025\n",
      "step 11900: train loss 1.7478, val loss 1.8992\n",
      "step 12000: train loss 1.7280, val loss 1.8788\n",
      "step 12100: train loss 1.7472, val loss 1.8859\n",
      "step 12200: train loss 1.7398, val loss 1.8870\n",
      "step 12300: train loss 1.7435, val loss 1.9049\n",
      "step 12400: train loss 1.7432, val loss 1.8996\n",
      "step 12500: train loss 1.7496, val loss 1.8925\n",
      "step 12600: train loss 1.7443, val loss 1.8969\n",
      "step 12700: train loss 1.7455, val loss 1.8956\n",
      "step 12800: train loss 1.7427, val loss 1.8937\n",
      "step 12900: train loss 1.7346, val loss 1.8898\n",
      "step 13000: train loss 1.7371, val loss 1.8940\n",
      "step 13100: train loss 1.7403, val loss 1.8883\n",
      "step 13200: train loss 1.7450, val loss 1.8898\n",
      "step 13300: train loss 1.7336, val loss 1.8713\n",
      "step 13400: train loss 1.7400, val loss 1.8802\n",
      "step 13500: train loss 1.7274, val loss 1.8915\n",
      "step 13600: train loss 1.7228, val loss 1.8830\n",
      "step 13700: train loss 1.7338, val loss 1.8791\n",
      "step 13800: train loss 1.7374, val loss 1.8957\n",
      "step 13900: train loss 1.7399, val loss 1.8822\n",
      "step 14000: train loss 1.7270, val loss 1.8775\n",
      "step 14100: train loss 1.7287, val loss 1.8762\n",
      "step 14200: train loss 1.7204, val loss 1.8714\n",
      "step 14300: train loss 1.7445, val loss 1.8834\n",
      "step 14400: train loss 1.7223, val loss 1.8867\n",
      "step 14500: train loss 1.7245, val loss 1.8821\n",
      "step 14600: train loss 1.7191, val loss 1.8735\n",
      "step 14700: train loss 1.7218, val loss 1.8645\n",
      "step 14800: train loss 1.7155, val loss 1.8727\n",
      "step 14900: train loss 1.7155, val loss 1.8740\n",
      "step 15000: train loss 1.7243, val loss 1.8770\n",
      "step 15100: train loss 1.7261, val loss 1.8697\n",
      "step 15200: train loss 1.7238, val loss 1.8683\n",
      "step 15300: train loss 1.7105, val loss 1.8584\n",
      "step 15400: train loss 1.7190, val loss 1.8715\n",
      "step 15500: train loss 1.7074, val loss 1.8712\n",
      "step 15600: train loss 1.7190, val loss 1.8651\n",
      "step 15700: train loss 1.7089, val loss 1.8707\n",
      "step 15800: train loss 1.7125, val loss 1.8587\n",
      "step 15900: train loss 1.7157, val loss 1.8639\n",
      "step 16000: train loss 1.7128, val loss 1.8648\n",
      "step 16100: train loss 1.7135, val loss 1.8664\n",
      "step 16200: train loss 1.7081, val loss 1.8675\n",
      "step 16300: train loss 1.7028, val loss 1.8689\n",
      "step 16400: train loss 1.7074, val loss 1.8578\n",
      "step 16500: train loss 1.6973, val loss 1.8612\n",
      "step 16600: train loss 1.7180, val loss 1.8655\n",
      "step 16700: train loss 1.7176, val loss 1.8721\n",
      "step 16800: train loss 1.6975, val loss 1.8732\n",
      "step 16900: train loss 1.7034, val loss 1.8610\n",
      "step 17000: train loss 1.7137, val loss 1.8615\n",
      "step 17100: train loss 1.7131, val loss 1.8868\n",
      "step 17200: train loss 1.7043, val loss 1.8613\n",
      "step 17300: train loss 1.6952, val loss 1.8620\n",
      "step 17400: train loss 1.7022, val loss 1.8654\n",
      "step 17500: train loss 1.7034, val loss 1.8599\n",
      "step 17600: train loss 1.7066, val loss 1.8633\n",
      "step 17700: train loss 1.6966, val loss 1.8547\n",
      "step 17800: train loss 1.7017, val loss 1.8607\n",
      "step 17900: train loss 1.7064, val loss 1.8616\n",
      "step 18000: train loss 1.7076, val loss 1.8536\n",
      "step 18100: train loss 1.7003, val loss 1.8607\n",
      "step 18200: train loss 1.6917, val loss 1.8539\n",
      "step 18300: train loss 1.6937, val loss 1.8502\n",
      "step 18400: train loss 1.7050, val loss 1.8444\n",
      "step 18500: train loss 1.6963, val loss 1.8488\n",
      "step 18600: train loss 1.6986, val loss 1.8586\n",
      "step 18700: train loss 1.7092, val loss 1.8583\n",
      "step 18800: train loss 1.7030, val loss 1.8573\n",
      "step 18900: train loss 1.6943, val loss 1.8595\n",
      "step 19000: train loss 1.6887, val loss 1.8582\n",
      "step 19100: train loss 1.6936, val loss 1.8597\n",
      "step 19200: train loss 1.6880, val loss 1.8523\n",
      "step 19300: train loss 1.6987, val loss 1.8588\n",
      "step 19400: train loss 1.6989, val loss 1.8581\n",
      "step 19500: train loss 1.6847, val loss 1.8475\n",
      "step 19600: train loss 1.6890, val loss 1.8512\n",
      "step 19700: train loss 1.7040, val loss 1.8500\n",
      "step 19800: train loss 1.6965, val loss 1.8653\n",
      "step 19900: train loss 1.6861, val loss 1.8496\n",
      "step 20000: train loss 1.6998, val loss 1.8478\n",
      "step 20100: train loss 1.6814, val loss 1.8621\n",
      "step 20200: train loss 1.7019, val loss 1.8517\n",
      "step 20300: train loss 1.6912, val loss 1.8568\n",
      "step 20400: train loss 1.6871, val loss 1.8502\n",
      "step 20500: train loss 1.6864, val loss 1.8438\n",
      "step 20600: train loss 1.6927, val loss 1.8423\n",
      "step 20700: train loss 1.6866, val loss 1.8471\n",
      "step 20800: train loss 1.6872, val loss 1.8516\n",
      "step 20900: train loss 1.6834, val loss 1.8510\n",
      "step 21000: train loss 1.6839, val loss 1.8475\n",
      "step 21100: train loss 1.6892, val loss 1.8423\n",
      "step 21200: train loss 1.6806, val loss 1.8413\n",
      "step 21300: train loss 1.6943, val loss 1.8540\n",
      "step 21400: train loss 1.6815, val loss 1.8502\n",
      "step 21500: train loss 1.6844, val loss 1.8307\n",
      "step 21600: train loss 1.6815, val loss 1.8450\n",
      "step 21700: train loss 1.6772, val loss 1.8429\n",
      "step 21800: train loss 1.6770, val loss 1.8486\n",
      "step 21900: train loss 1.6857, val loss 1.8465\n",
      "step 22000: train loss 1.6832, val loss 1.8368\n",
      "step 22100: train loss 1.6863, val loss 1.8422\n",
      "step 22200: train loss 1.6761, val loss 1.8539\n",
      "step 22300: train loss 1.6817, val loss 1.8506\n",
      "step 22400: train loss 1.6826, val loss 1.8558\n",
      "step 22500: train loss 1.6787, val loss 1.8458\n",
      "step 22600: train loss 1.6748, val loss 1.8337\n",
      "step 22700: train loss 1.6816, val loss 1.8512\n",
      "step 22800: train loss 1.6779, val loss 1.8394\n",
      "step 22900: train loss 1.6890, val loss 1.8360\n",
      "step 23000: train loss 1.6746, val loss 1.8516\n",
      "step 23100: train loss 1.6817, val loss 1.8420\n",
      "step 23200: train loss 1.6877, val loss 1.8477\n",
      "step 23300: train loss 1.6770, val loss 1.8437\n",
      "step 23400: train loss 1.6688, val loss 1.8451\n",
      "step 23500: train loss 1.6648, val loss 1.8350\n",
      "step 23600: train loss 1.6920, val loss 1.8400\n",
      "step 23700: train loss 1.6767, val loss 1.8573\n",
      "step 23800: train loss 1.6811, val loss 1.8219\n",
      "step 23900: train loss 1.6793, val loss 1.8267\n",
      "step 24000: train loss 1.6732, val loss 1.8297\n",
      "step 24100: train loss 1.6755, val loss 1.8362\n",
      "step 24200: train loss 1.6834, val loss 1.8233\n",
      "step 24300: train loss 1.6652, val loss 1.8367\n",
      "step 24400: train loss 1.6694, val loss 1.8333\n",
      "step 24500: train loss 1.6738, val loss 1.8355\n",
      "step 24600: train loss 1.6624, val loss 1.8341\n",
      "step 24700: train loss 1.6781, val loss 1.8567\n",
      "step 24800: train loss 1.6726, val loss 1.8264\n",
      "step 24900: train loss 1.6720, val loss 1.8504\n",
      "step 25000: train loss 1.6696, val loss 1.8239\n",
      "step 25100: train loss 1.6786, val loss 1.8499\n",
      "step 25200: train loss 1.6628, val loss 1.8337\n",
      "step 25300: train loss 1.6555, val loss 1.8307\n",
      "step 25400: train loss 1.6633, val loss 1.8165\n",
      "step 25500: train loss 1.6681, val loss 1.8278\n",
      "step 25600: train loss 1.6676, val loss 1.8419\n",
      "step 25700: train loss 1.6582, val loss 1.8241\n",
      "step 25800: train loss 1.6661, val loss 1.8391\n",
      "step 25900: train loss 1.6708, val loss 1.8282\n",
      "step 26000: train loss 1.6667, val loss 1.8213\n",
      "step 26100: train loss 1.6720, val loss 1.8235\n",
      "step 26200: train loss 1.6666, val loss 1.8303\n",
      "step 26300: train loss 1.6672, val loss 1.8310\n",
      "step 26400: train loss 1.6674, val loss 1.8307\n",
      "step 26500: train loss 1.6756, val loss 1.8269\n",
      "step 26600: train loss 1.6773, val loss 1.8345\n",
      "step 26700: train loss 1.6604, val loss 1.8281\n",
      "step 26800: train loss 1.6645, val loss 1.8244\n",
      "step 26900: train loss 1.6698, val loss 1.8279\n",
      "step 27000: train loss 1.6586, val loss 1.8231\n",
      "step 27100: train loss 1.6706, val loss 1.8288\n",
      "step 27200: train loss 1.6654, val loss 1.8158\n",
      "step 27300: train loss 1.6644, val loss 1.8132\n",
      "step 27400: train loss 1.6647, val loss 1.8151\n",
      "step 27500: train loss 1.6619, val loss 1.8123\n",
      "step 27600: train loss 1.6671, val loss 1.8339\n",
      "step 27700: train loss 1.6621, val loss 1.8324\n",
      "step 27800: train loss 1.6542, val loss 1.8147\n",
      "step 27900: train loss 1.6613, val loss 1.8117\n",
      "step 28000: train loss 1.6635, val loss 1.8256\n",
      "step 28100: train loss 1.6707, val loss 1.8260\n",
      "step 28200: train loss 1.6592, val loss 1.8181\n",
      "step 28300: train loss 1.6643, val loss 1.8181\n",
      "step 28400: train loss 1.6596, val loss 1.8255\n",
      "step 28500: train loss 1.6520, val loss 1.8230\n",
      "step 28600: train loss 1.6682, val loss 1.8230\n",
      "step 28700: train loss 1.6656, val loss 1.8140\n",
      "step 28800: train loss 1.6657, val loss 1.8365\n",
      "step 28900: train loss 1.6687, val loss 1.8269\n",
      "step 29000: train loss 1.6472, val loss 1.8101\n",
      "step 29100: train loss 1.6497, val loss 1.8319\n",
      "step 29200: train loss 1.6469, val loss 1.8289\n",
      "step 29300: train loss 1.6715, val loss 1.8172\n",
      "step 29400: train loss 1.6638, val loss 1.8206\n",
      "step 29500: train loss 1.6500, val loss 1.8253\n",
      "step 29600: train loss 1.6582, val loss 1.8157\n",
      "step 29700: train loss 1.6620, val loss 1.8235\n",
      "step 29800: train loss 1.6476, val loss 1.8122\n",
      "step 29900: train loss 1.6490, val loss 1.8261\n",
      "step 30000: train loss 1.6524, val loss 1.8289\n",
      "step 30100: train loss 1.6566, val loss 1.8188\n",
      "step 30200: train loss 1.6686, val loss 1.8188\n",
      "step 30300: train loss 1.6521, val loss 1.8200\n",
      "step 30400: train loss 1.6557, val loss 1.8198\n",
      "step 30500: train loss 1.6518, val loss 1.8324\n",
      "step 30600: train loss 1.6600, val loss 1.8326\n",
      "step 30700: train loss 1.6426, val loss 1.8268\n",
      "step 30800: train loss 1.6543, val loss 1.8262\n",
      "step 30900: train loss 1.6476, val loss 1.8282\n",
      "step 31000: train loss 1.6556, val loss 1.8028\n",
      "step 31100: train loss 1.6507, val loss 1.8151\n",
      "step 31200: train loss 1.6566, val loss 1.8081\n",
      "step 31300: train loss 1.6522, val loss 1.8150\n",
      "step 31400: train loss 1.6478, val loss 1.8225\n",
      "step 31500: train loss 1.6438, val loss 1.8220\n",
      "step 31600: train loss 1.6629, val loss 1.8035\n",
      "step 31700: train loss 1.6566, val loss 1.8318\n",
      "step 31800: train loss 1.6541, val loss 1.8159\n",
      "step 31900: train loss 1.6591, val loss 1.8126\n",
      "step 32000: train loss 1.6468, val loss 1.8061\n",
      "step 32100: train loss 1.6501, val loss 1.8175\n",
      "step 32200: train loss 1.6568, val loss 1.8116\n",
      "step 32300: train loss 1.6498, val loss 1.7955\n",
      "step 32400: train loss 1.6513, val loss 1.8010\n",
      "step 32500: train loss 1.6501, val loss 1.8134\n",
      "step 32600: train loss 1.6452, val loss 1.8033\n",
      "step 32700: train loss 1.6520, val loss 1.8132\n",
      "step 32800: train loss 1.6476, val loss 1.8231\n",
      "step 32900: train loss 1.6489, val loss 1.8117\n",
      "step 33000: train loss 1.6611, val loss 1.8119\n",
      "step 33100: train loss 1.6392, val loss 1.8148\n",
      "step 33200: train loss 1.6392, val loss 1.8167\n",
      "step 33300: train loss 1.6452, val loss 1.8122\n",
      "step 33400: train loss 1.6427, val loss 1.8073\n",
      "step 33500: train loss 1.6544, val loss 1.8156\n",
      "step 33600: train loss 1.6544, val loss 1.8285\n",
      "step 33700: train loss 1.6408, val loss 1.8147\n",
      "step 33800: train loss 1.6490, val loss 1.8149\n",
      "step 33900: train loss 1.6492, val loss 1.8264\n",
      "step 34000: train loss 1.6514, val loss 1.8187\n",
      "step 34100: train loss 1.6431, val loss 1.8191\n",
      "step 34200: train loss 1.6414, val loss 1.8084\n",
      "step 34300: train loss 1.6455, val loss 1.8273\n",
      "step 34400: train loss 1.6557, val loss 1.8130\n",
      "step 34500: train loss 1.6467, val loss 1.8021\n",
      "step 34600: train loss 1.6420, val loss 1.8123\n",
      "step 34700: train loss 1.6494, val loss 1.8171\n",
      "step 34800: train loss 1.6349, val loss 1.8127\n",
      "step 34900: train loss 1.6384, val loss 1.8064\n",
      "step 35000: train loss 1.6407, val loss 1.8214\n",
      "step 35100: train loss 1.6469, val loss 1.8093\n",
      "step 35200: train loss 1.6365, val loss 1.8068\n",
      "step 35300: train loss 1.6423, val loss 1.8145\n",
      "step 35400: train loss 1.6511, val loss 1.7970\n",
      "step 35500: train loss 1.6471, val loss 1.8077\n",
      "step 35600: train loss 1.6406, val loss 1.8085\n",
      "step 35700: train loss 1.6444, val loss 1.7956\n",
      "step 35800: train loss 1.6440, val loss 1.7909\n",
      "step 35900: train loss 1.6339, val loss 1.8064\n",
      "step 36000: train loss 1.6432, val loss 1.8058\n",
      "step 36100: train loss 1.6420, val loss 1.7932\n",
      "step 36200: train loss 1.6457, val loss 1.8164\n",
      "step 36300: train loss 1.6531, val loss 1.7932\n",
      "step 36400: train loss 1.6431, val loss 1.7799\n",
      "step 36500: train loss 1.6390, val loss 1.8014\n",
      "step 36600: train loss 1.6460, val loss 1.7989\n",
      "step 36700: train loss 1.6495, val loss 1.8029\n",
      "step 36800: train loss 1.6325, val loss 1.8031\n",
      "step 36900: train loss 1.6469, val loss 1.7973\n",
      "step 37000: train loss 1.6495, val loss 1.8049\n",
      "step 37100: train loss 1.6384, val loss 1.7945\n",
      "step 37200: train loss 1.6490, val loss 1.7972\n",
      "step 37300: train loss 1.6438, val loss 1.7997\n",
      "step 37400: train loss 1.6401, val loss 1.8086\n",
      "step 37500: train loss 1.6298, val loss 1.7928\n",
      "step 37600: train loss 1.6388, val loss 1.8157\n",
      "step 37700: train loss 1.6414, val loss 1.7969\n",
      "step 37800: train loss 1.6462, val loss 1.8050\n",
      "step 37900: train loss 1.6224, val loss 1.8023\n",
      "step 38000: train loss 1.6468, val loss 1.8042\n",
      "step 38100: train loss 1.6296, val loss 1.8052\n",
      "step 38200: train loss 1.6413, val loss 1.7979\n",
      "step 38300: train loss 1.6375, val loss 1.8054\n",
      "step 38400: train loss 1.6386, val loss 1.7850\n",
      "step 38500: train loss 1.6423, val loss 1.8145\n",
      "step 38600: train loss 1.6400, val loss 1.8041\n",
      "step 38700: train loss 1.6434, val loss 1.8126\n",
      "step 38800: train loss 1.6365, val loss 1.8033\n",
      "step 38900: train loss 1.6355, val loss 1.8044\n",
      "step 39000: train loss 1.6451, val loss 1.8063\n",
      "step 39100: train loss 1.6359, val loss 1.8014\n",
      "step 39200: train loss 1.6509, val loss 1.7943\n",
      "step 39300: train loss 1.6404, val loss 1.8063\n",
      "step 39400: train loss 1.6222, val loss 1.8085\n",
      "step 39500: train loss 1.6411, val loss 1.7932\n",
      "step 39600: train loss 1.6325, val loss 1.7891\n",
      "step 39700: train loss 1.6333, val loss 1.8027\n",
      "step 39800: train loss 1.6373, val loss 1.7926\n",
      "step 39900: train loss 1.6284, val loss 1.8034\n",
      "step 40000: train loss 1.6420, val loss 1.7862\n",
      "step 40100: train loss 1.6466, val loss 1.7918\n",
      "step 40200: train loss 1.6377, val loss 1.7913\n",
      "step 40300: train loss 1.6341, val loss 1.7958\n",
      "step 40400: train loss 1.6389, val loss 1.7969\n",
      "step 40500: train loss 1.6386, val loss 1.7995\n",
      "step 40600: train loss 1.6415, val loss 1.8017\n",
      "step 40700: train loss 1.6276, val loss 1.8051\n",
      "step 40800: train loss 1.6300, val loss 1.7875\n",
      "step 40900: train loss 1.6292, val loss 1.7912\n",
      "step 41000: train loss 1.6378, val loss 1.7900\n",
      "step 41100: train loss 1.6365, val loss 1.7798\n",
      "step 41200: train loss 1.6414, val loss 1.7880\n",
      "step 41300: train loss 1.6328, val loss 1.7920\n",
      "step 41400: train loss 1.6291, val loss 1.7977\n",
      "step 41500: train loss 1.6384, val loss 1.7962\n",
      "step 41600: train loss 1.6309, val loss 1.7949\n",
      "step 41700: train loss 1.6421, val loss 1.7952\n",
      "step 41800: train loss 1.6368, val loss 1.7997\n",
      "step 41900: train loss 1.6327, val loss 1.7906\n",
      "step 42000: train loss 1.6314, val loss 1.8009\n",
      "step 42100: train loss 1.6349, val loss 1.7887\n",
      "step 42200: train loss 1.6301, val loss 1.8003\n",
      "step 42300: train loss 1.6423, val loss 1.7917\n",
      "step 42400: train loss 1.6209, val loss 1.7910\n",
      "step 42500: train loss 1.6265, val loss 1.7973\n",
      "step 42600: train loss 1.6342, val loss 1.7777\n",
      "step 42700: train loss 1.6303, val loss 1.7995\n",
      "step 42800: train loss 1.6307, val loss 1.8049\n",
      "step 42900: train loss 1.6299, val loss 1.8049\n",
      "step 43000: train loss 1.6373, val loss 1.8032\n",
      "step 43100: train loss 1.6352, val loss 1.8017\n",
      "step 43200: train loss 1.6389, val loss 1.7923\n",
      "step 43300: train loss 1.6418, val loss 1.8035\n",
      "step 43400: train loss 1.6292, val loss 1.8145\n",
      "step 43500: train loss 1.6329, val loss 1.7937\n",
      "step 43600: train loss 1.6287, val loss 1.7963\n",
      "step 43700: train loss 1.6401, val loss 1.7923\n",
      "step 43800: train loss 1.6411, val loss 1.7956\n",
      "step 43900: train loss 1.6335, val loss 1.7997\n",
      "step 44000: train loss 1.6334, val loss 1.8015\n",
      "step 44100: train loss 1.6242, val loss 1.7849\n",
      "step 44200: train loss 1.6364, val loss 1.7872\n",
      "step 44300: train loss 1.6221, val loss 1.8012\n",
      "step 44400: train loss 1.6373, val loss 1.7961\n",
      "step 44500: train loss 1.6363, val loss 1.7892\n",
      "step 44600: train loss 1.6275, val loss 1.7903\n",
      "step 44700: train loss 1.6166, val loss 1.7831\n",
      "step 44800: train loss 1.6271, val loss 1.7783\n",
      "step 44900: train loss 1.6252, val loss 1.7933\n",
      "step 45000: train loss 1.6243, val loss 1.7871\n",
      "step 45100: train loss 1.6260, val loss 1.7826\n",
      "step 45200: train loss 1.6271, val loss 1.7869\n",
      "step 45300: train loss 1.6263, val loss 1.7781\n",
      "step 45400: train loss 1.6347, val loss 1.7823\n",
      "step 45500: train loss 1.6216, val loss 1.7824\n",
      "step 45600: train loss 1.6265, val loss 1.7824\n",
      "step 45700: train loss 1.6336, val loss 1.7965\n",
      "step 45800: train loss 1.6302, val loss 1.7952\n",
      "step 45900: train loss 1.6299, val loss 1.7863\n",
      "step 46000: train loss 1.6322, val loss 1.7875\n",
      "step 46100: train loss 1.6200, val loss 1.7738\n",
      "step 46200: train loss 1.6097, val loss 1.7942\n",
      "step 46300: train loss 1.6252, val loss 1.7843\n",
      "step 46400: train loss 1.6211, val loss 1.7829\n",
      "step 46500: train loss 1.6233, val loss 1.7900\n",
      "step 46600: train loss 1.6197, val loss 1.7937\n",
      "step 46700: train loss 1.6134, val loss 1.7894\n",
      "step 46800: train loss 1.6233, val loss 1.7912\n",
      "step 46900: train loss 1.6272, val loss 1.7937\n",
      "step 47000: train loss 1.6333, val loss 1.7818\n",
      "step 47100: train loss 1.6242, val loss 1.7935\n",
      "step 47200: train loss 1.6316, val loss 1.8011\n",
      "step 47300: train loss 1.6339, val loss 1.8093\n",
      "step 47400: train loss 1.6313, val loss 1.7884\n",
      "step 47500: train loss 1.6229, val loss 1.7842\n",
      "step 47600: train loss 1.6364, val loss 1.7831\n",
      "step 47700: train loss 1.6278, val loss 1.7893\n",
      "step 47800: train loss 1.6257, val loss 1.7936\n",
      "step 47900: train loss 1.6336, val loss 1.7877\n",
      "step 48000: train loss 1.6325, val loss 1.7967\n",
      "step 48100: train loss 1.6218, val loss 1.7966\n",
      "step 48200: train loss 1.6285, val loss 1.7794\n",
      "step 48300: train loss 1.6251, val loss 1.7828\n",
      "step 48400: train loss 1.6115, val loss 1.7946\n",
      "step 48500: train loss 1.6131, val loss 1.7996\n",
      "step 48600: train loss 1.6350, val loss 1.7967\n",
      "step 48700: train loss 1.6300, val loss 1.7993\n",
      "step 48800: train loss 1.6117, val loss 1.8048\n",
      "step 48900: train loss 1.6180, val loss 1.7950\n",
      "step 49000: train loss 1.6200, val loss 1.7860\n",
      "step 49100: train loss 1.6266, val loss 1.7818\n",
      "step 49200: train loss 1.6195, val loss 1.8004\n",
      "step 49300: train loss 1.6172, val loss 1.7787\n",
      "step 49400: train loss 1.6263, val loss 1.7990\n",
      "step 49500: train loss 1.6116, val loss 1.7817\n",
      "step 49600: train loss 1.6299, val loss 1.8056\n",
      "step 49700: train loss 1.6224, val loss 1.7876\n",
      "step 49800: train loss 1.6261, val loss 1.7991\n",
      "step 49900: train loss 1.6243, val loss 1.7817\n",
      "step 49999: train loss 1.6247, val loss 1.7945\n",
      "Results for configuration res1_dropout=0.025_res2_dropout=0.1_res4_dropout=0.0_use_double_layers=False saved.\n",
      "Training model with configuration: {'res1_dropout': 0.025, 'res2_dropout': 0.2, 'res4_dropout': 0.0, 'use_double_layers': False}\n",
      "step 0: train loss 4.3918, val loss 4.3895\n",
      "step 100: train loss 2.7413, val loss 2.7620\n",
      "step 200: train loss 2.5864, val loss 2.5899\n",
      "step 300: train loss 2.5142, val loss 2.5235\n",
      "step 400: train loss 2.4652, val loss 2.4679\n",
      "step 500: train loss 2.4258, val loss 2.4324\n",
      "step 600: train loss 2.3835, val loss 2.3954\n",
      "step 700: train loss 2.3476, val loss 2.3627\n",
      "step 800: train loss 2.3113, val loss 2.3309\n",
      "step 900: train loss 2.2889, val loss 2.2860\n",
      "step 1000: train loss 2.2535, val loss 2.2784\n",
      "step 1100: train loss 2.2245, val loss 2.2397\n",
      "step 1200: train loss 2.2029, val loss 2.2209\n",
      "step 1300: train loss 2.1809, val loss 2.1956\n",
      "step 1400: train loss 2.1566, val loss 2.1852\n",
      "step 1500: train loss 2.1465, val loss 2.1731\n",
      "step 1600: train loss 2.1333, val loss 2.1658\n",
      "step 1700: train loss 2.1261, val loss 2.1513\n",
      "step 1800: train loss 2.1031, val loss 2.1380\n",
      "step 1900: train loss 2.0909, val loss 2.1354\n",
      "step 2000: train loss 2.0800, val loss 2.1202\n",
      "step 2100: train loss 2.0739, val loss 2.1078\n",
      "step 2200: train loss 2.0553, val loss 2.1078\n",
      "step 2300: train loss 2.0332, val loss 2.1006\n",
      "step 2400: train loss 2.0405, val loss 2.0926\n",
      "step 2500: train loss 2.0267, val loss 2.0818\n",
      "step 2600: train loss 2.0171, val loss 2.0720\n",
      "step 2700: train loss 2.0067, val loss 2.0707\n",
      "step 2800: train loss 2.0031, val loss 2.0839\n",
      "step 2900: train loss 1.9992, val loss 2.0568\n",
      "step 3000: train loss 1.9906, val loss 2.0433\n",
      "step 3100: train loss 1.9809, val loss 2.0446\n",
      "step 3200: train loss 1.9691, val loss 2.0330\n",
      "step 3300: train loss 1.9801, val loss 2.0445\n",
      "step 3400: train loss 1.9632, val loss 2.0309\n",
      "step 3500: train loss 1.9570, val loss 2.0273\n",
      "step 3600: train loss 1.9527, val loss 2.0411\n",
      "step 3700: train loss 1.9389, val loss 2.0246\n",
      "step 3800: train loss 1.9303, val loss 2.0107\n",
      "step 3900: train loss 1.9210, val loss 2.0214\n",
      "step 4000: train loss 1.9337, val loss 2.0037\n",
      "step 4100: train loss 1.9248, val loss 2.0129\n",
      "step 4200: train loss 1.9183, val loss 1.9985\n",
      "step 4300: train loss 1.9056, val loss 1.9980\n",
      "step 4400: train loss 1.9045, val loss 2.0080\n",
      "step 4500: train loss 1.9141, val loss 1.9976\n",
      "step 4600: train loss 1.8978, val loss 1.9913\n",
      "step 4700: train loss 1.8991, val loss 1.9981\n",
      "step 4800: train loss 1.9036, val loss 1.9903\n",
      "step 4900: train loss 1.8813, val loss 1.9822\n",
      "step 5000: train loss 1.8899, val loss 1.9718\n",
      "step 5100: train loss 1.8846, val loss 1.9857\n",
      "step 5200: train loss 1.8697, val loss 1.9820\n",
      "step 5300: train loss 1.8700, val loss 1.9880\n",
      "step 5400: train loss 1.8726, val loss 1.9649\n",
      "step 5500: train loss 1.8653, val loss 1.9684\n",
      "step 5600: train loss 1.8611, val loss 1.9759\n",
      "step 5700: train loss 1.8576, val loss 1.9775\n",
      "step 5800: train loss 1.8558, val loss 1.9625\n",
      "step 5900: train loss 1.8501, val loss 1.9538\n",
      "step 6000: train loss 1.8508, val loss 1.9574\n",
      "step 6100: train loss 1.8436, val loss 1.9665\n",
      "step 6200: train loss 1.8448, val loss 1.9658\n",
      "step 6300: train loss 1.8419, val loss 1.9621\n",
      "step 6400: train loss 1.8400, val loss 1.9421\n",
      "step 6500: train loss 1.8269, val loss 1.9581\n",
      "step 6600: train loss 1.8364, val loss 1.9425\n",
      "step 6700: train loss 1.8223, val loss 1.9344\n",
      "step 6800: train loss 1.8276, val loss 1.9376\n",
      "step 6900: train loss 1.8186, val loss 1.9373\n",
      "step 7000: train loss 1.8252, val loss 1.9416\n",
      "step 7100: train loss 1.8326, val loss 1.9435\n",
      "step 7200: train loss 1.8178, val loss 1.9435\n",
      "step 7300: train loss 1.8202, val loss 1.9515\n",
      "step 7400: train loss 1.8235, val loss 1.9390\n",
      "step 7500: train loss 1.8074, val loss 1.9365\n",
      "step 7600: train loss 1.8111, val loss 1.9275\n",
      "step 7700: train loss 1.8038, val loss 1.9402\n",
      "step 7800: train loss 1.8038, val loss 1.9228\n",
      "step 7900: train loss 1.7895, val loss 1.9243\n",
      "step 8000: train loss 1.8012, val loss 1.9210\n",
      "step 8100: train loss 1.7960, val loss 1.9144\n",
      "step 8200: train loss 1.7984, val loss 1.9267\n",
      "step 8300: train loss 1.8016, val loss 1.9267\n",
      "step 8400: train loss 1.8028, val loss 1.9297\n",
      "step 8500: train loss 1.7890, val loss 1.9317\n",
      "step 8600: train loss 1.7879, val loss 1.9191\n",
      "step 8700: train loss 1.7804, val loss 1.9114\n",
      "step 8800: train loss 1.7816, val loss 1.9229\n",
      "step 8900: train loss 1.7875, val loss 1.9194\n",
      "step 9000: train loss 1.7840, val loss 1.9260\n",
      "step 9100: train loss 1.7881, val loss 1.9141\n",
      "step 9200: train loss 1.7898, val loss 1.9114\n",
      "step 9300: train loss 1.7803, val loss 1.9262\n",
      "step 9400: train loss 1.7734, val loss 1.9113\n",
      "step 9500: train loss 1.7750, val loss 1.9078\n",
      "step 9600: train loss 1.7698, val loss 1.8938\n",
      "step 9700: train loss 1.7726, val loss 1.9169\n",
      "step 9800: train loss 1.7602, val loss 1.9145\n",
      "step 9900: train loss 1.7745, val loss 1.9234\n",
      "step 10000: train loss 1.7679, val loss 1.9177\n",
      "step 10100: train loss 1.7591, val loss 1.8944\n",
      "step 10200: train loss 1.7550, val loss 1.9005\n",
      "step 10300: train loss 1.7643, val loss 1.9048\n",
      "step 10400: train loss 1.7618, val loss 1.9123\n",
      "step 10500: train loss 1.7615, val loss 1.8995\n",
      "step 10600: train loss 1.7636, val loss 1.9085\n",
      "step 10700: train loss 1.7573, val loss 1.9015\n",
      "step 10800: train loss 1.7553, val loss 1.8975\n",
      "step 10900: train loss 1.7538, val loss 1.8981\n",
      "step 11000: train loss 1.7467, val loss 1.8969\n",
      "step 11100: train loss 1.7490, val loss 1.8866\n",
      "step 11200: train loss 1.7594, val loss 1.9060\n",
      "step 11300: train loss 1.7582, val loss 1.9057\n",
      "step 11400: train loss 1.7548, val loss 1.9140\n",
      "step 11500: train loss 1.7457, val loss 1.8962\n",
      "step 11600: train loss 1.7381, val loss 1.8928\n",
      "step 11700: train loss 1.7443, val loss 1.9141\n",
      "step 11800: train loss 1.7586, val loss 1.8980\n",
      "step 11900: train loss 1.7444, val loss 1.8933\n",
      "step 12000: train loss 1.7400, val loss 1.9018\n",
      "step 12100: train loss 1.7362, val loss 1.8966\n",
      "step 12200: train loss 1.7393, val loss 1.9012\n",
      "step 12300: train loss 1.7417, val loss 1.8815\n",
      "step 12400: train loss 1.7516, val loss 1.8894\n",
      "step 12500: train loss 1.7296, val loss 1.8982\n",
      "step 12600: train loss 1.7304, val loss 1.8829\n",
      "step 12700: train loss 1.7392, val loss 1.8873\n",
      "step 12800: train loss 1.7348, val loss 1.8864\n",
      "step 12900: train loss 1.7382, val loss 1.8849\n",
      "step 13000: train loss 1.7310, val loss 1.8752\n",
      "step 13100: train loss 1.7419, val loss 1.8884\n",
      "step 13200: train loss 1.7373, val loss 1.8781\n",
      "step 13300: train loss 1.7277, val loss 1.8746\n",
      "step 13400: train loss 1.7257, val loss 1.8666\n",
      "step 13500: train loss 1.7322, val loss 1.8697\n",
      "step 13600: train loss 1.7226, val loss 1.8812\n",
      "step 13700: train loss 1.7368, val loss 1.8733\n",
      "step 13800: train loss 1.7326, val loss 1.8914\n",
      "step 13900: train loss 1.7279, val loss 1.8865\n",
      "step 14000: train loss 1.7265, val loss 1.8792\n",
      "step 14100: train loss 1.7246, val loss 1.8793\n",
      "step 14200: train loss 1.7281, val loss 1.8759\n",
      "step 14300: train loss 1.7277, val loss 1.8691\n",
      "step 14400: train loss 1.7279, val loss 1.8836\n",
      "step 14500: train loss 1.7247, val loss 1.8805\n",
      "step 14600: train loss 1.7191, val loss 1.8731\n",
      "step 14700: train loss 1.7211, val loss 1.8922\n",
      "step 14800: train loss 1.7164, val loss 1.8795\n",
      "step 14900: train loss 1.7111, val loss 1.8658\n",
      "step 15000: train loss 1.7126, val loss 1.8657\n",
      "step 15100: train loss 1.7113, val loss 1.8889\n",
      "step 15200: train loss 1.7154, val loss 1.8763\n",
      "step 15300: train loss 1.7119, val loss 1.8711\n",
      "step 15400: train loss 1.7204, val loss 1.8722\n",
      "step 15500: train loss 1.7197, val loss 1.8603\n",
      "step 15600: train loss 1.7116, val loss 1.8737\n",
      "step 15700: train loss 1.7182, val loss 1.8704\n",
      "step 15800: train loss 1.7239, val loss 1.8634\n",
      "step 15900: train loss 1.7131, val loss 1.8716\n",
      "step 16000: train loss 1.7102, val loss 1.8668\n",
      "step 16100: train loss 1.7128, val loss 1.8670\n",
      "step 16200: train loss 1.7258, val loss 1.8672\n",
      "step 16300: train loss 1.7121, val loss 1.8598\n",
      "step 16400: train loss 1.6977, val loss 1.8791\n",
      "step 16500: train loss 1.7077, val loss 1.8661\n",
      "step 16600: train loss 1.7094, val loss 1.8704\n",
      "step 16700: train loss 1.7033, val loss 1.8635\n",
      "step 16800: train loss 1.7062, val loss 1.8649\n",
      "step 16900: train loss 1.7135, val loss 1.8619\n",
      "step 17000: train loss 1.7033, val loss 1.8563\n",
      "step 17100: train loss 1.6945, val loss 1.8639\n",
      "step 17200: train loss 1.7098, val loss 1.8560\n",
      "step 17300: train loss 1.7064, val loss 1.8597\n",
      "step 17400: train loss 1.7138, val loss 1.8501\n",
      "step 17500: train loss 1.6956, val loss 1.8477\n",
      "step 17600: train loss 1.6957, val loss 1.8636\n",
      "step 17700: train loss 1.7039, val loss 1.8486\n",
      "step 17800: train loss 1.7071, val loss 1.8595\n",
      "step 17900: train loss 1.7109, val loss 1.8598\n",
      "step 18000: train loss 1.6993, val loss 1.8691\n",
      "step 18100: train loss 1.6926, val loss 1.8554\n",
      "step 18200: train loss 1.6970, val loss 1.8553\n",
      "step 18300: train loss 1.6959, val loss 1.8620\n",
      "step 18400: train loss 1.6894, val loss 1.8435\n",
      "step 18500: train loss 1.6986, val loss 1.8642\n",
      "step 18600: train loss 1.7043, val loss 1.8487\n",
      "step 18700: train loss 1.7055, val loss 1.8599\n",
      "step 18800: train loss 1.6935, val loss 1.8469\n",
      "step 18900: train loss 1.6925, val loss 1.8539\n",
      "step 19000: train loss 1.7044, val loss 1.8663\n",
      "step 19100: train loss 1.6923, val loss 1.8532\n",
      "step 19200: train loss 1.6967, val loss 1.8645\n",
      "step 19300: train loss 1.6887, val loss 1.8496\n",
      "step 19400: train loss 1.6993, val loss 1.8682\n",
      "step 19500: train loss 1.6977, val loss 1.8627\n",
      "step 19600: train loss 1.6864, val loss 1.8536\n",
      "step 19700: train loss 1.6815, val loss 1.8637\n",
      "step 19800: train loss 1.6953, val loss 1.8537\n",
      "step 19900: train loss 1.6895, val loss 1.8418\n",
      "step 20000: train loss 1.6889, val loss 1.8484\n",
      "step 20100: train loss 1.6890, val loss 1.8578\n",
      "step 20200: train loss 1.6938, val loss 1.8558\n",
      "step 20300: train loss 1.6962, val loss 1.8537\n",
      "step 20400: train loss 1.6827, val loss 1.8574\n",
      "step 20500: train loss 1.6827, val loss 1.8513\n",
      "step 20600: train loss 1.6753, val loss 1.8641\n",
      "step 20700: train loss 1.6886, val loss 1.8690\n",
      "step 20800: train loss 1.6894, val loss 1.8431\n",
      "step 20900: train loss 1.6867, val loss 1.8510\n",
      "step 21000: train loss 1.6893, val loss 1.8425\n",
      "step 21100: train loss 1.6819, val loss 1.8474\n",
      "step 21200: train loss 1.6880, val loss 1.8499\n",
      "step 21300: train loss 1.6785, val loss 1.8420\n",
      "step 21400: train loss 1.6921, val loss 1.8420\n",
      "step 21500: train loss 1.6787, val loss 1.8376\n",
      "step 21600: train loss 1.6824, val loss 1.8407\n",
      "step 21700: train loss 1.6664, val loss 1.8379\n",
      "step 21800: train loss 1.6838, val loss 1.8561\n",
      "step 21900: train loss 1.6888, val loss 1.8486\n",
      "step 22000: train loss 1.6779, val loss 1.8545\n",
      "step 22100: train loss 1.6757, val loss 1.8433\n",
      "step 22200: train loss 1.6780, val loss 1.8377\n",
      "step 22300: train loss 1.6811, val loss 1.8592\n",
      "step 22400: train loss 1.6931, val loss 1.8467\n",
      "step 22500: train loss 1.6827, val loss 1.8491\n",
      "step 22600: train loss 1.6818, val loss 1.8442\n",
      "step 22700: train loss 1.6659, val loss 1.8351\n",
      "step 22800: train loss 1.6886, val loss 1.8425\n",
      "step 22900: train loss 1.6865, val loss 1.8465\n",
      "step 23000: train loss 1.6813, val loss 1.8365\n",
      "step 23100: train loss 1.6686, val loss 1.8452\n",
      "step 23200: train loss 1.6781, val loss 1.8398\n",
      "step 23300: train loss 1.6721, val loss 1.8431\n",
      "step 23400: train loss 1.6670, val loss 1.8473\n",
      "step 23500: train loss 1.6747, val loss 1.8321\n",
      "step 23600: train loss 1.6759, val loss 1.8519\n",
      "step 23700: train loss 1.6800, val loss 1.8438\n",
      "step 23800: train loss 1.6648, val loss 1.8494\n",
      "step 23900: train loss 1.6777, val loss 1.8372\n",
      "step 24000: train loss 1.6833, val loss 1.8467\n",
      "step 24100: train loss 1.6714, val loss 1.8333\n",
      "step 24200: train loss 1.6781, val loss 1.8415\n",
      "step 24300: train loss 1.6705, val loss 1.8493\n",
      "step 24400: train loss 1.6740, val loss 1.8483\n",
      "step 24500: train loss 1.6620, val loss 1.8432\n",
      "step 24600: train loss 1.6835, val loss 1.8457\n",
      "step 24700: train loss 1.6783, val loss 1.8376\n",
      "step 24800: train loss 1.6658, val loss 1.8458\n",
      "step 24900: train loss 1.6768, val loss 1.8466\n",
      "step 25000: train loss 1.6681, val loss 1.8486\n",
      "step 25100: train loss 1.6627, val loss 1.8428\n",
      "step 25200: train loss 1.6724, val loss 1.8245\n",
      "step 25300: train loss 1.6699, val loss 1.8368\n",
      "step 25400: train loss 1.6682, val loss 1.8333\n",
      "step 25500: train loss 1.6682, val loss 1.8448\n",
      "step 25600: train loss 1.6580, val loss 1.8376\n",
      "step 25700: train loss 1.6813, val loss 1.8244\n",
      "step 25800: train loss 1.6665, val loss 1.8400\n",
      "step 25900: train loss 1.6620, val loss 1.8405\n",
      "step 26000: train loss 1.6640, val loss 1.8281\n",
      "step 26100: train loss 1.6672, val loss 1.8272\n",
      "step 26200: train loss 1.6697, val loss 1.8292\n",
      "step 26300: train loss 1.6689, val loss 1.8287\n",
      "step 26400: train loss 1.6672, val loss 1.8325\n",
      "step 26500: train loss 1.6689, val loss 1.8346\n",
      "step 26600: train loss 1.6613, val loss 1.8311\n",
      "step 26700: train loss 1.6671, val loss 1.8513\n",
      "step 26800: train loss 1.6658, val loss 1.8309\n",
      "step 26900: train loss 1.6703, val loss 1.8372\n",
      "step 27000: train loss 1.6590, val loss 1.8266\n",
      "step 27100: train loss 1.6691, val loss 1.8401\n",
      "step 27200: train loss 1.6572, val loss 1.8313\n",
      "step 27300: train loss 1.6691, val loss 1.8309\n",
      "step 27400: train loss 1.6702, val loss 1.8360\n",
      "step 27500: train loss 1.6746, val loss 1.8233\n",
      "step 27600: train loss 1.6581, val loss 1.8390\n",
      "step 27700: train loss 1.6765, val loss 1.8376\n",
      "step 27800: train loss 1.6646, val loss 1.8291\n",
      "step 27900: train loss 1.6573, val loss 1.8297\n",
      "step 28000: train loss 1.6664, val loss 1.8330\n",
      "step 28100: train loss 1.6681, val loss 1.8225\n",
      "step 28200: train loss 1.6713, val loss 1.8315\n",
      "step 28300: train loss 1.6693, val loss 1.8391\n",
      "step 28400: train loss 1.6640, val loss 1.8282\n",
      "step 28500: train loss 1.6667, val loss 1.8116\n",
      "step 28600: train loss 1.6498, val loss 1.8413\n",
      "step 28700: train loss 1.6608, val loss 1.8411\n",
      "step 28800: train loss 1.6592, val loss 1.8238\n",
      "step 28900: train loss 1.6633, val loss 1.8239\n",
      "step 29000: train loss 1.6563, val loss 1.8217\n",
      "step 29100: train loss 1.6580, val loss 1.8281\n",
      "step 29200: train loss 1.6645, val loss 1.8294\n",
      "step 29300: train loss 1.6475, val loss 1.8237\n",
      "step 29400: train loss 1.6570, val loss 1.8298\n",
      "step 29500: train loss 1.6608, val loss 1.8357\n",
      "step 29600: train loss 1.6670, val loss 1.8335\n",
      "step 29700: train loss 1.6730, val loss 1.8296\n",
      "step 29800: train loss 1.6521, val loss 1.8320\n",
      "step 29900: train loss 1.6498, val loss 1.8243\n",
      "step 30000: train loss 1.6538, val loss 1.8119\n",
      "step 30100: train loss 1.6554, val loss 1.8290\n",
      "step 30200: train loss 1.6635, val loss 1.8355\n",
      "step 30300: train loss 1.6525, val loss 1.8390\n",
      "step 30400: train loss 1.6705, val loss 1.8277\n",
      "step 30500: train loss 1.6460, val loss 1.8233\n",
      "step 30600: train loss 1.6586, val loss 1.8300\n",
      "step 30700: train loss 1.6541, val loss 1.8261\n",
      "step 30800: train loss 1.6532, val loss 1.8149\n",
      "step 30900: train loss 1.6606, val loss 1.8254\n",
      "step 31000: train loss 1.6534, val loss 1.8327\n",
      "step 31100: train loss 1.6556, val loss 1.8193\n",
      "step 31200: train loss 1.6509, val loss 1.8325\n",
      "step 31300: train loss 1.6494, val loss 1.8271\n",
      "step 31400: train loss 1.6617, val loss 1.8148\n",
      "step 31500: train loss 1.6563, val loss 1.8330\n",
      "step 31600: train loss 1.6392, val loss 1.8345\n",
      "step 31700: train loss 1.6446, val loss 1.8302\n",
      "step 31800: train loss 1.6442, val loss 1.8239\n",
      "step 31900: train loss 1.6505, val loss 1.8271\n",
      "step 32000: train loss 1.6641, val loss 1.8272\n",
      "step 32100: train loss 1.6442, val loss 1.8456\n",
      "step 32200: train loss 1.6593, val loss 1.8274\n",
      "step 32300: train loss 1.6578, val loss 1.8226\n",
      "step 32400: train loss 1.6580, val loss 1.8206\n",
      "step 32500: train loss 1.6569, val loss 1.8217\n",
      "step 32600: train loss 1.6556, val loss 1.8214\n",
      "step 32700: train loss 1.6452, val loss 1.8175\n",
      "step 32800: train loss 1.6535, val loss 1.8269\n",
      "step 32900: train loss 1.6520, val loss 1.8359\n",
      "step 33000: train loss 1.6538, val loss 1.8282\n",
      "step 33100: train loss 1.6555, val loss 1.8161\n",
      "step 33200: train loss 1.6596, val loss 1.8145\n",
      "step 33300: train loss 1.6538, val loss 1.8226\n",
      "step 33400: train loss 1.6390, val loss 1.8374\n",
      "step 33500: train loss 1.6492, val loss 1.8162\n",
      "step 33600: train loss 1.6662, val loss 1.8266\n",
      "step 33700: train loss 1.6498, val loss 1.8259\n",
      "step 33800: train loss 1.6428, val loss 1.8127\n",
      "step 33900: train loss 1.6523, val loss 1.8234\n",
      "step 34000: train loss 1.6573, val loss 1.8103\n",
      "step 34100: train loss 1.6528, val loss 1.8372\n",
      "step 34200: train loss 1.6428, val loss 1.8242\n",
      "step 34300: train loss 1.6524, val loss 1.8337\n",
      "step 34400: train loss 1.6467, val loss 1.8216\n",
      "step 34500: train loss 1.6435, val loss 1.8321\n",
      "step 34600: train loss 1.6519, val loss 1.8269\n",
      "step 34700: train loss 1.6490, val loss 1.8275\n",
      "step 34800: train loss 1.6436, val loss 1.8218\n",
      "step 34900: train loss 1.6523, val loss 1.8225\n",
      "step 35000: train loss 1.6557, val loss 1.8179\n",
      "step 35100: train loss 1.6493, val loss 1.8290\n",
      "step 35200: train loss 1.6417, val loss 1.8133\n",
      "step 35300: train loss 1.6463, val loss 1.8263\n",
      "step 35400: train loss 1.6527, val loss 1.8195\n",
      "step 35500: train loss 1.6443, val loss 1.8221\n",
      "step 35600: train loss 1.6474, val loss 1.8173\n",
      "step 35700: train loss 1.6429, val loss 1.8413\n",
      "step 35800: train loss 1.6358, val loss 1.8284\n",
      "step 35900: train loss 1.6477, val loss 1.8324\n",
      "step 36000: train loss 1.6495, val loss 1.8188\n",
      "step 36100: train loss 1.6505, val loss 1.8318\n",
      "step 36200: train loss 1.6527, val loss 1.8207\n",
      "step 36300: train loss 1.6546, val loss 1.8268\n",
      "step 36400: train loss 1.6374, val loss 1.8291\n",
      "step 36500: train loss 1.6451, val loss 1.8317\n",
      "step 36600: train loss 1.6402, val loss 1.8184\n",
      "step 36700: train loss 1.6419, val loss 1.8200\n",
      "step 36800: train loss 1.6423, val loss 1.8168\n",
      "step 36900: train loss 1.6441, val loss 1.8092\n",
      "step 37000: train loss 1.6423, val loss 1.8196\n",
      "step 37100: train loss 1.6561, val loss 1.8283\n",
      "step 37200: train loss 1.6433, val loss 1.8251\n",
      "step 37300: train loss 1.6414, val loss 1.8201\n",
      "step 37400: train loss 1.6475, val loss 1.8238\n",
      "step 37500: train loss 1.6434, val loss 1.8213\n",
      "step 37600: train loss 1.6445, val loss 1.8218\n",
      "step 37700: train loss 1.6404, val loss 1.8157\n",
      "step 37800: train loss 1.6443, val loss 1.8200\n",
      "step 37900: train loss 1.6365, val loss 1.8300\n",
      "step 38000: train loss 1.6468, val loss 1.8161\n",
      "step 38100: train loss 1.6485, val loss 1.8154\n",
      "step 38200: train loss 1.6340, val loss 1.8254\n",
      "step 38300: train loss 1.6366, val loss 1.8100\n",
      "step 38400: train loss 1.6385, val loss 1.8162\n",
      "step 38500: train loss 1.6484, val loss 1.8228\n",
      "step 38600: train loss 1.6396, val loss 1.8181\n",
      "step 38700: train loss 1.6345, val loss 1.8159\n",
      "step 38800: train loss 1.6461, val loss 1.8265\n",
      "step 38900: train loss 1.6397, val loss 1.8158\n",
      "step 39000: train loss 1.6347, val loss 1.8185\n",
      "step 39100: train loss 1.6426, val loss 1.8110\n",
      "step 39200: train loss 1.6500, val loss 1.8209\n",
      "step 39300: train loss 1.6427, val loss 1.8157\n",
      "step 39400: train loss 1.6373, val loss 1.8124\n",
      "step 39500: train loss 1.6449, val loss 1.8126\n",
      "step 39600: train loss 1.6424, val loss 1.8139\n",
      "step 39700: train loss 1.6432, val loss 1.8232\n",
      "step 39800: train loss 1.6350, val loss 1.8287\n",
      "step 39900: train loss 1.6488, val loss 1.8191\n",
      "step 40000: train loss 1.6465, val loss 1.8258\n",
      "step 40100: train loss 1.6451, val loss 1.8240\n",
      "step 40200: train loss 1.6353, val loss 1.8207\n",
      "step 40300: train loss 1.6428, val loss 1.8256\n",
      "step 40400: train loss 1.6422, val loss 1.8113\n",
      "step 40500: train loss 1.6441, val loss 1.8035\n",
      "step 40600: train loss 1.6383, val loss 1.8136\n",
      "step 40700: train loss 1.6505, val loss 1.8154\n",
      "step 40800: train loss 1.6327, val loss 1.8082\n",
      "step 40900: train loss 1.6304, val loss 1.8182\n",
      "step 41000: train loss 1.6484, val loss 1.8058\n",
      "step 41100: train loss 1.6380, val loss 1.8089\n",
      "step 41200: train loss 1.6297, val loss 1.8094\n",
      "step 41300: train loss 1.6304, val loss 1.8121\n",
      "step 41400: train loss 1.6350, val loss 1.8129\n",
      "step 41500: train loss 1.6448, val loss 1.8027\n",
      "step 41600: train loss 1.6364, val loss 1.8112\n",
      "step 41700: train loss 1.6496, val loss 1.8192\n",
      "step 41800: train loss 1.6280, val loss 1.7896\n",
      "step 41900: train loss 1.6323, val loss 1.8128\n",
      "step 42000: train loss 1.6370, val loss 1.8066\n",
      "step 42100: train loss 1.6348, val loss 1.8073\n",
      "step 42200: train loss 1.6355, val loss 1.8123\n",
      "step 42300: train loss 1.6359, val loss 1.8089\n",
      "step 42400: train loss 1.6334, val loss 1.8125\n",
      "step 42500: train loss 1.6354, val loss 1.7986\n",
      "step 42600: train loss 1.6479, val loss 1.8124\n",
      "step 42700: train loss 1.6260, val loss 1.8052\n",
      "step 42800: train loss 1.6284, val loss 1.7936\n",
      "step 42900: train loss 1.6367, val loss 1.8186\n",
      "step 43000: train loss 1.6424, val loss 1.8113\n",
      "step 43100: train loss 1.6416, val loss 1.8280\n",
      "step 43200: train loss 1.6404, val loss 1.8006\n",
      "step 43300: train loss 1.6425, val loss 1.8118\n",
      "step 43400: train loss 1.6328, val loss 1.8066\n",
      "step 43500: train loss 1.6256, val loss 1.8164\n",
      "step 43600: train loss 1.6437, val loss 1.8080\n",
      "step 43700: train loss 1.6454, val loss 1.8057\n",
      "step 43800: train loss 1.6318, val loss 1.8083\n",
      "step 43900: train loss 1.6347, val loss 1.8008\n",
      "step 44000: train loss 1.6368, val loss 1.8036\n",
      "step 44100: train loss 1.6273, val loss 1.8041\n",
      "step 44200: train loss 1.6332, val loss 1.7980\n",
      "step 44300: train loss 1.6296, val loss 1.8098\n",
      "step 44400: train loss 1.6281, val loss 1.8052\n",
      "step 44500: train loss 1.6397, val loss 1.8021\n",
      "step 44600: train loss 1.6438, val loss 1.8124\n",
      "step 44700: train loss 1.6353, val loss 1.8127\n",
      "step 44800: train loss 1.6376, val loss 1.8094\n",
      "step 44900: train loss 1.6373, val loss 1.8105\n",
      "step 45000: train loss 1.6235, val loss 1.8018\n",
      "step 45100: train loss 1.6317, val loss 1.8118\n",
      "step 45200: train loss 1.6324, val loss 1.8104\n",
      "step 45300: train loss 1.6347, val loss 1.7927\n",
      "step 45400: train loss 1.6410, val loss 1.7896\n",
      "step 45500: train loss 1.6386, val loss 1.8025\n",
      "step 45600: train loss 1.6349, val loss 1.8105\n",
      "step 45700: train loss 1.6378, val loss 1.8042\n",
      "step 45800: train loss 1.6271, val loss 1.7970\n",
      "step 45900: train loss 1.6362, val loss 1.8035\n",
      "step 46000: train loss 1.6243, val loss 1.8192\n",
      "step 46100: train loss 1.6306, val loss 1.8074\n",
      "step 46200: train loss 1.6397, val loss 1.8145\n",
      "step 46300: train loss 1.6261, val loss 1.7996\n",
      "step 46400: train loss 1.6381, val loss 1.8026\n",
      "step 46500: train loss 1.6386, val loss 1.8056\n",
      "step 46600: train loss 1.6373, val loss 1.7971\n",
      "step 46700: train loss 1.6415, val loss 1.8090\n",
      "step 46800: train loss 1.6437, val loss 1.7969\n",
      "step 46900: train loss 1.6312, val loss 1.8130\n",
      "step 47000: train loss 1.6271, val loss 1.8150\n",
      "step 47100: train loss 1.6432, val loss 1.8031\n",
      "step 47200: train loss 1.6209, val loss 1.8112\n",
      "step 47300: train loss 1.6315, val loss 1.8151\n",
      "step 47400: train loss 1.6358, val loss 1.8150\n",
      "step 47500: train loss 1.6423, val loss 1.8101\n",
      "step 47600: train loss 1.6323, val loss 1.8077\n",
      "step 47700: train loss 1.6401, val loss 1.8214\n",
      "step 47800: train loss 1.6234, val loss 1.8237\n",
      "step 47900: train loss 1.6311, val loss 1.8051\n",
      "step 48000: train loss 1.6272, val loss 1.8075\n",
      "step 48100: train loss 1.6388, val loss 1.8200\n",
      "step 48200: train loss 1.6204, val loss 1.8045\n",
      "step 48300: train loss 1.6302, val loss 1.8159\n",
      "step 48400: train loss 1.6241, val loss 1.8130\n",
      "step 48500: train loss 1.6356, val loss 1.8185\n",
      "step 48600: train loss 1.6326, val loss 1.8152\n",
      "step 48700: train loss 1.6365, val loss 1.8059\n",
      "step 48800: train loss 1.6228, val loss 1.8071\n",
      "step 48900: train loss 1.6285, val loss 1.8030\n",
      "step 49000: train loss 1.6300, val loss 1.8132\n",
      "step 49100: train loss 1.6298, val loss 1.8190\n",
      "step 49200: train loss 1.6303, val loss 1.8151\n",
      "step 49300: train loss 1.6264, val loss 1.8025\n",
      "step 49400: train loss 1.6225, val loss 1.8113\n",
      "step 49500: train loss 1.6187, val loss 1.8018\n",
      "step 49600: train loss 1.6274, val loss 1.8208\n",
      "step 49700: train loss 1.6396, val loss 1.7975\n",
      "step 49800: train loss 1.6360, val loss 1.8067\n",
      "step 49900: train loss 1.6251, val loss 1.8078\n",
      "step 49999: train loss 1.6221, val loss 1.8106\n",
      "Results for configuration res1_dropout=0.025_res2_dropout=0.2_res4_dropout=0.0_use_double_layers=False saved.\n",
      "Training model with configuration: {'res1_dropout': 0.025, 'res2_dropout': 0.5, 'res4_dropout': 0.0, 'use_double_layers': False}\n",
      "step 0: train loss 4.3692, val loss 4.3693\n",
      "step 100: train loss 2.7658, val loss 2.7891\n",
      "step 200: train loss 2.5728, val loss 2.5851\n",
      "step 300: train loss 2.5069, val loss 2.5151\n",
      "step 400: train loss 2.4551, val loss 2.4572\n",
      "step 500: train loss 2.4125, val loss 2.4137\n",
      "step 600: train loss 2.3762, val loss 2.3886\n",
      "step 700: train loss 2.3328, val loss 2.3464\n",
      "step 800: train loss 2.3145, val loss 2.3165\n",
      "step 900: train loss 2.2853, val loss 2.2943\n",
      "step 1000: train loss 2.2691, val loss 2.2786\n",
      "step 1100: train loss 2.2342, val loss 2.2539\n",
      "step 1200: train loss 2.2235, val loss 2.2271\n",
      "step 1300: train loss 2.1984, val loss 2.2196\n",
      "step 1400: train loss 2.1873, val loss 2.1968\n",
      "step 1500: train loss 2.1705, val loss 2.1872\n",
      "step 1600: train loss 2.1505, val loss 2.1877\n",
      "step 1700: train loss 2.1465, val loss 2.1774\n",
      "step 1800: train loss 2.1249, val loss 2.1628\n",
      "step 1900: train loss 2.1147, val loss 2.1282\n",
      "step 2000: train loss 2.1198, val loss 2.1289\n",
      "step 2100: train loss 2.0939, val loss 2.1259\n",
      "step 2200: train loss 2.0904, val loss 2.1244\n",
      "step 2300: train loss 2.0664, val loss 2.1105\n",
      "step 2400: train loss 2.0601, val loss 2.1125\n",
      "step 2500: train loss 2.0577, val loss 2.0983\n",
      "step 2600: train loss 2.0423, val loss 2.1007\n",
      "step 2700: train loss 2.0325, val loss 2.1015\n",
      "step 2800: train loss 2.0256, val loss 2.0865\n",
      "step 2900: train loss 2.0235, val loss 2.0759\n",
      "step 3000: train loss 2.0098, val loss 2.0754\n",
      "step 3100: train loss 2.0119, val loss 2.0740\n",
      "step 3200: train loss 2.0057, val loss 2.0612\n",
      "step 3300: train loss 1.9972, val loss 2.0547\n",
      "step 3400: train loss 1.9917, val loss 2.0616\n",
      "step 3500: train loss 1.9895, val loss 2.0513\n",
      "step 3600: train loss 1.9787, val loss 2.0486\n",
      "step 3700: train loss 1.9742, val loss 2.0408\n",
      "step 3800: train loss 1.9703, val loss 2.0436\n",
      "step 3900: train loss 1.9693, val loss 2.0405\n",
      "step 4000: train loss 1.9518, val loss 2.0297\n",
      "step 4100: train loss 1.9573, val loss 2.0233\n",
      "step 4200: train loss 1.9497, val loss 2.0266\n",
      "step 4300: train loss 1.9530, val loss 2.0239\n",
      "step 4400: train loss 1.9323, val loss 2.0137\n",
      "step 4500: train loss 1.9321, val loss 2.0075\n",
      "step 4600: train loss 1.9219, val loss 1.9944\n",
      "step 4700: train loss 1.9118, val loss 1.9932\n",
      "step 4800: train loss 1.9101, val loss 1.9917\n",
      "step 4900: train loss 1.9172, val loss 2.0071\n",
      "step 5000: train loss 1.9113, val loss 1.9988\n",
      "step 5100: train loss 1.9101, val loss 1.9937\n",
      "step 5200: train loss 1.8952, val loss 1.9967\n",
      "step 5300: train loss 1.8968, val loss 1.9975\n",
      "step 5400: train loss 1.8991, val loss 1.9878\n",
      "step 5500: train loss 1.8904, val loss 1.9837\n",
      "step 5600: train loss 1.8913, val loss 1.9922\n",
      "step 5700: train loss 1.8759, val loss 1.9829\n",
      "step 5800: train loss 1.8832, val loss 1.9764\n",
      "step 5900: train loss 1.8731, val loss 1.9793\n",
      "step 6000: train loss 1.8685, val loss 1.9842\n",
      "step 6100: train loss 1.8708, val loss 1.9709\n",
      "step 6200: train loss 1.8660, val loss 1.9725\n",
      "step 6300: train loss 1.8585, val loss 1.9755\n",
      "step 6400: train loss 1.8533, val loss 1.9707\n",
      "step 6500: train loss 1.8574, val loss 1.9699\n",
      "step 6600: train loss 1.8537, val loss 1.9735\n",
      "step 6700: train loss 1.8512, val loss 1.9709\n",
      "step 6800: train loss 1.8501, val loss 1.9696\n",
      "step 6900: train loss 1.8544, val loss 1.9570\n",
      "step 7000: train loss 1.8509, val loss 1.9619\n",
      "step 7100: train loss 1.8507, val loss 1.9587\n",
      "step 7200: train loss 1.8448, val loss 1.9509\n",
      "step 7300: train loss 1.8456, val loss 1.9527\n",
      "step 7400: train loss 1.8243, val loss 1.9542\n",
      "step 7500: train loss 1.8249, val loss 1.9499\n",
      "step 7600: train loss 1.8353, val loss 1.9474\n",
      "step 7700: train loss 1.8255, val loss 1.9513\n",
      "step 7800: train loss 1.8275, val loss 1.9416\n",
      "step 7900: train loss 1.8227, val loss 1.9474\n",
      "step 8000: train loss 1.8232, val loss 1.9558\n",
      "step 8100: train loss 1.8251, val loss 1.9551\n",
      "step 8200: train loss 1.8155, val loss 1.9404\n",
      "step 8300: train loss 1.8221, val loss 1.9509\n",
      "step 8400: train loss 1.8193, val loss 1.9398\n",
      "step 8500: train loss 1.8019, val loss 1.9385\n",
      "step 8600: train loss 1.8059, val loss 1.9399\n",
      "step 8700: train loss 1.8139, val loss 1.9357\n",
      "step 8800: train loss 1.7999, val loss 1.9259\n",
      "step 8900: train loss 1.8059, val loss 1.9353\n",
      "step 9000: train loss 1.8081, val loss 1.9354\n",
      "step 9100: train loss 1.8184, val loss 1.9390\n",
      "step 9200: train loss 1.8040, val loss 1.9417\n",
      "step 9300: train loss 1.8012, val loss 1.9297\n",
      "step 9400: train loss 1.7974, val loss 1.9305\n",
      "step 9500: train loss 1.7920, val loss 1.9365\n",
      "step 9600: train loss 1.7956, val loss 1.9448\n",
      "step 9700: train loss 1.7898, val loss 1.9325\n",
      "step 9800: train loss 1.7983, val loss 1.9249\n",
      "step 9900: train loss 1.7938, val loss 1.9279\n",
      "step 10000: train loss 1.7921, val loss 1.9271\n",
      "step 10100: train loss 1.7906, val loss 1.9256\n",
      "step 10200: train loss 1.7880, val loss 1.9266\n",
      "step 10300: train loss 1.7916, val loss 1.9246\n",
      "step 10400: train loss 1.7884, val loss 1.9154\n",
      "step 10500: train loss 1.7908, val loss 1.9259\n",
      "step 10600: train loss 1.7846, val loss 1.9208\n",
      "step 10700: train loss 1.7899, val loss 1.9229\n",
      "step 10800: train loss 1.7869, val loss 1.9254\n",
      "step 10900: train loss 1.7853, val loss 1.9192\n",
      "step 11000: train loss 1.7849, val loss 1.9267\n",
      "step 11100: train loss 1.7871, val loss 1.9223\n",
      "step 11200: train loss 1.7782, val loss 1.9124\n",
      "step 11300: train loss 1.7780, val loss 1.9212\n",
      "step 11400: train loss 1.7753, val loss 1.9146\n",
      "step 11500: train loss 1.7781, val loss 1.9190\n",
      "step 11600: train loss 1.7732, val loss 1.9144\n",
      "step 11700: train loss 1.7796, val loss 1.9200\n",
      "step 11800: train loss 1.7702, val loss 1.9148\n",
      "step 11900: train loss 1.7732, val loss 1.9176\n",
      "step 12000: train loss 1.7660, val loss 1.9096\n",
      "step 12100: train loss 1.7733, val loss 1.9093\n",
      "step 12200: train loss 1.7718, val loss 1.9103\n",
      "step 12300: train loss 1.7648, val loss 1.9107\n",
      "step 12400: train loss 1.7605, val loss 1.9146\n",
      "step 12500: train loss 1.7590, val loss 1.8984\n",
      "step 12600: train loss 1.7700, val loss 1.9130\n",
      "step 12700: train loss 1.7494, val loss 1.9136\n",
      "step 12800: train loss 1.7618, val loss 1.8987\n",
      "step 12900: train loss 1.7501, val loss 1.9144\n",
      "step 13000: train loss 1.7585, val loss 1.8934\n",
      "step 13100: train loss 1.7592, val loss 1.8917\n",
      "step 13200: train loss 1.7640, val loss 1.9055\n",
      "step 13300: train loss 1.7609, val loss 1.9051\n",
      "step 13400: train loss 1.7446, val loss 1.8983\n",
      "step 13500: train loss 1.7591, val loss 1.8908\n",
      "step 13600: train loss 1.7448, val loss 1.8962\n",
      "step 13700: train loss 1.7435, val loss 1.8940\n",
      "step 13800: train loss 1.7414, val loss 1.8887\n",
      "step 13900: train loss 1.7483, val loss 1.8902\n",
      "step 14000: train loss 1.7533, val loss 1.8930\n",
      "step 14100: train loss 1.7572, val loss 1.8906\n",
      "step 14200: train loss 1.7442, val loss 1.8941\n",
      "step 14300: train loss 1.7473, val loss 1.9064\n",
      "step 14400: train loss 1.7431, val loss 1.8940\n",
      "step 14500: train loss 1.7426, val loss 1.8938\n",
      "step 14600: train loss 1.7486, val loss 1.8812\n",
      "step 14700: train loss 1.7420, val loss 1.8886\n",
      "step 14800: train loss 1.7407, val loss 1.8925\n",
      "step 14900: train loss 1.7533, val loss 1.8946\n",
      "step 15000: train loss 1.7526, val loss 1.9092\n",
      "step 15100: train loss 1.7382, val loss 1.8998\n",
      "step 15200: train loss 1.7436, val loss 1.8892\n",
      "step 15300: train loss 1.7410, val loss 1.8898\n",
      "step 15400: train loss 1.7378, val loss 1.8849\n",
      "step 15500: train loss 1.7328, val loss 1.8809\n",
      "step 15600: train loss 1.7402, val loss 1.8771\n",
      "step 15700: train loss 1.7338, val loss 1.8855\n",
      "step 15800: train loss 1.7397, val loss 1.8931\n",
      "step 15900: train loss 1.7413, val loss 1.8936\n",
      "step 16000: train loss 1.7256, val loss 1.8797\n",
      "step 16100: train loss 1.7222, val loss 1.8699\n",
      "step 16200: train loss 1.7270, val loss 1.8934\n",
      "step 16300: train loss 1.7197, val loss 1.8873\n",
      "step 16400: train loss 1.7367, val loss 1.8908\n",
      "step 16500: train loss 1.7232, val loss 1.8791\n",
      "step 16600: train loss 1.7235, val loss 1.8860\n",
      "step 16700: train loss 1.7235, val loss 1.8902\n",
      "step 16800: train loss 1.7370, val loss 1.8785\n",
      "step 16900: train loss 1.7365, val loss 1.8816\n",
      "step 17000: train loss 1.7245, val loss 1.8839\n",
      "step 17100: train loss 1.7265, val loss 1.8808\n",
      "step 17200: train loss 1.7282, val loss 1.8813\n",
      "step 17300: train loss 1.7242, val loss 1.8812\n",
      "step 17400: train loss 1.7284, val loss 1.8831\n",
      "step 17500: train loss 1.7329, val loss 1.8584\n",
      "step 17600: train loss 1.7246, val loss 1.8835\n",
      "step 17700: train loss 1.7258, val loss 1.8969\n",
      "step 17800: train loss 1.7237, val loss 1.8717\n",
      "step 17900: train loss 1.7249, val loss 1.8746\n",
      "step 18000: train loss 1.7286, val loss 1.8700\n",
      "step 18100: train loss 1.7233, val loss 1.8762\n",
      "step 18200: train loss 1.7236, val loss 1.8733\n",
      "step 18300: train loss 1.7132, val loss 1.8816\n",
      "step 18400: train loss 1.7187, val loss 1.8683\n",
      "step 18500: train loss 1.7149, val loss 1.8771\n",
      "step 18600: train loss 1.7132, val loss 1.8660\n",
      "step 18700: train loss 1.7146, val loss 1.8693\n",
      "step 18800: train loss 1.7121, val loss 1.8598\n",
      "step 18900: train loss 1.7114, val loss 1.8740\n",
      "step 19000: train loss 1.7254, val loss 1.8681\n",
      "step 19100: train loss 1.7137, val loss 1.8645\n",
      "step 19200: train loss 1.7048, val loss 1.8709\n",
      "step 19300: train loss 1.7105, val loss 1.8723\n",
      "step 19400: train loss 1.7064, val loss 1.8630\n",
      "step 19500: train loss 1.7085, val loss 1.8656\n",
      "step 19600: train loss 1.7016, val loss 1.8699\n",
      "step 19700: train loss 1.7134, val loss 1.8792\n",
      "step 19800: train loss 1.7019, val loss 1.8713\n",
      "step 19900: train loss 1.7151, val loss 1.8778\n",
      "step 20000: train loss 1.7222, val loss 1.8855\n",
      "step 20100: train loss 1.7242, val loss 1.8874\n",
      "step 20200: train loss 1.7111, val loss 1.8776\n",
      "step 20300: train loss 1.7195, val loss 1.8799\n",
      "step 20400: train loss 1.7099, val loss 1.8818\n",
      "step 20500: train loss 1.7137, val loss 1.8928\n",
      "step 20600: train loss 1.7041, val loss 1.8651\n",
      "step 20700: train loss 1.6963, val loss 1.8622\n",
      "step 20800: train loss 1.7021, val loss 1.8705\n",
      "step 20900: train loss 1.7061, val loss 1.8677\n",
      "step 21000: train loss 1.7014, val loss 1.8670\n",
      "step 21100: train loss 1.6954, val loss 1.8500\n",
      "step 21200: train loss 1.7028, val loss 1.8753\n",
      "step 21300: train loss 1.7071, val loss 1.8659\n",
      "step 21400: train loss 1.6991, val loss 1.8527\n",
      "step 21500: train loss 1.7024, val loss 1.8590\n",
      "step 21600: train loss 1.7059, val loss 1.8686\n",
      "step 21700: train loss 1.7062, val loss 1.8666\n",
      "step 21800: train loss 1.6961, val loss 1.8677\n",
      "step 21900: train loss 1.7007, val loss 1.8575\n",
      "step 22000: train loss 1.7068, val loss 1.8776\n",
      "step 22100: train loss 1.7096, val loss 1.8687\n",
      "step 22200: train loss 1.6975, val loss 1.8644\n",
      "step 22300: train loss 1.6978, val loss 1.8684\n",
      "step 22400: train loss 1.7036, val loss 1.8524\n",
      "step 22500: train loss 1.7043, val loss 1.8641\n",
      "step 22600: train loss 1.6932, val loss 1.8661\n",
      "step 22700: train loss 1.6985, val loss 1.8665\n",
      "step 22800: train loss 1.7069, val loss 1.8737\n",
      "step 22900: train loss 1.6968, val loss 1.8608\n",
      "step 23000: train loss 1.6973, val loss 1.8563\n",
      "step 23100: train loss 1.6960, val loss 1.8571\n",
      "step 23200: train loss 1.6829, val loss 1.8537\n",
      "step 23300: train loss 1.6954, val loss 1.8518\n",
      "step 23400: train loss 1.6860, val loss 1.8558\n",
      "step 23500: train loss 1.6861, val loss 1.8582\n",
      "step 23600: train loss 1.7039, val loss 1.8680\n",
      "step 23700: train loss 1.6958, val loss 1.8535\n",
      "step 23800: train loss 1.6895, val loss 1.8551\n",
      "step 23900: train loss 1.6862, val loss 1.8543\n",
      "step 24000: train loss 1.7000, val loss 1.8509\n",
      "step 24100: train loss 1.6898, val loss 1.8707\n",
      "step 24200: train loss 1.6857, val loss 1.8581\n",
      "step 24300: train loss 1.6886, val loss 1.8577\n",
      "step 24400: train loss 1.6867, val loss 1.8559\n",
      "step 24500: train loss 1.6969, val loss 1.8532\n",
      "step 24600: train loss 1.6853, val loss 1.8495\n",
      "step 24700: train loss 1.6952, val loss 1.8536\n",
      "step 24800: train loss 1.6857, val loss 1.8574\n",
      "step 24900: train loss 1.6929, val loss 1.8567\n",
      "step 25000: train loss 1.6903, val loss 1.8486\n",
      "step 25100: train loss 1.6913, val loss 1.8599\n",
      "step 25200: train loss 1.6976, val loss 1.8445\n",
      "step 25300: train loss 1.6955, val loss 1.8577\n",
      "step 25400: train loss 1.7000, val loss 1.8607\n",
      "step 25500: train loss 1.6889, val loss 1.8490\n",
      "step 25600: train loss 1.6963, val loss 1.8586\n",
      "step 25700: train loss 1.6916, val loss 1.8439\n",
      "step 25800: train loss 1.6837, val loss 1.8526\n",
      "step 25900: train loss 1.6949, val loss 1.8516\n",
      "step 26000: train loss 1.6882, val loss 1.8559\n",
      "step 26100: train loss 1.6939, val loss 1.8387\n",
      "step 26200: train loss 1.6865, val loss 1.8575\n",
      "step 26300: train loss 1.6818, val loss 1.8485\n",
      "step 26400: train loss 1.6847, val loss 1.8569\n",
      "step 26500: train loss 1.6838, val loss 1.8573\n",
      "step 26600: train loss 1.6743, val loss 1.8636\n",
      "step 26700: train loss 1.6822, val loss 1.8549\n",
      "step 26800: train loss 1.6776, val loss 1.8427\n",
      "step 26900: train loss 1.6878, val loss 1.8587\n",
      "step 27000: train loss 1.6772, val loss 1.8418\n",
      "step 27100: train loss 1.6930, val loss 1.8523\n",
      "step 27200: train loss 1.6815, val loss 1.8450\n",
      "step 27300: train loss 1.6851, val loss 1.8667\n",
      "step 27400: train loss 1.6834, val loss 1.8580\n",
      "step 27500: train loss 1.6796, val loss 1.8484\n",
      "step 27600: train loss 1.6886, val loss 1.8557\n",
      "step 27700: train loss 1.6718, val loss 1.8449\n",
      "step 27800: train loss 1.6866, val loss 1.8454\n",
      "step 27900: train loss 1.6900, val loss 1.8385\n",
      "step 28000: train loss 1.6890, val loss 1.8552\n",
      "step 28100: train loss 1.6768, val loss 1.8372\n",
      "step 28200: train loss 1.6774, val loss 1.8436\n",
      "step 28300: train loss 1.6816, val loss 1.8529\n",
      "step 28400: train loss 1.6806, val loss 1.8504\n",
      "step 28500: train loss 1.6678, val loss 1.8422\n",
      "step 28600: train loss 1.6730, val loss 1.8625\n",
      "step 28700: train loss 1.6788, val loss 1.8386\n",
      "step 28800: train loss 1.6808, val loss 1.8461\n",
      "step 28900: train loss 1.6734, val loss 1.8486\n",
      "step 29000: train loss 1.6754, val loss 1.8333\n",
      "step 29100: train loss 1.6734, val loss 1.8386\n",
      "step 29200: train loss 1.6768, val loss 1.8384\n",
      "step 29300: train loss 1.6816, val loss 1.8257\n",
      "step 29400: train loss 1.6889, val loss 1.8469\n",
      "step 29500: train loss 1.6725, val loss 1.8402\n",
      "step 29600: train loss 1.6697, val loss 1.8376\n",
      "step 29700: train loss 1.6798, val loss 1.8533\n",
      "step 29800: train loss 1.6784, val loss 1.8359\n",
      "step 29900: train loss 1.6769, val loss 1.8436\n",
      "step 30000: train loss 1.6774, val loss 1.8426\n",
      "step 30100: train loss 1.6806, val loss 1.8435\n",
      "step 30200: train loss 1.6751, val loss 1.8344\n",
      "step 30300: train loss 1.6675, val loss 1.8324\n",
      "step 30400: train loss 1.6869, val loss 1.8410\n",
      "step 30500: train loss 1.6785, val loss 1.8497\n",
      "step 30600: train loss 1.6702, val loss 1.8270\n",
      "step 30700: train loss 1.6675, val loss 1.8257\n",
      "step 30800: train loss 1.6735, val loss 1.8406\n",
      "step 30900: train loss 1.6689, val loss 1.8387\n",
      "step 31000: train loss 1.6716, val loss 1.8352\n",
      "step 31100: train loss 1.6740, val loss 1.8378\n",
      "step 31200: train loss 1.6811, val loss 1.8362\n",
      "step 31300: train loss 1.6779, val loss 1.8381\n",
      "step 31400: train loss 1.6681, val loss 1.8439\n",
      "step 31500: train loss 1.6698, val loss 1.8341\n",
      "step 31600: train loss 1.6860, val loss 1.8269\n",
      "step 31700: train loss 1.6655, val loss 1.8380\n",
      "step 31800: train loss 1.6699, val loss 1.8336\n",
      "step 31900: train loss 1.6655, val loss 1.8376\n",
      "step 32000: train loss 1.6674, val loss 1.8338\n",
      "step 32100: train loss 1.6584, val loss 1.8344\n",
      "step 32200: train loss 1.6768, val loss 1.8366\n",
      "step 32300: train loss 1.6685, val loss 1.8320\n",
      "step 32400: train loss 1.6723, val loss 1.8294\n",
      "step 32500: train loss 1.6661, val loss 1.8192\n",
      "step 32600: train loss 1.6676, val loss 1.8271\n",
      "step 32700: train loss 1.6685, val loss 1.8290\n",
      "step 32800: train loss 1.6660, val loss 1.8257\n",
      "step 32900: train loss 1.6657, val loss 1.8385\n",
      "step 33000: train loss 1.6695, val loss 1.8287\n",
      "step 33100: train loss 1.6772, val loss 1.8380\n",
      "step 33200: train loss 1.6718, val loss 1.8413\n",
      "step 33300: train loss 1.6797, val loss 1.8407\n",
      "step 33400: train loss 1.6684, val loss 1.8414\n",
      "step 33500: train loss 1.6706, val loss 1.8366\n",
      "step 33600: train loss 1.6658, val loss 1.8281\n",
      "step 33700: train loss 1.6659, val loss 1.8487\n",
      "step 33800: train loss 1.6732, val loss 1.8255\n",
      "step 33900: train loss 1.6665, val loss 1.8239\n",
      "step 34000: train loss 1.6674, val loss 1.8329\n",
      "step 34100: train loss 1.6586, val loss 1.8113\n",
      "step 34200: train loss 1.6673, val loss 1.8252\n",
      "step 34300: train loss 1.6562, val loss 1.8299\n",
      "step 34400: train loss 1.6733, val loss 1.8488\n",
      "step 34500: train loss 1.6659, val loss 1.8300\n",
      "step 34600: train loss 1.6548, val loss 1.8180\n",
      "step 34700: train loss 1.6678, val loss 1.8287\n",
      "step 34800: train loss 1.6729, val loss 1.8235\n",
      "step 34900: train loss 1.6627, val loss 1.8252\n",
      "step 35000: train loss 1.6572, val loss 1.8199\n",
      "step 35100: train loss 1.6672, val loss 1.8185\n",
      "step 35200: train loss 1.6594, val loss 1.8126\n",
      "step 35300: train loss 1.6615, val loss 1.8283\n",
      "step 35400: train loss 1.6584, val loss 1.8292\n",
      "step 35500: train loss 1.6647, val loss 1.8349\n",
      "step 35600: train loss 1.6699, val loss 1.8203\n",
      "step 35700: train loss 1.6587, val loss 1.8185\n",
      "step 35800: train loss 1.6585, val loss 1.8209\n",
      "step 35900: train loss 1.6646, val loss 1.8194\n",
      "step 36000: train loss 1.6645, val loss 1.8354\n",
      "step 36100: train loss 1.6577, val loss 1.8315\n",
      "step 36200: train loss 1.6510, val loss 1.8289\n",
      "step 36300: train loss 1.6592, val loss 1.8163\n",
      "step 36400: train loss 1.6575, val loss 1.8304\n",
      "step 36500: train loss 1.6667, val loss 1.8235\n",
      "step 36600: train loss 1.6534, val loss 1.8170\n",
      "step 36700: train loss 1.6597, val loss 1.8407\n",
      "step 36800: train loss 1.6631, val loss 1.8273\n",
      "step 36900: train loss 1.6663, val loss 1.8297\n",
      "step 37000: train loss 1.6582, val loss 1.8332\n",
      "step 37100: train loss 1.6520, val loss 1.8311\n",
      "step 37200: train loss 1.6462, val loss 1.8283\n",
      "step 37300: train loss 1.6700, val loss 1.8345\n",
      "step 37400: train loss 1.6614, val loss 1.8246\n",
      "step 37500: train loss 1.6620, val loss 1.8217\n",
      "step 37600: train loss 1.6562, val loss 1.8212\n",
      "step 37700: train loss 1.6467, val loss 1.8281\n",
      "step 37800: train loss 1.6601, val loss 1.8422\n",
      "step 37900: train loss 1.6620, val loss 1.8302\n",
      "step 38000: train loss 1.6591, val loss 1.8260\n",
      "step 38100: train loss 1.6567, val loss 1.8304\n",
      "step 38200: train loss 1.6572, val loss 1.8194\n",
      "step 38300: train loss 1.6524, val loss 1.8270\n",
      "step 38400: train loss 1.6492, val loss 1.8337\n",
      "step 38500: train loss 1.6578, val loss 1.8226\n",
      "step 38600: train loss 1.6618, val loss 1.8334\n",
      "step 38700: train loss 1.6519, val loss 1.8278\n",
      "step 38800: train loss 1.6573, val loss 1.8317\n",
      "step 38900: train loss 1.6564, val loss 1.8174\n",
      "step 39000: train loss 1.6566, val loss 1.8334\n",
      "step 39100: train loss 1.6451, val loss 1.8206\n",
      "step 39200: train loss 1.6473, val loss 1.8324\n",
      "step 39300: train loss 1.6567, val loss 1.8220\n",
      "step 39400: train loss 1.6515, val loss 1.8195\n",
      "step 39500: train loss 1.6607, val loss 1.8426\n",
      "step 39600: train loss 1.6464, val loss 1.8314\n",
      "step 39700: train loss 1.6588, val loss 1.8317\n",
      "step 39800: train loss 1.6667, val loss 1.8291\n",
      "step 39900: train loss 1.6558, val loss 1.8325\n",
      "step 40000: train loss 1.6565, val loss 1.8218\n",
      "step 40100: train loss 1.6589, val loss 1.8273\n",
      "step 40200: train loss 1.6567, val loss 1.8211\n",
      "step 40300: train loss 1.6516, val loss 1.8293\n",
      "step 40400: train loss 1.6586, val loss 1.8286\n",
      "step 40500: train loss 1.6492, val loss 1.8209\n",
      "step 40600: train loss 1.6486, val loss 1.8312\n",
      "step 40700: train loss 1.6590, val loss 1.8150\n",
      "step 40800: train loss 1.6610, val loss 1.8388\n",
      "step 40900: train loss 1.6493, val loss 1.8103\n",
      "step 41000: train loss 1.6536, val loss 1.8273\n",
      "step 41100: train loss 1.6603, val loss 1.8194\n",
      "step 41200: train loss 1.6562, val loss 1.8248\n",
      "step 41300: train loss 1.6587, val loss 1.8208\n",
      "step 41400: train loss 1.6487, val loss 1.8175\n",
      "step 41500: train loss 1.6537, val loss 1.8156\n",
      "step 41600: train loss 1.6525, val loss 1.8126\n",
      "step 41700: train loss 1.6545, val loss 1.8320\n",
      "step 41800: train loss 1.6391, val loss 1.8231\n",
      "step 41900: train loss 1.6488, val loss 1.8063\n",
      "step 42000: train loss 1.6511, val loss 1.8233\n",
      "step 42100: train loss 1.6570, val loss 1.8129\n",
      "step 42200: train loss 1.6467, val loss 1.8126\n",
      "step 42300: train loss 1.6469, val loss 1.8179\n",
      "step 42400: train loss 1.6546, val loss 1.8104\n",
      "step 42500: train loss 1.6535, val loss 1.8064\n",
      "step 42600: train loss 1.6396, val loss 1.8178\n",
      "step 42700: train loss 1.6565, val loss 1.8146\n",
      "step 42800: train loss 1.6440, val loss 1.8190\n",
      "step 42900: train loss 1.6510, val loss 1.8154\n",
      "step 43000: train loss 1.6521, val loss 1.8219\n",
      "step 43100: train loss 1.6602, val loss 1.8320\n",
      "step 43200: train loss 1.6453, val loss 1.8288\n",
      "step 43300: train loss 1.6429, val loss 1.8251\n",
      "step 43400: train loss 1.6486, val loss 1.8230\n",
      "step 43500: train loss 1.6493, val loss 1.8254\n",
      "step 43600: train loss 1.6393, val loss 1.8222\n",
      "step 43700: train loss 1.6451, val loss 1.8079\n",
      "step 43800: train loss 1.6415, val loss 1.8195\n",
      "step 43900: train loss 1.6473, val loss 1.8188\n",
      "step 44000: train loss 1.6505, val loss 1.8147\n",
      "step 44100: train loss 1.6498, val loss 1.8186\n",
      "step 44200: train loss 1.6450, val loss 1.8218\n",
      "step 44300: train loss 1.6399, val loss 1.8251\n",
      "step 44400: train loss 1.6555, val loss 1.8328\n",
      "step 44500: train loss 1.6346, val loss 1.8176\n",
      "step 44600: train loss 1.6544, val loss 1.8243\n",
      "step 44700: train loss 1.6488, val loss 1.8259\n",
      "step 44800: train loss 1.6519, val loss 1.8147\n",
      "step 44900: train loss 1.6485, val loss 1.8131\n",
      "step 45000: train loss 1.6402, val loss 1.8215\n",
      "step 45100: train loss 1.6489, val loss 1.8234\n",
      "step 45200: train loss 1.6405, val loss 1.8178\n",
      "step 45300: train loss 1.6392, val loss 1.7988\n",
      "step 45400: train loss 1.6473, val loss 1.8281\n",
      "step 45500: train loss 1.6421, val loss 1.8187\n",
      "step 45600: train loss 1.6462, val loss 1.8224\n",
      "step 45700: train loss 1.6494, val loss 1.8229\n",
      "step 45800: train loss 1.6485, val loss 1.8197\n",
      "step 45900: train loss 1.6467, val loss 1.8122\n",
      "step 46000: train loss 1.6446, val loss 1.8208\n",
      "step 46100: train loss 1.6440, val loss 1.8124\n",
      "step 46200: train loss 1.6506, val loss 1.8113\n",
      "step 46300: train loss 1.6387, val loss 1.8021\n",
      "step 46400: train loss 1.6388, val loss 1.8117\n",
      "step 46500: train loss 1.6315, val loss 1.8111\n",
      "step 46600: train loss 1.6560, val loss 1.8214\n",
      "step 46700: train loss 1.6376, val loss 1.8158\n",
      "step 46800: train loss 1.6519, val loss 1.8175\n",
      "step 46900: train loss 1.6377, val loss 1.8087\n",
      "step 47000: train loss 1.6442, val loss 1.8111\n",
      "step 47100: train loss 1.6385, val loss 1.8149\n",
      "step 47200: train loss 1.6450, val loss 1.8076\n",
      "step 47300: train loss 1.6470, val loss 1.8123\n",
      "step 47400: train loss 1.6363, val loss 1.8163\n",
      "step 47500: train loss 1.6518, val loss 1.8118\n",
      "step 47600: train loss 1.6430, val loss 1.8238\n",
      "step 47700: train loss 1.6474, val loss 1.8268\n",
      "step 47800: train loss 1.6393, val loss 1.8105\n",
      "step 47900: train loss 1.6437, val loss 1.8134\n",
      "step 48000: train loss 1.6485, val loss 1.8250\n",
      "step 48100: train loss 1.6324, val loss 1.8105\n",
      "step 48200: train loss 1.6359, val loss 1.7987\n",
      "step 48300: train loss 1.6422, val loss 1.8044\n",
      "step 48400: train loss 1.6428, val loss 1.8106\n",
      "step 48500: train loss 1.6357, val loss 1.8079\n",
      "step 48600: train loss 1.6386, val loss 1.8017\n",
      "step 48700: train loss 1.6440, val loss 1.8131\n",
      "step 48800: train loss 1.6474, val loss 1.8206\n",
      "step 48900: train loss 1.6450, val loss 1.8190\n",
      "step 49000: train loss 1.6334, val loss 1.8262\n",
      "step 49100: train loss 1.6315, val loss 1.8146\n",
      "step 49200: train loss 1.6357, val loss 1.8126\n",
      "step 49300: train loss 1.6401, val loss 1.8028\n",
      "step 49400: train loss 1.6332, val loss 1.8065\n",
      "step 49500: train loss 1.6422, val loss 1.8129\n",
      "step 49600: train loss 1.6502, val loss 1.8240\n",
      "step 49700: train loss 1.6305, val loss 1.8137\n",
      "step 49800: train loss 1.6420, val loss 1.8006\n",
      "step 49900: train loss 1.6419, val loss 1.8058\n",
      "step 49999: train loss 1.6436, val loss 1.7990\n",
      "Results for configuration res1_dropout=0.025_res2_dropout=0.5_res4_dropout=0.0_use_double_layers=False saved.\n",
      "Training model with configuration: {'res1_dropout': 0.025, 'res2_dropout': 0.99, 'res4_dropout': 0.0, 'use_double_layers': False}\n",
      "step 0: train loss 4.3606, val loss 4.3606\n",
      "step 100: train loss 2.7084, val loss 2.7384\n",
      "step 200: train loss 2.5709, val loss 2.5711\n",
      "step 300: train loss 2.5010, val loss 2.5032\n",
      "step 400: train loss 2.4462, val loss 2.4800\n",
      "step 500: train loss 2.4093, val loss 2.4123\n",
      "step 600: train loss 2.3755, val loss 2.3797\n",
      "step 700: train loss 2.3271, val loss 2.3389\n",
      "step 800: train loss 2.2900, val loss 2.2972\n",
      "step 900: train loss 2.2572, val loss 2.2699\n",
      "step 1000: train loss 2.2274, val loss 2.2474\n",
      "step 1100: train loss 2.2041, val loss 2.2296\n",
      "step 1200: train loss 2.1833, val loss 2.2002\n",
      "step 1300: train loss 2.1650, val loss 2.1836\n",
      "step 1400: train loss 2.1468, val loss 2.1740\n",
      "step 1500: train loss 2.1378, val loss 2.1707\n",
      "step 1600: train loss 2.1191, val loss 2.1486\n",
      "step 1700: train loss 2.1102, val loss 2.1464\n",
      "step 1800: train loss 2.0952, val loss 2.1254\n",
      "step 1900: train loss 2.0864, val loss 2.1340\n",
      "step 2000: train loss 2.0696, val loss 2.1050\n",
      "step 2100: train loss 2.0566, val loss 2.0986\n",
      "step 2200: train loss 2.0337, val loss 2.0925\n",
      "step 2300: train loss 2.0317, val loss 2.0851\n",
      "step 2400: train loss 2.0152, val loss 2.0833\n",
      "step 2500: train loss 2.0248, val loss 2.0771\n",
      "step 2600: train loss 2.0067, val loss 2.0743\n",
      "step 2700: train loss 1.9990, val loss 2.0626\n",
      "step 2800: train loss 1.9836, val loss 2.0518\n",
      "step 2900: train loss 1.9758, val loss 2.0391\n",
      "step 3000: train loss 1.9707, val loss 2.0413\n",
      "step 3100: train loss 1.9539, val loss 2.0347\n",
      "step 3200: train loss 1.9675, val loss 2.0303\n",
      "step 3300: train loss 1.9542, val loss 2.0329\n",
      "step 3400: train loss 1.9444, val loss 2.0171\n",
      "step 3500: train loss 1.9342, val loss 2.0167\n",
      "step 3600: train loss 1.9288, val loss 2.0333\n",
      "step 3700: train loss 1.9402, val loss 2.0147\n",
      "step 3800: train loss 1.9284, val loss 2.0011\n",
      "step 3900: train loss 1.9194, val loss 1.9994\n",
      "step 4000: train loss 1.9046, val loss 2.0021\n",
      "step 4100: train loss 1.8968, val loss 1.9976\n",
      "step 4200: train loss 1.9098, val loss 1.9963\n",
      "step 4300: train loss 1.8990, val loss 1.9884\n",
      "step 4400: train loss 1.9049, val loss 1.9928\n",
      "step 4500: train loss 1.8973, val loss 1.9895\n",
      "step 4600: train loss 1.8875, val loss 1.9871\n",
      "step 4700: train loss 1.8865, val loss 1.9811\n",
      "step 4800: train loss 1.8881, val loss 1.9789\n",
      "step 4900: train loss 1.8797, val loss 1.9809\n",
      "step 5000: train loss 1.8673, val loss 1.9786\n",
      "step 5100: train loss 1.8785, val loss 1.9758\n",
      "step 5200: train loss 1.8706, val loss 1.9916\n",
      "step 5300: train loss 1.8694, val loss 1.9817\n",
      "step 5400: train loss 1.8598, val loss 1.9719\n",
      "step 5500: train loss 1.8641, val loss 1.9758\n",
      "step 5600: train loss 1.8583, val loss 1.9622\n",
      "step 5700: train loss 1.8527, val loss 1.9653\n",
      "step 5800: train loss 1.8541, val loss 1.9726\n",
      "step 5900: train loss 1.8375, val loss 1.9671\n",
      "step 6000: train loss 1.8428, val loss 1.9678\n",
      "step 6100: train loss 1.8338, val loss 1.9681\n",
      "step 6200: train loss 1.8207, val loss 1.9579\n",
      "step 6300: train loss 1.8418, val loss 1.9698\n",
      "step 6400: train loss 1.8400, val loss 1.9605\n",
      "step 6500: train loss 1.8255, val loss 1.9536\n",
      "step 6600: train loss 1.8393, val loss 1.9566\n",
      "step 6700: train loss 1.8276, val loss 1.9521\n",
      "step 6800: train loss 1.8252, val loss 1.9450\n",
      "step 6900: train loss 1.8152, val loss 1.9560\n",
      "step 7000: train loss 1.8134, val loss 1.9522\n",
      "step 7100: train loss 1.8197, val loss 1.9428\n",
      "step 7200: train loss 1.8133, val loss 1.9446\n",
      "step 7300: train loss 1.8172, val loss 1.9404\n",
      "step 7400: train loss 1.8115, val loss 1.9303\n",
      "step 7500: train loss 1.8122, val loss 1.9430\n",
      "step 7600: train loss 1.8083, val loss 1.9472\n",
      "step 7700: train loss 1.7987, val loss 1.9426\n",
      "step 7800: train loss 1.8023, val loss 1.9332\n",
      "step 7900: train loss 1.8126, val loss 1.9372\n",
      "step 8000: train loss 1.7839, val loss 1.9213\n",
      "step 8100: train loss 1.7966, val loss 1.9380\n",
      "step 8200: train loss 1.7974, val loss 1.9265\n",
      "step 8300: train loss 1.7988, val loss 1.9361\n",
      "step 8400: train loss 1.7798, val loss 1.9274\n",
      "step 8500: train loss 1.7828, val loss 1.9339\n",
      "step 8600: train loss 1.7870, val loss 1.9386\n",
      "step 8700: train loss 1.7856, val loss 1.9363\n",
      "step 8800: train loss 1.7786, val loss 1.9281\n",
      "step 8900: train loss 1.7771, val loss 1.9100\n",
      "step 9000: train loss 1.7700, val loss 1.9196\n",
      "step 9100: train loss 1.7798, val loss 1.9117\n",
      "step 9200: train loss 1.7726, val loss 1.9130\n",
      "step 9300: train loss 1.7719, val loss 1.9155\n",
      "step 9400: train loss 1.7706, val loss 1.9119\n",
      "step 9500: train loss 1.7698, val loss 1.9355\n",
      "step 9600: train loss 1.7728, val loss 1.9224\n",
      "step 9700: train loss 1.7737, val loss 1.9290\n",
      "step 9800: train loss 1.7789, val loss 1.9158\n",
      "step 9900: train loss 1.7690, val loss 1.9167\n",
      "step 10000: train loss 1.7685, val loss 1.9159\n",
      "step 10100: train loss 1.7659, val loss 1.9113\n",
      "step 10200: train loss 1.7672, val loss 1.9152\n",
      "step 10300: train loss 1.7661, val loss 1.9136\n",
      "step 10400: train loss 1.7603, val loss 1.9074\n",
      "step 10500: train loss 1.7798, val loss 1.9036\n",
      "step 10600: train loss 1.7543, val loss 1.9059\n",
      "step 10700: train loss 1.7512, val loss 1.9186\n",
      "step 10800: train loss 1.7489, val loss 1.9000\n",
      "step 10900: train loss 1.7571, val loss 1.8945\n",
      "step 11000: train loss 1.7615, val loss 1.9149\n",
      "step 11100: train loss 1.7437, val loss 1.9048\n",
      "step 11200: train loss 1.7571, val loss 1.9088\n",
      "step 11300: train loss 1.7475, val loss 1.8981\n",
      "step 11400: train loss 1.7565, val loss 1.9045\n",
      "step 11500: train loss 1.7585, val loss 1.9093\n",
      "step 11600: train loss 1.7440, val loss 1.9050\n",
      "step 11700: train loss 1.7523, val loss 1.8850\n",
      "step 11800: train loss 1.7484, val loss 1.9037\n",
      "step 11900: train loss 1.7533, val loss 1.8904\n",
      "step 12000: train loss 1.7457, val loss 1.8955\n",
      "step 12100: train loss 1.7484, val loss 1.8966\n",
      "step 12200: train loss 1.7371, val loss 1.8949\n",
      "step 12300: train loss 1.7437, val loss 1.8977\n",
      "step 12400: train loss 1.7278, val loss 1.8833\n",
      "step 12500: train loss 1.7349, val loss 1.8871\n",
      "step 12600: train loss 1.7512, val loss 1.8952\n",
      "step 12700: train loss 1.7396, val loss 1.8836\n",
      "step 12800: train loss 1.7366, val loss 1.8879\n",
      "step 12900: train loss 1.7427, val loss 1.8890\n",
      "step 13000: train loss 1.7358, val loss 1.9003\n",
      "step 13100: train loss 1.7378, val loss 1.8915\n",
      "step 13200: train loss 1.7344, val loss 1.8750\n",
      "step 13300: train loss 1.7374, val loss 1.8892\n",
      "step 13400: train loss 1.7267, val loss 1.8837\n",
      "step 13500: train loss 1.7305, val loss 1.8864\n",
      "step 13600: train loss 1.7371, val loss 1.8807\n",
      "step 13700: train loss 1.7360, val loss 1.8860\n",
      "step 13800: train loss 1.7215, val loss 1.8852\n",
      "step 13900: train loss 1.7283, val loss 1.8876\n",
      "step 14000: train loss 1.7319, val loss 1.8910\n",
      "step 14100: train loss 1.7218, val loss 1.8822\n",
      "step 14200: train loss 1.7300, val loss 1.8786\n",
      "step 14300: train loss 1.7263, val loss 1.8798\n",
      "step 14400: train loss 1.7192, val loss 1.8823\n",
      "step 14500: train loss 1.7183, val loss 1.8603\n",
      "step 14600: train loss 1.7184, val loss 1.8665\n",
      "step 14700: train loss 1.7165, val loss 1.8780\n",
      "step 14800: train loss 1.7186, val loss 1.8654\n",
      "step 14900: train loss 1.7205, val loss 1.8576\n",
      "step 15000: train loss 1.7259, val loss 1.8743\n",
      "step 15100: train loss 1.7162, val loss 1.8783\n",
      "step 15200: train loss 1.7169, val loss 1.8757\n",
      "step 15300: train loss 1.7181, val loss 1.8589\n",
      "step 15400: train loss 1.7205, val loss 1.8803\n",
      "step 15500: train loss 1.7272, val loss 1.8803\n",
      "step 15600: train loss 1.7240, val loss 1.8729\n",
      "step 15700: train loss 1.7258, val loss 1.8642\n",
      "step 15800: train loss 1.7151, val loss 1.8674\n",
      "step 15900: train loss 1.7141, val loss 1.8755\n",
      "step 16000: train loss 1.7172, val loss 1.8639\n",
      "step 16100: train loss 1.7182, val loss 1.8707\n",
      "step 16200: train loss 1.7151, val loss 1.8696\n",
      "step 16300: train loss 1.7103, val loss 1.8784\n",
      "step 16400: train loss 1.7129, val loss 1.8751\n",
      "step 16500: train loss 1.6977, val loss 1.8704\n",
      "step 16600: train loss 1.7094, val loss 1.8765\n",
      "step 16700: train loss 1.7110, val loss 1.8698\n",
      "step 16800: train loss 1.7151, val loss 1.8753\n",
      "step 16900: train loss 1.7151, val loss 1.8745\n",
      "step 17000: train loss 1.7094, val loss 1.8632\n",
      "step 17100: train loss 1.7064, val loss 1.8602\n",
      "step 17200: train loss 1.7193, val loss 1.8702\n",
      "step 17300: train loss 1.7043, val loss 1.8508\n",
      "step 17400: train loss 1.7244, val loss 1.8615\n",
      "step 17500: train loss 1.7056, val loss 1.8613\n",
      "step 17600: train loss 1.7085, val loss 1.8689\n",
      "step 17700: train loss 1.7032, val loss 1.8519\n",
      "step 17800: train loss 1.7029, val loss 1.8569\n",
      "step 17900: train loss 1.7038, val loss 1.8597\n",
      "step 18000: train loss 1.7071, val loss 1.8756\n",
      "step 18100: train loss 1.7025, val loss 1.8665\n",
      "step 18200: train loss 1.7077, val loss 1.8614\n",
      "step 18300: train loss 1.6989, val loss 1.8634\n",
      "step 18400: train loss 1.7053, val loss 1.8692\n",
      "step 18500: train loss 1.6989, val loss 1.8542\n",
      "step 18600: train loss 1.6927, val loss 1.8575\n",
      "step 18700: train loss 1.6974, val loss 1.8553\n",
      "step 18800: train loss 1.7009, val loss 1.8603\n",
      "step 18900: train loss 1.6979, val loss 1.8639\n",
      "step 19000: train loss 1.6932, val loss 1.8716\n",
      "step 19100: train loss 1.6992, val loss 1.8516\n",
      "step 19200: train loss 1.6998, val loss 1.8759\n",
      "step 19300: train loss 1.6961, val loss 1.8585\n",
      "step 19400: train loss 1.7049, val loss 1.8503\n",
      "step 19500: train loss 1.6941, val loss 1.8538\n",
      "step 19600: train loss 1.6927, val loss 1.8661\n",
      "step 19700: train loss 1.6923, val loss 1.8587\n",
      "step 19800: train loss 1.7014, val loss 1.8446\n",
      "step 19900: train loss 1.6908, val loss 1.8499\n",
      "step 20000: train loss 1.7025, val loss 1.8641\n",
      "step 20100: train loss 1.6908, val loss 1.8542\n",
      "step 20200: train loss 1.6933, val loss 1.8599\n",
      "step 20300: train loss 1.6971, val loss 1.8546\n",
      "step 20400: train loss 1.6886, val loss 1.8570\n",
      "step 20500: train loss 1.6943, val loss 1.8596\n",
      "step 20600: train loss 1.6931, val loss 1.8621\n",
      "step 20700: train loss 1.6858, val loss 1.8722\n",
      "step 20800: train loss 1.7040, val loss 1.8629\n",
      "step 20900: train loss 1.6975, val loss 1.8558\n",
      "step 21000: train loss 1.6976, val loss 1.8338\n",
      "step 21100: train loss 1.6853, val loss 1.8547\n",
      "step 21200: train loss 1.6903, val loss 1.8465\n",
      "step 21300: train loss 1.6909, val loss 1.8717\n",
      "step 21400: train loss 1.6792, val loss 1.8633\n",
      "step 21500: train loss 1.6883, val loss 1.8496\n",
      "step 21600: train loss 1.6863, val loss 1.8586\n",
      "step 21700: train loss 1.6967, val loss 1.8704\n",
      "step 21800: train loss 1.6822, val loss 1.8678\n",
      "step 21900: train loss 1.6945, val loss 1.8538\n",
      "step 22000: train loss 1.6929, val loss 1.8525\n",
      "step 22100: train loss 1.6838, val loss 1.8378\n",
      "step 22200: train loss 1.6833, val loss 1.8430\n",
      "step 22300: train loss 1.6785, val loss 1.8461\n",
      "step 22400: train loss 1.6856, val loss 1.8393\n",
      "step 22500: train loss 1.6958, val loss 1.8382\n",
      "step 22600: train loss 1.6858, val loss 1.8426\n",
      "step 22700: train loss 1.6900, val loss 1.8333\n",
      "step 22800: train loss 1.6895, val loss 1.8418\n",
      "step 22900: train loss 1.6806, val loss 1.8369\n",
      "step 23000: train loss 1.6910, val loss 1.8373\n",
      "step 23100: train loss 1.6921, val loss 1.8395\n",
      "step 23200: train loss 1.6840, val loss 1.8523\n",
      "step 23300: train loss 1.6850, val loss 1.8463\n",
      "step 23400: train loss 1.6802, val loss 1.8335\n",
      "step 23500: train loss 1.6764, val loss 1.8532\n",
      "step 23600: train loss 1.6832, val loss 1.8392\n",
      "step 23700: train loss 1.6821, val loss 1.8491\n",
      "step 23800: train loss 1.6899, val loss 1.8451\n",
      "step 23900: train loss 1.6873, val loss 1.8431\n",
      "step 24000: train loss 1.6802, val loss 1.8423\n",
      "step 24100: train loss 1.6787, val loss 1.8551\n",
      "step 24200: train loss 1.6816, val loss 1.8437\n",
      "step 24300: train loss 1.6787, val loss 1.8453\n",
      "step 24400: train loss 1.6806, val loss 1.8659\n",
      "step 24500: train loss 1.6841, val loss 1.8477\n",
      "step 24600: train loss 1.6769, val loss 1.8254\n",
      "step 24700: train loss 1.6878, val loss 1.8433\n",
      "step 24800: train loss 1.6825, val loss 1.8561\n",
      "step 24900: train loss 1.6823, val loss 1.8415\n",
      "step 25000: train loss 1.6627, val loss 1.8275\n",
      "step 25100: train loss 1.6831, val loss 1.8377\n",
      "step 25200: train loss 1.6790, val loss 1.8401\n",
      "step 25300: train loss 1.6746, val loss 1.8233\n",
      "step 25400: train loss 1.6725, val loss 1.8427\n",
      "step 25500: train loss 1.6783, val loss 1.8480\n",
      "step 25600: train loss 1.6728, val loss 1.8340\n",
      "step 25700: train loss 1.6795, val loss 1.8246\n",
      "step 25800: train loss 1.6949, val loss 1.8409\n",
      "step 25900: train loss 1.6744, val loss 1.8331\n",
      "step 26000: train loss 1.6701, val loss 1.8420\n",
      "step 26100: train loss 1.6625, val loss 1.8412\n",
      "step 26200: train loss 1.6788, val loss 1.8298\n",
      "step 26300: train loss 1.6762, val loss 1.8393\n",
      "step 26400: train loss 1.6805, val loss 1.8191\n",
      "step 26500: train loss 1.6726, val loss 1.8309\n",
      "step 26600: train loss 1.6711, val loss 1.8306\n",
      "step 26700: train loss 1.6866, val loss 1.8375\n",
      "step 26800: train loss 1.6759, val loss 1.8380\n",
      "step 26900: train loss 1.6689, val loss 1.8387\n",
      "step 27000: train loss 1.6650, val loss 1.8470\n",
      "step 27100: train loss 1.6668, val loss 1.8287\n",
      "step 27200: train loss 1.6706, val loss 1.8614\n",
      "step 27300: train loss 1.6794, val loss 1.8259\n",
      "step 27400: train loss 1.6685, val loss 1.8343\n",
      "step 27500: train loss 1.6778, val loss 1.8308\n",
      "step 27600: train loss 1.6751, val loss 1.8336\n",
      "step 27700: train loss 1.6706, val loss 1.8267\n",
      "step 27800: train loss 1.6729, val loss 1.8486\n",
      "step 27900: train loss 1.6697, val loss 1.8397\n",
      "step 28000: train loss 1.6739, val loss 1.8489\n",
      "step 28100: train loss 1.6711, val loss 1.8377\n",
      "step 28200: train loss 1.6549, val loss 1.8392\n",
      "step 28300: train loss 1.6759, val loss 1.8329\n",
      "step 28400: train loss 1.6716, val loss 1.8379\n",
      "step 28500: train loss 1.6724, val loss 1.8319\n",
      "step 28600: train loss 1.6659, val loss 1.8469\n",
      "step 28700: train loss 1.6675, val loss 1.8354\n",
      "step 28800: train loss 1.6714, val loss 1.8239\n",
      "step 28900: train loss 1.6711, val loss 1.8332\n",
      "step 29000: train loss 1.6645, val loss 1.8337\n",
      "step 29100: train loss 1.6620, val loss 1.8326\n",
      "step 29200: train loss 1.6686, val loss 1.8274\n",
      "step 29300: train loss 1.6686, val loss 1.8321\n",
      "step 29400: train loss 1.6840, val loss 1.8398\n",
      "step 29500: train loss 1.6789, val loss 1.8167\n",
      "step 29600: train loss 1.6699, val loss 1.8290\n",
      "step 29700: train loss 1.6653, val loss 1.8392\n",
      "step 29800: train loss 1.6665, val loss 1.8384\n",
      "step 29900: train loss 1.6700, val loss 1.8398\n",
      "step 30000: train loss 1.6766, val loss 1.8338\n",
      "step 30100: train loss 1.6667, val loss 1.8344\n",
      "step 30200: train loss 1.6650, val loss 1.8432\n",
      "step 30300: train loss 1.6624, val loss 1.8188\n",
      "step 30400: train loss 1.6646, val loss 1.8340\n",
      "step 30500: train loss 1.6564, val loss 1.8320\n",
      "step 30600: train loss 1.6691, val loss 1.8215\n",
      "step 30700: train loss 1.6608, val loss 1.8335\n",
      "step 30800: train loss 1.6688, val loss 1.8368\n",
      "step 30900: train loss 1.6627, val loss 1.8410\n",
      "step 31000: train loss 1.6590, val loss 1.8371\n",
      "step 31100: train loss 1.6604, val loss 1.8399\n",
      "step 31200: train loss 1.6578, val loss 1.8291\n",
      "step 31300: train loss 1.6674, val loss 1.8169\n",
      "step 31400: train loss 1.6579, val loss 1.8194\n",
      "step 31500: train loss 1.6540, val loss 1.8241\n",
      "step 31600: train loss 1.6648, val loss 1.8368\n",
      "step 31700: train loss 1.6525, val loss 1.8233\n",
      "step 31800: train loss 1.6484, val loss 1.8246\n",
      "step 31900: train loss 1.6533, val loss 1.8208\n",
      "step 32000: train loss 1.6552, val loss 1.8208\n",
      "step 32100: train loss 1.6580, val loss 1.8237\n",
      "step 32200: train loss 1.6637, val loss 1.8232\n",
      "step 32300: train loss 1.6503, val loss 1.8385\n",
      "step 32400: train loss 1.6686, val loss 1.8290\n",
      "step 32500: train loss 1.6725, val loss 1.8345\n",
      "step 32600: train loss 1.6591, val loss 1.8302\n",
      "step 32700: train loss 1.6663, val loss 1.8342\n",
      "step 32800: train loss 1.6664, val loss 1.8423\n",
      "step 32900: train loss 1.6657, val loss 1.8278\n",
      "step 33000: train loss 1.6647, val loss 1.8458\n",
      "step 33100: train loss 1.6652, val loss 1.8357\n",
      "step 33200: train loss 1.6633, val loss 1.8141\n",
      "step 33300: train loss 1.6644, val loss 1.8367\n",
      "step 33400: train loss 1.6543, val loss 1.8241\n",
      "step 33500: train loss 1.6582, val loss 1.8209\n",
      "step 33600: train loss 1.6480, val loss 1.8245\n",
      "step 33700: train loss 1.6640, val loss 1.8009\n",
      "step 33800: train loss 1.6564, val loss 1.8215\n",
      "step 33900: train loss 1.6529, val loss 1.8372\n",
      "step 34000: train loss 1.6606, val loss 1.8476\n",
      "step 34100: train loss 1.6559, val loss 1.8389\n",
      "step 34200: train loss 1.6524, val loss 1.8182\n",
      "step 34300: train loss 1.6515, val loss 1.8397\n",
      "step 34400: train loss 1.6599, val loss 1.8271\n",
      "step 34500: train loss 1.6608, val loss 1.8370\n",
      "step 34600: train loss 1.6590, val loss 1.8254\n",
      "step 34700: train loss 1.6617, val loss 1.8215\n",
      "step 34800: train loss 1.6582, val loss 1.8151\n",
      "step 34900: train loss 1.6571, val loss 1.8229\n",
      "step 35000: train loss 1.6512, val loss 1.8053\n",
      "step 35100: train loss 1.6547, val loss 1.8237\n",
      "step 35200: train loss 1.6578, val loss 1.8152\n",
      "step 35300: train loss 1.6578, val loss 1.8401\n",
      "step 35400: train loss 1.6481, val loss 1.8211\n",
      "step 35500: train loss 1.6573, val loss 1.8343\n",
      "step 35600: train loss 1.6677, val loss 1.8244\n",
      "step 35700: train loss 1.6506, val loss 1.8118\n",
      "step 35800: train loss 1.6618, val loss 1.8232\n",
      "step 35900: train loss 1.6547, val loss 1.8086\n",
      "step 36000: train loss 1.6662, val loss 1.8164\n",
      "step 36100: train loss 1.6564, val loss 1.8355\n",
      "step 36200: train loss 1.6549, val loss 1.8331\n",
      "step 36300: train loss 1.6483, val loss 1.8226\n",
      "step 36400: train loss 1.6496, val loss 1.8174\n",
      "step 36500: train loss 1.6422, val loss 1.8139\n",
      "step 36600: train loss 1.6577, val loss 1.8231\n",
      "step 36700: train loss 1.6605, val loss 1.8317\n",
      "step 36800: train loss 1.6484, val loss 1.8252\n",
      "step 36900: train loss 1.6459, val loss 1.8273\n",
      "step 37000: train loss 1.6536, val loss 1.8250\n",
      "step 37100: train loss 1.6514, val loss 1.8367\n",
      "step 37200: train loss 1.6517, val loss 1.8283\n",
      "step 37300: train loss 1.6541, val loss 1.8226\n",
      "step 37400: train loss 1.6645, val loss 1.8395\n",
      "step 37500: train loss 1.6572, val loss 1.8320\n",
      "step 37600: train loss 1.6481, val loss 1.8290\n",
      "step 37700: train loss 1.6524, val loss 1.8352\n",
      "step 37800: train loss 1.6456, val loss 1.8197\n",
      "step 37900: train loss 1.6562, val loss 1.8261\n",
      "step 38000: train loss 1.6423, val loss 1.8278\n",
      "step 38100: train loss 1.6468, val loss 1.8215\n",
      "step 38200: train loss 1.6542, val loss 1.8197\n",
      "step 38300: train loss 1.6501, val loss 1.8335\n",
      "step 38400: train loss 1.6555, val loss 1.8210\n",
      "step 38500: train loss 1.6520, val loss 1.8163\n",
      "step 38600: train loss 1.6515, val loss 1.8282\n",
      "step 38700: train loss 1.6616, val loss 1.8187\n",
      "step 38800: train loss 1.6490, val loss 1.8241\n",
      "step 38900: train loss 1.6508, val loss 1.8269\n",
      "step 39000: train loss 1.6529, val loss 1.8230\n",
      "step 39100: train loss 1.6467, val loss 1.8262\n",
      "step 39200: train loss 1.6411, val loss 1.8148\n",
      "step 39300: train loss 1.6405, val loss 1.8218\n",
      "step 39400: train loss 1.6508, val loss 1.8144\n",
      "step 39500: train loss 1.6560, val loss 1.7924\n",
      "step 39600: train loss 1.6534, val loss 1.8153\n",
      "step 39700: train loss 1.6501, val loss 1.8260\n",
      "step 39800: train loss 1.6531, val loss 1.8069\n",
      "step 39900: train loss 1.6543, val loss 1.8221\n",
      "step 40000: train loss 1.6411, val loss 1.8099\n",
      "step 40100: train loss 1.6565, val loss 1.8122\n",
      "step 40200: train loss 1.6433, val loss 1.8192\n",
      "step 40300: train loss 1.6568, val loss 1.8011\n",
      "step 40400: train loss 1.6468, val loss 1.8291\n",
      "step 40500: train loss 1.6497, val loss 1.8165\n",
      "step 40600: train loss 1.6431, val loss 1.8216\n",
      "step 40700: train loss 1.6502, val loss 1.8127\n",
      "step 40800: train loss 1.6498, val loss 1.8155\n",
      "step 40900: train loss 1.6463, val loss 1.8262\n",
      "step 41000: train loss 1.6483, val loss 1.8205\n",
      "step 41100: train loss 1.6449, val loss 1.8216\n",
      "step 41200: train loss 1.6492, val loss 1.8388\n",
      "step 41300: train loss 1.6480, val loss 1.8257\n",
      "step 41400: train loss 1.6461, val loss 1.8228\n",
      "step 41500: train loss 1.6481, val loss 1.8116\n",
      "step 41600: train loss 1.6419, val loss 1.8162\n",
      "step 41700: train loss 1.6471, val loss 1.8375\n",
      "step 41800: train loss 1.6451, val loss 1.8131\n",
      "step 41900: train loss 1.6532, val loss 1.8259\n",
      "step 42000: train loss 1.6553, val loss 1.8131\n",
      "step 42100: train loss 1.6501, val loss 1.8254\n",
      "step 42200: train loss 1.6477, val loss 1.8310\n",
      "step 42300: train loss 1.6582, val loss 1.8240\n",
      "step 42400: train loss 1.6409, val loss 1.8185\n",
      "step 42500: train loss 1.6438, val loss 1.8204\n",
      "step 42600: train loss 1.6372, val loss 1.8191\n",
      "step 42700: train loss 1.6490, val loss 1.8179\n",
      "step 42800: train loss 1.6423, val loss 1.8196\n",
      "step 42900: train loss 1.6449, val loss 1.8337\n",
      "step 43000: train loss 1.6421, val loss 1.8194\n",
      "step 43100: train loss 1.6483, val loss 1.8213\n",
      "step 43200: train loss 1.6435, val loss 1.8147\n",
      "step 43300: train loss 1.6466, val loss 1.8032\n",
      "step 43400: train loss 1.6401, val loss 1.8216\n",
      "step 43500: train loss 1.6449, val loss 1.8105\n",
      "step 43600: train loss 1.6496, val loss 1.8229\n",
      "step 43700: train loss 1.6469, val loss 1.8158\n",
      "step 43800: train loss 1.6350, val loss 1.8012\n",
      "step 43900: train loss 1.6440, val loss 1.7966\n",
      "step 44000: train loss 1.6521, val loss 1.8183\n",
      "step 44100: train loss 1.6401, val loss 1.8186\n",
      "step 44200: train loss 1.6479, val loss 1.7943\n",
      "step 44300: train loss 1.6419, val loss 1.8088\n",
      "step 44400: train loss 1.6526, val loss 1.8047\n",
      "step 44500: train loss 1.6465, val loss 1.8023\n",
      "step 44600: train loss 1.6355, val loss 1.7865\n",
      "step 44700: train loss 1.6264, val loss 1.8067\n",
      "step 44800: train loss 1.6421, val loss 1.8119\n",
      "step 44900: train loss 1.6403, val loss 1.8073\n",
      "step 45000: train loss 1.6414, val loss 1.8093\n",
      "step 45100: train loss 1.6506, val loss 1.8009\n",
      "step 45200: train loss 1.6405, val loss 1.7913\n",
      "step 45300: train loss 1.6364, val loss 1.8112\n",
      "step 45400: train loss 1.6395, val loss 1.8114\n",
      "step 45500: train loss 1.6391, val loss 1.8068\n",
      "step 45600: train loss 1.6403, val loss 1.8007\n",
      "step 45700: train loss 1.6374, val loss 1.8008\n",
      "step 45800: train loss 1.6473, val loss 1.8013\n",
      "step 45900: train loss 1.6351, val loss 1.8039\n",
      "step 46000: train loss 1.6343, val loss 1.8122\n",
      "step 46100: train loss 1.6399, val loss 1.8291\n",
      "step 46200: train loss 1.6436, val loss 1.8099\n",
      "step 46300: train loss 1.6480, val loss 1.8137\n",
      "step 46400: train loss 1.6352, val loss 1.8103\n",
      "step 46500: train loss 1.6489, val loss 1.7978\n",
      "step 46600: train loss 1.6394, val loss 1.8140\n",
      "step 46700: train loss 1.6551, val loss 1.8170\n",
      "step 46800: train loss 1.6386, val loss 1.8055\n",
      "step 46900: train loss 1.6440, val loss 1.7978\n",
      "step 47000: train loss 1.6333, val loss 1.8085\n",
      "step 47100: train loss 1.6412, val loss 1.8161\n",
      "step 47200: train loss 1.6357, val loss 1.7966\n",
      "step 47300: train loss 1.6476, val loss 1.8081\n",
      "step 47400: train loss 1.6432, val loss 1.8129\n",
      "step 47500: train loss 1.6384, val loss 1.8089\n",
      "step 47600: train loss 1.6382, val loss 1.8188\n",
      "step 47700: train loss 1.6414, val loss 1.8180\n",
      "step 47800: train loss 1.6414, val loss 1.8096\n",
      "step 47900: train loss 1.6391, val loss 1.8201\n",
      "step 48000: train loss 1.6450, val loss 1.7916\n",
      "step 48100: train loss 1.6343, val loss 1.7963\n",
      "step 48200: train loss 1.6385, val loss 1.7955\n",
      "step 48300: train loss 1.6403, val loss 1.8081\n",
      "step 48400: train loss 1.6359, val loss 1.8127\n",
      "step 48500: train loss 1.6359, val loss 1.8011\n",
      "step 48600: train loss 1.6356, val loss 1.8111\n",
      "step 48700: train loss 1.6329, val loss 1.8009\n",
      "step 48800: train loss 1.6395, val loss 1.8158\n",
      "step 48900: train loss 1.6283, val loss 1.8061\n",
      "step 49000: train loss 1.6327, val loss 1.8124\n",
      "step 49100: train loss 1.6265, val loss 1.8198\n",
      "step 49200: train loss 1.6321, val loss 1.8169\n",
      "step 49300: train loss 1.6435, val loss 1.8132\n",
      "step 49400: train loss 1.6438, val loss 1.8099\n",
      "step 49500: train loss 1.6422, val loss 1.8213\n",
      "step 49600: train loss 1.6426, val loss 1.8077\n",
      "step 49700: train loss 1.6329, val loss 1.8187\n",
      "step 49800: train loss 1.6312, val loss 1.8053\n",
      "step 49900: train loss 1.6355, val loss 1.8179\n",
      "step 49999: train loss 1.6367, val loss 1.8056\n",
      "Results for configuration res1_dropout=0.025_res2_dropout=0.99_res4_dropout=0.0_use_double_layers=False saved.\n",
      "Training model with configuration: {'res1_dropout': 0.025, 'res2_dropout': 0.99, 'res4_dropout': 0.1, 'use_double_layers': True}\n",
      "step 0: train loss 4.3829, val loss 4.3777\n",
      "step 100: train loss 2.7413, val loss 2.7551\n",
      "step 200: train loss 2.5566, val loss 2.5579\n",
      "step 300: train loss 2.4802, val loss 2.4731\n",
      "step 400: train loss 2.4282, val loss 2.4326\n",
      "step 500: train loss 2.3817, val loss 2.3849\n",
      "step 600: train loss 2.3356, val loss 2.3599\n",
      "step 700: train loss 2.3221, val loss 2.3245\n",
      "step 800: train loss 2.2737, val loss 2.2773\n",
      "step 900: train loss 2.2523, val loss 2.2638\n",
      "step 1000: train loss 2.2265, val loss 2.2436\n",
      "step 1100: train loss 2.1988, val loss 2.2181\n",
      "step 1200: train loss 2.1750, val loss 2.2070\n",
      "step 1300: train loss 2.1714, val loss 2.1982\n",
      "step 1400: train loss 2.1423, val loss 2.1639\n",
      "step 1500: train loss 2.1233, val loss 2.1431\n",
      "step 1600: train loss 2.0978, val loss 2.1453\n",
      "step 1700: train loss 2.0871, val loss 2.1192\n",
      "step 1800: train loss 2.0845, val loss 2.1290\n",
      "step 1900: train loss 2.0566, val loss 2.0926\n",
      "step 2000: train loss 2.0474, val loss 2.0817\n",
      "step 2100: train loss 2.0432, val loss 2.0872\n",
      "step 2200: train loss 2.0183, val loss 2.0723\n",
      "step 2300: train loss 2.0364, val loss 2.0810\n",
      "step 2400: train loss 2.0102, val loss 2.0618\n",
      "step 2500: train loss 1.9960, val loss 2.0512\n",
      "step 2600: train loss 1.9761, val loss 2.0442\n",
      "step 2700: train loss 1.9757, val loss 2.0569\n",
      "step 2800: train loss 1.9615, val loss 2.0317\n",
      "step 2900: train loss 1.9615, val loss 2.0301\n",
      "step 3000: train loss 1.9523, val loss 2.0293\n",
      "step 3100: train loss 1.9529, val loss 2.0314\n",
      "step 3200: train loss 1.9397, val loss 2.0247\n",
      "step 3300: train loss 1.9204, val loss 2.0219\n",
      "step 3400: train loss 1.9219, val loss 2.0102\n",
      "step 3500: train loss 1.9117, val loss 1.9981\n",
      "step 3600: train loss 1.9043, val loss 1.9873\n",
      "step 3700: train loss 1.9135, val loss 1.9971\n",
      "step 3800: train loss 1.8880, val loss 1.9810\n",
      "step 3900: train loss 1.8969, val loss 1.9791\n",
      "step 4000: train loss 1.8877, val loss 1.9957\n",
      "step 4100: train loss 1.8797, val loss 1.9804\n",
      "step 4200: train loss 1.8825, val loss 1.9838\n",
      "step 4300: train loss 1.8827, val loss 1.9886\n",
      "step 4400: train loss 1.8647, val loss 1.9692\n",
      "step 4500: train loss 1.8648, val loss 1.9684\n",
      "step 4600: train loss 1.8493, val loss 1.9634\n",
      "step 4700: train loss 1.8618, val loss 1.9659\n",
      "step 4800: train loss 1.8325, val loss 1.9492\n",
      "step 4900: train loss 1.8394, val loss 1.9670\n",
      "step 5000: train loss 1.8351, val loss 1.9400\n",
      "step 5100: train loss 1.8331, val loss 1.9520\n",
      "step 5200: train loss 1.8385, val loss 1.9462\n",
      "step 5300: train loss 1.8298, val loss 1.9615\n",
      "step 5400: train loss 1.8269, val loss 1.9524\n",
      "step 5500: train loss 1.8326, val loss 1.9538\n",
      "step 5600: train loss 1.8241, val loss 1.9446\n",
      "step 5700: train loss 1.8087, val loss 1.9326\n",
      "step 5800: train loss 1.8122, val loss 1.9265\n",
      "step 5900: train loss 1.8070, val loss 1.9298\n",
      "step 6000: train loss 1.7897, val loss 1.9148\n",
      "step 6100: train loss 1.7931, val loss 1.9073\n",
      "step 6200: train loss 1.7948, val loss 1.9189\n",
      "step 6300: train loss 1.7892, val loss 1.9259\n",
      "step 6400: train loss 1.7930, val loss 1.9178\n",
      "step 6500: train loss 1.7949, val loss 1.9260\n",
      "step 6600: train loss 1.7888, val loss 1.9054\n",
      "step 6700: train loss 1.7931, val loss 1.9146\n",
      "step 6800: train loss 1.7911, val loss 1.9223\n",
      "step 6900: train loss 1.7811, val loss 1.9239\n",
      "step 7000: train loss 1.7813, val loss 1.9041\n",
      "step 7100: train loss 1.7742, val loss 1.9063\n",
      "step 7200: train loss 1.7645, val loss 1.9052\n",
      "step 7300: train loss 1.7764, val loss 1.9185\n",
      "step 7400: train loss 1.7653, val loss 1.9077\n",
      "step 7500: train loss 1.7608, val loss 1.8953\n",
      "step 7600: train loss 1.7698, val loss 1.9079\n",
      "step 7700: train loss 1.7687, val loss 1.9074\n",
      "step 7800: train loss 1.7504, val loss 1.9054\n",
      "step 7900: train loss 1.7555, val loss 1.8929\n",
      "step 8000: train loss 1.7515, val loss 1.9127\n",
      "step 8100: train loss 1.7544, val loss 1.8945\n",
      "step 8200: train loss 1.7511, val loss 1.9005\n",
      "step 8300: train loss 1.7409, val loss 1.8894\n",
      "step 8400: train loss 1.7526, val loss 1.9046\n",
      "step 8500: train loss 1.7464, val loss 1.8848\n",
      "step 8600: train loss 1.7470, val loss 1.9066\n",
      "step 8700: train loss 1.7313, val loss 1.8854\n",
      "step 8800: train loss 1.7431, val loss 1.8982\n",
      "step 8900: train loss 1.7424, val loss 1.8982\n",
      "step 9000: train loss 1.7367, val loss 1.8923\n",
      "step 9100: train loss 1.7372, val loss 1.8908\n",
      "step 9200: train loss 1.7424, val loss 1.8788\n",
      "step 9300: train loss 1.7381, val loss 1.8931\n",
      "step 9400: train loss 1.7331, val loss 1.8836\n",
      "step 9500: train loss 1.7364, val loss 1.8702\n",
      "step 9600: train loss 1.7258, val loss 1.8654\n",
      "step 9700: train loss 1.7259, val loss 1.8605\n",
      "step 9800: train loss 1.7299, val loss 1.8757\n",
      "step 9900: train loss 1.7210, val loss 1.8700\n",
      "step 10000: train loss 1.7210, val loss 1.8669\n",
      "step 10100: train loss 1.7202, val loss 1.8710\n",
      "step 10200: train loss 1.7259, val loss 1.8732\n",
      "step 10300: train loss 1.7075, val loss 1.8765\n",
      "step 10400: train loss 1.7095, val loss 1.8752\n",
      "step 10500: train loss 1.7209, val loss 1.8792\n",
      "step 10600: train loss 1.7178, val loss 1.8625\n",
      "step 10700: train loss 1.7158, val loss 1.8730\n",
      "step 10800: train loss 1.7091, val loss 1.8545\n",
      "step 10900: train loss 1.7064, val loss 1.8549\n",
      "step 11000: train loss 1.7050, val loss 1.8486\n",
      "step 11100: train loss 1.7062, val loss 1.8515\n",
      "step 11200: train loss 1.7129, val loss 1.8516\n",
      "step 11300: train loss 1.7081, val loss 1.8651\n",
      "step 11400: train loss 1.7061, val loss 1.8543\n",
      "step 11500: train loss 1.6957, val loss 1.8561\n",
      "step 11600: train loss 1.6973, val loss 1.8599\n",
      "step 11700: train loss 1.7014, val loss 1.8610\n",
      "step 11800: train loss 1.6991, val loss 1.8564\n",
      "step 11900: train loss 1.6904, val loss 1.8647\n",
      "step 12000: train loss 1.6971, val loss 1.8472\n",
      "step 12100: train loss 1.7008, val loss 1.8608\n",
      "step 12200: train loss 1.6865, val loss 1.8497\n",
      "step 12300: train loss 1.7039, val loss 1.8416\n",
      "step 12400: train loss 1.6933, val loss 1.8405\n",
      "step 12500: train loss 1.6900, val loss 1.8425\n",
      "step 12600: train loss 1.6901, val loss 1.8496\n",
      "step 12700: train loss 1.6863, val loss 1.8463\n",
      "step 12800: train loss 1.6812, val loss 1.8528\n",
      "step 12900: train loss 1.6775, val loss 1.8465\n",
      "step 13000: train loss 1.6816, val loss 1.8370\n",
      "step 13100: train loss 1.6966, val loss 1.8521\n",
      "step 13200: train loss 1.6865, val loss 1.8420\n",
      "step 13300: train loss 1.6814, val loss 1.8342\n",
      "step 13400: train loss 1.6724, val loss 1.8437\n",
      "step 13500: train loss 1.6793, val loss 1.8390\n",
      "step 13600: train loss 1.6857, val loss 1.8541\n",
      "step 13700: train loss 1.6808, val loss 1.8417\n",
      "step 13800: train loss 1.6894, val loss 1.8357\n",
      "step 13900: train loss 1.6809, val loss 1.8448\n",
      "step 14000: train loss 1.6715, val loss 1.8439\n",
      "step 14100: train loss 1.6707, val loss 1.8441\n",
      "step 14200: train loss 1.6738, val loss 1.8197\n",
      "step 14300: train loss 1.6774, val loss 1.8482\n",
      "step 14400: train loss 1.6803, val loss 1.8322\n",
      "step 14500: train loss 1.6714, val loss 1.8280\n",
      "step 14600: train loss 1.6734, val loss 1.8336\n",
      "step 14700: train loss 1.6755, val loss 1.8306\n",
      "step 14800: train loss 1.6804, val loss 1.8445\n",
      "step 14900: train loss 1.6616, val loss 1.8335\n",
      "step 15000: train loss 1.6666, val loss 1.8388\n",
      "step 15100: train loss 1.6786, val loss 1.8411\n",
      "step 15200: train loss 1.6697, val loss 1.8467\n",
      "step 15300: train loss 1.6706, val loss 1.8367\n",
      "step 15400: train loss 1.6706, val loss 1.8281\n",
      "step 15500: train loss 1.6710, val loss 1.8429\n",
      "step 15600: train loss 1.6630, val loss 1.8278\n",
      "step 15700: train loss 1.6642, val loss 1.8265\n",
      "step 15800: train loss 1.6727, val loss 1.8335\n",
      "step 15900: train loss 1.6699, val loss 1.8299\n",
      "step 16000: train loss 1.6750, val loss 1.8340\n",
      "step 16100: train loss 1.6598, val loss 1.8228\n",
      "step 16200: train loss 1.6627, val loss 1.8150\n",
      "step 16300: train loss 1.6545, val loss 1.8145\n",
      "step 16400: train loss 1.6539, val loss 1.8268\n",
      "step 16500: train loss 1.6619, val loss 1.8170\n",
      "step 16600: train loss 1.6621, val loss 1.8282\n",
      "step 16700: train loss 1.6637, val loss 1.8381\n",
      "step 16800: train loss 1.6511, val loss 1.8331\n",
      "step 16900: train loss 1.6527, val loss 1.8179\n",
      "step 17000: train loss 1.6589, val loss 1.8106\n",
      "step 17100: train loss 1.6585, val loss 1.8209\n",
      "step 17200: train loss 1.6550, val loss 1.8121\n",
      "step 17300: train loss 1.6617, val loss 1.8009\n",
      "step 17400: train loss 1.6553, val loss 1.8110\n",
      "step 17500: train loss 1.6487, val loss 1.8091\n",
      "step 17600: train loss 1.6479, val loss 1.8067\n",
      "step 17700: train loss 1.6461, val loss 1.8060\n",
      "step 17800: train loss 1.6452, val loss 1.8125\n",
      "step 17900: train loss 1.6391, val loss 1.8139\n",
      "step 18000: train loss 1.6529, val loss 1.7924\n",
      "step 18100: train loss 1.6465, val loss 1.8093\n",
      "step 18200: train loss 1.6500, val loss 1.8147\n",
      "step 18300: train loss 1.6364, val loss 1.7870\n",
      "step 18400: train loss 1.6517, val loss 1.8275\n",
      "step 18500: train loss 1.6515, val loss 1.8152\n",
      "step 18600: train loss 1.6478, val loss 1.8160\n",
      "step 18700: train loss 1.6493, val loss 1.8006\n",
      "step 18800: train loss 1.6530, val loss 1.8166\n",
      "step 18900: train loss 1.6575, val loss 1.8039\n",
      "step 19000: train loss 1.6538, val loss 1.8101\n",
      "step 19100: train loss 1.6398, val loss 1.7985\n",
      "step 19200: train loss 1.6524, val loss 1.7941\n",
      "step 19300: train loss 1.6507, val loss 1.8124\n",
      "step 19400: train loss 1.6358, val loss 1.8106\n",
      "step 19500: train loss 1.6442, val loss 1.8182\n",
      "step 19600: train loss 1.6436, val loss 1.8125\n",
      "step 19700: train loss 1.6325, val loss 1.8054\n",
      "step 19800: train loss 1.6403, val loss 1.8050\n",
      "step 19900: train loss 1.6416, val loss 1.8000\n",
      "step 20000: train loss 1.6309, val loss 1.8067\n",
      "step 20100: train loss 1.6401, val loss 1.7939\n",
      "step 20200: train loss 1.6403, val loss 1.8157\n",
      "step 20300: train loss 1.6345, val loss 1.7835\n",
      "step 20400: train loss 1.6396, val loss 1.8098\n",
      "step 20500: train loss 1.6409, val loss 1.8066\n",
      "step 20600: train loss 1.6414, val loss 1.8042\n",
      "step 20700: train loss 1.6355, val loss 1.7929\n",
      "step 20800: train loss 1.6459, val loss 1.7930\n",
      "step 20900: train loss 1.6515, val loss 1.8141\n",
      "step 21000: train loss 1.6400, val loss 1.8001\n",
      "step 21100: train loss 1.6293, val loss 1.7885\n",
      "step 21200: train loss 1.6291, val loss 1.7992\n",
      "step 21300: train loss 1.6485, val loss 1.8036\n",
      "step 21400: train loss 1.6304, val loss 1.8068\n",
      "step 21500: train loss 1.6311, val loss 1.7890\n",
      "step 21600: train loss 1.6409, val loss 1.8003\n",
      "step 21700: train loss 1.6206, val loss 1.7866\n",
      "step 21800: train loss 1.6320, val loss 1.7901\n",
      "step 21900: train loss 1.6241, val loss 1.8039\n",
      "step 22000: train loss 1.6314, val loss 1.7931\n",
      "step 22100: train loss 1.6250, val loss 1.8017\n",
      "step 22200: train loss 1.6274, val loss 1.8131\n",
      "step 22300: train loss 1.6337, val loss 1.7952\n",
      "step 22400: train loss 1.6278, val loss 1.7992\n",
      "step 22500: train loss 1.6240, val loss 1.7919\n",
      "step 22600: train loss 1.6328, val loss 1.8045\n",
      "step 22700: train loss 1.6312, val loss 1.8130\n",
      "step 22800: train loss 1.6344, val loss 1.7963\n",
      "step 22900: train loss 1.6269, val loss 1.7990\n",
      "step 23000: train loss 1.6303, val loss 1.8057\n",
      "step 23100: train loss 1.6294, val loss 1.7904\n",
      "step 23200: train loss 1.6244, val loss 1.7879\n",
      "step 23300: train loss 1.6243, val loss 1.8024\n",
      "step 23400: train loss 1.6267, val loss 1.7991\n",
      "step 23500: train loss 1.6223, val loss 1.7862\n",
      "step 23600: train loss 1.6290, val loss 1.7914\n",
      "step 23700: train loss 1.6183, val loss 1.7898\n",
      "step 23800: train loss 1.6307, val loss 1.7960\n",
      "step 23900: train loss 1.6205, val loss 1.7890\n",
      "step 24000: train loss 1.6329, val loss 1.8003\n",
      "step 24100: train loss 1.6150, val loss 1.8008\n",
      "step 24200: train loss 1.6302, val loss 1.7892\n",
      "step 24300: train loss 1.6333, val loss 1.7933\n",
      "step 24400: train loss 1.6155, val loss 1.7973\n",
      "step 24500: train loss 1.6213, val loss 1.7959\n",
      "step 24600: train loss 1.6230, val loss 1.7907\n",
      "step 24700: train loss 1.6158, val loss 1.8041\n",
      "step 24800: train loss 1.6211, val loss 1.8045\n",
      "step 24900: train loss 1.6146, val loss 1.7990\n",
      "step 25000: train loss 1.6218, val loss 1.8090\n",
      "step 25100: train loss 1.6179, val loss 1.7920\n",
      "step 25200: train loss 1.6212, val loss 1.7944\n",
      "step 25300: train loss 1.6151, val loss 1.7898\n",
      "step 25400: train loss 1.6188, val loss 1.7874\n",
      "step 25500: train loss 1.6222, val loss 1.7817\n",
      "step 25600: train loss 1.6107, val loss 1.7918\n",
      "step 25700: train loss 1.6073, val loss 1.7769\n",
      "step 25800: train loss 1.6241, val loss 1.7871\n",
      "step 25900: train loss 1.6256, val loss 1.7820\n",
      "step 26000: train loss 1.6083, val loss 1.7799\n",
      "step 26100: train loss 1.6073, val loss 1.7831\n",
      "step 26200: train loss 1.6097, val loss 1.7916\n",
      "step 26300: train loss 1.6071, val loss 1.8013\n",
      "step 26400: train loss 1.6213, val loss 1.7803\n",
      "step 26500: train loss 1.6045, val loss 1.7709\n",
      "step 26600: train loss 1.6057, val loss 1.7927\n",
      "step 26700: train loss 1.6093, val loss 1.7838\n",
      "step 26800: train loss 1.6107, val loss 1.7738\n",
      "step 26900: train loss 1.6092, val loss 1.7806\n",
      "step 27000: train loss 1.6065, val loss 1.7857\n",
      "step 27100: train loss 1.6013, val loss 1.7868\n",
      "step 27200: train loss 1.6098, val loss 1.7686\n",
      "step 27300: train loss 1.6215, val loss 1.7681\n",
      "step 27400: train loss 1.6109, val loss 1.7770\n",
      "step 27500: train loss 1.5991, val loss 1.7674\n",
      "step 27600: train loss 1.6034, val loss 1.7781\n",
      "step 27700: train loss 1.6048, val loss 1.7687\n",
      "step 27800: train loss 1.6055, val loss 1.7771\n",
      "step 27900: train loss 1.6099, val loss 1.7603\n",
      "step 28000: train loss 1.6140, val loss 1.7808\n",
      "step 28100: train loss 1.6059, val loss 1.7773\n",
      "step 28200: train loss 1.6127, val loss 1.7737\n",
      "step 28300: train loss 1.6051, val loss 1.7855\n",
      "step 28400: train loss 1.6110, val loss 1.7574\n",
      "step 28500: train loss 1.6170, val loss 1.7675\n",
      "step 28600: train loss 1.6077, val loss 1.7676\n",
      "step 28700: train loss 1.6103, val loss 1.7732\n",
      "step 28800: train loss 1.6021, val loss 1.7704\n",
      "step 28900: train loss 1.5941, val loss 1.7819\n",
      "step 29000: train loss 1.6033, val loss 1.7818\n",
      "step 29100: train loss 1.5948, val loss 1.7647\n",
      "step 29200: train loss 1.6168, val loss 1.7929\n",
      "step 29300: train loss 1.6083, val loss 1.7684\n",
      "step 29400: train loss 1.6058, val loss 1.7662\n",
      "step 29500: train loss 1.5978, val loss 1.7842\n",
      "step 29600: train loss 1.6043, val loss 1.7564\n",
      "step 29700: train loss 1.6131, val loss 1.7736\n",
      "step 29800: train loss 1.5978, val loss 1.7747\n",
      "step 29900: train loss 1.5941, val loss 1.7689\n",
      "step 30000: train loss 1.6035, val loss 1.7780\n",
      "step 30100: train loss 1.6079, val loss 1.7796\n",
      "step 30200: train loss 1.5968, val loss 1.7751\n",
      "step 30300: train loss 1.5976, val loss 1.7734\n",
      "step 30400: train loss 1.5979, val loss 1.7821\n",
      "step 30500: train loss 1.6125, val loss 1.7777\n",
      "step 30600: train loss 1.6033, val loss 1.7682\n",
      "step 30700: train loss 1.6017, val loss 1.7704\n",
      "step 30800: train loss 1.6078, val loss 1.7726\n",
      "step 30900: train loss 1.6059, val loss 1.7746\n",
      "step 31000: train loss 1.5994, val loss 1.7837\n",
      "step 31100: train loss 1.6045, val loss 1.7559\n",
      "step 31200: train loss 1.6050, val loss 1.7775\n",
      "step 31300: train loss 1.6011, val loss 1.7764\n",
      "step 31400: train loss 1.5959, val loss 1.7700\n",
      "step 31500: train loss 1.5931, val loss 1.7658\n",
      "step 31600: train loss 1.5982, val loss 1.7799\n",
      "step 31700: train loss 1.6001, val loss 1.7767\n",
      "step 31800: train loss 1.5901, val loss 1.7714\n",
      "step 31900: train loss 1.6071, val loss 1.7705\n",
      "step 32000: train loss 1.6063, val loss 1.7721\n",
      "step 32100: train loss 1.6034, val loss 1.7848\n",
      "step 32200: train loss 1.5955, val loss 1.7658\n",
      "step 32300: train loss 1.5949, val loss 1.7657\n",
      "step 32400: train loss 1.5949, val loss 1.7560\n",
      "step 32500: train loss 1.6019, val loss 1.7721\n",
      "step 32600: train loss 1.5831, val loss 1.7616\n",
      "step 32700: train loss 1.5955, val loss 1.7525\n",
      "step 32800: train loss 1.5990, val loss 1.7705\n",
      "step 32900: train loss 1.5946, val loss 1.7640\n",
      "step 33000: train loss 1.5975, val loss 1.7711\n",
      "step 33100: train loss 1.5966, val loss 1.7832\n",
      "step 33200: train loss 1.5939, val loss 1.7794\n",
      "step 33300: train loss 1.5861, val loss 1.7738\n",
      "step 33400: train loss 1.5929, val loss 1.7643\n",
      "step 33500: train loss 1.5914, val loss 1.7664\n",
      "step 33600: train loss 1.5999, val loss 1.7566\n",
      "step 33700: train loss 1.5939, val loss 1.7643\n",
      "step 33800: train loss 1.5908, val loss 1.7596\n",
      "step 33900: train loss 1.5934, val loss 1.7687\n",
      "step 34000: train loss 1.6069, val loss 1.7560\n",
      "step 34100: train loss 1.5901, val loss 1.7603\n",
      "step 34200: train loss 1.5882, val loss 1.7493\n",
      "step 34300: train loss 1.5994, val loss 1.7544\n",
      "step 34400: train loss 1.5878, val loss 1.7571\n",
      "step 34500: train loss 1.5855, val loss 1.7681\n",
      "step 34600: train loss 1.5948, val loss 1.7483\n",
      "step 34700: train loss 1.5959, val loss 1.7542\n",
      "step 34800: train loss 1.5931, val loss 1.7719\n",
      "step 34900: train loss 1.5974, val loss 1.7624\n",
      "step 35000: train loss 1.5914, val loss 1.7676\n",
      "step 35100: train loss 1.5864, val loss 1.7586\n",
      "step 35200: train loss 1.6039, val loss 1.7551\n",
      "step 35300: train loss 1.5832, val loss 1.7551\n",
      "step 35400: train loss 1.5965, val loss 1.7544\n",
      "step 35500: train loss 1.5842, val loss 1.7596\n",
      "step 35600: train loss 1.5860, val loss 1.7578\n",
      "step 35700: train loss 1.5894, val loss 1.7731\n",
      "step 35800: train loss 1.5851, val loss 1.7638\n",
      "step 35900: train loss 1.5855, val loss 1.7626\n",
      "step 36000: train loss 1.5926, val loss 1.7643\n",
      "step 36100: train loss 1.6002, val loss 1.7645\n",
      "step 36200: train loss 1.5942, val loss 1.7601\n",
      "step 36300: train loss 1.5762, val loss 1.7648\n",
      "step 36400: train loss 1.5925, val loss 1.7607\n",
      "step 36500: train loss 1.5887, val loss 1.7561\n",
      "step 36600: train loss 1.5882, val loss 1.7549\n",
      "step 36700: train loss 1.5902, val loss 1.7558\n",
      "step 36800: train loss 1.5901, val loss 1.7453\n",
      "step 36900: train loss 1.5864, val loss 1.7685\n",
      "step 37000: train loss 1.5843, val loss 1.7545\n",
      "step 37100: train loss 1.5845, val loss 1.7751\n",
      "step 37200: train loss 1.5868, val loss 1.7621\n",
      "step 37300: train loss 1.5659, val loss 1.7708\n",
      "step 37400: train loss 1.5725, val loss 1.7685\n",
      "step 37500: train loss 1.5895, val loss 1.7581\n",
      "step 37600: train loss 1.5797, val loss 1.7433\n",
      "step 37700: train loss 1.5808, val loss 1.7627\n",
      "step 37800: train loss 1.5911, val loss 1.7523\n",
      "step 37900: train loss 1.5838, val loss 1.7577\n",
      "step 38000: train loss 1.5928, val loss 1.7690\n",
      "step 38100: train loss 1.5818, val loss 1.7662\n",
      "step 38200: train loss 1.5892, val loss 1.7428\n",
      "step 38300: train loss 1.5855, val loss 1.7537\n",
      "step 38400: train loss 1.5909, val loss 1.7469\n",
      "step 38500: train loss 1.5833, val loss 1.7502\n",
      "step 38600: train loss 1.5732, val loss 1.7686\n",
      "step 38700: train loss 1.5817, val loss 1.7623\n",
      "step 38800: train loss 1.5771, val loss 1.7565\n",
      "step 38900: train loss 1.5810, val loss 1.7513\n",
      "step 39000: train loss 1.5869, val loss 1.7757\n",
      "step 39100: train loss 1.5886, val loss 1.7662\n",
      "step 39200: train loss 1.5809, val loss 1.7657\n",
      "step 39300: train loss 1.5900, val loss 1.7675\n",
      "step 39400: train loss 1.5823, val loss 1.7589\n",
      "step 39500: train loss 1.5744, val loss 1.7579\n",
      "step 39600: train loss 1.5842, val loss 1.7502\n",
      "step 39700: train loss 1.5831, val loss 1.7498\n",
      "step 39800: train loss 1.5859, val loss 1.7516\n",
      "step 39900: train loss 1.5777, val loss 1.7527\n",
      "step 40000: train loss 1.5845, val loss 1.7485\n",
      "step 40100: train loss 1.5752, val loss 1.7530\n",
      "step 40200: train loss 1.5856, val loss 1.7346\n",
      "step 40300: train loss 1.5830, val loss 1.7405\n",
      "step 40400: train loss 1.5779, val loss 1.7666\n",
      "step 40500: train loss 1.5715, val loss 1.7544\n",
      "step 40600: train loss 1.5829, val loss 1.7510\n",
      "step 40700: train loss 1.5826, val loss 1.7455\n",
      "step 40800: train loss 1.5702, val loss 1.7522\n",
      "step 40900: train loss 1.5735, val loss 1.7539\n",
      "step 41000: train loss 1.5765, val loss 1.7604\n",
      "step 41100: train loss 1.5797, val loss 1.7491\n",
      "step 41200: train loss 1.5756, val loss 1.7468\n",
      "step 41300: train loss 1.5692, val loss 1.7477\n",
      "step 41400: train loss 1.5712, val loss 1.7505\n",
      "step 41500: train loss 1.5707, val loss 1.7597\n",
      "step 41600: train loss 1.5798, val loss 1.7555\n",
      "step 41700: train loss 1.5829, val loss 1.7612\n",
      "step 41800: train loss 1.5850, val loss 1.7556\n",
      "step 41900: train loss 1.5780, val loss 1.7677\n",
      "step 42000: train loss 1.5768, val loss 1.7529\n",
      "step 42100: train loss 1.5823, val loss 1.7499\n",
      "step 42200: train loss 1.5676, val loss 1.7510\n",
      "step 42300: train loss 1.5818, val loss 1.7492\n",
      "step 42400: train loss 1.5730, val loss 1.7481\n",
      "step 42500: train loss 1.5863, val loss 1.7465\n",
      "step 42600: train loss 1.5809, val loss 1.7489\n",
      "step 42700: train loss 1.5761, val loss 1.7488\n",
      "step 42800: train loss 1.5739, val loss 1.7416\n",
      "step 42900: train loss 1.5776, val loss 1.7412\n",
      "step 43000: train loss 1.5626, val loss 1.7387\n",
      "step 43100: train loss 1.5690, val loss 1.7454\n",
      "step 43200: train loss 1.5747, val loss 1.7499\n",
      "step 43300: train loss 1.5644, val loss 1.7493\n",
      "step 43400: train loss 1.5789, val loss 1.7442\n",
      "step 43500: train loss 1.5780, val loss 1.7412\n",
      "step 43600: train loss 1.5784, val loss 1.7427\n",
      "step 43700: train loss 1.5659, val loss 1.7586\n",
      "step 43800: train loss 1.5799, val loss 1.7558\n",
      "step 43900: train loss 1.5812, val loss 1.7522\n",
      "step 44000: train loss 1.5649, val loss 1.7438\n",
      "step 44100: train loss 1.5704, val loss 1.7487\n",
      "step 44200: train loss 1.5696, val loss 1.7436\n",
      "step 44300: train loss 1.5651, val loss 1.7500\n",
      "step 44400: train loss 1.5735, val loss 1.7397\n",
      "step 44500: train loss 1.5650, val loss 1.7434\n",
      "step 44600: train loss 1.5722, val loss 1.7442\n",
      "step 44700: train loss 1.5680, val loss 1.7473\n",
      "step 44800: train loss 1.5731, val loss 1.7406\n",
      "step 44900: train loss 1.5702, val loss 1.7349\n",
      "step 45000: train loss 1.5795, val loss 1.7422\n",
      "step 45100: train loss 1.5698, val loss 1.7430\n",
      "step 45200: train loss 1.5826, val loss 1.7526\n",
      "step 45300: train loss 1.5772, val loss 1.7455\n",
      "step 45400: train loss 1.5787, val loss 1.7335\n",
      "step 45500: train loss 1.5673, val loss 1.7444\n",
      "step 45600: train loss 1.5725, val loss 1.7570\n",
      "step 45700: train loss 1.5775, val loss 1.7415\n",
      "step 45800: train loss 1.5774, val loss 1.7469\n",
      "step 45900: train loss 1.5688, val loss 1.7486\n",
      "step 46000: train loss 1.5616, val loss 1.7544\n",
      "step 46100: train loss 1.5622, val loss 1.7574\n",
      "step 46200: train loss 1.5592, val loss 1.7636\n",
      "step 46300: train loss 1.5790, val loss 1.7417\n",
      "step 46400: train loss 1.5631, val loss 1.7452\n",
      "step 46500: train loss 1.5742, val loss 1.7467\n",
      "step 46600: train loss 1.5649, val loss 1.7422\n",
      "step 46700: train loss 1.5664, val loss 1.7492\n",
      "step 46800: train loss 1.5631, val loss 1.7565\n",
      "step 46900: train loss 1.5776, val loss 1.7512\n",
      "step 47000: train loss 1.5633, val loss 1.7540\n",
      "step 47100: train loss 1.5736, val loss 1.7428\n",
      "step 47200: train loss 1.5688, val loss 1.7411\n",
      "step 47300: train loss 1.5735, val loss 1.7539\n",
      "step 47400: train loss 1.5658, val loss 1.7458\n",
      "step 47500: train loss 1.5637, val loss 1.7681\n",
      "step 47600: train loss 1.5728, val loss 1.7411\n",
      "step 47700: train loss 1.5547, val loss 1.7447\n",
      "step 47800: train loss 1.5651, val loss 1.7473\n",
      "step 47900: train loss 1.5739, val loss 1.7565\n",
      "step 48000: train loss 1.5621, val loss 1.7481\n",
      "step 48100: train loss 1.5750, val loss 1.7468\n",
      "step 48200: train loss 1.5715, val loss 1.7499\n",
      "step 48300: train loss 1.5671, val loss 1.7543\n",
      "step 48400: train loss 1.5791, val loss 1.7467\n",
      "step 48500: train loss 1.5708, val loss 1.7404\n",
      "step 48600: train loss 1.5651, val loss 1.7395\n",
      "step 48700: train loss 1.5737, val loss 1.7470\n",
      "step 48800: train loss 1.5673, val loss 1.7441\n",
      "step 48900: train loss 1.5668, val loss 1.7476\n",
      "step 49000: train loss 1.5666, val loss 1.7360\n",
      "step 49100: train loss 1.5685, val loss 1.7552\n",
      "step 49200: train loss 1.5665, val loss 1.7323\n",
      "step 49300: train loss 1.5661, val loss 1.7539\n",
      "step 49400: train loss 1.5592, val loss 1.7366\n",
      "step 49500: train loss 1.5516, val loss 1.7461\n",
      "step 49600: train loss 1.5705, val loss 1.7461\n",
      "step 49700: train loss 1.5624, val loss 1.7347\n",
      "step 49800: train loss 1.5640, val loss 1.7418\n",
      "step 49900: train loss 1.5618, val loss 1.7405\n",
      "step 49999: train loss 1.5580, val loss 1.7358\n",
      "Results for configuration res1_dropout=0.025_res2_dropout=0.99_res4_dropout=0.1_use_double_layers=True saved.\n",
      "Training model with configuration: {'res1_dropout': 0.025, 'res2_dropout': 0.99, 'res4_dropout': 0.2, 'use_double_layers': True}\n",
      "step 0: train loss 4.4022, val loss 4.4024\n",
      "step 100: train loss 2.7078, val loss 2.7076\n",
      "step 200: train loss 2.5486, val loss 2.5492\n",
      "step 300: train loss 2.4841, val loss 2.4820\n",
      "step 400: train loss 2.4236, val loss 2.4274\n",
      "step 500: train loss 2.3916, val loss 2.3931\n",
      "step 600: train loss 2.3596, val loss 2.3633\n",
      "step 700: train loss 2.3301, val loss 2.3254\n",
      "step 800: train loss 2.2989, val loss 2.3062\n",
      "step 900: train loss 2.2630, val loss 2.2786\n",
      "step 1000: train loss 2.2343, val loss 2.2442\n",
      "step 1100: train loss 2.2077, val loss 2.2245\n",
      "step 1200: train loss 2.1838, val loss 2.2115\n",
      "step 1300: train loss 2.1764, val loss 2.1883\n",
      "step 1400: train loss 2.1559, val loss 2.1820\n",
      "step 1500: train loss 2.1279, val loss 2.1448\n",
      "step 1600: train loss 2.1143, val loss 2.1419\n",
      "step 1700: train loss 2.1082, val loss 2.1360\n",
      "step 1800: train loss 2.0857, val loss 2.1346\n",
      "step 1900: train loss 2.0790, val loss 2.1104\n",
      "step 2000: train loss 2.0578, val loss 2.1017\n",
      "step 2100: train loss 2.0382, val loss 2.0815\n",
      "step 2200: train loss 2.0333, val loss 2.0898\n",
      "step 2300: train loss 2.0244, val loss 2.0726\n",
      "step 2400: train loss 2.0110, val loss 2.0663\n",
      "step 2500: train loss 2.0157, val loss 2.0616\n",
      "step 2600: train loss 2.0092, val loss 2.0459\n",
      "step 2700: train loss 1.9907, val loss 2.0469\n",
      "step 2800: train loss 1.9761, val loss 2.0402\n",
      "step 2900: train loss 1.9664, val loss 2.0411\n",
      "step 3000: train loss 1.9595, val loss 2.0249\n",
      "step 3100: train loss 1.9537, val loss 2.0237\n",
      "step 3200: train loss 1.9509, val loss 2.0270\n",
      "step 3300: train loss 1.9393, val loss 2.0047\n",
      "step 3400: train loss 1.9417, val loss 2.0297\n",
      "step 3500: train loss 1.9285, val loss 2.0023\n",
      "step 3600: train loss 1.9231, val loss 1.9965\n",
      "step 3700: train loss 1.9247, val loss 2.0104\n",
      "step 3800: train loss 1.9138, val loss 1.9993\n",
      "step 3900: train loss 1.9072, val loss 1.9934\n",
      "step 4000: train loss 1.8954, val loss 1.9887\n",
      "step 4100: train loss 1.8922, val loss 1.9748\n",
      "step 4200: train loss 1.8851, val loss 1.9866\n",
      "step 4300: train loss 1.8798, val loss 1.9706\n",
      "step 4400: train loss 1.8807, val loss 1.9769\n",
      "step 4500: train loss 1.8732, val loss 1.9650\n",
      "step 4600: train loss 1.8686, val loss 1.9708\n",
      "step 4700: train loss 1.8493, val loss 1.9700\n",
      "step 4800: train loss 1.8537, val loss 1.9694\n",
      "step 4900: train loss 1.8507, val loss 1.9605\n",
      "step 5000: train loss 1.8599, val loss 1.9654\n",
      "step 5100: train loss 1.8331, val loss 1.9495\n",
      "step 5200: train loss 1.8450, val loss 1.9550\n",
      "step 5300: train loss 1.8387, val loss 1.9522\n",
      "step 5400: train loss 1.8263, val loss 1.9466\n",
      "step 5500: train loss 1.8295, val loss 1.9431\n",
      "step 5600: train loss 1.8293, val loss 1.9579\n",
      "step 5700: train loss 1.8203, val loss 1.9439\n",
      "step 5800: train loss 1.8179, val loss 1.9421\n",
      "step 5900: train loss 1.8109, val loss 1.9332\n",
      "step 6000: train loss 1.8096, val loss 1.9292\n",
      "step 6100: train loss 1.7989, val loss 1.9291\n",
      "step 6200: train loss 1.8081, val loss 1.9342\n",
      "step 6300: train loss 1.8057, val loss 1.9269\n",
      "step 6400: train loss 1.7937, val loss 1.9421\n",
      "step 6500: train loss 1.8007, val loss 1.9208\n",
      "step 6600: train loss 1.7978, val loss 1.9316\n",
      "step 6700: train loss 1.8004, val loss 1.9140\n",
      "step 6800: train loss 1.8050, val loss 1.9148\n",
      "step 6900: train loss 1.7821, val loss 1.9275\n",
      "step 7000: train loss 1.7802, val loss 1.9206\n",
      "step 7100: train loss 1.7779, val loss 1.9173\n",
      "step 7200: train loss 1.7883, val loss 1.9094\n",
      "step 7300: train loss 1.7698, val loss 1.9121\n",
      "step 7400: train loss 1.7601, val loss 1.9150\n",
      "step 7500: train loss 1.7770, val loss 1.9209\n",
      "step 7600: train loss 1.7657, val loss 1.8947\n",
      "step 7700: train loss 1.7749, val loss 1.9191\n",
      "step 7800: train loss 1.7625, val loss 1.9065\n",
      "step 7900: train loss 1.7620, val loss 1.9014\n",
      "step 8000: train loss 1.7557, val loss 1.8976\n",
      "step 8100: train loss 1.7541, val loss 1.9002\n",
      "step 8200: train loss 1.7577, val loss 1.9025\n",
      "step 8300: train loss 1.7531, val loss 1.9180\n",
      "step 8400: train loss 1.7580, val loss 1.9172\n",
      "step 8500: train loss 1.7731, val loss 1.8936\n",
      "step 8600: train loss 1.7514, val loss 1.9027\n",
      "step 8700: train loss 1.7474, val loss 1.8887\n",
      "step 8800: train loss 1.7440, val loss 1.9059\n",
      "step 8900: train loss 1.7497, val loss 1.8873\n",
      "step 9000: train loss 1.7406, val loss 1.9064\n",
      "step 9100: train loss 1.7362, val loss 1.8926\n",
      "step 9200: train loss 1.7367, val loss 1.8870\n",
      "step 9300: train loss 1.7376, val loss 1.8906\n",
      "step 9400: train loss 1.7443, val loss 1.8904\n",
      "step 9500: train loss 1.7353, val loss 1.8824\n",
      "step 9600: train loss 1.7328, val loss 1.8815\n",
      "step 9700: train loss 1.7341, val loss 1.8954\n",
      "step 9800: train loss 1.7205, val loss 1.8842\n",
      "step 9900: train loss 1.7228, val loss 1.8754\n",
      "step 10000: train loss 1.7244, val loss 1.8956\n",
      "step 10100: train loss 1.7241, val loss 1.8739\n",
      "step 10200: train loss 1.7184, val loss 1.8745\n",
      "step 10300: train loss 1.7216, val loss 1.8734\n",
      "step 10400: train loss 1.7234, val loss 1.8719\n",
      "step 10500: train loss 1.7185, val loss 1.8773\n",
      "step 10600: train loss 1.7072, val loss 1.8683\n",
      "step 10700: train loss 1.7251, val loss 1.8721\n",
      "step 10800: train loss 1.7226, val loss 1.8619\n",
      "step 10900: train loss 1.7122, val loss 1.8794\n",
      "step 11000: train loss 1.7012, val loss 1.8704\n",
      "step 11100: train loss 1.7156, val loss 1.8639\n",
      "step 11200: train loss 1.7056, val loss 1.8617\n",
      "step 11300: train loss 1.7147, val loss 1.8784\n",
      "step 11400: train loss 1.7105, val loss 1.8703\n",
      "step 11500: train loss 1.7052, val loss 1.8773\n",
      "step 11600: train loss 1.7011, val loss 1.8602\n",
      "step 11700: train loss 1.7061, val loss 1.8774\n",
      "step 11800: train loss 1.7015, val loss 1.8725\n",
      "step 11900: train loss 1.6871, val loss 1.8630\n",
      "step 12000: train loss 1.6953, val loss 1.8529\n",
      "step 12100: train loss 1.6989, val loss 1.8488\n",
      "step 12200: train loss 1.6936, val loss 1.8601\n",
      "step 12300: train loss 1.7053, val loss 1.8509\n",
      "step 12400: train loss 1.7014, val loss 1.8706\n",
      "step 12500: train loss 1.6974, val loss 1.8546\n",
      "step 12600: train loss 1.6839, val loss 1.8607\n",
      "step 12700: train loss 1.6914, val loss 1.8594\n",
      "step 12800: train loss 1.6962, val loss 1.8469\n",
      "step 12900: train loss 1.6875, val loss 1.8564\n",
      "step 13000: train loss 1.6944, val loss 1.8576\n",
      "step 13100: train loss 1.6877, val loss 1.8473\n",
      "step 13200: train loss 1.6834, val loss 1.8524\n",
      "step 13300: train loss 1.6866, val loss 1.8592\n",
      "step 13400: train loss 1.6815, val loss 1.8534\n",
      "step 13500: train loss 1.6863, val loss 1.8450\n",
      "step 13600: train loss 1.6780, val loss 1.8529\n",
      "step 13700: train loss 1.6858, val loss 1.8434\n",
      "step 13800: train loss 1.6723, val loss 1.8374\n",
      "step 13900: train loss 1.6823, val loss 1.8385\n",
      "step 14000: train loss 1.6816, val loss 1.8406\n",
      "step 14100: train loss 1.6750, val loss 1.8338\n",
      "step 14200: train loss 1.6783, val loss 1.8337\n",
      "step 14300: train loss 1.6785, val loss 1.8508\n",
      "step 14400: train loss 1.6756, val loss 1.8517\n",
      "step 14500: train loss 1.6695, val loss 1.8465\n",
      "step 14600: train loss 1.6935, val loss 1.8487\n",
      "step 14700: train loss 1.6565, val loss 1.8478\n",
      "step 14800: train loss 1.6712, val loss 1.8382\n",
      "step 14900: train loss 1.6710, val loss 1.8376\n",
      "step 15000: train loss 1.6733, val loss 1.8496\n",
      "step 15100: train loss 1.6752, val loss 1.8470\n",
      "step 15200: train loss 1.6647, val loss 1.8482\n",
      "step 15300: train loss 1.6753, val loss 1.8434\n",
      "step 15400: train loss 1.6773, val loss 1.8507\n",
      "step 15500: train loss 1.6627, val loss 1.8414\n",
      "step 15600: train loss 1.6745, val loss 1.8324\n",
      "step 15700: train loss 1.6551, val loss 1.8281\n",
      "step 15800: train loss 1.6621, val loss 1.8452\n",
      "step 15900: train loss 1.6670, val loss 1.8458\n",
      "step 16000: train loss 1.6596, val loss 1.8358\n",
      "step 16100: train loss 1.6689, val loss 1.8434\n",
      "step 16200: train loss 1.6559, val loss 1.8273\n",
      "step 16300: train loss 1.6635, val loss 1.8273\n",
      "step 16400: train loss 1.6564, val loss 1.8306\n",
      "step 16500: train loss 1.6571, val loss 1.8383\n",
      "step 16600: train loss 1.6745, val loss 1.8497\n",
      "step 16700: train loss 1.6541, val loss 1.8293\n",
      "step 16800: train loss 1.6669, val loss 1.8257\n",
      "step 16900: train loss 1.6580, val loss 1.8244\n",
      "step 17000: train loss 1.6617, val loss 1.8419\n",
      "step 17100: train loss 1.6615, val loss 1.8186\n",
      "step 17200: train loss 1.6617, val loss 1.8324\n",
      "step 17300: train loss 1.6551, val loss 1.8352\n",
      "step 17400: train loss 1.6643, val loss 1.8406\n",
      "step 17500: train loss 1.6632, val loss 1.8306\n",
      "step 17600: train loss 1.6534, val loss 1.8251\n",
      "step 17700: train loss 1.6438, val loss 1.8374\n",
      "step 17800: train loss 1.6466, val loss 1.8268\n",
      "step 17900: train loss 1.6498, val loss 1.8171\n",
      "step 18000: train loss 1.6609, val loss 1.8335\n",
      "step 18100: train loss 1.6614, val loss 1.8199\n",
      "step 18200: train loss 1.6586, val loss 1.8132\n",
      "step 18300: train loss 1.6493, val loss 1.8216\n",
      "step 18400: train loss 1.6454, val loss 1.8218\n",
      "step 18500: train loss 1.6488, val loss 1.8321\n",
      "step 18600: train loss 1.6434, val loss 1.8174\n",
      "step 18700: train loss 1.6514, val loss 1.8158\n",
      "step 18800: train loss 1.6459, val loss 1.8251\n",
      "step 18900: train loss 1.6444, val loss 1.8148\n",
      "step 19000: train loss 1.6409, val loss 1.8238\n",
      "step 19100: train loss 1.6511, val loss 1.8223\n",
      "step 19200: train loss 1.6489, val loss 1.8155\n",
      "step 19300: train loss 1.6379, val loss 1.8095\n",
      "step 19400: train loss 1.6416, val loss 1.8212\n",
      "step 19500: train loss 1.6314, val loss 1.8175\n",
      "step 19600: train loss 1.6458, val loss 1.8213\n",
      "step 19700: train loss 1.6448, val loss 1.8245\n",
      "step 19800: train loss 1.6456, val loss 1.8043\n",
      "step 19900: train loss 1.6474, val loss 1.8059\n",
      "step 20000: train loss 1.6399, val loss 1.8178\n",
      "step 20100: train loss 1.6412, val loss 1.8063\n",
      "step 20200: train loss 1.6291, val loss 1.7991\n",
      "step 20300: train loss 1.6595, val loss 1.8039\n",
      "step 20400: train loss 1.6453, val loss 1.8123\n",
      "step 20500: train loss 1.6342, val loss 1.8133\n",
      "step 20600: train loss 1.6458, val loss 1.8012\n",
      "step 20700: train loss 1.6394, val loss 1.8036\n",
      "step 20800: train loss 1.6359, val loss 1.8108\n",
      "step 20900: train loss 1.6366, val loss 1.8179\n",
      "step 21000: train loss 1.6407, val loss 1.8130\n",
      "step 21100: train loss 1.6427, val loss 1.8140\n",
      "step 21200: train loss 1.6374, val loss 1.8095\n",
      "step 21300: train loss 1.6395, val loss 1.8020\n",
      "step 21400: train loss 1.6342, val loss 1.8049\n",
      "step 21500: train loss 1.6409, val loss 1.8032\n",
      "step 21600: train loss 1.6372, val loss 1.8106\n",
      "step 21700: train loss 1.6359, val loss 1.8029\n",
      "step 21800: train loss 1.6464, val loss 1.7945\n",
      "step 21900: train loss 1.6359, val loss 1.8065\n",
      "step 22000: train loss 1.6265, val loss 1.7959\n",
      "step 22100: train loss 1.6349, val loss 1.7981\n",
      "step 22200: train loss 1.6265, val loss 1.8100\n",
      "step 22300: train loss 1.6310, val loss 1.8020\n",
      "step 22400: train loss 1.6302, val loss 1.7935\n",
      "step 22500: train loss 1.6371, val loss 1.8135\n",
      "step 22600: train loss 1.6332, val loss 1.7934\n",
      "step 22700: train loss 1.6421, val loss 1.8025\n",
      "step 22800: train loss 1.6268, val loss 1.7915\n",
      "step 22900: train loss 1.6289, val loss 1.7925\n",
      "step 23000: train loss 1.6275, val loss 1.7965\n",
      "step 23100: train loss 1.6174, val loss 1.8047\n",
      "step 23200: train loss 1.6206, val loss 1.8012\n",
      "step 23300: train loss 1.6310, val loss 1.8127\n",
      "step 23400: train loss 1.6339, val loss 1.7946\n",
      "step 23500: train loss 1.6340, val loss 1.7959\n",
      "step 23600: train loss 1.6354, val loss 1.8011\n",
      "step 23700: train loss 1.6185, val loss 1.7967\n",
      "step 23800: train loss 1.6159, val loss 1.7968\n",
      "step 23900: train loss 1.6293, val loss 1.7844\n",
      "step 24000: train loss 1.6176, val loss 1.7923\n",
      "step 24100: train loss 1.6215, val loss 1.7939\n",
      "step 24200: train loss 1.6201, val loss 1.8067\n",
      "step 24300: train loss 1.6388, val loss 1.7927\n",
      "step 24400: train loss 1.6269, val loss 1.7935\n",
      "step 24500: train loss 1.6204, val loss 1.7995\n",
      "step 24600: train loss 1.6281, val loss 1.7999\n",
      "step 24700: train loss 1.6204, val loss 1.7981\n",
      "step 24800: train loss 1.6207, val loss 1.7960\n",
      "step 24900: train loss 1.6231, val loss 1.7969\n",
      "step 25000: train loss 1.6210, val loss 1.7901\n",
      "step 25100: train loss 1.6167, val loss 1.7892\n",
      "step 25200: train loss 1.6204, val loss 1.7886\n",
      "step 25300: train loss 1.6148, val loss 1.7914\n",
      "step 25400: train loss 1.6292, val loss 1.7948\n",
      "step 25500: train loss 1.6136, val loss 1.7786\n",
      "step 25600: train loss 1.6032, val loss 1.7787\n",
      "step 25700: train loss 1.6242, val loss 1.7779\n",
      "step 25800: train loss 1.6165, val loss 1.7807\n",
      "step 25900: train loss 1.6258, val loss 1.7994\n",
      "step 26000: train loss 1.6097, val loss 1.7820\n",
      "step 26100: train loss 1.6213, val loss 1.7852\n",
      "step 26200: train loss 1.6256, val loss 1.8036\n",
      "step 26300: train loss 1.6267, val loss 1.7805\n",
      "step 26400: train loss 1.6131, val loss 1.7803\n",
      "step 26500: train loss 1.6051, val loss 1.7844\n",
      "step 26600: train loss 1.6085, val loss 1.7693\n",
      "step 26700: train loss 1.6148, val loss 1.7791\n",
      "step 26800: train loss 1.6095, val loss 1.7847\n",
      "step 26900: train loss 1.5997, val loss 1.7802\n",
      "step 27000: train loss 1.6224, val loss 1.7766\n",
      "step 27100: train loss 1.6052, val loss 1.7844\n",
      "step 27200: train loss 1.6005, val loss 1.7875\n",
      "step 27300: train loss 1.6194, val loss 1.7850\n",
      "step 27400: train loss 1.6139, val loss 1.7774\n",
      "step 27500: train loss 1.6154, val loss 1.7828\n",
      "step 27600: train loss 1.6133, val loss 1.7787\n",
      "step 27700: train loss 1.6180, val loss 1.7792\n",
      "step 27800: train loss 1.6100, val loss 1.7854\n",
      "step 27900: train loss 1.6054, val loss 1.7843\n",
      "step 28000: train loss 1.6099, val loss 1.7849\n",
      "step 28100: train loss 1.6150, val loss 1.7780\n",
      "step 28200: train loss 1.6099, val loss 1.7705\n",
      "step 28300: train loss 1.6070, val loss 1.7914\n",
      "step 28400: train loss 1.6014, val loss 1.7796\n",
      "step 28500: train loss 1.6068, val loss 1.7874\n",
      "step 28600: train loss 1.6155, val loss 1.7788\n",
      "step 28700: train loss 1.6069, val loss 1.7922\n",
      "step 28800: train loss 1.6128, val loss 1.7717\n",
      "step 28900: train loss 1.6068, val loss 1.7762\n",
      "step 29000: train loss 1.6060, val loss 1.7698\n",
      "step 29100: train loss 1.6036, val loss 1.7757\n",
      "step 29200: train loss 1.5953, val loss 1.7650\n",
      "step 29300: train loss 1.6050, val loss 1.7833\n",
      "step 29400: train loss 1.6055, val loss 1.7786\n",
      "step 29500: train loss 1.6068, val loss 1.7885\n",
      "step 29600: train loss 1.6089, val loss 1.7898\n",
      "step 29700: train loss 1.6010, val loss 1.7866\n",
      "step 29800: train loss 1.5999, val loss 1.7643\n",
      "step 29900: train loss 1.6014, val loss 1.7682\n",
      "step 30000: train loss 1.6052, val loss 1.7788\n",
      "step 30100: train loss 1.6032, val loss 1.7770\n",
      "step 30200: train loss 1.5937, val loss 1.7857\n",
      "step 30300: train loss 1.6022, val loss 1.7757\n",
      "step 30400: train loss 1.5956, val loss 1.7702\n",
      "step 30500: train loss 1.6036, val loss 1.7558\n",
      "step 30600: train loss 1.5979, val loss 1.7654\n",
      "step 30700: train loss 1.5975, val loss 1.7655\n",
      "step 30800: train loss 1.6078, val loss 1.7772\n",
      "step 30900: train loss 1.5884, val loss 1.7709\n",
      "step 31000: train loss 1.6023, val loss 1.7776\n",
      "step 31100: train loss 1.6042, val loss 1.7793\n",
      "step 31200: train loss 1.6075, val loss 1.7799\n",
      "step 31300: train loss 1.5982, val loss 1.7788\n",
      "step 31400: train loss 1.5994, val loss 1.7660\n",
      "step 31500: train loss 1.5967, val loss 1.7731\n",
      "step 31600: train loss 1.5987, val loss 1.7697\n",
      "step 31700: train loss 1.5962, val loss 1.7727\n",
      "step 31800: train loss 1.5940, val loss 1.7686\n",
      "step 31900: train loss 1.6030, val loss 1.7665\n",
      "step 32000: train loss 1.6062, val loss 1.7729\n",
      "step 32100: train loss 1.5996, val loss 1.7688\n",
      "step 32200: train loss 1.5904, val loss 1.7693\n",
      "step 32300: train loss 1.5920, val loss 1.7680\n",
      "step 32400: train loss 1.6019, val loss 1.7791\n",
      "step 32500: train loss 1.5945, val loss 1.7854\n",
      "step 32600: train loss 1.5982, val loss 1.7741\n",
      "step 32700: train loss 1.5950, val loss 1.7763\n",
      "step 32800: train loss 1.6027, val loss 1.7802\n",
      "step 32900: train loss 1.5888, val loss 1.7730\n",
      "step 33000: train loss 1.5945, val loss 1.7638\n",
      "step 33100: train loss 1.6034, val loss 1.7655\n",
      "step 33200: train loss 1.5974, val loss 1.7718\n",
      "step 33300: train loss 1.5993, val loss 1.7664\n",
      "step 33400: train loss 1.6028, val loss 1.7737\n",
      "step 33500: train loss 1.6009, val loss 1.7661\n",
      "step 33600: train loss 1.5891, val loss 1.7722\n",
      "step 33700: train loss 1.5858, val loss 1.7721\n",
      "step 33800: train loss 1.5911, val loss 1.7582\n",
      "step 33900: train loss 1.5942, val loss 1.7656\n",
      "step 34000: train loss 1.5990, val loss 1.7699\n",
      "step 34100: train loss 1.5898, val loss 1.7641\n",
      "step 34200: train loss 1.6045, val loss 1.7789\n",
      "step 34300: train loss 1.5870, val loss 1.7728\n",
      "step 34400: train loss 1.5924, val loss 1.7579\n",
      "step 34500: train loss 1.5851, val loss 1.7860\n",
      "step 34600: train loss 1.5930, val loss 1.7647\n",
      "step 34700: train loss 1.5976, val loss 1.7544\n",
      "step 34800: train loss 1.5883, val loss 1.7664\n",
      "step 34900: train loss 1.5898, val loss 1.7744\n",
      "step 35000: train loss 1.5873, val loss 1.7705\n",
      "step 35100: train loss 1.5947, val loss 1.7543\n",
      "step 35200: train loss 1.5944, val loss 1.7711\n",
      "step 35300: train loss 1.5845, val loss 1.7705\n",
      "step 35400: train loss 1.5852, val loss 1.7746\n",
      "step 35500: train loss 1.5885, val loss 1.7646\n",
      "step 35600: train loss 1.6017, val loss 1.7632\n",
      "step 35700: train loss 1.5911, val loss 1.7632\n",
      "step 35800: train loss 1.5947, val loss 1.7542\n",
      "step 35900: train loss 1.5835, val loss 1.7625\n",
      "step 36000: train loss 1.5885, val loss 1.7791\n",
      "step 36100: train loss 1.5925, val loss 1.7570\n",
      "step 36200: train loss 1.5907, val loss 1.7531\n",
      "step 36300: train loss 1.5872, val loss 1.7722\n",
      "step 36400: train loss 1.6049, val loss 1.7736\n",
      "step 36500: train loss 1.5996, val loss 1.7743\n",
      "step 36600: train loss 1.5903, val loss 1.7715\n",
      "step 36700: train loss 1.5962, val loss 1.7663\n",
      "step 36800: train loss 1.5777, val loss 1.7662\n",
      "step 36900: train loss 1.5790, val loss 1.7607\n",
      "step 37000: train loss 1.5872, val loss 1.7685\n",
      "step 37100: train loss 1.5936, val loss 1.7549\n",
      "step 37200: train loss 1.5822, val loss 1.7548\n",
      "step 37300: train loss 1.5899, val loss 1.7525\n",
      "step 37400: train loss 1.5975, val loss 1.7609\n",
      "step 37500: train loss 1.5855, val loss 1.7602\n",
      "step 37600: train loss 1.5823, val loss 1.7797\n",
      "step 37700: train loss 1.5866, val loss 1.7596\n",
      "step 37800: train loss 1.5889, val loss 1.7634\n",
      "step 37900: train loss 1.5832, val loss 1.7545\n",
      "step 38000: train loss 1.6044, val loss 1.7578\n",
      "step 38100: train loss 1.5881, val loss 1.7589\n",
      "step 38200: train loss 1.5855, val loss 1.7547\n",
      "step 38300: train loss 1.5833, val loss 1.7649\n",
      "step 38400: train loss 1.5859, val loss 1.7545\n",
      "step 38500: train loss 1.5896, val loss 1.7597\n",
      "step 38600: train loss 1.5896, val loss 1.7568\n",
      "step 38700: train loss 1.5789, val loss 1.7582\n",
      "step 38800: train loss 1.5802, val loss 1.7452\n",
      "step 38900: train loss 1.5867, val loss 1.7490\n",
      "step 39000: train loss 1.5819, val loss 1.7461\n",
      "step 39100: train loss 1.5736, val loss 1.7578\n",
      "step 39200: train loss 1.5835, val loss 1.7657\n",
      "step 39300: train loss 1.5835, val loss 1.7542\n",
      "step 39400: train loss 1.5869, val loss 1.7570\n",
      "step 39500: train loss 1.5875, val loss 1.7516\n",
      "step 39600: train loss 1.5982, val loss 1.7586\n",
      "step 39700: train loss 1.5841, val loss 1.7566\n",
      "step 39800: train loss 1.5825, val loss 1.7610\n",
      "step 39900: train loss 1.5872, val loss 1.7618\n",
      "step 40000: train loss 1.5893, val loss 1.7548\n",
      "step 40100: train loss 1.5874, val loss 1.7505\n",
      "step 40200: train loss 1.5819, val loss 1.7540\n",
      "step 40300: train loss 1.5794, val loss 1.7517\n",
      "step 40400: train loss 1.5876, val loss 1.7821\n",
      "step 40500: train loss 1.5779, val loss 1.7585\n",
      "step 40600: train loss 1.5755, val loss 1.7560\n",
      "step 40700: train loss 1.5894, val loss 1.7548\n",
      "step 40800: train loss 1.5748, val loss 1.7475\n",
      "step 40900: train loss 1.5820, val loss 1.7559\n",
      "step 41000: train loss 1.5789, val loss 1.7648\n",
      "step 41100: train loss 1.5887, val loss 1.7432\n",
      "step 41200: train loss 1.5774, val loss 1.7433\n",
      "step 41300: train loss 1.5852, val loss 1.7695\n",
      "step 41400: train loss 1.5690, val loss 1.7612\n",
      "step 41500: train loss 1.5702, val loss 1.7573\n",
      "step 41600: train loss 1.5810, val loss 1.7463\n",
      "step 41700: train loss 1.5683, val loss 1.7298\n",
      "step 41800: train loss 1.5797, val loss 1.7495\n",
      "step 41900: train loss 1.5763, val loss 1.7515\n",
      "step 42000: train loss 1.5829, val loss 1.7366\n",
      "step 42100: train loss 1.5825, val loss 1.7530\n",
      "step 42200: train loss 1.5748, val loss 1.7395\n",
      "step 42300: train loss 1.5798, val loss 1.7473\n",
      "step 42400: train loss 1.5770, val loss 1.7426\n",
      "step 42500: train loss 1.5707, val loss 1.7363\n",
      "step 42600: train loss 1.5720, val loss 1.7393\n",
      "step 42700: train loss 1.5852, val loss 1.7588\n",
      "step 42800: train loss 1.5702, val loss 1.7380\n",
      "step 42900: train loss 1.5800, val loss 1.7418\n",
      "step 43000: train loss 1.5700, val loss 1.7601\n",
      "step 43100: train loss 1.5765, val loss 1.7547\n",
      "step 43200: train loss 1.5750, val loss 1.7573\n",
      "step 43300: train loss 1.5705, val loss 1.7427\n",
      "step 43400: train loss 1.5829, val loss 1.7404\n",
      "step 43500: train loss 1.5744, val loss 1.7530\n",
      "step 43600: train loss 1.5823, val loss 1.7422\n",
      "step 43700: train loss 1.5765, val loss 1.7464\n",
      "step 43800: train loss 1.5692, val loss 1.7422\n",
      "step 43900: train loss 1.5730, val loss 1.7548\n",
      "step 44000: train loss 1.5645, val loss 1.7444\n",
      "step 44100: train loss 1.5720, val loss 1.7560\n",
      "step 44200: train loss 1.5747, val loss 1.7502\n",
      "step 44300: train loss 1.5781, val loss 1.7424\n",
      "step 44400: train loss 1.5747, val loss 1.7387\n",
      "step 44500: train loss 1.5827, val loss 1.7514\n",
      "step 44600: train loss 1.5712, val loss 1.7501\n",
      "step 44700: train loss 1.5637, val loss 1.7453\n",
      "step 44800: train loss 1.5728, val loss 1.7494\n",
      "step 44900: train loss 1.5606, val loss 1.7507\n",
      "step 45000: train loss 1.5700, val loss 1.7541\n",
      "step 45100: train loss 1.5742, val loss 1.7490\n",
      "step 45200: train loss 1.5760, val loss 1.7466\n",
      "step 45300: train loss 1.5743, val loss 1.7436\n",
      "step 45400: train loss 1.5742, val loss 1.7425\n",
      "step 45500: train loss 1.5788, val loss 1.7558\n",
      "step 45600: train loss 1.5766, val loss 1.7623\n",
      "step 45700: train loss 1.5823, val loss 1.7586\n",
      "step 45800: train loss 1.5822, val loss 1.7437\n",
      "step 45900: train loss 1.5875, val loss 1.7514\n",
      "step 46000: train loss 1.5736, val loss 1.7321\n",
      "step 46100: train loss 1.5721, val loss 1.7389\n",
      "step 46200: train loss 1.5842, val loss 1.7470\n",
      "step 46300: train loss 1.5813, val loss 1.7278\n",
      "step 46400: train loss 1.5672, val loss 1.7268\n",
      "step 46500: train loss 1.5634, val loss 1.7408\n",
      "step 46600: train loss 1.5829, val loss 1.7345\n",
      "step 46700: train loss 1.5703, val loss 1.7320\n",
      "step 46800: train loss 1.5746, val loss 1.7362\n",
      "step 46900: train loss 1.5723, val loss 1.7450\n",
      "step 47000: train loss 1.5732, val loss 1.7367\n",
      "step 47100: train loss 1.5674, val loss 1.7302\n",
      "step 47200: train loss 1.5689, val loss 1.7342\n",
      "step 47300: train loss 1.5641, val loss 1.7334\n",
      "step 47400: train loss 1.5827, val loss 1.7436\n",
      "step 47500: train loss 1.5799, val loss 1.7471\n",
      "step 47600: train loss 1.5690, val loss 1.7444\n",
      "step 47700: train loss 1.5752, val loss 1.7305\n",
      "step 47800: train loss 1.5647, val loss 1.7436\n",
      "step 47900: train loss 1.5675, val loss 1.7238\n",
      "step 48000: train loss 1.5659, val loss 1.7444\n",
      "step 48100: train loss 1.5662, val loss 1.7423\n",
      "step 48200: train loss 1.5628, val loss 1.7303\n",
      "step 48300: train loss 1.5681, val loss 1.7335\n",
      "step 48400: train loss 1.5642, val loss 1.7319\n",
      "step 48500: train loss 1.5755, val loss 1.7459\n",
      "step 48600: train loss 1.5694, val loss 1.7361\n",
      "step 48700: train loss 1.5568, val loss 1.7316\n",
      "step 48800: train loss 1.5681, val loss 1.7487\n",
      "step 48900: train loss 1.5701, val loss 1.7454\n",
      "step 49000: train loss 1.5750, val loss 1.7340\n",
      "step 49100: train loss 1.5636, val loss 1.7321\n",
      "step 49200: train loss 1.5660, val loss 1.7428\n",
      "step 49300: train loss 1.5657, val loss 1.7536\n",
      "step 49400: train loss 1.5720, val loss 1.7571\n",
      "step 49500: train loss 1.5712, val loss 1.7371\n",
      "step 49600: train loss 1.5759, val loss 1.7444\n",
      "step 49700: train loss 1.5726, val loss 1.7395\n",
      "step 49800: train loss 1.5698, val loss 1.7493\n",
      "step 49900: train loss 1.5685, val loss 1.7508\n",
      "step 49999: train loss 1.5666, val loss 1.7364\n",
      "Results for configuration res1_dropout=0.025_res2_dropout=0.99_res4_dropout=0.2_use_double_layers=True saved.\n",
      "Training model with configuration: {'res1_dropout': 0.025, 'res2_dropout': 0.99, 'res4_dropout': 0.5, 'use_double_layers': True}\n",
      "step 0: train loss 4.3975, val loss 4.3998\n",
      "step 100: train loss 2.7308, val loss 2.7385\n",
      "step 200: train loss 2.5615, val loss 2.5552\n",
      "step 300: train loss 2.4867, val loss 2.4867\n",
      "step 400: train loss 2.4473, val loss 2.4408\n",
      "step 500: train loss 2.3929, val loss 2.3960\n",
      "step 600: train loss 2.3567, val loss 2.3576\n",
      "step 700: train loss 2.3304, val loss 2.3333\n",
      "step 800: train loss 2.2864, val loss 2.2980\n",
      "step 900: train loss 2.2647, val loss 2.2748\n",
      "step 1000: train loss 2.2393, val loss 2.2501\n",
      "step 1100: train loss 2.2215, val loss 2.2314\n",
      "step 1200: train loss 2.2184, val loss 2.2325\n",
      "step 1300: train loss 2.1807, val loss 2.1922\n",
      "step 1400: train loss 2.1594, val loss 2.1900\n",
      "step 1500: train loss 2.1487, val loss 2.1555\n",
      "step 1600: train loss 2.1182, val loss 2.1606\n",
      "step 1700: train loss 2.1087, val loss 2.1376\n",
      "step 1800: train loss 2.0922, val loss 2.1283\n",
      "step 1900: train loss 2.0933, val loss 2.1244\n",
      "step 2000: train loss 2.0702, val loss 2.1054\n",
      "step 2100: train loss 2.0720, val loss 2.1074\n",
      "step 2200: train loss 2.0565, val loss 2.0887\n",
      "step 2300: train loss 2.0408, val loss 2.0723\n",
      "step 2400: train loss 2.0506, val loss 2.0790\n",
      "step 2500: train loss 2.0285, val loss 2.0567\n",
      "step 2600: train loss 2.0247, val loss 2.0730\n",
      "step 2700: train loss 2.0052, val loss 2.0418\n",
      "step 2800: train loss 2.0006, val loss 2.0553\n",
      "step 2900: train loss 2.0044, val loss 2.0440\n",
      "step 3000: train loss 1.9858, val loss 2.0424\n",
      "step 3100: train loss 1.9766, val loss 2.0365\n",
      "step 3200: train loss 1.9587, val loss 2.0260\n",
      "step 3300: train loss 1.9599, val loss 2.0249\n",
      "step 3400: train loss 1.9534, val loss 2.0223\n",
      "step 3500: train loss 1.9581, val loss 2.0357\n",
      "step 3600: train loss 1.9467, val loss 2.0084\n",
      "step 3700: train loss 1.9365, val loss 1.9943\n",
      "step 3800: train loss 1.9236, val loss 1.9892\n",
      "step 3900: train loss 1.9324, val loss 2.0039\n",
      "step 4000: train loss 1.9123, val loss 1.9878\n",
      "step 4100: train loss 1.9039, val loss 1.9830\n",
      "step 4200: train loss 1.8985, val loss 1.9855\n",
      "step 4300: train loss 1.9024, val loss 1.9942\n",
      "step 4400: train loss 1.9011, val loss 1.9760\n",
      "step 4500: train loss 1.9024, val loss 1.9753\n",
      "step 4600: train loss 1.8836, val loss 1.9690\n",
      "step 4700: train loss 1.8845, val loss 1.9600\n",
      "step 4800: train loss 1.8649, val loss 1.9585\n",
      "step 4900: train loss 1.8659, val loss 1.9598\n",
      "step 5000: train loss 1.8648, val loss 1.9589\n",
      "step 5100: train loss 1.8642, val loss 1.9673\n",
      "step 5200: train loss 1.8634, val loss 1.9552\n",
      "step 5300: train loss 1.8651, val loss 1.9571\n",
      "step 5400: train loss 1.8550, val loss 1.9483\n",
      "step 5500: train loss 1.8468, val loss 1.9405\n",
      "step 5600: train loss 1.8403, val loss 1.9475\n",
      "step 5700: train loss 1.8486, val loss 1.9612\n",
      "step 5800: train loss 1.8372, val loss 1.9485\n",
      "step 5900: train loss 1.8287, val loss 1.9428\n",
      "step 6000: train loss 1.8221, val loss 1.9292\n",
      "step 6100: train loss 1.8313, val loss 1.9527\n",
      "step 6200: train loss 1.8229, val loss 1.9404\n",
      "step 6300: train loss 1.8283, val loss 1.9488\n",
      "step 6400: train loss 1.8176, val loss 1.9314\n",
      "step 6500: train loss 1.8244, val loss 1.9326\n",
      "step 6600: train loss 1.8167, val loss 1.9375\n",
      "step 6700: train loss 1.8138, val loss 1.9323\n",
      "step 6800: train loss 1.8163, val loss 1.9277\n",
      "step 6900: train loss 1.8045, val loss 1.9213\n",
      "step 7000: train loss 1.7953, val loss 1.9142\n",
      "step 7100: train loss 1.8007, val loss 1.9345\n",
      "step 7200: train loss 1.7947, val loss 1.9129\n",
      "step 7300: train loss 1.7919, val loss 1.9180\n",
      "step 7400: train loss 1.7960, val loss 1.9184\n",
      "step 7500: train loss 1.7941, val loss 1.9286\n",
      "step 7600: train loss 1.7893, val loss 1.9076\n",
      "step 7700: train loss 1.7836, val loss 1.9032\n",
      "step 7800: train loss 1.7865, val loss 1.9098\n",
      "step 7900: train loss 1.7911, val loss 1.9221\n",
      "step 8000: train loss 1.7686, val loss 1.9067\n",
      "step 8100: train loss 1.7779, val loss 1.9173\n",
      "step 8200: train loss 1.7683, val loss 1.9064\n",
      "step 8300: train loss 1.7654, val loss 1.9036\n",
      "step 8400: train loss 1.7716, val loss 1.9013\n",
      "step 8500: train loss 1.7708, val loss 1.9052\n",
      "step 8600: train loss 1.7753, val loss 1.9029\n",
      "step 8700: train loss 1.7641, val loss 1.9082\n",
      "step 8800: train loss 1.7648, val loss 1.9015\n",
      "step 8900: train loss 1.7513, val loss 1.8975\n",
      "step 9000: train loss 1.7597, val loss 1.8893\n",
      "step 9100: train loss 1.7582, val loss 1.9089\n",
      "step 9200: train loss 1.7702, val loss 1.8991\n",
      "step 9300: train loss 1.7513, val loss 1.8947\n",
      "step 9400: train loss 1.7548, val loss 1.8946\n",
      "step 9500: train loss 1.7556, val loss 1.9002\n",
      "step 9600: train loss 1.7416, val loss 1.8950\n",
      "step 9700: train loss 1.7364, val loss 1.8974\n",
      "step 9800: train loss 1.7513, val loss 1.8726\n",
      "step 9900: train loss 1.7476, val loss 1.8901\n",
      "step 10000: train loss 1.7462, val loss 1.8966\n",
      "step 10100: train loss 1.7469, val loss 1.9003\n",
      "step 10200: train loss 1.7438, val loss 1.8652\n",
      "step 10300: train loss 1.7355, val loss 1.8881\n",
      "step 10400: train loss 1.7512, val loss 1.8896\n",
      "step 10500: train loss 1.7280, val loss 1.8860\n",
      "step 10600: train loss 1.7303, val loss 1.8758\n",
      "step 10700: train loss 1.7393, val loss 1.8853\n",
      "step 10800: train loss 1.7401, val loss 1.8892\n",
      "step 10900: train loss 1.7299, val loss 1.8684\n",
      "step 11000: train loss 1.7408, val loss 1.8777\n",
      "step 11100: train loss 1.7266, val loss 1.8750\n",
      "step 11200: train loss 1.7176, val loss 1.8544\n",
      "step 11300: train loss 1.7215, val loss 1.8708\n",
      "step 11400: train loss 1.7260, val loss 1.8778\n",
      "step 11500: train loss 1.7124, val loss 1.8875\n",
      "step 11600: train loss 1.7178, val loss 1.8754\n",
      "step 11700: train loss 1.7130, val loss 1.8607\n",
      "step 11800: train loss 1.7163, val loss 1.8692\n",
      "step 11900: train loss 1.7288, val loss 1.8631\n",
      "step 12000: train loss 1.7228, val loss 1.8676\n",
      "step 12100: train loss 1.7102, val loss 1.8558\n",
      "step 12200: train loss 1.7106, val loss 1.8616\n",
      "step 12300: train loss 1.7133, val loss 1.8617\n",
      "step 12400: train loss 1.7108, val loss 1.8549\n",
      "step 12500: train loss 1.7099, val loss 1.8787\n",
      "step 12600: train loss 1.7106, val loss 1.8707\n",
      "step 12700: train loss 1.7031, val loss 1.8694\n",
      "step 12800: train loss 1.7110, val loss 1.8424\n",
      "step 12900: train loss 1.7026, val loss 1.8618\n",
      "step 13000: train loss 1.7132, val loss 1.8581\n",
      "step 13100: train loss 1.7074, val loss 1.8644\n",
      "step 13200: train loss 1.7048, val loss 1.8402\n",
      "step 13300: train loss 1.7016, val loss 1.8486\n",
      "step 13400: train loss 1.7019, val loss 1.8473\n",
      "step 13500: train loss 1.7059, val loss 1.8507\n",
      "step 13600: train loss 1.6995, val loss 1.8427\n",
      "step 13700: train loss 1.6879, val loss 1.8431\n",
      "step 13800: train loss 1.7088, val loss 1.8458\n",
      "step 13900: train loss 1.6943, val loss 1.8420\n",
      "step 14000: train loss 1.6944, val loss 1.8371\n",
      "step 14100: train loss 1.6969, val loss 1.8537\n",
      "step 14200: train loss 1.6945, val loss 1.8522\n",
      "step 14300: train loss 1.7001, val loss 1.8530\n",
      "step 14400: train loss 1.6901, val loss 1.8599\n",
      "step 14500: train loss 1.6874, val loss 1.8457\n",
      "step 14600: train loss 1.6886, val loss 1.8551\n",
      "step 14700: train loss 1.6825, val loss 1.8329\n",
      "step 14800: train loss 1.6920, val loss 1.8329\n",
      "step 14900: train loss 1.6862, val loss 1.8440\n",
      "step 15000: train loss 1.6951, val loss 1.8487\n",
      "step 15100: train loss 1.6914, val loss 1.8465\n",
      "step 15200: train loss 1.6944, val loss 1.8410\n",
      "step 15300: train loss 1.6869, val loss 1.8391\n",
      "step 15400: train loss 1.6782, val loss 1.8371\n",
      "step 15500: train loss 1.6863, val loss 1.8349\n",
      "step 15600: train loss 1.6803, val loss 1.8452\n",
      "step 15700: train loss 1.6773, val loss 1.8345\n",
      "step 15800: train loss 1.6864, val loss 1.8374\n",
      "step 15900: train loss 1.6821, val loss 1.8422\n",
      "step 16000: train loss 1.6751, val loss 1.8324\n",
      "step 16100: train loss 1.6702, val loss 1.8417\n",
      "step 16200: train loss 1.6694, val loss 1.8232\n",
      "step 16300: train loss 1.6755, val loss 1.8296\n",
      "step 16400: train loss 1.6922, val loss 1.8383\n",
      "step 16500: train loss 1.6775, val loss 1.8382\n",
      "step 16600: train loss 1.6783, val loss 1.8276\n",
      "step 16700: train loss 1.6818, val loss 1.8339\n",
      "step 16800: train loss 1.6782, val loss 1.8217\n",
      "step 16900: train loss 1.6712, val loss 1.8196\n",
      "step 17000: train loss 1.6730, val loss 1.8272\n",
      "step 17100: train loss 1.6788, val loss 1.8240\n",
      "step 17200: train loss 1.6726, val loss 1.8354\n",
      "step 17300: train loss 1.6751, val loss 1.8193\n",
      "step 17400: train loss 1.6600, val loss 1.8209\n",
      "step 17500: train loss 1.6766, val loss 1.8277\n",
      "step 17600: train loss 1.6596, val loss 1.8209\n",
      "step 17700: train loss 1.6729, val loss 1.8198\n",
      "step 17800: train loss 1.6757, val loss 1.8301\n",
      "step 17900: train loss 1.6703, val loss 1.8189\n",
      "step 18000: train loss 1.6661, val loss 1.8272\n",
      "step 18100: train loss 1.6590, val loss 1.8231\n",
      "step 18200: train loss 1.6635, val loss 1.8211\n",
      "step 18300: train loss 1.6728, val loss 1.8276\n",
      "step 18400: train loss 1.6559, val loss 1.8167\n",
      "step 18500: train loss 1.6748, val loss 1.8296\n",
      "step 18600: train loss 1.6568, val loss 1.8213\n",
      "step 18700: train loss 1.6673, val loss 1.8271\n",
      "step 18800: train loss 1.6689, val loss 1.8114\n",
      "step 18900: train loss 1.6687, val loss 1.8254\n",
      "step 19000: train loss 1.6645, val loss 1.8149\n",
      "step 19100: train loss 1.6557, val loss 1.8290\n",
      "step 19200: train loss 1.6694, val loss 1.8228\n",
      "step 19300: train loss 1.6589, val loss 1.8209\n",
      "step 19400: train loss 1.6570, val loss 1.8257\n",
      "step 19500: train loss 1.6585, val loss 1.8258\n",
      "step 19600: train loss 1.6593, val loss 1.8328\n",
      "step 19700: train loss 1.6601, val loss 1.8344\n",
      "step 19800: train loss 1.6489, val loss 1.8064\n",
      "step 19900: train loss 1.6593, val loss 1.8175\n",
      "step 20000: train loss 1.6529, val loss 1.8203\n",
      "step 20100: train loss 1.6590, val loss 1.8183\n",
      "step 20200: train loss 1.6628, val loss 1.8134\n",
      "step 20300: train loss 1.6547, val loss 1.8168\n",
      "step 20400: train loss 1.6495, val loss 1.8096\n",
      "step 20500: train loss 1.6565, val loss 1.8213\n",
      "step 20600: train loss 1.6558, val loss 1.8188\n",
      "step 20700: train loss 1.6540, val loss 1.8146\n",
      "step 20800: train loss 1.6550, val loss 1.8035\n",
      "step 20900: train loss 1.6590, val loss 1.8057\n",
      "step 21000: train loss 1.6493, val loss 1.7957\n",
      "step 21100: train loss 1.6368, val loss 1.7992\n",
      "step 21200: train loss 1.6486, val loss 1.8045\n",
      "step 21300: train loss 1.6457, val loss 1.8010\n",
      "step 21400: train loss 1.6517, val loss 1.8225\n",
      "step 21500: train loss 1.6554, val loss 1.8317\n",
      "step 21600: train loss 1.6536, val loss 1.8170\n",
      "step 21700: train loss 1.6483, val loss 1.8051\n",
      "step 21800: train loss 1.6459, val loss 1.8117\n",
      "step 21900: train loss 1.6482, val loss 1.8115\n",
      "step 22000: train loss 1.6450, val loss 1.8143\n",
      "step 22100: train loss 1.6528, val loss 1.8139\n",
      "step 22200: train loss 1.6459, val loss 1.8031\n",
      "step 22300: train loss 1.6396, val loss 1.8057\n",
      "step 22400: train loss 1.6529, val loss 1.7932\n",
      "step 22500: train loss 1.6482, val loss 1.8005\n",
      "step 22600: train loss 1.6378, val loss 1.8034\n",
      "step 22700: train loss 1.6431, val loss 1.8006\n",
      "step 22800: train loss 1.6493, val loss 1.7977\n",
      "step 22900: train loss 1.6435, val loss 1.8117\n",
      "step 23000: train loss 1.6419, val loss 1.7960\n",
      "step 23100: train loss 1.6449, val loss 1.7959\n",
      "step 23200: train loss 1.6396, val loss 1.8036\n",
      "step 23300: train loss 1.6555, val loss 1.8072\n",
      "step 23400: train loss 1.6467, val loss 1.8063\n",
      "step 23500: train loss 1.6381, val loss 1.7972\n",
      "step 23600: train loss 1.6465, val loss 1.8014\n",
      "step 23700: train loss 1.6368, val loss 1.8061\n",
      "step 23800: train loss 1.6353, val loss 1.7908\n",
      "step 23900: train loss 1.6446, val loss 1.7966\n",
      "step 24000: train loss 1.6318, val loss 1.7953\n",
      "step 24100: train loss 1.6382, val loss 1.8123\n",
      "step 24200: train loss 1.6453, val loss 1.8044\n",
      "step 24300: train loss 1.6305, val loss 1.8056\n",
      "step 24400: train loss 1.6439, val loss 1.8119\n",
      "step 24500: train loss 1.6295, val loss 1.8002\n",
      "step 24600: train loss 1.6301, val loss 1.8159\n",
      "step 24700: train loss 1.6346, val loss 1.7995\n",
      "step 24800: train loss 1.6322, val loss 1.8116\n",
      "step 24900: train loss 1.6356, val loss 1.7978\n",
      "step 25000: train loss 1.6413, val loss 1.8015\n",
      "step 25100: train loss 1.6312, val loss 1.8044\n",
      "step 25200: train loss 1.6229, val loss 1.7848\n",
      "step 25300: train loss 1.6368, val loss 1.8002\n",
      "step 25400: train loss 1.6274, val loss 1.7921\n",
      "step 25500: train loss 1.6253, val loss 1.7934\n",
      "step 25600: train loss 1.6317, val loss 1.7993\n",
      "step 25700: train loss 1.6318, val loss 1.8068\n",
      "step 25800: train loss 1.6118, val loss 1.7957\n",
      "step 25900: train loss 1.6339, val loss 1.7973\n",
      "step 26000: train loss 1.6355, val loss 1.8014\n",
      "step 26100: train loss 1.6320, val loss 1.7898\n",
      "step 26200: train loss 1.6294, val loss 1.7858\n",
      "step 26300: train loss 1.6321, val loss 1.7867\n",
      "step 26400: train loss 1.6382, val loss 1.8020\n",
      "step 26500: train loss 1.6259, val loss 1.7965\n",
      "step 26600: train loss 1.6361, val loss 1.7900\n",
      "step 26700: train loss 1.6290, val loss 1.7915\n",
      "step 26800: train loss 1.6216, val loss 1.8095\n",
      "step 26900: train loss 1.6316, val loss 1.7995\n",
      "step 27000: train loss 1.6260, val loss 1.7768\n",
      "step 27100: train loss 1.6220, val loss 1.7895\n",
      "step 27200: train loss 1.6233, val loss 1.8013\n",
      "step 27300: train loss 1.6335, val loss 1.7848\n",
      "step 27400: train loss 1.6227, val loss 1.7879\n",
      "step 27500: train loss 1.6183, val loss 1.7783\n",
      "step 27600: train loss 1.6192, val loss 1.7906\n",
      "step 27700: train loss 1.6187, val loss 1.7988\n",
      "step 27800: train loss 1.6174, val loss 1.7865\n",
      "step 27900: train loss 1.6141, val loss 1.7806\n",
      "step 28000: train loss 1.6276, val loss 1.7843\n",
      "step 28100: train loss 1.6221, val loss 1.7904\n",
      "step 28200: train loss 1.6137, val loss 1.7927\n",
      "step 28300: train loss 1.6118, val loss 1.7891\n",
      "step 28400: train loss 1.6248, val loss 1.7849\n",
      "step 28500: train loss 1.6290, val loss 1.8003\n",
      "step 28600: train loss 1.6226, val loss 1.7967\n",
      "step 28700: train loss 1.6269, val loss 1.7844\n",
      "step 28800: train loss 1.6256, val loss 1.7943\n",
      "step 28900: train loss 1.6232, val loss 1.7906\n",
      "step 29000: train loss 1.6286, val loss 1.7841\n",
      "step 29100: train loss 1.6142, val loss 1.7901\n",
      "step 29200: train loss 1.6246, val loss 1.7702\n",
      "step 29300: train loss 1.6317, val loss 1.7750\n",
      "step 29400: train loss 1.6165, val loss 1.7750\n",
      "step 29500: train loss 1.6217, val loss 1.7888\n",
      "step 29600: train loss 1.6264, val loss 1.7871\n",
      "step 29700: train loss 1.6154, val loss 1.7823\n",
      "step 29800: train loss 1.6224, val loss 1.7940\n",
      "step 29900: train loss 1.6160, val loss 1.7849\n",
      "step 30000: train loss 1.6178, val loss 1.7770\n",
      "step 30100: train loss 1.6156, val loss 1.7907\n",
      "step 30200: train loss 1.6185, val loss 1.7760\n",
      "step 30300: train loss 1.6207, val loss 1.7920\n",
      "step 30400: train loss 1.6229, val loss 1.7945\n",
      "step 30500: train loss 1.6281, val loss 1.7802\n",
      "step 30600: train loss 1.6071, val loss 1.7891\n",
      "step 30700: train loss 1.6146, val loss 1.7736\n",
      "step 30800: train loss 1.6223, val loss 1.7763\n",
      "step 30900: train loss 1.6030, val loss 1.7792\n",
      "step 31000: train loss 1.6153, val loss 1.7757\n",
      "step 31100: train loss 1.6120, val loss 1.7748\n",
      "step 31200: train loss 1.6067, val loss 1.7935\n",
      "step 31300: train loss 1.6064, val loss 1.7821\n",
      "step 31400: train loss 1.6098, val loss 1.7936\n",
      "step 31500: train loss 1.6190, val loss 1.7886\n",
      "step 31600: train loss 1.6047, val loss 1.7885\n",
      "step 31700: train loss 1.6190, val loss 1.7898\n",
      "step 31800: train loss 1.6149, val loss 1.7904\n",
      "step 31900: train loss 1.6202, val loss 1.7791\n",
      "step 32000: train loss 1.6176, val loss 1.7783\n",
      "step 32100: train loss 1.6089, val loss 1.7871\n",
      "step 32200: train loss 1.6154, val loss 1.7800\n",
      "step 32300: train loss 1.6149, val loss 1.7912\n",
      "step 32400: train loss 1.6125, val loss 1.7826\n",
      "step 32500: train loss 1.6143, val loss 1.7859\n",
      "step 32600: train loss 1.6139, val loss 1.7887\n",
      "step 32700: train loss 1.6119, val loss 1.7723\n",
      "step 32800: train loss 1.6097, val loss 1.7982\n",
      "step 32900: train loss 1.6146, val loss 1.7946\n",
      "step 33000: train loss 1.6070, val loss 1.7749\n",
      "step 33100: train loss 1.6053, val loss 1.7795\n",
      "step 33200: train loss 1.6026, val loss 1.7813\n",
      "step 33300: train loss 1.5987, val loss 1.7837\n",
      "step 33400: train loss 1.6089, val loss 1.7849\n",
      "step 33500: train loss 1.6093, val loss 1.7871\n",
      "step 33600: train loss 1.6091, val loss 1.7857\n",
      "step 33700: train loss 1.6106, val loss 1.7626\n",
      "step 33800: train loss 1.6113, val loss 1.7815\n",
      "step 33900: train loss 1.6056, val loss 1.7713\n",
      "step 34000: train loss 1.6053, val loss 1.7827\n",
      "step 34100: train loss 1.6086, val loss 1.7902\n",
      "step 34200: train loss 1.6037, val loss 1.7884\n",
      "step 34300: train loss 1.6099, val loss 1.7731\n",
      "step 34400: train loss 1.6080, val loss 1.7830\n",
      "step 34500: train loss 1.6096, val loss 1.7752\n",
      "step 34600: train loss 1.6005, val loss 1.7814\n",
      "step 34700: train loss 1.5993, val loss 1.7738\n",
      "step 34800: train loss 1.6099, val loss 1.7781\n",
      "step 34900: train loss 1.5985, val loss 1.7736\n",
      "step 35000: train loss 1.6101, val loss 1.7577\n",
      "step 35100: train loss 1.6099, val loss 1.7667\n",
      "step 35200: train loss 1.6002, val loss 1.7595\n",
      "step 35300: train loss 1.5956, val loss 1.7729\n",
      "step 35400: train loss 1.6028, val loss 1.7711\n",
      "step 35500: train loss 1.6095, val loss 1.7692\n",
      "step 35600: train loss 1.6113, val loss 1.7720\n",
      "step 35700: train loss 1.5938, val loss 1.7706\n",
      "step 35800: train loss 1.6011, val loss 1.7733\n",
      "step 35900: train loss 1.5954, val loss 1.7477\n",
      "step 36000: train loss 1.6021, val loss 1.7645\n",
      "step 36100: train loss 1.6094, val loss 1.7532\n",
      "step 36200: train loss 1.5955, val loss 1.7776\n",
      "step 36300: train loss 1.6065, val loss 1.7672\n",
      "step 36400: train loss 1.6022, val loss 1.7743\n",
      "step 36500: train loss 1.5987, val loss 1.7718\n",
      "step 36600: train loss 1.6060, val loss 1.7684\n",
      "step 36700: train loss 1.5990, val loss 1.7808\n",
      "step 36800: train loss 1.5965, val loss 1.7823\n",
      "step 36900: train loss 1.5913, val loss 1.7608\n",
      "step 37000: train loss 1.5890, val loss 1.7829\n",
      "step 37100: train loss 1.6042, val loss 1.7673\n",
      "step 37200: train loss 1.6022, val loss 1.7814\n",
      "step 37300: train loss 1.5935, val loss 1.7778\n",
      "step 37400: train loss 1.6082, val loss 1.7706\n",
      "step 37500: train loss 1.5902, val loss 1.7809\n",
      "step 37600: train loss 1.5931, val loss 1.7699\n",
      "step 37700: train loss 1.6044, val loss 1.7590\n",
      "step 37800: train loss 1.5981, val loss 1.7625\n",
      "step 37900: train loss 1.6018, val loss 1.7789\n",
      "step 38000: train loss 1.5888, val loss 1.7790\n",
      "step 38100: train loss 1.6023, val loss 1.7863\n",
      "step 38200: train loss 1.6008, val loss 1.7716\n",
      "step 38300: train loss 1.5861, val loss 1.7704\n",
      "step 38400: train loss 1.6049, val loss 1.7857\n",
      "step 38500: train loss 1.5969, val loss 1.7674\n",
      "step 38600: train loss 1.5988, val loss 1.7548\n",
      "step 38700: train loss 1.5985, val loss 1.7730\n",
      "step 38800: train loss 1.5886, val loss 1.7686\n",
      "step 38900: train loss 1.5892, val loss 1.7610\n",
      "step 39000: train loss 1.5937, val loss 1.7669\n",
      "step 39100: train loss 1.5948, val loss 1.7492\n",
      "step 39200: train loss 1.5893, val loss 1.7672\n",
      "step 39300: train loss 1.6002, val loss 1.7676\n",
      "step 39400: train loss 1.5980, val loss 1.7616\n",
      "step 39500: train loss 1.5966, val loss 1.7630\n",
      "step 39600: train loss 1.5996, val loss 1.7466\n",
      "step 39700: train loss 1.5962, val loss 1.7525\n",
      "step 39800: train loss 1.6042, val loss 1.7698\n",
      "step 39900: train loss 1.5922, val loss 1.7520\n",
      "step 40000: train loss 1.5873, val loss 1.7509\n",
      "step 40100: train loss 1.6095, val loss 1.7602\n",
      "step 40200: train loss 1.5983, val loss 1.7559\n",
      "step 40300: train loss 1.6021, val loss 1.7650\n",
      "step 40400: train loss 1.5972, val loss 1.7657\n",
      "step 40500: train loss 1.5961, val loss 1.7654\n",
      "step 40600: train loss 1.6021, val loss 1.7562\n",
      "step 40700: train loss 1.6012, val loss 1.7659\n",
      "step 40800: train loss 1.5920, val loss 1.7668\n",
      "step 40900: train loss 1.5929, val loss 1.7651\n",
      "step 41000: train loss 1.5761, val loss 1.7668\n",
      "step 41100: train loss 1.5816, val loss 1.7948\n",
      "step 41200: train loss 1.5923, val loss 1.7667\n",
      "step 41300: train loss 1.5981, val loss 1.7555\n",
      "step 41400: train loss 1.5998, val loss 1.7578\n",
      "step 41500: train loss 1.5795, val loss 1.7619\n",
      "step 41600: train loss 1.6013, val loss 1.7503\n",
      "step 41700: train loss 1.5896, val loss 1.7646\n",
      "step 41800: train loss 1.5927, val loss 1.7645\n",
      "step 41900: train loss 1.5885, val loss 1.7547\n",
      "step 42000: train loss 1.5898, val loss 1.7629\n",
      "step 42100: train loss 1.5840, val loss 1.7597\n",
      "step 42200: train loss 1.6016, val loss 1.7632\n",
      "step 42300: train loss 1.5916, val loss 1.7560\n",
      "step 42400: train loss 1.5872, val loss 1.7585\n",
      "step 42500: train loss 1.5866, val loss 1.7655\n",
      "step 42600: train loss 1.5945, val loss 1.7610\n",
      "step 42700: train loss 1.5828, val loss 1.7522\n",
      "step 42800: train loss 1.5830, val loss 1.7486\n",
      "step 42900: train loss 1.5947, val loss 1.7562\n",
      "step 43000: train loss 1.5894, val loss 1.7532\n",
      "step 43100: train loss 1.5977, val loss 1.7523\n",
      "step 43200: train loss 1.5917, val loss 1.7536\n",
      "step 43300: train loss 1.5884, val loss 1.7694\n",
      "step 43400: train loss 1.5755, val loss 1.7628\n",
      "step 43500: train loss 1.5871, val loss 1.7412\n",
      "step 43600: train loss 1.5864, val loss 1.7573\n",
      "step 43700: train loss 1.5885, val loss 1.7520\n",
      "step 43800: train loss 1.5821, val loss 1.7519\n",
      "step 43900: train loss 1.5802, val loss 1.7695\n",
      "step 44000: train loss 1.5913, val loss 1.7455\n",
      "step 44100: train loss 1.5856, val loss 1.7486\n",
      "step 44200: train loss 1.5852, val loss 1.7541\n",
      "step 44300: train loss 1.5879, val loss 1.7568\n",
      "step 44400: train loss 1.5839, val loss 1.7501\n",
      "step 44500: train loss 1.5856, val loss 1.7587\n",
      "step 44600: train loss 1.5828, val loss 1.7446\n",
      "step 44700: train loss 1.5929, val loss 1.7485\n",
      "step 44800: train loss 1.5937, val loss 1.7489\n",
      "step 44900: train loss 1.5674, val loss 1.7629\n",
      "step 45000: train loss 1.5754, val loss 1.7731\n",
      "step 45100: train loss 1.5743, val loss 1.7615\n",
      "step 45200: train loss 1.5898, val loss 1.7603\n",
      "step 45300: train loss 1.5899, val loss 1.7530\n",
      "step 45400: train loss 1.5804, val loss 1.7671\n",
      "step 45500: train loss 1.5781, val loss 1.7574\n",
      "step 45600: train loss 1.5907, val loss 1.7455\n",
      "step 45700: train loss 1.5921, val loss 1.7630\n",
      "step 45800: train loss 1.5875, val loss 1.7477\n",
      "step 45900: train loss 1.5811, val loss 1.7513\n",
      "step 46000: train loss 1.5735, val loss 1.7520\n",
      "step 46100: train loss 1.5793, val loss 1.7507\n",
      "step 46200: train loss 1.5845, val loss 1.7600\n",
      "step 46300: train loss 1.5842, val loss 1.7577\n",
      "step 46400: train loss 1.5833, val loss 1.7450\n",
      "step 46500: train loss 1.5906, val loss 1.7399\n",
      "step 46600: train loss 1.5758, val loss 1.7507\n",
      "step 46700: train loss 1.5849, val loss 1.7419\n",
      "step 46800: train loss 1.5769, val loss 1.7550\n",
      "step 46900: train loss 1.5809, val loss 1.7457\n",
      "step 47000: train loss 1.5744, val loss 1.7515\n",
      "step 47100: train loss 1.5781, val loss 1.7544\n",
      "step 47200: train loss 1.5958, val loss 1.7479\n",
      "step 47300: train loss 1.5792, val loss 1.7559\n",
      "step 47400: train loss 1.5793, val loss 1.7437\n",
      "step 47500: train loss 1.5859, val loss 1.7606\n",
      "step 47600: train loss 1.5804, val loss 1.7564\n",
      "step 47700: train loss 1.5783, val loss 1.7703\n",
      "step 47800: train loss 1.5781, val loss 1.7517\n",
      "step 47900: train loss 1.5684, val loss 1.7369\n",
      "step 48000: train loss 1.5798, val loss 1.7496\n",
      "step 48100: train loss 1.5775, val loss 1.7484\n",
      "step 48200: train loss 1.5850, val loss 1.7656\n",
      "step 48300: train loss 1.5832, val loss 1.7573\n",
      "step 48400: train loss 1.5760, val loss 1.7519\n",
      "step 48500: train loss 1.5824, val loss 1.7675\n",
      "step 48600: train loss 1.5663, val loss 1.7629\n",
      "step 48700: train loss 1.5820, val loss 1.7758\n",
      "step 48800: train loss 1.5832, val loss 1.7734\n",
      "step 48900: train loss 1.5765, val loss 1.7609\n",
      "step 49000: train loss 1.5815, val loss 1.7666\n",
      "step 49100: train loss 1.5807, val loss 1.7496\n",
      "step 49200: train loss 1.5815, val loss 1.7589\n",
      "step 49300: train loss 1.5737, val loss 1.7687\n",
      "step 49400: train loss 1.5853, val loss 1.7426\n",
      "step 49500: train loss 1.5659, val loss 1.7521\n",
      "step 49600: train loss 1.5769, val loss 1.7412\n",
      "step 49700: train loss 1.5805, val loss 1.7477\n",
      "step 49800: train loss 1.5811, val loss 1.7388\n",
      "step 49900: train loss 1.5802, val loss 1.7413\n",
      "step 49999: train loss 1.5799, val loss 1.7476\n",
      "Results for configuration res1_dropout=0.025_res2_dropout=0.99_res4_dropout=0.5_use_double_layers=True saved.\n",
      "Training model with configuration: {'res1_dropout': 0.025, 'res2_dropout': 0.99, 'res4_dropout': 0.99, 'use_double_layers': True}\n",
      "step 0: train loss 4.3276, val loss 4.3189\n",
      "step 100: train loss 2.6744, val loss 2.6806\n",
      "step 200: train loss 2.5436, val loss 2.5369\n",
      "step 300: train loss 2.4763, val loss 2.4711\n",
      "step 400: train loss 2.4213, val loss 2.4424\n",
      "step 500: train loss 2.3817, val loss 2.3753\n",
      "step 600: train loss 2.3397, val loss 2.3556\n",
      "step 700: train loss 2.3073, val loss 2.3132\n",
      "step 800: train loss 2.2871, val loss 2.2832\n",
      "step 900: train loss 2.2524, val loss 2.2742\n",
      "step 1000: train loss 2.2398, val loss 2.2389\n",
      "step 1100: train loss 2.2019, val loss 2.2288\n",
      "step 1200: train loss 2.1906, val loss 2.2070\n",
      "step 1300: train loss 2.1696, val loss 2.1785\n",
      "step 1400: train loss 2.1453, val loss 2.1704\n",
      "step 1500: train loss 2.1309, val loss 2.1526\n",
      "step 1600: train loss 2.1071, val loss 2.1422\n",
      "step 1700: train loss 2.1066, val loss 2.1272\n",
      "step 1800: train loss 2.0870, val loss 2.1237\n",
      "step 1900: train loss 2.0687, val loss 2.1208\n",
      "step 2000: train loss 2.0495, val loss 2.1059\n",
      "step 2100: train loss 2.0399, val loss 2.0714\n",
      "step 2200: train loss 2.0289, val loss 2.0738\n",
      "step 2300: train loss 2.0298, val loss 2.0747\n",
      "step 2400: train loss 2.0080, val loss 2.0678\n",
      "step 2500: train loss 2.0070, val loss 2.0526\n",
      "step 2600: train loss 1.9963, val loss 2.0461\n",
      "step 2700: train loss 1.9808, val loss 2.0466\n",
      "step 2800: train loss 1.9777, val loss 2.0464\n",
      "step 2900: train loss 1.9725, val loss 2.0390\n",
      "step 3000: train loss 1.9644, val loss 2.0425\n",
      "step 3100: train loss 1.9605, val loss 2.0223\n",
      "step 3200: train loss 1.9501, val loss 2.0148\n",
      "step 3300: train loss 1.9402, val loss 2.0131\n",
      "step 3400: train loss 1.9276, val loss 2.0181\n",
      "step 3500: train loss 1.9210, val loss 1.9968\n",
      "step 3600: train loss 1.9090, val loss 1.9907\n",
      "step 3700: train loss 1.9109, val loss 1.9898\n",
      "step 3800: train loss 1.8990, val loss 1.9795\n",
      "step 3900: train loss 1.9022, val loss 1.9909\n",
      "step 4000: train loss 1.8922, val loss 1.9810\n",
      "step 4100: train loss 1.8934, val loss 1.9899\n",
      "step 4200: train loss 1.8902, val loss 1.9916\n",
      "step 4300: train loss 1.8725, val loss 1.9742\n",
      "step 4400: train loss 1.8728, val loss 1.9880\n",
      "step 4500: train loss 1.8704, val loss 1.9786\n",
      "step 4600: train loss 1.8736, val loss 1.9681\n",
      "step 4700: train loss 1.8668, val loss 1.9621\n",
      "step 4800: train loss 1.8583, val loss 1.9572\n",
      "step 4900: train loss 1.8498, val loss 1.9579\n",
      "step 5000: train loss 1.8597, val loss 1.9601\n",
      "step 5100: train loss 1.8331, val loss 1.9468\n",
      "step 5200: train loss 1.8346, val loss 1.9575\n",
      "step 5300: train loss 1.8322, val loss 1.9491\n",
      "step 5400: train loss 1.8290, val loss 1.9522\n",
      "step 5500: train loss 1.8326, val loss 1.9504\n",
      "step 5600: train loss 1.8271, val loss 1.9318\n",
      "step 5700: train loss 1.8236, val loss 1.9356\n",
      "step 5800: train loss 1.8279, val loss 1.9396\n",
      "step 5900: train loss 1.8199, val loss 1.9367\n",
      "step 6000: train loss 1.8115, val loss 1.9432\n",
      "step 6100: train loss 1.8121, val loss 1.9248\n",
      "step 6200: train loss 1.8078, val loss 1.9285\n",
      "step 6300: train loss 1.8147, val loss 1.9388\n",
      "step 6400: train loss 1.8112, val loss 1.9206\n",
      "step 6500: train loss 1.7952, val loss 1.9222\n",
      "step 6600: train loss 1.7981, val loss 1.9200\n",
      "step 6700: train loss 1.8020, val loss 1.9210\n",
      "step 6800: train loss 1.7994, val loss 1.9041\n",
      "step 6900: train loss 1.7928, val loss 1.9245\n",
      "step 7000: train loss 1.7918, val loss 1.9222\n",
      "step 7100: train loss 1.7921, val loss 1.9288\n",
      "step 7200: train loss 1.7875, val loss 1.9173\n",
      "step 7300: train loss 1.7791, val loss 1.9024\n",
      "step 7400: train loss 1.7908, val loss 1.9241\n",
      "step 7500: train loss 1.7751, val loss 1.9154\n",
      "step 7600: train loss 1.7666, val loss 1.9078\n",
      "step 7700: train loss 1.7772, val loss 1.9031\n",
      "step 7800: train loss 1.7717, val loss 1.9277\n",
      "step 7900: train loss 1.7649, val loss 1.8988\n",
      "step 8000: train loss 1.7705, val loss 1.8931\n",
      "step 8100: train loss 1.7713, val loss 1.8885\n",
      "step 8200: train loss 1.7673, val loss 1.8919\n",
      "step 8300: train loss 1.7644, val loss 1.9039\n",
      "step 8400: train loss 1.7524, val loss 1.8992\n",
      "step 8500: train loss 1.7624, val loss 1.9120\n",
      "step 8600: train loss 1.7546, val loss 1.8853\n",
      "step 8700: train loss 1.7491, val loss 1.8885\n",
      "step 8800: train loss 1.7553, val loss 1.8866\n",
      "step 8900: train loss 1.7527, val loss 1.8909\n",
      "step 9000: train loss 1.7510, val loss 1.8943\n",
      "step 9100: train loss 1.7550, val loss 1.8919\n",
      "step 9200: train loss 1.7416, val loss 1.8955\n",
      "step 9300: train loss 1.7396, val loss 1.8884\n",
      "step 9400: train loss 1.7448, val loss 1.8948\n",
      "step 9500: train loss 1.7362, val loss 1.8971\n",
      "step 9600: train loss 1.7462, val loss 1.8914\n",
      "step 9700: train loss 1.7481, val loss 1.8946\n",
      "step 9800: train loss 1.7329, val loss 1.8850\n",
      "step 9900: train loss 1.7399, val loss 1.8865\n",
      "step 10000: train loss 1.7401, val loss 1.8931\n",
      "step 10100: train loss 1.7449, val loss 1.8787\n",
      "step 10200: train loss 1.7361, val loss 1.8694\n",
      "step 10300: train loss 1.7351, val loss 1.8731\n",
      "step 10400: train loss 1.7262, val loss 1.8658\n",
      "step 10500: train loss 1.7346, val loss 1.8852\n",
      "step 10600: train loss 1.7311, val loss 1.8810\n",
      "step 10700: train loss 1.7322, val loss 1.8698\n",
      "step 10800: train loss 1.7368, val loss 1.8655\n",
      "step 10900: train loss 1.7338, val loss 1.8830\n",
      "step 11000: train loss 1.7256, val loss 1.8833\n",
      "step 11100: train loss 1.7210, val loss 1.8810\n",
      "step 11200: train loss 1.7236, val loss 1.8653\n",
      "step 11300: train loss 1.7224, val loss 1.8791\n",
      "step 11400: train loss 1.7120, val loss 1.8806\n",
      "step 11500: train loss 1.7184, val loss 1.8713\n",
      "step 11600: train loss 1.7114, val loss 1.8647\n",
      "step 11700: train loss 1.7078, val loss 1.8702\n",
      "step 11800: train loss 1.7079, val loss 1.8692\n",
      "step 11900: train loss 1.7183, val loss 1.8595\n",
      "step 12000: train loss 1.7094, val loss 1.8738\n",
      "step 12100: train loss 1.7139, val loss 1.8597\n",
      "step 12200: train loss 1.7057, val loss 1.8756\n",
      "step 12300: train loss 1.7141, val loss 1.8534\n",
      "step 12400: train loss 1.7030, val loss 1.8515\n",
      "step 12500: train loss 1.6994, val loss 1.8509\n",
      "step 12600: train loss 1.7099, val loss 1.8378\n",
      "step 12700: train loss 1.6915, val loss 1.8754\n",
      "step 12800: train loss 1.6993, val loss 1.8580\n",
      "step 12900: train loss 1.7017, val loss 1.8512\n",
      "step 13000: train loss 1.7049, val loss 1.8486\n",
      "step 13100: train loss 1.7052, val loss 1.8466\n",
      "step 13200: train loss 1.6849, val loss 1.8515\n",
      "step 13300: train loss 1.7017, val loss 1.8485\n",
      "step 13400: train loss 1.6932, val loss 1.8490\n",
      "step 13500: train loss 1.6965, val loss 1.8512\n",
      "step 13600: train loss 1.6901, val loss 1.8481\n",
      "step 13700: train loss 1.6920, val loss 1.8404\n",
      "step 13800: train loss 1.6802, val loss 1.8408\n",
      "step 13900: train loss 1.6942, val loss 1.8415\n",
      "step 14000: train loss 1.6974, val loss 1.8419\n",
      "step 14100: train loss 1.6888, val loss 1.8496\n",
      "step 14200: train loss 1.6857, val loss 1.8325\n",
      "step 14300: train loss 1.6959, val loss 1.8343\n",
      "step 14400: train loss 1.6968, val loss 1.8494\n",
      "step 14500: train loss 1.6886, val loss 1.8495\n",
      "step 14600: train loss 1.6887, val loss 1.8369\n",
      "step 14700: train loss 1.6961, val loss 1.8433\n",
      "step 14800: train loss 1.6864, val loss 1.8466\n",
      "step 14900: train loss 1.6909, val loss 1.8463\n",
      "step 15000: train loss 1.6793, val loss 1.8321\n",
      "step 15100: train loss 1.6799, val loss 1.8404\n",
      "step 15200: train loss 1.6717, val loss 1.8224\n",
      "step 15300: train loss 1.6827, val loss 1.8367\n",
      "step 15400: train loss 1.6798, val loss 1.8343\n",
      "step 15500: train loss 1.6845, val loss 1.8370\n",
      "step 15600: train loss 1.6739, val loss 1.8495\n",
      "step 15700: train loss 1.6697, val loss 1.8207\n",
      "step 15800: train loss 1.6719, val loss 1.8368\n",
      "step 15900: train loss 1.6780, val loss 1.8436\n",
      "step 16000: train loss 1.6812, val loss 1.8344\n",
      "step 16100: train loss 1.6706, val loss 1.8258\n",
      "step 16200: train loss 1.6810, val loss 1.8429\n",
      "step 16300: train loss 1.6871, val loss 1.8381\n",
      "step 16400: train loss 1.6650, val loss 1.8278\n",
      "step 16500: train loss 1.6662, val loss 1.8355\n",
      "step 16600: train loss 1.6761, val loss 1.8278\n",
      "step 16700: train loss 1.6716, val loss 1.8322\n",
      "step 16800: train loss 1.6667, val loss 1.8401\n",
      "step 16900: train loss 1.6709, val loss 1.8225\n",
      "step 17000: train loss 1.6679, val loss 1.8176\n",
      "step 17100: train loss 1.6592, val loss 1.8263\n",
      "step 17200: train loss 1.6663, val loss 1.8306\n",
      "step 17300: train loss 1.6672, val loss 1.8143\n",
      "step 17400: train loss 1.6676, val loss 1.8291\n",
      "step 17500: train loss 1.6639, val loss 1.8334\n",
      "step 17600: train loss 1.6743, val loss 1.8337\n",
      "step 17700: train loss 1.6605, val loss 1.8201\n",
      "step 17800: train loss 1.6694, val loss 1.8200\n",
      "step 17900: train loss 1.6711, val loss 1.8071\n",
      "step 18000: train loss 1.6550, val loss 1.8162\n",
      "step 18100: train loss 1.6581, val loss 1.8265\n",
      "step 18200: train loss 1.6658, val loss 1.8340\n",
      "step 18300: train loss 1.6542, val loss 1.8316\n",
      "step 18400: train loss 1.6612, val loss 1.8235\n",
      "step 18500: train loss 1.6619, val loss 1.8257\n",
      "step 18600: train loss 1.6581, val loss 1.8305\n",
      "step 18700: train loss 1.6609, val loss 1.8301\n",
      "step 18800: train loss 1.6674, val loss 1.8143\n",
      "step 18900: train loss 1.6535, val loss 1.8243\n",
      "step 19000: train loss 1.6679, val loss 1.8228\n",
      "step 19100: train loss 1.6556, val loss 1.8308\n",
      "step 19200: train loss 1.6657, val loss 1.8308\n",
      "step 19300: train loss 1.6586, val loss 1.8195\n",
      "step 19400: train loss 1.6523, val loss 1.8109\n",
      "step 19500: train loss 1.6569, val loss 1.8203\n",
      "step 19600: train loss 1.6576, val loss 1.8340\n",
      "step 19700: train loss 1.6575, val loss 1.8245\n",
      "step 19800: train loss 1.6626, val loss 1.8265\n",
      "step 19900: train loss 1.6522, val loss 1.8065\n",
      "step 20000: train loss 1.6440, val loss 1.8093\n",
      "step 20100: train loss 1.6526, val loss 1.8260\n",
      "step 20200: train loss 1.6540, val loss 1.8129\n",
      "step 20300: train loss 1.6538, val loss 1.8186\n",
      "step 20400: train loss 1.6477, val loss 1.8307\n",
      "step 20500: train loss 1.6468, val loss 1.8242\n",
      "step 20600: train loss 1.6409, val loss 1.8129\n",
      "step 20700: train loss 1.6457, val loss 1.8296\n",
      "step 20800: train loss 1.6410, val loss 1.8257\n",
      "step 20900: train loss 1.6445, val loss 1.8255\n",
      "step 21000: train loss 1.6509, val loss 1.8206\n",
      "step 21100: train loss 1.6462, val loss 1.8187\n",
      "step 21200: train loss 1.6470, val loss 1.8140\n",
      "step 21300: train loss 1.6660, val loss 1.8178\n",
      "step 21400: train loss 1.6431, val loss 1.8032\n",
      "step 21500: train loss 1.6446, val loss 1.8299\n",
      "step 21600: train loss 1.6457, val loss 1.8214\n",
      "step 21700: train loss 1.6396, val loss 1.8025\n",
      "step 21800: train loss 1.6483, val loss 1.8040\n",
      "step 21900: train loss 1.6411, val loss 1.8083\n",
      "step 22000: train loss 1.6520, val loss 1.8218\n",
      "step 22100: train loss 1.6451, val loss 1.8003\n",
      "step 22200: train loss 1.6435, val loss 1.8085\n",
      "step 22300: train loss 1.6408, val loss 1.7994\n",
      "step 22400: train loss 1.6451, val loss 1.8127\n",
      "step 22500: train loss 1.6406, val loss 1.8138\n",
      "step 22600: train loss 1.6281, val loss 1.8053\n",
      "step 22700: train loss 1.6404, val loss 1.8211\n",
      "step 22800: train loss 1.6387, val loss 1.8161\n",
      "step 22900: train loss 1.6402, val loss 1.7988\n",
      "step 23000: train loss 1.6375, val loss 1.8147\n",
      "step 23100: train loss 1.6466, val loss 1.8086\n",
      "step 23200: train loss 1.6410, val loss 1.7994\n",
      "step 23300: train loss 1.6444, val loss 1.7930\n",
      "step 23400: train loss 1.6338, val loss 1.8041\n",
      "step 23500: train loss 1.6306, val loss 1.8063\n",
      "step 23600: train loss 1.6434, val loss 1.8174\n",
      "step 23700: train loss 1.6414, val loss 1.8177\n",
      "step 23800: train loss 1.6276, val loss 1.8045\n",
      "step 23900: train loss 1.6294, val loss 1.8077\n",
      "step 24000: train loss 1.6320, val loss 1.8078\n",
      "step 24100: train loss 1.6287, val loss 1.8012\n",
      "step 24200: train loss 1.6385, val loss 1.7920\n",
      "step 24300: train loss 1.6290, val loss 1.7887\n",
      "step 24400: train loss 1.6396, val loss 1.8063\n",
      "step 24500: train loss 1.6371, val loss 1.7900\n",
      "step 24600: train loss 1.6271, val loss 1.7945\n",
      "step 24700: train loss 1.6328, val loss 1.7982\n",
      "step 24800: train loss 1.6358, val loss 1.8085\n",
      "step 24900: train loss 1.6236, val loss 1.8014\n",
      "step 25000: train loss 1.6413, val loss 1.7868\n",
      "step 25100: train loss 1.6378, val loss 1.7978\n",
      "step 25200: train loss 1.6212, val loss 1.8065\n",
      "step 25300: train loss 1.6294, val loss 1.8065\n",
      "step 25400: train loss 1.6339, val loss 1.8026\n",
      "step 25500: train loss 1.6341, val loss 1.8176\n",
      "step 25600: train loss 1.6298, val loss 1.7996\n",
      "step 25700: train loss 1.6309, val loss 1.8081\n",
      "step 25800: train loss 1.6277, val loss 1.7984\n",
      "step 25900: train loss 1.6177, val loss 1.7915\n",
      "step 26000: train loss 1.6264, val loss 1.7949\n",
      "step 26100: train loss 1.6221, val loss 1.7935\n",
      "step 26200: train loss 1.6161, val loss 1.7825\n",
      "step 26300: train loss 1.6255, val loss 1.7802\n",
      "step 26400: train loss 1.6239, val loss 1.7870\n",
      "step 26500: train loss 1.6251, val loss 1.8009\n",
      "step 26600: train loss 1.6178, val loss 1.7915\n",
      "step 26700: train loss 1.6216, val loss 1.7952\n",
      "step 26800: train loss 1.6286, val loss 1.8013\n",
      "step 26900: train loss 1.6387, val loss 1.8067\n",
      "step 27000: train loss 1.6237, val loss 1.8071\n",
      "step 27100: train loss 1.6184, val loss 1.8022\n",
      "step 27200: train loss 1.6156, val loss 1.7961\n",
      "step 27300: train loss 1.6255, val loss 1.8079\n",
      "step 27400: train loss 1.6209, val loss 1.8080\n",
      "step 27500: train loss 1.6278, val loss 1.7819\n",
      "step 27600: train loss 1.6156, val loss 1.7918\n",
      "step 27700: train loss 1.6162, val loss 1.7806\n",
      "step 27800: train loss 1.6231, val loss 1.7866\n",
      "step 27900: train loss 1.6201, val loss 1.8022\n",
      "step 28000: train loss 1.6166, val loss 1.7880\n",
      "step 28100: train loss 1.6294, val loss 1.7983\n",
      "step 28200: train loss 1.6171, val loss 1.7880\n",
      "step 28300: train loss 1.6244, val loss 1.8001\n",
      "step 28400: train loss 1.6154, val loss 1.7980\n",
      "step 28500: train loss 1.6156, val loss 1.7793\n",
      "step 28600: train loss 1.6146, val loss 1.7867\n",
      "step 28700: train loss 1.6121, val loss 1.7884\n",
      "step 28800: train loss 1.6235, val loss 1.7824\n",
      "step 28900: train loss 1.6172, val loss 1.7819\n",
      "step 29000: train loss 1.6202, val loss 1.7825\n",
      "step 29100: train loss 1.6133, val loss 1.7925\n",
      "step 29200: train loss 1.6212, val loss 1.7938\n",
      "step 29300: train loss 1.6181, val loss 1.7914\n",
      "step 29400: train loss 1.6238, val loss 1.7905\n",
      "step 29500: train loss 1.6090, val loss 1.7945\n",
      "step 29600: train loss 1.6142, val loss 1.7696\n",
      "step 29700: train loss 1.6185, val loss 1.7942\n",
      "step 29800: train loss 1.6135, val loss 1.7708\n",
      "step 29900: train loss 1.6082, val loss 1.7821\n",
      "step 30000: train loss 1.6098, val loss 1.7835\n",
      "step 30100: train loss 1.6151, val loss 1.7951\n",
      "step 30200: train loss 1.6205, val loss 1.7851\n",
      "step 30300: train loss 1.6166, val loss 1.7799\n",
      "step 30400: train loss 1.6183, val loss 1.7839\n",
      "step 30500: train loss 1.6194, val loss 1.7967\n",
      "step 30600: train loss 1.6185, val loss 1.7756\n",
      "step 30700: train loss 1.6084, val loss 1.7791\n",
      "step 30800: train loss 1.6064, val loss 1.7969\n",
      "step 30900: train loss 1.6081, val loss 1.7722\n",
      "step 31000: train loss 1.6168, val loss 1.7742\n",
      "step 31100: train loss 1.6243, val loss 1.7821\n",
      "step 31200: train loss 1.6189, val loss 1.7916\n",
      "step 31300: train loss 1.6103, val loss 1.7955\n",
      "step 31400: train loss 1.6181, val loss 1.7806\n",
      "step 31500: train loss 1.6047, val loss 1.7769\n",
      "step 31600: train loss 1.6052, val loss 1.7814\n",
      "step 31700: train loss 1.6061, val loss 1.7776\n",
      "step 31800: train loss 1.6079, val loss 1.7670\n",
      "step 31900: train loss 1.6034, val loss 1.7790\n",
      "step 32000: train loss 1.6018, val loss 1.7817\n",
      "step 32100: train loss 1.6079, val loss 1.7913\n",
      "step 32200: train loss 1.6021, val loss 1.7920\n",
      "step 32300: train loss 1.6178, val loss 1.7724\n",
      "step 32400: train loss 1.6054, val loss 1.7971\n",
      "step 32500: train loss 1.6136, val loss 1.7771\n",
      "step 32600: train loss 1.6129, val loss 1.7813\n",
      "step 32700: train loss 1.6202, val loss 1.7751\n",
      "step 32800: train loss 1.5994, val loss 1.7848\n",
      "step 32900: train loss 1.6150, val loss 1.7780\n",
      "step 33000: train loss 1.5989, val loss 1.7863\n",
      "step 33100: train loss 1.6083, val loss 1.7679\n",
      "step 33200: train loss 1.6052, val loss 1.7869\n",
      "step 33300: train loss 1.6030, val loss 1.7919\n",
      "step 33400: train loss 1.6087, val loss 1.7852\n",
      "step 33500: train loss 1.6106, val loss 1.7777\n",
      "step 33600: train loss 1.5992, val loss 1.7902\n",
      "step 33700: train loss 1.6052, val loss 1.7784\n",
      "step 33800: train loss 1.6046, val loss 1.7737\n",
      "step 33900: train loss 1.5974, val loss 1.7698\n",
      "step 34000: train loss 1.6066, val loss 1.7805\n",
      "step 34100: train loss 1.5994, val loss 1.7621\n",
      "step 34200: train loss 1.5888, val loss 1.7802\n",
      "step 34300: train loss 1.6042, val loss 1.7649\n",
      "step 34400: train loss 1.6071, val loss 1.7713\n",
      "step 34500: train loss 1.6082, val loss 1.7704\n",
      "step 34600: train loss 1.5983, val loss 1.7904\n",
      "step 34700: train loss 1.5984, val loss 1.7810\n",
      "step 34800: train loss 1.6110, val loss 1.7751\n",
      "step 34900: train loss 1.6139, val loss 1.7760\n",
      "step 35000: train loss 1.6113, val loss 1.7773\n",
      "step 35100: train loss 1.6131, val loss 1.7725\n",
      "step 35200: train loss 1.5993, val loss 1.7747\n",
      "step 35300: train loss 1.6079, val loss 1.7871\n",
      "step 35400: train loss 1.6030, val loss 1.7765\n",
      "step 35500: train loss 1.6029, val loss 1.7872\n",
      "step 35600: train loss 1.5950, val loss 1.7540\n",
      "step 35700: train loss 1.6000, val loss 1.7815\n",
      "step 35800: train loss 1.6087, val loss 1.7812\n",
      "step 35900: train loss 1.6074, val loss 1.7613\n",
      "step 36000: train loss 1.6037, val loss 1.7768\n",
      "step 36100: train loss 1.6061, val loss 1.7672\n",
      "step 36200: train loss 1.5950, val loss 1.7654\n",
      "step 36300: train loss 1.5980, val loss 1.7730\n",
      "step 36400: train loss 1.6061, val loss 1.7943\n",
      "step 36500: train loss 1.5970, val loss 1.7761\n",
      "step 36600: train loss 1.6020, val loss 1.7602\n",
      "step 36700: train loss 1.5982, val loss 1.7677\n",
      "step 36800: train loss 1.5931, val loss 1.7786\n",
      "step 36900: train loss 1.5846, val loss 1.7770\n",
      "step 37000: train loss 1.5942, val loss 1.7656\n",
      "step 37100: train loss 1.6017, val loss 1.7769\n",
      "step 37200: train loss 1.5978, val loss 1.7572\n",
      "step 37300: train loss 1.6034, val loss 1.7806\n",
      "step 37400: train loss 1.6070, val loss 1.7771\n",
      "step 37500: train loss 1.5968, val loss 1.7642\n",
      "step 37600: train loss 1.5940, val loss 1.7600\n",
      "step 37700: train loss 1.5923, val loss 1.7678\n",
      "step 37800: train loss 1.6107, val loss 1.7749\n",
      "step 37900: train loss 1.5970, val loss 1.7775\n",
      "step 38000: train loss 1.5953, val loss 1.7783\n",
      "step 38100: train loss 1.6013, val loss 1.7723\n",
      "step 38200: train loss 1.5867, val loss 1.7731\n",
      "step 38300: train loss 1.6040, val loss 1.7702\n",
      "step 38400: train loss 1.5991, val loss 1.7691\n",
      "step 38500: train loss 1.6028, val loss 1.7624\n",
      "step 38600: train loss 1.5959, val loss 1.7687\n",
      "step 38700: train loss 1.5959, val loss 1.7680\n",
      "step 38800: train loss 1.5947, val loss 1.7627\n",
      "step 38900: train loss 1.6027, val loss 1.7655\n",
      "step 39000: train loss 1.5849, val loss 1.7686\n",
      "step 39100: train loss 1.6031, val loss 1.7829\n",
      "step 39200: train loss 1.5848, val loss 1.7706\n",
      "step 39300: train loss 1.6024, val loss 1.7651\n",
      "step 39400: train loss 1.5947, val loss 1.7626\n",
      "step 39500: train loss 1.5881, val loss 1.7609\n",
      "step 39600: train loss 1.5917, val loss 1.7624\n",
      "step 39700: train loss 1.5984, val loss 1.7740\n",
      "step 39800: train loss 1.5881, val loss 1.7660\n",
      "step 39900: train loss 1.5952, val loss 1.7685\n",
      "step 40000: train loss 1.5854, val loss 1.7638\n",
      "step 40100: train loss 1.5909, val loss 1.7569\n",
      "step 40200: train loss 1.5935, val loss 1.7629\n",
      "step 40300: train loss 1.5914, val loss 1.7591\n",
      "step 40400: train loss 1.5921, val loss 1.7610\n",
      "step 40500: train loss 1.5914, val loss 1.7612\n",
      "step 40600: train loss 1.5942, val loss 1.7658\n",
      "step 40700: train loss 1.5932, val loss 1.7583\n",
      "step 40800: train loss 1.6033, val loss 1.7729\n",
      "step 40900: train loss 1.5801, val loss 1.7725\n",
      "step 41000: train loss 1.5914, val loss 1.7702\n",
      "step 41100: train loss 1.5929, val loss 1.7519\n",
      "step 41200: train loss 1.5791, val loss 1.7612\n",
      "step 41300: train loss 1.5906, val loss 1.7838\n",
      "step 41400: train loss 1.5823, val loss 1.7568\n",
      "step 41500: train loss 1.5967, val loss 1.7521\n",
      "step 41600: train loss 1.5851, val loss 1.7589\n",
      "step 41700: train loss 1.5993, val loss 1.7574\n",
      "step 41800: train loss 1.5878, val loss 1.7556\n",
      "step 41900: train loss 1.5827, val loss 1.7712\n",
      "step 42000: train loss 1.5746, val loss 1.7687\n",
      "step 42100: train loss 1.5846, val loss 1.7595\n",
      "step 42200: train loss 1.5965, val loss 1.7724\n",
      "step 42300: train loss 1.5924, val loss 1.7600\n",
      "step 42400: train loss 1.5905, val loss 1.7534\n",
      "step 42500: train loss 1.5928, val loss 1.7621\n",
      "step 42600: train loss 1.5867, val loss 1.7644\n",
      "step 42700: train loss 1.5887, val loss 1.7575\n",
      "step 42800: train loss 1.5844, val loss 1.7585\n",
      "step 42900: train loss 1.5859, val loss 1.7639\n",
      "step 43000: train loss 1.5905, val loss 1.7719\n",
      "step 43100: train loss 1.5858, val loss 1.7511\n",
      "step 43200: train loss 1.5878, val loss 1.7822\n",
      "step 43300: train loss 1.5885, val loss 1.7598\n",
      "step 43400: train loss 1.5798, val loss 1.7688\n",
      "step 43500: train loss 1.5889, val loss 1.7637\n",
      "step 43600: train loss 1.5910, val loss 1.7680\n",
      "step 43700: train loss 1.5831, val loss 1.7668\n",
      "step 43800: train loss 1.5984, val loss 1.7734\n",
      "step 43900: train loss 1.5767, val loss 1.7732\n",
      "step 44000: train loss 1.5738, val loss 1.7700\n",
      "step 44100: train loss 1.5887, val loss 1.7742\n",
      "step 44200: train loss 1.5841, val loss 1.7717\n",
      "step 44300: train loss 1.5817, val loss 1.7599\n",
      "step 44400: train loss 1.5805, val loss 1.7802\n",
      "step 44500: train loss 1.5947, val loss 1.7675\n",
      "step 44600: train loss 1.5837, val loss 1.7741\n",
      "step 44700: train loss 1.5861, val loss 1.7623\n",
      "step 44800: train loss 1.5894, val loss 1.7789\n",
      "step 44900: train loss 1.5953, val loss 1.7776\n",
      "step 45000: train loss 1.5900, val loss 1.7580\n",
      "step 45100: train loss 1.5886, val loss 1.7695\n",
      "step 45200: train loss 1.5841, val loss 1.7703\n",
      "step 45300: train loss 1.5840, val loss 1.7694\n",
      "step 45400: train loss 1.5891, val loss 1.7872\n",
      "step 45500: train loss 1.5850, val loss 1.7629\n",
      "step 45600: train loss 1.5818, val loss 1.7589\n",
      "step 45700: train loss 1.5768, val loss 1.7588\n",
      "step 45800: train loss 1.5855, val loss 1.7534\n",
      "step 45900: train loss 1.5907, val loss 1.7779\n",
      "step 46000: train loss 1.5738, val loss 1.7801\n",
      "step 46100: train loss 1.5798, val loss 1.7566\n",
      "step 46200: train loss 1.5885, val loss 1.7769\n",
      "step 46300: train loss 1.5790, val loss 1.7668\n",
      "step 46400: train loss 1.5738, val loss 1.7730\n",
      "step 46500: train loss 1.5905, val loss 1.7713\n",
      "step 46600: train loss 1.5892, val loss 1.7530\n",
      "step 46700: train loss 1.5796, val loss 1.7626\n",
      "step 46800: train loss 1.5728, val loss 1.7683\n",
      "step 46900: train loss 1.5800, val loss 1.7621\n",
      "step 47000: train loss 1.5790, val loss 1.7672\n",
      "step 47100: train loss 1.5818, val loss 1.7648\n",
      "step 47200: train loss 1.5732, val loss 1.7607\n",
      "step 47300: train loss 1.5749, val loss 1.7643\n",
      "step 47400: train loss 1.5813, val loss 1.7679\n",
      "step 47500: train loss 1.5810, val loss 1.7635\n",
      "step 47600: train loss 1.5750, val loss 1.7534\n",
      "step 47700: train loss 1.5788, val loss 1.7583\n",
      "step 47800: train loss 1.5919, val loss 1.7535\n",
      "step 47900: train loss 1.5849, val loss 1.7650\n",
      "step 48000: train loss 1.5751, val loss 1.7644\n",
      "step 48100: train loss 1.5846, val loss 1.7599\n",
      "step 48200: train loss 1.5771, val loss 1.7673\n",
      "step 48300: train loss 1.5778, val loss 1.7653\n",
      "step 48400: train loss 1.5829, val loss 1.7630\n",
      "step 48500: train loss 1.5831, val loss 1.7651\n",
      "step 48600: train loss 1.5840, val loss 1.7606\n",
      "step 48700: train loss 1.5887, val loss 1.7657\n",
      "step 48800: train loss 1.5776, val loss 1.7574\n",
      "step 48900: train loss 1.5784, val loss 1.7620\n",
      "step 49000: train loss 1.5757, val loss 1.7565\n",
      "step 49100: train loss 1.5846, val loss 1.7589\n",
      "step 49200: train loss 1.5786, val loss 1.7647\n",
      "step 49300: train loss 1.5776, val loss 1.7690\n",
      "step 49400: train loss 1.5725, val loss 1.7569\n",
      "step 49500: train loss 1.5743, val loss 1.7689\n",
      "step 49600: train loss 1.5837, val loss 1.7732\n",
      "step 49700: train loss 1.5802, val loss 1.7631\n",
      "step 49800: train loss 1.5795, val loss 1.7553\n",
      "step 49900: train loss 1.5726, val loss 1.7677\n",
      "step 49999: train loss 1.5831, val loss 1.7608\n",
      "Results for configuration res1_dropout=0.025_res2_dropout=0.99_res4_dropout=0.99_use_double_layers=True saved.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Example: Different dropout configurations\n",
    "dropout_configurations = [\n",
    "    {\"res1_dropout\": 0.025, \"res2_dropout\": 0.99, \"res4_dropout\": 0.0, \"use_double_layers\": False},\n",
    "    {\"res1_dropout\": 0.1, \"res2_dropout\": 0.99, \"res4_dropout\": 0.0, \"use_double_layers\": False},\n",
    "    {\"res1_dropout\": 0.2, \"res2_dropout\": 0.99, \"res4_dropout\": 0.0, \"use_double_layers\": False},\n",
    "    {\"res1_dropout\": 0.5, \"res2_dropout\": 0.99, \"res4_dropout\": 0.0, \"use_double_layers\": False},\n",
    "\n",
    "    {\"res1_dropout\": 0.025, \"res2_dropout\": 0.1, \"res4_dropout\": 0.0, \"use_double_layers\": False},\n",
    "    {\"res1_dropout\": 0.025, \"res2_dropout\": 0.2, \"res4_dropout\": 0.0, \"use_double_layers\": False},\n",
    "    {\"res1_dropout\": 0.025, \"res2_dropout\": 0.5, \"res4_dropout\": 0.0, \"use_double_layers\": False},\n",
    "    {\"res1_dropout\": 0.025, \"res2_dropout\": 0.99, \"res4_dropout\": 0.0, \"use_double_layers\": False},\n",
    "\n",
    "    {\"res1_dropout\": 0.025, \"res2_dropout\": 0.99, \"res4_dropout\": 0.1, \"use_double_layers\": True},\n",
    "    {\"res1_dropout\": 0.025, \"res2_dropout\": 0.99, \"res4_dropout\": 0.2, \"use_double_layers\": True},\n",
    "    {\"res1_dropout\": 0.025, \"res2_dropout\": 0.99, \"res4_dropout\": 0.5, \"use_double_layers\": True},\n",
    "    {\"res1_dropout\": 0.025, \"res2_dropout\": 0.99, \"res4_dropout\": 0.99, \"use_double_layers\": True}\n",
    "]\n",
    "\n",
    "for config in dropout_configurations:\n",
    "    print(f\"Training model with configuration: {config}\")\n",
    "\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Instantiate the model with the current configuration\n",
    "    model = BigramLanguageModel(\n",
    "        res1_dropout=config['res1_dropout'],\n",
    "        res2_dropout=config['res2_dropout'],\n",
    "        res4_dropout=config['res4_dropout'],\n",
    "        use_double_layers=config['use_double_layers']\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Store the loss values for the current configuration\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for iter in range(max_iters):\n",
    "        # Regularly evaluate the loss on training and validation sets\n",
    "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "            losses = estimate_loss()  # Ensure this function uses the model from the current loop\n",
    "            train_losses.append(losses['train'].item())\n",
    "            val_losses.append(losses['val'].item())\n",
    "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        \n",
    "        # Sample a batch of data\n",
    "        xb, yb = get_batch('train')\n",
    "        \n",
    "        # Calculate the loss\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time  # Calculate total training time\n",
    "\n",
    "    # Construct the path and filename for saving results\n",
    "    config_str = \"_\".join(f\"{k}={v}\" for k, v in config.items())\n",
    "    folder_path = \"./loss_time/res_all\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    loss_file_path = os.path.join(folder_path, f\"{config_str}_losses.json\")\n",
    "    time_file_path = os.path.join(folder_path, f\"{config_str}_training_time.json\")\n",
    "    \n",
    "    # Save results\n",
    "    with open(loss_file_path, 'w') as f:\n",
    "        json.dump({\"train_losses\": train_losses, \"val_losses\": val_losses}, f)\n",
    "    with open(time_file_path, 'w') as f:\n",
    "        json.dump({\"training_time\": training_time}, f)\n",
    "    \n",
    "    print(f\"Results for configuration {config_str} saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to ./visualization/res_all_loss_curves.png\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Specify the folder path where the loss JSON files are stored\n",
    "folder_path = \"./loss_time/res_all\"\n",
    "# Specify the path to save the visualization result\n",
    "visualization_save_path = \"./visualization/res_all_loss_curves.png\"\n",
    "\n",
    "# Use a pattern or a specific part of the file name to identify loss files\n",
    "loss_files = [f for f in os.listdir(folder_path) if 'losses' in f]\n",
    "\n",
    "# Visualize the loss curves for each dropout configuration\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for file in loss_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    \n",
    "    # Read the loss values from the JSON file\n",
    "    with open(file_path, 'r') as f:\n",
    "        losses = json.load(f)\n",
    "    \n",
    "    # Extract the dropout values from the file name\n",
    "    parts = file.replace('res1_dropout=', '').replace('res2_dropout=', '').replace('res4_dropout=', '').replace('use_double_layers=False_losses', '').split('_')\n",
    "    res1_dropout, res2_dropout, res4_dropout = parts[:3]\n",
    "    dropout_label = f\"res1={res1_dropout}, res2={res2_dropout}, res4={res4_dropout}\"\n",
    "    \n",
    "    # Plot the validation loss curves\n",
    "    plt.plot(losses['val_losses'], label=f\"{dropout_label}\")\n",
    "\n",
    "plt.title(\"Loss Curves for Different Dropout Configurations\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the visualization\n",
    "plt.savefig(visualization_save_path)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Visualization saved to {visualization_save_path}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
