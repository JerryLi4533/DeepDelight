{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82fdcbca",
      "metadata": {
        "id": "82fdcbca"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertConfig, BertForTokenClassification\n",
        "# Using the dlite function\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f8d35a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f8d35a4",
        "outputId": "3e588172-6c95-4db1-81b0-79f869f6b108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting seqeval[gpu]\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval[gpu]) (1.2.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=33a1143412f1e2f23318ee23d696b59acf4e4515ec0927f90bff281805e671cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers seqeval[gpu]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oJUgaJuLMMMB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJUgaJuLMMMB",
        "outputId": "aa51dc16-e2d9-49e8-a71f-6d9fc97921e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c8951f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c8951f4",
        "outputId": "404ce1fb-bb7d-46a7-bd2b-74253fe00bee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c27912f",
      "metadata": {
        "id": "2c27912f"
      },
      "outputs": [],
      "source": [
        "# Ner dataset website ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeab7a44",
      "metadata": {
        "id": "eeab7a44"
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/datasets/namanj27/ner-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c81b64e9",
      "metadata": {
        "id": "c81b64e9"
      },
      "source": [
        "# Named Entity Recognition (NER) Dataset\n",
        "\n",
        "This is a very clean dataset and is for anyone who wants to try his/her hand on the NER ( Named Entity recognition ) task of NLP. The dataset with 1M x 4 dimensions contains columns = ['# Sentence', 'Word', 'POS', 'Tag'] and is grouped by #Sentence.\n",
        "\n",
        "\n",
        "\n",
        "* **`Geographic location`**: `'B-geo'`  and `'I-geo'`\n",
        "\n",
        "* **`geopolitical `**: `'B-gpe'`  and `'I-gpe'`\n",
        "\n",
        "* **`Organization`**: `'B-ORG'` and `'I-ORG'`\n",
        "\n",
        "* **`Person`**: `'B-PER'` and  `'I-PER'`\n",
        "\n",
        "* **`Time`**: `'B-tim'` and `'I-tim'`\n",
        "\n",
        "* **`Other(non-named entity)`**: `'O'`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fddbe20",
      "metadata": {
        "id": "7fddbe20"
      },
      "source": [
        "## Micro Table\n",
        "\n",
        "| Loss | Train Iteration | Precision | Recall | F1-score | Training time |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| CE | 9515 | 0.79 | 0.81 | 0.80 | 19 min 11s |\n",
        "| L1 | 9515 | 0.77 | 0.59 | 0.67 | 19 min 19s |\n",
        "| D-Lite | 9515 | 0.79 | 0.79 | 0.79 | 19 min 19s |\n",
        "| KL | 9515 | 0.80 | 0.81 | 0.80 | 19 min 26 s |\n",
        "\n",
        "\n",
        "## Macro Table\n",
        "\n",
        "| Loss | Train Iteration | Precision | Recall | F1-score | Training time |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| CE | 9515 | 0.80 | 0.81 | 0.80 | 19 min 11s |\n",
        "| L1 | 9515 | 0.63 | 0.60 | 0.61 | 19 min 19s |\n",
        "| D-Lite | 9515 | 0.79 | 0.79 | 0.79 | 19 min 19s |\n",
        "| KL | 9515 | 0.81 | 0.81 | 0.81 | 19 min 26 s |\n",
        "\n",
        "## Weighted Table\n",
        "\n",
        "| Loss | Train Iteration | Precision | Recall | F1-score | Training time |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| CE | 9515 | 0.80 | 0.81 | 0.80 | 19 min 11s |\n",
        "| L1 | 9515 | 0.61 | 0.59 | 0.60 | 19 min 19s |\n",
        "| D-Lite | 9515 | 0.78 | 0.79 | 0.79 | 19 min 19s |\n",
        "| KL | 9515 | 0.80 | 0.81 | 0.80 | 19 min 26 s |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d46be561",
      "metadata": {
        "id": "d46be561"
      },
      "source": [
        "# New Coding methods\n",
        "\n",
        "## Micro Table\n",
        "\n",
        "| Loss | Train Iteration | Precision | Recall | F1-score | Training time |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| CE | 9515 | 0.96 | 0.96 | 0.96 | 19 min 11s |\n",
        "| L1 | 9515 | 0.92 | 0.92 | 0.92 | 19 min 19s |\n",
        "| D-Lite | 9515 | 0.96 | 0.96 | 0.96 | 19 min 19s |\n",
        "| D-Lite Prefer | 9515 | 0.82 | 0.82 | 0.82 | 19 min 27s |\n",
        "| KL | 9515 | 0.96 | 0.96 | 0.96 | 19 min 26 s |\n",
        "| D-Lite Cubic Root | 9515 | 0.82 | 0.82 | 0.82 | 19 min 29s |\n",
        "\n",
        "## Macro Table\n",
        "\n",
        "| Loss | Train Iteration | Precision | Recall | F1-score | Training time |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| CE | 9515 | 0.84 | 0.77 | 0.80 | 19 min 11s |\n",
        "| L1 | 9515 | 0.93 | 0.47 | 0.47 | 19 min 19s |\n",
        "| D-Lite | 9515 | 0.85 | 0.70 | 0.72 | 19 min 19s |\n",
        "| D-Lite Prefer | 9515 | 0.98 | 0.09 | 0.09 | 19 min 27s |\n",
        "| KL | 9515 | 0.85 | 0.78| 0.79 | 19 min 26 s |\n",
        "| D-Lite Cubic Root | 9515 | 0.98 | 0.09 | 0.08 | 19 min 29s |\n",
        "\n",
        "## Weighted Table\n",
        "\n",
        "| Loss | Train Iteration | Precision | Recall | F1-score | Training time |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| CE | 9515 | 0.95 | 0.96 | 0.96 | 19 min 11s |\n",
        "| L1 | 9515 | 0.93 | 0.92 | 0.90 | 19 min 19s |\n",
        "| D-Lite | 9515 | 0.95 | 0.96 | 0.95 | 19 min 19s |\n",
        "| D-Lite Prefer | 9515 | 0.86 | 0.82 | 0.74 | 19 min 27s |\n",
        "| KL | 9515 | 0.96 | 0.96 | 0.96 | 19 min 26 s |\n",
        "| D-Lite Cubic Root | 9515 | 0.85| 0.82 | 0.75 | 19 min 29s |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8328f08",
      "metadata": {
        "id": "e8328f08"
      },
      "source": [
        "# Data preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36181a52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "36181a52",
        "outputId": "267a3e16-9644-4514-9861-d4c37fa41cf0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1          NaN             of   IN   O\n",
              "2          NaN  demonstrators  NNS   O\n",
              "3          NaN           have  VBP   O\n",
              "4          NaN        marched  VBN   O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe3da941-5519-467c-861a-d7a8decab127\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe3da941-5519-467c-861a-d7a8decab127')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe3da941-5519-467c-861a-d7a8decab127 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe3da941-5519-467c-861a-d7a8decab127');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e1d894ab-c28c-4567-85e2-6cc405751478\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1d894ab-c28c-4567-85e2-6cc405751478')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e1d894ab-c28c-4567-85e2-6cc405751478 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data = pd.read_csv(\"ner_datasetreference.csv\", encoding='unicode_escape')\n",
        "data.head() # preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "374ae95e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "374ae95e",
        "outputId": "a4d266a3-efde-469a-c38a-5a81071727e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #      47959\n",
              "Word          1048575\n",
              "POS           1048575\n",
              "Tag           1048575\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.count()\n",
        "# count of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d45f5e61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d45f5e61",
        "outputId": "544c70e8-e892-41ec-e56d-ff7f2ffb761f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tags: 17\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        887908\n",
              "B-geo     37644\n",
              "B-tim     20333\n",
              "B-org     20143\n",
              "I-per     17251\n",
              "B-per     16990\n",
              "I-org     16784\n",
              "B-gpe     15870\n",
              "I-geo      7414\n",
              "I-tim      6528\n",
              "B-art       402\n",
              "B-eve       308\n",
              "I-art       297\n",
              "I-eve       253\n",
              "B-nat       201\n",
              "I-gpe       198\n",
              "I-nat        51\n",
              "Name: Tag, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "print(\"Number of tags: {}\".format(len(data.Tag.unique())))\n",
        "frequencies = data.Tag.value_counts()\n",
        "frequencies\n",
        "# Look at differnt NER tags and their frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc1c532e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc1c532e",
        "outputId": "5aea2bc0-1ead-453b-85af-ee628084ae2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('geo', 45058), ('org', 36927), ('per', 34241), ('tim', 26861), ('gpe', 16068), ('art', 699), ('eve', 561), ('nat', 252)]\n"
          ]
        }
      ],
      "source": [
        "tags = {}\n",
        "for tag, count in zip(frequencies.index, frequencies):\n",
        "    if tag != \"O\":\n",
        "        if tag[2:5] not in tags.keys():\n",
        "            tags[tag[2:5]] = count\n",
        "        else:\n",
        "            tags[tag[2:5]] += count\n",
        "    continue\n",
        "\n",
        "print(sorted(tags.items(), key=lambda x: x[1], reverse=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f98c4bf1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f98c4bf1",
        "outputId": "f7fdf55a-3fe2-4bf6-dd45-48604e19e7dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1          NaN             of   IN   O\n",
              "2          NaN  demonstrators  NNS   O\n",
              "3          NaN           have  VBP   O\n",
              "4          NaN        marched  VBN   O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4b5c945-daa2-4ca9-b693-3ec742b9ac79\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4b5c945-daa2-4ca9-b693-3ec742b9ac79')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e4b5c945-daa2-4ca9-b693-3ec742b9ac79 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e4b5c945-daa2-4ca9-b693-3ec742b9ac79');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-26649b98-153f-4bda-87fb-d81b1078bc92\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-26649b98-153f-4bda-87fb-d81b1078bc92')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-26649b98-153f-4bda-87fb-d81b1078bc92 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# removed \\\"art\\\", \\\"eve\\\", \\\"nat\\\" named entities\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Sentence #\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Sentence: 1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"of\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"IN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "entities_to_remove = [\"B-art\", \"I-art\", \"B-eve\", \"I-eve\", \"B-nat\", \"I-nat\"]\n",
        "data = data[~data.Tag.isin(entities_to_remove)]\n",
        "data.head()\n",
        "\n",
        "# removed \"art\", \"eve\", \"nat\" named entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e00e8202",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "e00e8202",
        "outputId": "7a382b34-ea08-45c3-dde4-b90622416240"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1  Sentence: 1             of   IN   O\n",
              "2  Sentence: 1  demonstrators  NNS   O\n",
              "3  Sentence: 1           have  VBP   O\n",
              "4  Sentence: 1        marched  VBN   O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db55ba4f-f8ab-4640-9eaa-3f70c1bcc645\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db55ba4f-f8ab-4640-9eaa-3f70c1bcc645')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db55ba4f-f8ab-4640-9eaa-3f70c1bcc645 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db55ba4f-f8ab-4640-9eaa-3f70c1bcc645');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6f42269f-1829-4569-b0c5-5e9634d9387c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f42269f-1829-4569-b0c5-5e9634d9387c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6f42269f-1829-4569-b0c5-5e9634d9387c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# pandas has a very handy \"forward fill\" function to fill missing values based on the last upper non-nan value\n",
        "data = data.fillna(method='ffill')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50f30fd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "50f30fd7",
        "outputId": "70404890-bdfa-44b9-b4c7-2025866271c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Sentence #           Word  POS Tag  \\\n",
              "0  Sentence: 1      Thousands  NNS   O   \n",
              "1  Sentence: 1             of   IN   O   \n",
              "2  Sentence: 1  demonstrators  NNS   O   \n",
              "3  Sentence: 1           have  VBP   O   \n",
              "4  Sentence: 1        marched  VBN   O   \n",
              "\n",
              "                                            sentence  \\\n",
              "0  Thousands of demonstrators have marched throug...   \n",
              "1  Thousands of demonstrators have marched throug...   \n",
              "2  Thousands of demonstrators have marched throug...   \n",
              "3  Thousands of demonstrators have marched throug...   \n",
              "4  Thousands of demonstrators have marched throug...   \n",
              "\n",
              "                                         word_labels  \n",
              "0  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
              "1  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
              "2  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
              "3  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
              "4  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-efd5487b-a96d-46af-8573-397e158f29fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>Thousands of demonstrators have marched throug...</td>\n",
              "      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>Thousands of demonstrators have marched throug...</td>\n",
              "      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>Thousands of demonstrators have marched throug...</td>\n",
              "      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "      <td>Thousands of demonstrators have marched throug...</td>\n",
              "      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "      <td>Thousands of demonstrators have marched throug...</td>\n",
              "      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efd5487b-a96d-46af-8573-397e158f29fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-efd5487b-a96d-46af-8573-397e158f29fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-efd5487b-a96d-46af-8573-397e158f29fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a8877814-6ad4-4c17-8453-d8828c2fe75c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a8877814-6ad4-4c17-8453-d8828c2fe75c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a8877814-6ad4-4c17-8453-d8828c2fe75c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# let's create a new column called \"sentence\" which groups the words by sentence\n",
        "data['sentence'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Word'].transform(lambda x: ' '.join(x))\n",
        "# let's also create a new column called \"word_labels\" which groups the tags by sentence\n",
        "data['word_labels'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Tag'].transform(lambda x: ','.join(x))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18fa680b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18fa680b",
        "outputId": "af847a9f-d26f-4405-884a-1ea4f46bab35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'O': 0,\n",
              " 'B-geo': 1,\n",
              " 'B-gpe': 2,\n",
              " 'B-per': 3,\n",
              " 'I-geo': 4,\n",
              " 'B-org': 5,\n",
              " 'I-org': 6,\n",
              " 'B-tim': 7,\n",
              " 'I-per': 8,\n",
              " 'I-gpe': 9,\n",
              " 'I-tim': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "label2id = {k: v for v, k in enumerate(data.Tag.unique())}\n",
        "id2label = {v: k for v, k in enumerate(data.Tag.unique())}\n",
        "label2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2a382d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "d2a382d4",
        "outputId": "5c557e88-fd6e-4299-b96d-35d682569792"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  Thousands of demonstrators have marched throug...   \n",
              "1  Families of soldiers killed in the conflict jo...   \n",
              "2  They marched from the Houses of Parliament to ...   \n",
              "3  Police put the number of marchers at 10,000 wh...   \n",
              "4  The protest comes on the eve of the annual con...   \n",
              "\n",
              "                                         word_labels  \n",
              "0  O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...  \n",
              "1  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O,...  \n",
              "2                O,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O  \n",
              "3                      O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
              "4  O,O,O,O,O,O,O,O,O,O,O,B-geo,O,O,B-org,I-org,O,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-897b9b91-6b13-4dd2-8a11-18428d281de1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thousands of demonstrators have marched throug...</td>\n",
              "      <td>O,O,O,O,O,O,B-geo,O,O,O,O,O,B-geo,O,O,O,O,O,B-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Families of soldiers killed in the conflict jo...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-per,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They marched from the Houses of Parliament to ...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Police put the number of marchers at 10,000 wh...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The protest comes on the eve of the annual con...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,B-geo,O,O,B-org,I-org,O,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-897b9b91-6b13-4dd2-8a11-18428d281de1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-897b9b91-6b13-4dd2-8a11-18428d281de1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-897b9b91-6b13-4dd2-8a11-18428d281de1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4de5748a-6ef2-4261-8965-428814b5faad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4de5748a-6ef2-4261-8965-428814b5faad')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4de5748a-6ef2-4261-8965-428814b5faad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 47571,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 47541,\n        \"samples\": [\n          \"Tuesday , Britain , the United States , China , Russia and France said the IAEA should refer Iran to the United Nations Security Council for allegedly violating a key nuclear treaty with its atomic program .\",\n          \"The 2008 municipal elections were marred by widespread irregularities .\",\n          \"Israeli warplanes have dropped leaflets warning Gaza residents to stay clear of the border , after Palestinian militants fired at least 10 mortar shells at Israel .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_labels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33040,\n        \"samples\": [\n          \"O,B-geo,O,O,O,O,O,B-geo,B-tim,O,O,O,O,O,O,O\",\n          \"O,O,O,B-gpe,O,B-tim,O,O,O,O,O,O,B-org,O,O,O,O\",\n          \"O,B-geo,I-geo,O,O,O,O,O,O,O,O,O,O,B-geo,I-geo,O,B-geo,I-geo,O,O,O,O,O,O,B-org,I-org,O,O,O,O,O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data = data[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44849c60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44849c60",
        "outputId": "6d3c95b6-a624-4492-a9a4-72978dc6d802"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47571"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c11a364",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "1c11a364",
        "outputId": "5c5b8231-8b38-4acd-d92f-acd62e56ac63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bedfordshire police said Tuesday that Omar Khayam was arrested in Bedford for breaching the conditions of his parole .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "data.iloc[41].sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4a449a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d4a449a6",
        "outputId": "b47f7d72-ae8f-4fb0-925a-5e0396830269"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'B-gpe,O,O,B-tim,O,B-per,I-per,O,O,O,B-geo,O,O,O,O,O,O,O,O'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "data.iloc[41].word_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b1ea60b",
      "metadata": {
        "id": "0b1ea60b"
      },
      "source": [
        "# Data preparing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4905bf7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "4905bf7d",
        "outputId": "a4389481-0bc4-4d31-a06d-962688b17d25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (47571, 2)\n",
            "TRAIN Dataset: (31873, 2)\n",
            "TEST Dataset: (7611, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected input batch_size (1) to match target batch_size (128).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-22f3ca77e28d>\u001b[0m in \u001b[0;36m<cell line: 155>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0minitial_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0minitial_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1597\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"single_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multi_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (128)."
          ]
        }
      ],
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 5e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenization\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "# Bert imput\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        sentence = self.data.sentence[index]\n",
        "        word_labels = self.data.word_labels[index]\n",
        "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# define training size 80/20 split\n",
        "\n",
        "train_size = 0.67\n",
        "# Assuming you want the test size to be 16% of the original data.\n",
        "test_size = 0.16\n",
        "\n",
        "# Sampling the training dataset\n",
        "train_dataset = data.sample(frac=train_size, random_state=200)\n",
        "\n",
        "# Calculating the fraction of the remaining data to sample for the test dataset to make it 16% of the original data\n",
        "remaining_size = test_size / (1 - train_size)\n",
        "test_dataset = data.drop(train_dataset.index).sample(frac=remaining_size, random_state=200)\n",
        "\n",
        "# Resetting the index\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "test_dataset = test_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(data.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "# pyTorch dataloaders\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = len(id2label),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d7c632e",
      "metadata": {
        "id": "7d7c632e"
      },
      "source": [
        "# Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9efa25b",
      "metadata": {
        "id": "f9efa25b"
      },
      "outputs": [],
      "source": [
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "    print(f\"Training steps: {nb_tr_steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d46c2d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d46c2d4",
        "outputId": "c7e6b740-0e52-4211-e24e-9dd8b92668e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training loss per 100 training steps: 2.356534242630005\n",
            "Training loss per 100 training steps: 0.20436748220483855\n",
            "Training loss per 100 training steps: 0.13285900612560966\n",
            "Training loss per 100 training steps: 0.10717547164171735\n",
            "Training loss per 100 training steps: 0.09095046109522222\n",
            "Training loss per 100 training steps: 0.08243987394939223\n",
            "Training loss per 100 training steps: 0.07437837078505678\n",
            "Training loss per 100 training steps: 0.06881866983560508\n",
            "Training loss per 100 training steps: 0.06427143399630407\n",
            "Training loss per 100 training steps: 0.06088531448544064\n",
            "Training loss per 100 training steps: 0.05843555003978669\n",
            "Training loss per 100 training steps: 0.05622111530517728\n",
            "Training loss per 100 training steps: 0.05443755926855713\n",
            "Training loss per 100 training steps: 0.053139307071328835\n",
            "Training loss per 100 training steps: 0.05172939822458324\n",
            "Training loss per 100 training steps: 0.05093435063884642\n",
            "Training loss per 100 training steps: 0.049884864174208836\n",
            "Training loss per 100 training steps: 0.049176809621338614\n",
            "Training loss per 100 training steps: 0.04824830471339694\n",
            "Training loss per 100 training steps: 0.04741782512360726\n",
            "Training loss per 100 training steps: 0.0466866228121055\n",
            "Training loss per 100 training steps: 0.04624498796688951\n",
            "Training loss per 100 training steps: 0.0456385236204488\n",
            "Training loss per 100 training steps: 0.04508700345088159\n",
            "Training loss per 100 training steps: 0.044723542557050064\n",
            "Training loss per 100 training steps: 0.04436517010466838\n",
            "Training loss per 100 training steps: 0.043888319245299165\n",
            "Training loss per 100 training steps: 0.04354351998285002\n",
            "Training loss per 100 training steps: 0.043055859673814\n",
            "Training loss per 100 training steps: 0.04253970807657318\n",
            "Training loss per 100 training steps: 0.04217612460984217\n",
            "Training loss per 100 training steps: 0.041794509133464434\n",
            "Training loss per 100 training steps: 0.04140211252640902\n",
            "Training loss per 100 training steps: 0.041227173376609076\n",
            "Training loss per 100 training steps: 0.040833339343914477\n",
            "Training loss per 100 training steps: 0.04056577197886496\n",
            "Training loss per 100 training steps: 0.040256872234204065\n",
            "Training loss per 100 training steps: 0.04005311369904176\n",
            "Training loss per 100 training steps: 0.039785162818065475\n",
            "Training loss per 100 training steps: 0.03954012618936783\n",
            "Training loss per 100 training steps: 0.0393317960388199\n",
            "Training loss per 100 training steps: 0.03909405859803273\n",
            "Training loss per 100 training steps: 0.03894464700365761\n",
            "Training loss per 100 training steps: 0.038846511339360436\n",
            "Training loss per 100 training steps: 0.03860573527486156\n",
            "Training loss per 100 training steps: 0.03835361464513263\n",
            "Training loss per 100 training steps: 0.03816688279921007\n",
            "Training loss per 100 training steps: 0.037986222422239514\n",
            "Training loss per 100 training steps: 0.037918845820794744\n",
            "Training loss per 100 training steps: 0.037764881542425896\n",
            "Training loss per 100 training steps: 0.037605062317990476\n",
            "Training loss per 100 training steps: 0.037416130091070116\n",
            "Training loss per 100 training steps: 0.03717117544105777\n",
            "Training loss per 100 training steps: 0.03701512168598793\n",
            "Training loss per 100 training steps: 0.036837784690675564\n",
            "Training loss per 100 training steps: 0.03677035517828336\n",
            "Training loss per 100 training steps: 0.03660876763227435\n",
            "Training loss per 100 training steps: 0.036545715292986475\n",
            "Training loss per 100 training steps: 0.03642491143862141\n",
            "Training loss per 100 training steps: 0.03633636798528981\n",
            "Training loss per 100 training steps: 0.03617513004612404\n",
            "Training loss per 100 training steps: 0.03612014237585737\n",
            "Training loss per 100 training steps: 0.0359945095350037\n",
            "Training loss per 100 training steps: 0.035889728506978066\n",
            "Training loss per 100 training steps: 0.0358013664603832\n",
            "Training loss per 100 training steps: 0.03566617419381336\n",
            "Training loss per 100 training steps: 0.03548961197514997\n",
            "Training loss per 100 training steps: 0.0353690365238412\n",
            "Training loss per 100 training steps: 0.035311867652366685\n",
            "Training loss per 100 training steps: 0.03522458062131279\n",
            "Training loss per 100 training steps: 0.035098680534698425\n",
            "Training loss per 100 training steps: 0.035024232690553006\n",
            "Training loss per 100 training steps: 0.034949581463987876\n",
            "Training loss per 100 training steps: 0.0348201644510787\n",
            "Training loss per 100 training steps: 0.03466195329413171\n",
            "Training loss per 100 training steps: 0.03455156544938588\n",
            "Training loss per 100 training steps: 0.03444963615428602\n",
            "Training loss per 100 training steps: 0.03435817004843021\n",
            "Training loss per 100 training steps: 0.03425009436990595\n",
            "Training loss per 100 training steps: 0.03415320332213446\n",
            "Training loss epoch: 0.03410383247449595\n",
            "Training accuracy epoch: 0.952469959465756\n",
            "Training steps: 7969\n",
            "CPU times: user 6min 47s, sys: 2.63 s, total: 6min 50s\n",
            "Wall time: 6min 49s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e097d3",
      "metadata": {
        "id": "b9e097d3"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "    print(f\"Validation steps: {nb_eval_steps}\")\n",
        "\n",
        "    return labels, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a520c16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a520c16",
        "outputId": "f7fec306-02f1-45b4-a551-3333470ef8bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss per 100 evaluation steps: 0.007320071570575237\n",
            "Validation loss per 100 evaluation steps: 0.022557114784336085\n",
            "Validation loss per 100 evaluation steps: 0.026875264322850274\n",
            "Validation loss per 100 evaluation steps: 0.02766272579384558\n",
            "Validation loss per 100 evaluation steps: 0.02777646027566436\n",
            "Validation loss per 100 evaluation steps: 0.02788042495682863\n",
            "Validation loss per 100 evaluation steps: 0.026944029003152386\n",
            "Validation loss per 100 evaluation steps: 0.027394579181205744\n",
            "Validation loss per 100 evaluation steps: 0.026676354528700607\n",
            "Validation loss per 100 evaluation steps: 0.027402685065230793\n",
            "Validation loss per 100 evaluation steps: 0.027180171160474963\n",
            "Validation loss per 100 evaluation steps: 0.027029797536630578\n",
            "Validation loss per 100 evaluation steps: 0.02701576997605571\n",
            "Validation loss per 100 evaluation steps: 0.02646177578597677\n",
            "Validation loss per 100 evaluation steps: 0.026188371785442793\n",
            "Validation loss per 100 evaluation steps: 0.026422728387680266\n",
            "Validation loss per 100 evaluation steps: 0.026631535287664113\n",
            "Validation loss per 100 evaluation steps: 0.02667249283068908\n",
            "Validation loss per 100 evaluation steps: 0.02651796027952098\n",
            "Validation loss per 100 evaluation steps: 0.02648403425247411\n",
            "Validation loss per 100 evaluation steps: 0.026361134132484934\n",
            "Validation loss per 100 evaluation steps: 0.026089118359975613\n",
            "Validation loss per 100 evaluation steps: 0.0259994653712603\n",
            "Validation loss per 100 evaluation steps: 0.02598519063656928\n",
            "Validation loss per 100 evaluation steps: 0.026190479558837687\n",
            "Validation loss per 100 evaluation steps: 0.026172299026729337\n",
            "Validation loss per 100 evaluation steps: 0.026205307877414666\n",
            "Validation loss per 100 evaluation steps: 0.02607691515658048\n",
            "Validation loss per 100 evaluation steps: 0.02596328835344401\n",
            "Validation loss per 100 evaluation steps: 0.02605147385694576\n",
            "Validation loss per 100 evaluation steps: 0.02597976455116717\n",
            "Validation loss per 100 evaluation steps: 0.026030023790104353\n",
            "Validation loss per 100 evaluation steps: 0.026171098833991765\n",
            "Validation loss per 100 evaluation steps: 0.02603320457051363\n",
            "Validation loss per 100 evaluation steps: 0.0259901179391012\n",
            "Validation loss per 100 evaluation steps: 0.02616103339798228\n",
            "Validation loss per 100 evaluation steps: 0.02624384660776973\n",
            "Validation loss per 100 evaluation steps: 0.026355499299719008\n",
            "Validation loss per 100 evaluation steps: 0.026386523498097118\n",
            "Validation Loss: 0.02636871699719218\n",
            "Validation Accuracy: 0.9616018482567734\n",
            "Validation steps: 3806\n",
            "CPU times: user 1min, sys: 144 ms, total: 1min\n",
            "Wall time: 1min\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "labels, predictions = valid(model, testing_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92b96e45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92b96e45",
        "outputId": "bdec95ee-9e9e-4301-f17f-be903210d6fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-geo       0.86      0.85      0.85      9043\n",
            "       B-gpe       0.94      0.92      0.93      2621\n",
            "       B-org       0.73      0.68      0.71      5267\n",
            "       B-per       0.81      0.86      0.83      4217\n",
            "       B-tim       0.91      0.85      0.88      3490\n",
            "       I-geo       0.80      0.69      0.75      1480\n",
            "       I-gpe       0.83      0.57      0.68        42\n",
            "       I-org       0.77      0.62      0.69      3196\n",
            "       I-per       0.82      0.94      0.88      5081\n",
            "       I-tim       0.86      0.67      0.76      1167\n",
            "           O       0.99      0.99      0.99    165562\n",
            "\n",
            "    accuracy                           0.96    201166\n",
            "   macro avg       0.85      0.79      0.81    201166\n",
            "weighted avg       0.96      0.96      0.96    201166\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(labels, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffdcb88c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffdcb88c",
        "outputId": "f4b3745c-98c8-4b98-cc50-a5355cfae56d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9596800652197688, 0.9596800652197688, 0.9596800652197688, None)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision_recall_fscore_support(labels, predictions, average = \"micro\", zero_division = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e94b9fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e94b9fc",
        "outputId": "05cbacd3-ef04-48bb-c9f2-e7426a16a03b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8464737196713131, 0.7867527296514208, 0.8117985982569711, None)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"macro\", zero_division = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11b33051",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11b33051",
        "outputId": "eeb6d457-5a92-4f1c-c052-8aa3d04be1b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9589109271187543, 0.9596800652197688, 0.9589137729347816, None)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"weighted\", zero_division = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9910bf9f",
      "metadata": {
        "id": "9910bf9f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "955c0d17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "955c0d17",
        "outputId": "da636fe3-b434-4973-d3c7-a625cc9b00c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "india has a capital called mumbai . on wednesday , the president will give a presentation\n",
            "['B-geo', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "sentence = \"India has a capital called Mumbai. On Wednesday, the president will give a presentation\"\n",
        "\n",
        "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "\n",
        "# move to gpu\n",
        "ids = inputs[\"input_ids\"].to(device)\n",
        "mask = inputs[\"attention_mask\"].to(device)\n",
        "# forward pass\n",
        "outputs = model(ids, mask)\n",
        "logits = outputs[0]\n",
        "\n",
        "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
        "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "word_level_predictions = []\n",
        "for pair in wp_preds:\n",
        "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
        "    # skip prediction\n",
        "    continue\n",
        "  else:\n",
        "    word_level_predictions.append(pair[1])\n",
        "\n",
        "# we join tokens, if they are not special ones\n",
        "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
        "print(str_rep)\n",
        "print(word_level_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e09cf3f",
      "metadata": {
        "id": "6e09cf3f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a28eb627",
      "metadata": {
        "id": "a28eb627"
      },
      "outputs": [],
      "source": [
        "# L1 loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d582914",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d582914",
        "outputId": "4f0c101b-fb8f-4400-aaa2-6411a4ca74a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (47571, 2)\n",
            "TRAIN Dataset: (31873, 2)\n",
            "TEST Dataset: (7611, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 5e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenization\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "# Bert imput\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        sentence = self.data.sentence[index]\n",
        "        word_labels = self.data.word_labels[index]\n",
        "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# define training size 80/20 split\n",
        "\n",
        "train_size = 0.67\n",
        "# Assuming you want the test size to be 16% of the original data.\n",
        "test_size = 0.16\n",
        "\n",
        "# Sampling the training dataset\n",
        "train_dataset = data.sample(frac=train_size, random_state=200)\n",
        "\n",
        "# Calculating the fraction of the remaining data to sample for the test dataset to make it 16% of the original data\n",
        "remaining_size = test_size / (1 - train_size)\n",
        "test_dataset = data.drop(train_dataset.index).sample(frac=remaining_size, random_state=200)\n",
        "\n",
        "# Resetting the index\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "test_dataset = test_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(data.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "# pyTorch dataloaders\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id)\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66fefe2b",
      "metadata": {
        "id": "66fefe2b"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(targets, num_classes):\n",
        "    \"\"\"\n",
        "    One-hot encode a tensor of class indices.\n",
        "\n",
        "    Arguments:\n",
        "    - targets (torch.Tensor): A tensor of class indices, shape [N].\n",
        "    - num_classes (int): The number of classes.\n",
        "\n",
        "    Returns:\n",
        "    - torch.Tensor: The one-hot encoded tensor, shape [N, num_classes].\n",
        "    \"\"\"\n",
        "    return F.one_hot(targets, num_classes=num_classes).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db7e09f",
      "metadata": {
        "id": "4db7e09f"
      },
      "outputs": [],
      "source": [
        "l1_loss_fn = nn.L1Loss()\n",
        "\n",
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "\n",
        "        # implement l1 loss function\n",
        "        flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        flatten_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "\n",
        "        targets_one_hot = one_hot_encode(flatten_targets, num_classes= flatten_logits.size(-1))\n",
        "        loss = l1_loss_fn(flatten_logits, targets_one_hot)\n",
        "\n",
        "\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training l1 loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "    print(f\"Training steps: {nb_tr_steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9792cf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9792cf7",
        "outputId": "c91a80fb-a34f-44dc-8956-14366c99b1a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training l1 loss per 100 training steps: 0.2722763121128082\n",
            "Training l1 loss per 100 training steps: 0.046339708039223555\n",
            "Training l1 loss per 100 training steps: 0.03732629420597162\n",
            "Training l1 loss per 100 training steps: 0.03317789086125222\n",
            "Training l1 loss per 100 training steps: 0.030743303553124615\n",
            "Training l1 loss per 100 training steps: 0.02857397364530556\n",
            "Training l1 loss per 100 training steps: 0.026843529059776352\n",
            "Training l1 loss per 100 training steps: 0.025503173283169766\n",
            "Training l1 loss per 100 training steps: 0.024300403120961232\n",
            "Training l1 loss per 100 training steps: 0.02328394136735787\n",
            "Training l1 loss per 100 training steps: 0.02242362487141962\n",
            "Training l1 loss per 100 training steps: 0.021643675187878398\n",
            "Training l1 loss per 100 training steps: 0.020935147878195125\n",
            "Training l1 loss per 100 training steps: 0.020305170481459026\n",
            "Training l1 loss per 100 training steps: 0.01977430874525671\n",
            "Training l1 loss per 100 training steps: 0.019260121093098718\n",
            "Training l1 loss per 100 training steps: 0.018755783364153483\n",
            "Training l1 loss per 100 training steps: 0.01834088843589597\n",
            "Training l1 loss per 100 training steps: 0.01792839653676232\n",
            "Training l1 loss per 100 training steps: 0.01756777664865007\n",
            "Training l1 loss per 100 training steps: 0.01721330677372762\n",
            "Training l1 loss per 100 training steps: 0.016909450648537792\n",
            "Training l1 loss per 100 training steps: 0.016609713427345015\n",
            "Training l1 loss per 100 training steps: 0.01632066864640926\n",
            "Training l1 loss per 100 training steps: 0.016060330299136914\n",
            "Training l1 loss per 100 training steps: 0.015781307444222174\n",
            "Training l1 loss per 100 training steps: 0.01552766347475857\n",
            "Training l1 loss per 100 training steps: 0.015286001817298096\n",
            "Training l1 loss per 100 training steps: 0.015063838540818789\n",
            "Training l1 loss per 100 training steps: 0.014847852971234\n",
            "Training l1 loss per 100 training steps: 0.014629037818172869\n",
            "Training l1 loss per 100 training steps: 0.01442307438830533\n",
            "Training l1 loss per 100 training steps: 0.01422358158133838\n",
            "Training l1 loss per 100 training steps: 0.014044932396848278\n",
            "Training l1 loss per 100 training steps: 0.013864462262102214\n",
            "Training l1 loss per 100 training steps: 0.013693443809281338\n",
            "Training l1 loss per 100 training steps: 0.01353209416188819\n",
            "Training l1 loss per 100 training steps: 0.013367168506684415\n",
            "Training l1 loss per 100 training steps: 0.01321157399391997\n",
            "Training l1 loss per 100 training steps: 0.013054356939056436\n",
            "Training l1 loss per 100 training steps: 0.012911446288370492\n",
            "Training l1 loss per 100 training steps: 0.01277094328936332\n",
            "Training l1 loss per 100 training steps: 0.012642927026547717\n",
            "Training l1 loss per 100 training steps: 0.012512047349487666\n",
            "Training l1 loss per 100 training steps: 0.012397641834198338\n",
            "Training l1 loss per 100 training steps: 0.012265806285930532\n",
            "Training l1 loss per 100 training steps: 0.012144107797353735\n",
            "Training l1 loss per 100 training steps: 0.012027279120013895\n",
            "Training l1 loss per 100 training steps: 0.01191241254456228\n",
            "Training l1 loss per 100 training steps: 0.011800285804540928\n",
            "Training l1 loss per 100 training steps: 0.011694000077904481\n",
            "Training l1 loss per 100 training steps: 0.011588889532926106\n",
            "Training l1 loss per 100 training steps: 0.011487666448466143\n",
            "Training l1 loss per 100 training steps: 0.011394788463793413\n",
            "Training l1 loss per 100 training steps: 0.01130193985054203\n",
            "Training l1 loss per 100 training steps: 0.011207633368680083\n",
            "Training l1 loss per 100 training steps: 0.011118389450709011\n",
            "Training l1 loss per 100 training steps: 0.011028873205416583\n",
            "Training l1 loss per 100 training steps: 0.010945544254596346\n",
            "Training l1 loss per 100 training steps: 0.010862920672347565\n",
            "Training l1 loss per 100 training steps: 0.010783211978936438\n",
            "Training l1 loss per 100 training steps: 0.010700668627670997\n",
            "Training l1 loss per 100 training steps: 0.010628841199876535\n",
            "Training l1 loss per 100 training steps: 0.010551328271492333\n",
            "Training l1 loss per 100 training steps: 0.01047661972842957\n",
            "Training l1 loss per 100 training steps: 0.010401597113189956\n",
            "Training l1 loss per 100 training steps: 0.010330678310587838\n",
            "Training l1 loss per 100 training steps: 0.010258962579128226\n",
            "Training l1 loss per 100 training steps: 0.010190379923767437\n",
            "Training l1 loss per 100 training steps: 0.010134705151627621\n",
            "Training l1 loss per 100 training steps: 0.010067916207353138\n",
            "Training l1 loss per 100 training steps: 0.010002423456888775\n",
            "Training l1 loss per 100 training steps: 0.009939683726033613\n",
            "Training l1 loss per 100 training steps: 0.009873001757598959\n",
            "Training l1 loss per 100 training steps: 0.009808918728702421\n",
            "Training l1 loss per 100 training steps: 0.009744484784408616\n",
            "Training l1 loss per 100 training steps: 0.009688491066694779\n",
            "Training l1 loss per 100 training steps: 0.009629683192360287\n",
            "Training l1 loss per 100 training steps: 0.009573954132370867\n",
            "Training l1 loss per 100 training steps: 0.009513957397514853\n",
            "Training loss epoch: 0.009475833009323087\n",
            "Training accuracy epoch: 0.9110442883617255\n",
            "Training steps: 7969\n",
            "CPU times: user 6min 52s, sys: 1.57 s, total: 6min 53s\n",
            "Wall time: 6min 52s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e363015",
      "metadata": {
        "id": "0e363015"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "\n",
        "            # implement l1 loss\n",
        "            flatten_targets = targets.view(-1)\n",
        "            flatten_logits = eval_logits.view(-1, model.num_labels)\n",
        "            targets_one_hot = one_hot_encode(flatten_targets, num_classes= flatten_logits.size(-1))\n",
        "            loss = l1_loss_fn(flatten_logits, targets_one_hot)\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation l1 loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "    print(f\"Validation steps: {nb_eval_steps}\")\n",
        "\n",
        "    return labels, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f817764b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f817764b",
        "outputId": "04fd29cf-9f17-4df9-bbaa-c50d8b61fb37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation l1 loss per 100 evaluation steps: 0.004247431177645922\n",
            "Validation l1 loss per 100 evaluation steps: 0.003968594482832468\n",
            "Validation l1 loss per 100 evaluation steps: 0.003668451207963314\n",
            "Validation l1 loss per 100 evaluation steps: 0.0036079767674510907\n",
            "Validation l1 loss per 100 evaluation steps: 0.0035405918439627253\n",
            "Validation l1 loss per 100 evaluation steps: 0.003527944594781526\n",
            "Validation l1 loss per 100 evaluation steps: 0.003418208921201118\n",
            "Validation l1 loss per 100 evaluation steps: 0.0034045027884470032\n",
            "Validation l1 loss per 100 evaluation steps: 0.003410811207115362\n",
            "Validation l1 loss per 100 evaluation steps: 0.003384260590587196\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033400571683177968\n",
            "Validation l1 loss per 100 evaluation steps: 0.003339824093747664\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033600888332099245\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033712405355276393\n",
            "Validation l1 loss per 100 evaluation steps: 0.003350151277982831\n",
            "Validation l1 loss per 100 evaluation steps: 0.003341966401258214\n",
            "Validation l1 loss per 100 evaluation steps: 0.003355414241460442\n",
            "Validation l1 loss per 100 evaluation steps: 0.003350023103115214\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033525919757223894\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033527570603335026\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033623884976103804\n",
            "Validation l1 loss per 100 evaluation steps: 0.003365036469952038\n",
            "Validation l1 loss per 100 evaluation steps: 0.003358719450221065\n",
            "Validation l1 loss per 100 evaluation steps: 0.003369767526688798\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033769905142915103\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033648414482850015\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033705108918991515\n",
            "Validation l1 loss per 100 evaluation steps: 0.003370071118547533\n",
            "Validation l1 loss per 100 evaluation steps: 0.003365029404418638\n",
            "Validation l1 loss per 100 evaluation steps: 0.003363077073226054\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033696705114449567\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033765259319051416\n",
            "Validation l1 loss per 100 evaluation steps: 0.003375790257468617\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033809078517120237\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033823842195694308\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033747021434270006\n",
            "Validation l1 loss per 100 evaluation steps: 0.00337176052525653\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033638014867224887\n",
            "Validation l1 loss per 100 evaluation steps: 0.0033665718609673947\n",
            "Validation Loss: 0.0033656880753498994\n",
            "Validation Accuracy: 0.9465381437473456\n",
            "Validation steps: 3806\n",
            "CPU times: user 1min 1s, sys: 135 ms, total: 1min 1s\n",
            "Wall time: 1min 1s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "labels, predictions = valid(model, testing_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "889fd862",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "889fd862",
        "outputId": "75addb81-b5c8-4531-bede-be05b0055734",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-geo       0.77      0.87      0.82      9043\n",
            "       B-gpe       0.93      0.89      0.91      2621\n",
            "       B-org       0.66      0.50      0.57      5267\n",
            "       B-per       0.87      0.71      0.79      4217\n",
            "       B-tim       0.87      0.76      0.82      3490\n",
            "       I-geo       0.90      0.35      0.50      1480\n",
            "       I-gpe       0.00      0.00      0.00        42\n",
            "       I-org       0.55      0.38      0.45      3196\n",
            "       I-per       0.77      0.94      0.85      5081\n",
            "       I-tim       0.88      0.37      0.52      1167\n",
            "           O       0.98      0.99      0.98    165562\n",
            "\n",
            "    accuracy                           0.94    201166\n",
            "   macro avg       0.74      0.62      0.66    201166\n",
            "weighted avg       0.94      0.94      0.94    201166\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "print(classification_report(labels, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3abf94dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3abf94dd",
        "outputId": "74a1edf5-373d-4d3c-b150-bd9bf8a48a75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9444339500710855, 0.9444339500710855, 0.9444339500710855, None)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision_recall_fscore_support(labels, predictions, average = \"micro\", zero_division = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36819f3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36819f3d",
        "outputId": "5f54cf69-d91b-40ec-eb1c-fb365204661c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8358588313802927, 0.6165839132176685, 0.6560400105045726, None)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"macro\", zero_division = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02efda06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02efda06",
        "outputId": "365dd390-468a-41bd-e474-d5119cf70e9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9413208248674939, 0.9444339500710855, 0.9401164288094006, None)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"weighted\", zero_division = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79a50260",
      "metadata": {
        "id": "79a50260"
      },
      "outputs": [],
      "source": [
        "# L2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 5e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenization\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "# Bert imput\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        sentence = self.data.sentence[index]\n",
        "        word_labels = self.data.word_labels[index]\n",
        "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# define training size 80/20 split\n",
        "\n",
        "train_size = 0.67\n",
        "# Assuming you want the test size to be 16% of the original data.\n",
        "test_size = 0.16\n",
        "\n",
        "# Sampling the training dataset\n",
        "train_dataset = data.sample(frac=train_size, random_state=200)\n",
        "\n",
        "# Calculating the fraction of the remaining data to sample for the test dataset to make it 16% of the original data\n",
        "remaining_size = test_size / (1 - train_size)\n",
        "test_dataset = data.drop(train_dataset.index).sample(frac=remaining_size, random_state=200)\n",
        "\n",
        "# Resetting the index\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "test_dataset = test_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(data.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "# pyTorch dataloaders\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id)\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INjzam-_NKWK",
        "outputId": "46dda188-c7f9-4601-cb00-f0b3205d53f4"
      },
      "id": "INjzam-_NKWK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (47571, 2)\n",
            "TRAIN Dataset: (31873, 2)\n",
            "TEST Dataset: (7611, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(targets, num_classes):\n",
        "    \"\"\"\n",
        "    One-hot encode a tensor of class indices.\n",
        "\n",
        "    Arguments:\n",
        "    - targets (torch.Tensor): A tensor of class indices, shape [N].\n",
        "    - num_classes (int): The number of classes.\n",
        "\n",
        "    Returns:\n",
        "    - torch.Tensor: The one-hot encoded tensor, shape [N, num_classes].\n",
        "    \"\"\"\n",
        "    return F.one_hot(targets, num_classes=num_classes).float()"
      ],
      "metadata": {
        "id": "1Zd1hFE7NKYM"
      },
      "id": "1Zd1hFE7NKYM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l2_loss_fn = nn.MSELoss()\n",
        "\n",
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "\n",
        "        # implement l2 loss function\n",
        "        flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        flatten_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "\n",
        "        targets_one_hot = one_hot_encode(flatten_targets, num_classes= flatten_logits.size(-1))\n",
        "        loss = l2_loss_fn(flatten_logits, targets_one_hot)\n",
        "\n",
        "\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training l1 loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "    print(f\"Training steps: {nb_tr_steps}\")"
      ],
      "metadata": {
        "id": "EXAZXC7pNKb1"
      },
      "id": "EXAZXC7pNKb1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrdwgZ7xNKed",
        "outputId": "4ea5087a-f746-4415-998f-4221982db1ae"
      },
      "id": "jrdwgZ7xNKed",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training l1 loss per 100 training steps: 0.13172855973243713\n",
            "Training l1 loss per 100 training steps: 0.011672269223294783\n",
            "Training l1 loss per 100 training steps: 0.008226406106039585\n",
            "Training l1 loss per 100 training steps: 0.006777837904219661\n",
            "Training l1 loss per 100 training steps: 0.00582480041511668\n",
            "Training l1 loss per 100 training steps: 0.005244258865681542\n",
            "Training l1 loss per 100 training steps: 0.004785078442105388\n",
            "Training l1 loss per 100 training steps: 0.004439810504166997\n",
            "Training l1 loss per 100 training steps: 0.004157101918743242\n",
            "Training l1 loss per 100 training steps: 0.003934241678192591\n",
            "Training l1 loss per 100 training steps: 0.0037268051562680082\n",
            "Training l1 loss per 100 training steps: 0.0035577330959664336\n",
            "Training l1 loss per 100 training steps: 0.0034310623709367144\n",
            "Training l1 loss per 100 training steps: 0.003321380045238652\n",
            "Training l1 loss per 100 training steps: 0.0032098369553986324\n",
            "Training l1 loss per 100 training steps: 0.003109501107333868\n",
            "Training l1 loss per 100 training steps: 0.003028695832974022\n",
            "Training l1 loss per 100 training steps: 0.0029454304247461907\n",
            "Training l1 loss per 100 training steps: 0.0028708213482778375\n",
            "Training l1 loss per 100 training steps: 0.0028092759643739648\n",
            "Training l1 loss per 100 training steps: 0.0027565426159986825\n",
            "Training l1 loss per 100 training steps: 0.0027125573029204396\n",
            "Training l1 loss per 100 training steps: 0.002656487413907998\n",
            "Training l1 loss per 100 training steps: 0.002615224151464417\n",
            "Training l1 loss per 100 training steps: 0.002566623181119303\n",
            "Training l1 loss per 100 training steps: 0.0025214480796907253\n",
            "Training l1 loss per 100 training steps: 0.002489615931340895\n",
            "Training l1 loss per 100 training steps: 0.0024565199880282507\n",
            "Training l1 loss per 100 training steps: 0.00243267312961098\n",
            "Training l1 loss per 100 training steps: 0.002401580509713792\n",
            "Training l1 loss per 100 training steps: 0.002377328082080783\n",
            "Training l1 loss per 100 training steps: 0.0023447003761907516\n",
            "Training l1 loss per 100 training steps: 0.0023173453184031256\n",
            "Training l1 loss per 100 training steps: 0.002295386708673469\n",
            "Training l1 loss per 100 training steps: 0.0022676891142014172\n",
            "Training l1 loss per 100 training steps: 0.0022473101081530505\n",
            "Training l1 loss per 100 training steps: 0.0022267853192212985\n",
            "Training l1 loss per 100 training steps: 0.002206064429655436\n",
            "Training l1 loss per 100 training steps: 0.002188194218390806\n",
            "Training l1 loss per 100 training steps: 0.0021683728408467234\n",
            "Training l1 loss per 100 training steps: 0.002150958396408961\n",
            "Training l1 loss per 100 training steps: 0.0021301557337915196\n",
            "Training l1 loss per 100 training steps: 0.0021113238309117825\n",
            "Training l1 loss per 100 training steps: 0.0020979843187149193\n",
            "Training l1 loss per 100 training steps: 0.0020818570859985927\n",
            "Training l1 loss per 100 training steps: 0.002065471220540061\n",
            "Training l1 loss per 100 training steps: 0.0020517654105269402\n",
            "Training l1 loss per 100 training steps: 0.00204201309452101\n",
            "Training l1 loss per 100 training steps: 0.0020291569485964443\n",
            "Training l1 loss per 100 training steps: 0.0020164231571055424\n",
            "Training l1 loss per 100 training steps: 0.002004544240398407\n",
            "Training l1 loss per 100 training steps: 0.001994383356761104\n",
            "Training l1 loss per 100 training steps: 0.001982751204151598\n",
            "Training l1 loss per 100 training steps: 0.001973620419072625\n",
            "Training l1 loss per 100 training steps: 0.0019597128496265507\n",
            "Training l1 loss per 100 training steps: 0.0019470454290830218\n",
            "Training l1 loss per 100 training steps: 0.0019344882932136598\n",
            "Training l1 loss per 100 training steps: 0.0019242773213501956\n",
            "Training l1 loss per 100 training steps: 0.001915598556490826\n",
            "Training l1 loss per 100 training steps: 0.0019059841548183275\n",
            "Training l1 loss per 100 training steps: 0.001896156834443361\n",
            "Training l1 loss per 100 training steps: 0.0018885346878982922\n",
            "Training l1 loss per 100 training steps: 0.0018795117390953476\n",
            "Training l1 loss per 100 training steps: 0.0018715436689288227\n",
            "Training l1 loss per 100 training steps: 0.0018624578689759826\n",
            "Training l1 loss per 100 training steps: 0.0018564350369710211\n",
            "Training l1 loss per 100 training steps: 0.0018498767046997067\n",
            "Training l1 loss per 100 training steps: 0.0018440181035075734\n",
            "Training l1 loss per 100 training steps: 0.0018378454713892675\n",
            "Training l1 loss per 100 training steps: 0.0018279432269025925\n",
            "Training l1 loss per 100 training steps: 0.0018194674574435056\n",
            "Training l1 loss per 100 training steps: 0.0018130380324384166\n",
            "Training l1 loss per 100 training steps: 0.0018070245889719176\n",
            "Training l1 loss per 100 training steps: 0.0017999451026881996\n",
            "Training l1 loss per 100 training steps: 0.001791939162482873\n",
            "Training l1 loss per 100 training steps: 0.0017868244191872158\n",
            "Training l1 loss per 100 training steps: 0.0017838014337257816\n",
            "Training l1 loss per 100 training steps: 0.0017781192231630602\n",
            "Training l1 loss per 100 training steps: 0.001771342074444475\n",
            "Training l1 loss per 100 training steps: 0.0017670536920709671\n",
            "Training loss epoch: 0.0017640905006386382\n",
            "Training accuracy epoch: 0.952405565001366\n",
            "Training steps: 7969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "\n",
        "            # implement l2 loss\n",
        "            flatten_targets = targets.view(-1)\n",
        "            flatten_logits = eval_logits.view(-1, model.num_labels)\n",
        "            targets_one_hot = one_hot_encode(flatten_targets, num_classes= flatten_logits.size(-1))\n",
        "            loss = l2_loss_fn(flatten_logits, targets_one_hot)\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation l1 loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "    print(f\"Validation steps: {nb_eval_steps}\")\n",
        "\n",
        "    return labels, predictions"
      ],
      "metadata": {
        "id": "l0Aiw_GzNKhG"
      },
      "id": "l0Aiw_GzNKhG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels, predictions = valid(model, testing_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gmYAVB6NKjS",
        "outputId": "02e8b227-3533-4305-d016-762a3d7a588a"
      },
      "id": "2gmYAVB6NKjS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation l1 loss per 100 evaluation steps: 0.0005027727456763387\n",
            "Validation l1 loss per 100 evaluation steps: 0.0011153189771353972\n",
            "Validation l1 loss per 100 evaluation steps: 0.0011485325037359129\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012111870857364937\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012096884510267721\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012038972460093015\n",
            "Validation l1 loss per 100 evaluation steps: 0.0011976075846014554\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012157429090998558\n",
            "Validation l1 loss per 100 evaluation steps: 0.0011949459946780361\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012029099854264896\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012050184779307802\n",
            "Validation l1 loss per 100 evaluation steps: 0.001225942654529848\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012221575820146127\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012083133429764883\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012098693134338192\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012245200341555278\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012273025584614585\n",
            "Validation l1 loss per 100 evaluation steps: 0.00121708822760182\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012104334596331906\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012234290074596029\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012166461665360678\n",
            "Validation l1 loss per 100 evaluation steps: 0.001215364331935387\n",
            "Validation l1 loss per 100 evaluation steps: 0.001216276909601591\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012215448271548563\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012198341378520557\n",
            "Validation l1 loss per 100 evaluation steps: 0.001215554964293027\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012030064272616412\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012086901133268365\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012064033747731656\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012004865841988733\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012008544866314217\n",
            "Validation l1 loss per 100 evaluation steps: 0.0011991945965984568\n",
            "Validation l1 loss per 100 evaluation steps: 0.0011984762949913497\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012023087186190345\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012004878032320135\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012001110558016402\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012037970813242084\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012014790816261918\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012032755124735503\n",
            "Validation Loss: 0.001202709140382587\n",
            "Validation Accuracy: 0.960926000319129\n",
            "Validation steps: 3806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(labels, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAWKu9hRNdeE",
        "outputId": "41cd1a86-1f13-45c2-9b46-342b8cf70826"
      },
      "id": "cAWKu9hRNdeE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-geo       0.86      0.85      0.86      9043\n",
            "       B-gpe       0.95      0.91      0.93      2621\n",
            "       B-org       0.76      0.66      0.71      5267\n",
            "       B-per       0.80      0.88      0.84      4217\n",
            "       B-tim       0.90      0.86      0.88      3490\n",
            "       I-geo       0.81      0.71      0.76      1480\n",
            "       I-gpe       0.00      0.00      0.00        42\n",
            "       I-org       0.76      0.59      0.66      3196\n",
            "       I-per       0.82      0.90      0.86      5081\n",
            "       I-tim       0.84      0.68      0.75      1167\n",
            "           O       0.99      0.99      0.99    165562\n",
            "\n",
            "    accuracy                           0.96    201166\n",
            "   macro avg       0.77      0.73      0.75    201166\n",
            "weighted avg       0.96      0.96      0.96    201166\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision_recall_fscore_support(labels, predictions, average = \"micro\", zero_division = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ5iCAiONW8r",
        "outputId": "9910d0f7-c358-4666-8697-ae2f1ac69522"
      },
      "id": "PQ5iCAiONW8r",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9594861954803495, 0.9594861954803495, 0.9594861954803495, None)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"macro\", zero_division = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u0qSjk9NW_4",
        "outputId": "ed987286-8ec6-4c78-8a3a-8b9ba465c664"
      },
      "id": "0u0qSjk9NW_4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8627971343499254, 0.7307845684093661, 0.7485639437013422, None)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"weighted\", zero_division = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5y5Hq_GNXCr",
        "outputId": "67767616-759b-4ce1-f45a-6c6e1c6ef314"
      },
      "id": "u5y5Hq_GNXCr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.958216196187448, 0.9594861954803495, 0.9582972454092761, None)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5MWrs0xKNXFI"
      },
      "id": "5MWrs0xKNXFI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K4rjqWxLNXHT"
      },
      "id": "K4rjqWxLNXHT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X78X4zbENKlj"
      },
      "id": "X78X4zbENKlj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bd307163",
      "metadata": {
        "id": "bd307163"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb278f56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb278f56",
        "outputId": "7762a126-0343-4337-f9aa-6bf573e8d991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "india has a capital called mumbai . on wednesday , the president will give a presentation\n",
            "['B-geo', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "sentence = \"India has a capital called Mumbai. On Wednesday, the president will give a presentation\"\n",
        "\n",
        "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "\n",
        "# move to gpu\n",
        "ids = inputs[\"input_ids\"].to(device)\n",
        "mask = inputs[\"attention_mask\"].to(device)\n",
        "# forward pass\n",
        "outputs = model(ids, mask)\n",
        "logits = outputs[0]\n",
        "\n",
        "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
        "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "word_level_predictions = []\n",
        "for pair in wp_preds:\n",
        "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
        "    # skip prediction\n",
        "    continue\n",
        "  else:\n",
        "    word_level_predictions.append(pair[1])\n",
        "\n",
        "# we join tokens, if they are not special ones\n",
        "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
        "print(str_rep)\n",
        "print(word_level_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5659cba",
      "metadata": {
        "id": "b5659cba"
      },
      "outputs": [],
      "source": [
        "#Dlite loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be6377da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be6377da",
        "outputId": "d60e4dd8-7f04-444f-ede2-4bb5719cda34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (47571, 2)\n",
            "TRAIN Dataset: (31873, 2)\n",
            "TEST Dataset: (7611, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 5e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenization\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "# Bert imput\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        sentence = self.data.sentence[index]\n",
        "        word_labels = self.data.word_labels[index]\n",
        "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# define training size 80/20 split\n",
        "\n",
        "train_size = 0.67\n",
        "# Assuming you want the test size to be 16% of the original data.\n",
        "test_size = 0.16\n",
        "\n",
        "# Sampling the training dataset\n",
        "train_dataset = data.sample(frac=train_size, random_state=200)\n",
        "\n",
        "# Calculating the fraction of the remaining data to sample for the test dataset to make it 16% of the original data\n",
        "remaining_size = test_size / (1 - train_size)\n",
        "test_dataset = data.drop(train_dataset.index).sample(frac=remaining_size, random_state=200)\n",
        "\n",
        "# Resetting the index\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "test_dataset = test_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(data.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "# pyTorch dataloaders\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id)\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a113a92",
      "metadata": {
        "id": "9a113a92"
      },
      "outputs": [],
      "source": [
        "# DLITE Loss function\n",
        "class DLITELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DLITELoss, self).__init__()\n",
        "\n",
        "    def forward(self, logits, targets, epsilon=1e-10):\n",
        "        # Convert logits to probabilities using softmax\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        # One-hot encode the targets to get true probabilities\n",
        "        true_probs = F.one_hot(targets, num_classes=probs.size(-1)).float()\n",
        "\n",
        "        # Define the g function\n",
        "        g_values = torch.abs(probs * (1 - torch.log(probs + epsilon)) - true_probs * (1 - torch.log(true_probs + epsilon)))\n",
        "\n",
        "        # Define the delta_h function\n",
        "        delta_h_values = torch.abs(probs**2 * (1 - 2 * torch.log(probs + epsilon)) - true_probs**2 * (1 - 2 * torch.log(true_probs + epsilon))) / (2 * (probs + true_probs))\n",
        "\n",
        "        # Compute DLITE loss for each class\n",
        "        dl_values = g_values - delta_h_values\n",
        "\n",
        "        # Sum over all classes and average over batch size\n",
        "        loss = dl_values.sum(dim=-1).mean()\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56a99bb4",
      "metadata": {
        "id": "56a99bb4"
      },
      "outputs": [],
      "source": [
        "dlite_loss_fn = DLITELoss()\n",
        "\n",
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        # implement dlite loss function\n",
        "\n",
        "        loss = dlite_loss_fn(active_logits, flattened_targets)\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training dlite loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "    print(f\"Training steps: {nb_tr_steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb554fde",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb554fde",
        "outputId": "a316de80-57d8-4bbc-ded3-9cf03f405502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training dlite loss per 100 training steps: 0.7102293968200684\n",
            "Training dlite loss per 100 training steps: 0.05841915194627525\n",
            "Training dlite loss per 100 training steps: 0.04767701397904783\n",
            "Training dlite loss per 100 training steps: 0.04367065262761079\n",
            "Training dlite loss per 100 training steps: 0.04195375494226962\n",
            "Training dlite loss per 100 training steps: 0.04107257212510336\n",
            "Training dlite loss per 100 training steps: 0.03991258327853858\n",
            "Training dlite loss per 100 training steps: 0.0391869929322864\n",
            "Training dlite loss per 100 training steps: 0.03864330250755901\n",
            "Training dlite loss per 100 training steps: 0.038747839735599685\n",
            "Training dlite loss per 100 training steps: 0.03851459000271733\n",
            "Training dlite loss per 100 training steps: 0.03851807189362629\n",
            "Training dlite loss per 100 training steps: 0.03850418512556674\n",
            "Training dlite loss per 100 training steps: 0.038400449946474034\n",
            "Training dlite loss per 100 training steps: 0.038262398348792824\n",
            "Training dlite loss per 100 training steps: 0.03802407461080171\n",
            "Training dlite loss per 100 training steps: 0.03792750960341576\n",
            "Training dlite loss per 100 training steps: 0.03789721858572173\n",
            "Training dlite loss per 100 training steps: 0.03772918983253504\n",
            "Training dlite loss per 100 training steps: 0.03755404896101376\n",
            "Training dlite loss per 100 training steps: 0.03762077730147169\n",
            "Training dlite loss per 100 training steps: 0.037552788571278604\n",
            "Training dlite loss per 100 training steps: 0.03765682498588041\n",
            "Training dlite loss per 100 training steps: 0.0376524519867813\n",
            "Training dlite loss per 100 training steps: 0.037685803267468655\n",
            "Training dlite loss per 100 training steps: 0.03765708798436863\n",
            "Training dlite loss per 100 training steps: 0.0376155240816071\n",
            "Training dlite loss per 100 training steps: 0.03763845929016022\n",
            "Training dlite loss per 100 training steps: 0.037616495813101114\n",
            "Training dlite loss per 100 training steps: 0.0375791871717976\n",
            "Training dlite loss per 100 training steps: 0.03759379888087466\n",
            "Training dlite loss per 100 training steps: 0.037599888506025\n",
            "Training dlite loss per 100 training steps: 0.03760801794712095\n",
            "Training dlite loss per 100 training steps: 0.037612087364988195\n",
            "Training dlite loss per 100 training steps: 0.03762566435877294\n",
            "Training dlite loss per 100 training steps: 0.03764124097615391\n",
            "Training dlite loss per 100 training steps: 0.037650516152979846\n",
            "Training dlite loss per 100 training steps: 0.03756903985203706\n",
            "Training dlite loss per 100 training steps: 0.03761156231250199\n",
            "Training dlite loss per 100 training steps: 0.03761084178585337\n",
            "Training dlite loss per 100 training steps: 0.0375984330095725\n",
            "Training dlite loss per 100 training steps: 0.03759757525695661\n",
            "Training dlite loss per 100 training steps: 0.03757071617385073\n",
            "Training dlite loss per 100 training steps: 0.037580520145671294\n",
            "Training dlite loss per 100 training steps: 0.03754194393450125\n",
            "Training dlite loss per 100 training steps: 0.03752980993655497\n",
            "Training dlite loss per 100 training steps: 0.03747107982517084\n",
            "Training dlite loss per 100 training steps: 0.03745223605579173\n",
            "Training dlite loss per 100 training steps: 0.037423189424362034\n",
            "Training dlite loss per 100 training steps: 0.03736663161474057\n",
            "Training dlite loss per 100 training steps: 0.037298272816420355\n",
            "Training dlite loss per 100 training steps: 0.03735894339382422\n",
            "Training dlite loss per 100 training steps: 0.03737334191645704\n",
            "Training dlite loss per 100 training steps: 0.03739124758667482\n",
            "Training dlite loss per 100 training steps: 0.03740270179032505\n",
            "Training dlite loss per 100 training steps: 0.037440720967224846\n",
            "Training dlite loss per 100 training steps: 0.037477380434354446\n",
            "Training dlite loss per 100 training steps: 0.03742710446021272\n",
            "Training dlite loss per 100 training steps: 0.037388660606448625\n",
            "Training dlite loss per 100 training steps: 0.03736939080184368\n",
            "Training dlite loss per 100 training steps: 0.03738233192877835\n",
            "Training dlite loss per 100 training steps: 0.03732858074269822\n",
            "Training dlite loss per 100 training steps: 0.037319082424527916\n",
            "Training dlite loss per 100 training steps: 0.03733964146373841\n",
            "Training dlite loss per 100 training steps: 0.03735162369131261\n",
            "Training dlite loss per 100 training steps: 0.03730555330623767\n",
            "Training dlite loss per 100 training steps: 0.03727596774925161\n",
            "Training dlite loss per 100 training steps: 0.03726766692176923\n",
            "Training dlite loss per 100 training steps: 0.037241229835021\n",
            "Training dlite loss per 100 training steps: 0.03729169034846332\n",
            "Training dlite loss per 100 training steps: 0.0372642690580633\n",
            "Training dlite loss per 100 training steps: 0.03723404387498311\n",
            "Training dlite loss per 100 training steps: 0.03723205153795688\n",
            "Training dlite loss per 100 training steps: 0.037221017784135814\n",
            "Training dlite loss per 100 training steps: 0.037232449211635994\n",
            "Training dlite loss per 100 training steps: 0.03721337115587392\n",
            "Training dlite loss per 100 training steps: 0.03718168993911551\n",
            "Training dlite loss per 100 training steps: 0.03719419987512219\n",
            "Training dlite loss per 100 training steps: 0.03718911332763309\n",
            "Training dlite loss per 100 training steps: 0.037172536851888684\n",
            "Training loss epoch: 0.037170776455475105\n",
            "Training accuracy epoch: 0.8247623784292296\n",
            "Training steps: 7969\n",
            "CPU times: user 7min 4s, sys: 1.5 s, total: 7min 5s\n",
            "Wall time: 7min 5s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb6661bf",
      "metadata": {
        "id": "fb6661bf"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "            # implement dlite loss\n",
        "            loss = dlite_loss_fn(active_logits, flattened_targets)\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation dlite loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "    print(f\"Validation steps: {nb_eval_steps}\")\n",
        "\n",
        "    return labels, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af598b56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af598b56",
        "outputId": "9ff4efd1-fd77-4484-b4e5-d4549ef34234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation dlite loss per 100 evaluation steps: 0.019531581550836563\n",
            "Validation dlite loss per 100 evaluation steps: 0.03952689505301169\n",
            "Validation dlite loss per 100 evaluation steps: 0.03838259578925638\n",
            "Validation dlite loss per 100 evaluation steps: 0.03731081827404147\n",
            "Validation dlite loss per 100 evaluation steps: 0.03684178165778094\n",
            "Validation dlite loss per 100 evaluation steps: 0.03603759331227615\n",
            "Validation dlite loss per 100 evaluation steps: 0.0361899764776292\n",
            "Validation dlite loss per 100 evaluation steps: 0.035685921306508134\n",
            "Validation dlite loss per 100 evaluation steps: 0.03612700930275083\n",
            "Validation dlite loss per 100 evaluation steps: 0.03647885757007972\n",
            "Validation dlite loss per 100 evaluation steps: 0.03632334424637752\n",
            "Validation dlite loss per 100 evaluation steps: 0.03663247269925301\n",
            "Validation dlite loss per 100 evaluation steps: 0.036958424904090216\n",
            "Validation dlite loss per 100 evaluation steps: 0.03665779070356949\n",
            "Validation dlite loss per 100 evaluation steps: 0.0364892952783462\n",
            "Validation dlite loss per 100 evaluation steps: 0.03659308390609325\n",
            "Validation dlite loss per 100 evaluation steps: 0.03668390725202488\n",
            "Validation dlite loss per 100 evaluation steps: 0.03683753765892534\n",
            "Validation dlite loss per 100 evaluation steps: 0.036742032077584266\n",
            "Validation dlite loss per 100 evaluation steps: 0.036841509671031634\n",
            "Validation dlite loss per 100 evaluation steps: 0.036774872813124186\n",
            "Validation dlite loss per 100 evaluation steps: 0.03653795244173791\n",
            "Validation dlite loss per 100 evaluation steps: 0.03651245962638176\n",
            "Validation dlite loss per 100 evaluation steps: 0.036512949395352795\n",
            "Validation dlite loss per 100 evaluation steps: 0.036479232937763534\n",
            "Validation dlite loss per 100 evaluation steps: 0.036560667626910216\n",
            "Validation dlite loss per 100 evaluation steps: 0.0364691380678585\n",
            "Validation dlite loss per 100 evaluation steps: 0.0365145458341222\n",
            "Validation dlite loss per 100 evaluation steps: 0.03655950051174917\n",
            "Validation dlite loss per 100 evaluation steps: 0.03669695854434639\n",
            "Validation dlite loss per 100 evaluation steps: 0.03679531790103478\n",
            "Validation dlite loss per 100 evaluation steps: 0.03670846016377268\n",
            "Validation dlite loss per 100 evaluation steps: 0.03666119828379949\n",
            "Validation dlite loss per 100 evaluation steps: 0.036681884212821536\n",
            "Validation dlite loss per 100 evaluation steps: 0.03663588591355121\n",
            "Validation dlite loss per 100 evaluation steps: 0.0365780105455395\n",
            "Validation dlite loss per 100 evaluation steps: 0.03661121564022341\n",
            "Validation dlite loss per 100 evaluation steps: 0.03657613264887167\n",
            "Validation dlite loss per 100 evaluation steps: 0.0365367295213607\n",
            "Validation Loss: 0.03654210071818118\n",
            "Validation Accuracy: 0.8284178250442338\n",
            "Validation steps: 3806\n",
            "CPU times: user 1min 3s, sys: 101 ms, total: 1min 3s\n",
            "Wall time: 1min 3s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "labels, predictions = valid(model, testing_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c838bbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c838bbe",
        "outputId": "bc9fcd63-8cb7-4c97-a751-be507b4f0d2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-geo       0.00      0.00      0.00      9043\n",
            "       B-gpe       0.00      0.00      0.00      2621\n",
            "       B-org       0.00      0.00      0.00      5267\n",
            "       B-per       0.00      0.00      0.00      4217\n",
            "       B-tim       0.00      0.00      0.00      3490\n",
            "       I-geo       0.00      0.00      0.00      1480\n",
            "       I-gpe       0.00      0.00      0.00        42\n",
            "       I-org       0.00      0.00      0.00      3196\n",
            "       I-per       0.00      0.00      0.00      5081\n",
            "       I-tim       0.00      0.00      0.00      1167\n",
            "           O       0.82      1.00      0.90    165562\n",
            "\n",
            "    accuracy                           0.82    201166\n",
            "   macro avg       0.07      0.09      0.08    201166\n",
            "weighted avg       0.68      0.82      0.74    201166\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(labels, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c5f8ac0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c5f8ac0",
        "outputId": "2f9d981d-8b5a-4882-cdc3-0b48c351dc77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8230118409671614, 0.8230118409671614, 0.8230118409671614, None)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision_recall_fscore_support(labels, predictions, average = \"micro\", zero_division = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4803e9d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4803e9d7",
        "outputId": "011a4486-8d1c-4331-e3cd-cc5fb9eebeec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9839101673606511, 0.09090909090909091, 0.08208312923524197, None)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"macro\", zero_division = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4dc2cb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4dc2cb9",
        "outputId": "e5f07cdd-e225-4450-cb0a-2654a41123a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8543366494049948, 0.8230118409671614, 0.7431092603466611, None)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"weighted\", zero_division = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6007f4f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6007f4f7",
        "outputId": "eb5f5470-13ad-40b1-ce8a-20467a3ccc46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "india has a capital called mumbai . on wednesday , the president will give a presentation\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "sentence = \"India has a capital called Mumbai. On Wednesday, the president will give a presentation\"\n",
        "\n",
        "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "\n",
        "# move to gpu\n",
        "ids = inputs[\"input_ids\"].to(device)\n",
        "mask = inputs[\"attention_mask\"].to(device)\n",
        "# forward pass\n",
        "outputs = model(ids, mask)\n",
        "logits = outputs[0]\n",
        "\n",
        "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
        "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "word_level_predictions = []\n",
        "for pair in wp_preds:\n",
        "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
        "    # skip prediction\n",
        "    continue\n",
        "  else:\n",
        "    word_level_predictions.append(pair[1])\n",
        "\n",
        "# we join tokens, if they are not special ones\n",
        "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
        "print(str_rep)\n",
        "print(word_level_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c0812b0",
      "metadata": {
        "id": "3c0812b0"
      },
      "outputs": [],
      "source": [
        "# using preferred function, dlite loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68a1f32a",
      "metadata": {
        "id": "68a1f32a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1282ab63",
      "metadata": {
        "id": "1282ab63"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2531e79c",
      "metadata": {
        "id": "2531e79c"
      },
      "outputs": [],
      "source": [
        "# KL divergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a852a7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a852a7d",
        "outputId": "b83cf323-b9db-463f-ba01-c373fdaccc6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (47571, 2)\n",
            "TRAIN Dataset: (31873, 2)\n",
            "TEST Dataset: (7611, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 5e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenization\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "# Bert imput\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        sentence = self.data.sentence[index]\n",
        "        word_labels = self.data.word_labels[index]\n",
        "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# define training size 80/20 split\n",
        "\n",
        "train_size = 0.67\n",
        "# Assuming you want the test size to be 16% of the original data.\n",
        "test_size = 0.16\n",
        "\n",
        "# Sampling the training dataset\n",
        "train_dataset = data.sample(frac=train_size, random_state=200)\n",
        "\n",
        "# Calculating the fraction of the remaining data to sample for the test dataset to make it 16% of the original data\n",
        "remaining_size = test_size / (1 - train_size)\n",
        "test_dataset = data.drop(train_dataset.index).sample(frac=remaining_size, random_state=200)\n",
        "\n",
        "# Resetting the index\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "test_dataset = test_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(data.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "# pyTorch dataloaders\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id)\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c70987",
      "metadata": {
        "id": "25c70987"
      },
      "outputs": [],
      "source": [
        "# KL implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04286153",
      "metadata": {
        "id": "04286153"
      },
      "outputs": [],
      "source": [
        "class KLDivergenceLoss(nn.Module):\n",
        "    def __init__(self, reduction='mean'):\n",
        "        super(KLDivergenceLoss, self).__init__()\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        # Convert logits to probabilities using softmax\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        # One-hot encode the targets to get true probabilities\n",
        "        true_probs = F.one_hot(targets, num_classes=probs.size(-1)).float()\n",
        "\n",
        "        # Masks for non-zero elements of probs and true_probs\n",
        "        mask_probs = probs > 0\n",
        "        mask_true_probs = true_probs > 0\n",
        "\n",
        "        # Calculate g function for non-zero elements using the mask\n",
        "        kl_values = torch.zeros_like(probs)\n",
        "        kl_values[mask_true_probs] = true_probs[mask_true_probs] * torch.log(true_probs[mask_true_probs]/probs[mask_true_probs])\n",
        "\n",
        "        # Sum over all classes and average over the batch size\n",
        "        loss = kl_values.sum(dim=-1).mean()\n",
        "\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc21367",
      "metadata": {
        "id": "3bc21367"
      },
      "outputs": [],
      "source": [
        "kl_loss_fn = KLDivergenceLoss()\n",
        "\n",
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "\n",
        "        # implement dlite loss function\n",
        "        flatten_targets = targets.view(-1)\n",
        "        flatten_logits = tr_logits.view(-1, model.num_labels)\n",
        "\n",
        "        loss = kl_loss_fn(flatten_logits, flatten_targets)\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training kl loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "    print(f\"Training steps: {nb_tr_steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "778adc2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "778adc2c",
        "outputId": "04fffa58-dc0b-45e0-9e56-07d0cef6644f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training kl loss per 100 training steps: 2.4535903930664062\n",
            "Training kl loss per 100 training steps: 0.1889245381560361\n",
            "Training kl loss per 100 training steps: 0.12967257415505118\n",
            "Training kl loss per 100 training steps: 0.10435715145385048\n",
            "Training kl loss per 100 training steps: 0.0890245009608511\n",
            "Training kl loss per 100 training steps: 0.07809811092317365\n",
            "Training kl loss per 100 training steps: 0.07165064891554669\n",
            "Training kl loss per 100 training steps: 0.06658340947697212\n",
            "Training kl loss per 100 training steps: 0.0621540886652278\n",
            "Training kl loss per 100 training steps: 0.05985019314188105\n",
            "Training kl loss per 100 training steps: 0.058044415137443975\n",
            "Training kl loss per 100 training steps: 0.056176737966151274\n",
            "Training kl loss per 100 training steps: 0.05425312221426359\n",
            "Training kl loss per 100 training steps: 0.05264172481650703\n",
            "Training kl loss per 100 training steps: 0.05140121741024917\n",
            "Training kl loss per 100 training steps: 0.04993969774438933\n",
            "Training kl loss per 100 training steps: 0.048986548033754095\n",
            "Training kl loss per 100 training steps: 0.0480227696677579\n",
            "Training kl loss per 100 training steps: 0.04715768324588992\n",
            "Training kl loss per 100 training steps: 0.046427011842176076\n",
            "Training kl loss per 100 training steps: 0.04568887144127728\n",
            "Training kl loss per 100 training steps: 0.04511963649335291\n",
            "Training kl loss per 100 training steps: 0.04433024834927386\n",
            "Training kl loss per 100 training steps: 0.04393410527619692\n",
            "Training kl loss per 100 training steps: 0.04341370970181817\n",
            "Training kl loss per 100 training steps: 0.04303003081333925\n",
            "Training kl loss per 100 training steps: 0.042731524950254285\n",
            "Training kl loss per 100 training steps: 0.04231059890778674\n",
            "Training kl loss per 100 training steps: 0.042026080038353286\n",
            "Training kl loss per 100 training steps: 0.04179867401856175\n",
            "Training kl loss per 100 training steps: 0.041334532391526964\n",
            "Training kl loss per 100 training steps: 0.04120809549255695\n",
            "Training kl loss per 100 training steps: 0.040932840706233715\n",
            "Training kl loss per 100 training steps: 0.04068587723915513\n",
            "Training kl loss per 100 training steps: 0.040326157836597445\n",
            "Training kl loss per 100 training steps: 0.04002630159166934\n",
            "Training kl loss per 100 training steps: 0.03976649492917948\n",
            "Training kl loss per 100 training steps: 0.03956189003627522\n",
            "Training kl loss per 100 training steps: 0.039281241826244206\n",
            "Training kl loss per 100 training steps: 0.03913633203532501\n",
            "Training kl loss per 100 training steps: 0.03887177748148197\n",
            "Training kl loss per 100 training steps: 0.03861611517729172\n",
            "Training kl loss per 100 training steps: 0.03855687045915093\n",
            "Training kl loss per 100 training steps: 0.038388070369588384\n",
            "Training kl loss per 100 training steps: 0.03815524329328549\n",
            "Training kl loss per 100 training steps: 0.037964221331285804\n",
            "Training kl loss per 100 training steps: 0.037798981006575715\n",
            "Training kl loss per 100 training steps: 0.03761049580586123\n",
            "Training kl loss per 100 training steps: 0.03743380650621371\n",
            "Training kl loss per 100 training steps: 0.037319054197478045\n",
            "Training kl loss per 100 training steps: 0.037156790503779166\n",
            "Training kl loss per 100 training steps: 0.03699990815171889\n",
            "Training kl loss per 100 training steps: 0.03692700261376615\n",
            "Training kl loss per 100 training steps: 0.03686651824545778\n",
            "Training kl loss per 100 training steps: 0.03670341976233939\n",
            "Training kl loss per 100 training steps: 0.03657496821903452\n",
            "Training kl loss per 100 training steps: 0.03638962614195642\n",
            "Training kl loss per 100 training steps: 0.036241665356247905\n",
            "Training kl loss per 100 training steps: 0.03613738055011768\n",
            "Training kl loss per 100 training steps: 0.036025937379336785\n",
            "Training kl loss per 100 training steps: 0.03590434586031171\n",
            "Training kl loss per 100 training steps: 0.03578736174069531\n",
            "Training kl loss per 100 training steps: 0.03570310623646848\n",
            "Training kl loss per 100 training steps: 0.035543251269992276\n",
            "Training kl loss per 100 training steps: 0.0354288880916397\n",
            "Training kl loss per 100 training steps: 0.03536106785138842\n",
            "Training kl loss per 100 training steps: 0.03520132940660037\n",
            "Training kl loss per 100 training steps: 0.03500856963938704\n",
            "Training kl loss per 100 training steps: 0.034886731870862775\n",
            "Training kl loss per 100 training steps: 0.0347756389993179\n",
            "Training kl loss per 100 training steps: 0.03464844536118796\n",
            "Training kl loss per 100 training steps: 0.034532346773192675\n",
            "Training kl loss per 100 training steps: 0.034437223564666046\n",
            "Training kl loss per 100 training steps: 0.0343836092703059\n",
            "Training kl loss per 100 training steps: 0.0343519334599758\n",
            "Training kl loss per 100 training steps: 0.03427856707785424\n",
            "Training kl loss per 100 training steps: 0.03415762856809126\n",
            "Training kl loss per 100 training steps: 0.03408923989613905\n",
            "Training kl loss per 100 training steps: 0.034035004310040314\n",
            "Training kl loss per 100 training steps: 0.03392534921660787\n",
            "Training loss epoch: 0.03391253424963584\n",
            "Training accuracy epoch: 0.9528139744412067\n",
            "Training steps: 7969\n",
            "CPU times: user 7min 1s, sys: 1.59 s, total: 7min 3s\n",
            "Wall time: 7min 2s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea3e77df",
      "metadata": {
        "id": "ea3e77df"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "\n",
        "            # implement dlite loss\n",
        "            flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            flatten_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            loss = kl_loss_fn(flatten_logits, flatten_targets)\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation kl loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "    print(f\"Validation steps: {nb_eval_steps}\")\n",
        "\n",
        "    return labels, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a2f9aea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a2f9aea",
        "outputId": "437ffc40-59a1-4b13-c950-6df7955b7a9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation kl loss per 100 evaluation steps: 0.0014788158005103469\n",
            "Validation kl loss per 100 evaluation steps: 0.02289800909323339\n",
            "Validation kl loss per 100 evaluation steps: 0.026718967492596318\n",
            "Validation kl loss per 100 evaluation steps: 0.027139215984474944\n",
            "Validation kl loss per 100 evaluation steps: 0.02797001138817376\n",
            "Validation kl loss per 100 evaluation steps: 0.027989558365633768\n",
            "Validation kl loss per 100 evaluation steps: 0.029105555724745137\n",
            "Validation kl loss per 100 evaluation steps: 0.028251542981085266\n",
            "Validation kl loss per 100 evaluation steps: 0.02866638206506785\n",
            "Validation kl loss per 100 evaluation steps: 0.028197777945484725\n",
            "Validation kl loss per 100 evaluation steps: 0.027768253187003086\n",
            "Validation kl loss per 100 evaluation steps: 0.027524951110502724\n",
            "Validation kl loss per 100 evaluation steps: 0.027651932904652655\n",
            "Validation kl loss per 100 evaluation steps: 0.027614086253162643\n",
            "Validation kl loss per 100 evaluation steps: 0.0271274455876434\n",
            "Validation kl loss per 100 evaluation steps: 0.027220392029688043\n",
            "Validation kl loss per 100 evaluation steps: 0.027107937780284346\n",
            "Validation kl loss per 100 evaluation steps: 0.027171893798444813\n",
            "Validation kl loss per 100 evaluation steps: 0.027144165623250633\n",
            "Validation kl loss per 100 evaluation steps: 0.0272204992563953\n",
            "Validation kl loss per 100 evaluation steps: 0.026933549271953874\n",
            "Validation kl loss per 100 evaluation steps: 0.02698037836191936\n",
            "Validation kl loss per 100 evaluation steps: 0.027049307131111106\n",
            "Validation kl loss per 100 evaluation steps: 0.02698628669282253\n",
            "Validation kl loss per 100 evaluation steps: 0.026855343750333074\n",
            "Validation kl loss per 100 evaluation steps: 0.026617989747961146\n",
            "Validation kl loss per 100 evaluation steps: 0.026831208003130956\n",
            "Validation kl loss per 100 evaluation steps: 0.026956821449774165\n",
            "Validation kl loss per 100 evaluation steps: 0.026880020035722305\n",
            "Validation kl loss per 100 evaluation steps: 0.026824700870292716\n",
            "Validation kl loss per 100 evaluation steps: 0.026862982493605626\n",
            "Validation kl loss per 100 evaluation steps: 0.02688540477038831\n",
            "Validation kl loss per 100 evaluation steps: 0.026872650672735338\n",
            "Validation kl loss per 100 evaluation steps: 0.02674882625435257\n",
            "Validation kl loss per 100 evaluation steps: 0.026972162547666538\n",
            "Validation kl loss per 100 evaluation steps: 0.026889464577740028\n",
            "Validation kl loss per 100 evaluation steps: 0.026951748303742015\n",
            "Validation kl loss per 100 evaluation steps: 0.026965492649398553\n",
            "Validation kl loss per 100 evaluation steps: 0.027091213683384383\n",
            "Validation Loss: 0.027113240554125242\n",
            "Validation Accuracy: 0.960521411858854\n",
            "Validation steps: 3806\n",
            "CPU times: user 1min 3s, sys: 155 ms, total: 1min 3s\n",
            "Wall time: 1min 3s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "labels, predictions = valid(model, testing_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "302b2264",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "302b2264",
        "outputId": "e1fffb41-b303-4275-e9f4-aae7d960dee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-geo       0.83      0.89      0.86      9043\n",
            "       B-gpe       0.92      0.92      0.92      2621\n",
            "       B-org       0.79      0.64      0.71      5267\n",
            "       B-per       0.82      0.86      0.84      4217\n",
            "       B-tim       0.86      0.88      0.87      3490\n",
            "       I-geo       0.73      0.75      0.74      1480\n",
            "       I-gpe       0.76      0.31      0.44        42\n",
            "       I-org       0.81      0.51      0.63      3196\n",
            "       I-per       0.81      0.93      0.86      5081\n",
            "       I-tim       0.88      0.63      0.74      1167\n",
            "           O       0.99      0.99      0.99    165562\n",
            "\n",
            "    accuracy                           0.96    201166\n",
            "   macro avg       0.84      0.76      0.78    201166\n",
            "weighted avg       0.96      0.96      0.96    201166\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(labels, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd1517dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd1517dc",
        "outputId": "2c2b4267-9e57-4cc9-f5b1-caff3a37a5aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9588598470914568, 0.9588598470914568, 0.9588598470914568, None)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision_recall_fscore_support(labels, predictions, average = \"micro\", zero_division = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28a5d897",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28a5d897",
        "outputId": "fad32f06-24bf-4562-ce09-00ae471966ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8364733645961803, 0.7559943146075152, 0.7812588479879771, None)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"macro\", zero_division = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b20a628",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b20a628",
        "outputId": "dfcbe006-d44c-4ca6-e4a3-8b06c6f4c4ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9581191632902094, 0.9588598470914568, 0.9574457287607828, None)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"weighted\", zero_division = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d1498fe",
      "metadata": {
        "id": "0d1498fe"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a234d279",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a234d279",
        "outputId": "43df7554-672a-4ff9-b543-551a91ccb941"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "india has a capital called mumbai . on wednesday , the president will give a presentation\n",
            "['B-geo', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "sentence = \"India has a capital called Mumbai. On Wednesday, the president will give a presentation\"\n",
        "\n",
        "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "\n",
        "# move to gpu\n",
        "ids = inputs[\"input_ids\"].to(device)\n",
        "mask = inputs[\"attention_mask\"].to(device)\n",
        "# forward pass\n",
        "outputs = model(ids, mask)\n",
        "logits = outputs[0]\n",
        "\n",
        "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
        "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "word_level_predictions = []\n",
        "for pair in wp_preds:\n",
        "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
        "    # skip prediction\n",
        "    continue\n",
        "  else:\n",
        "    word_level_predictions.append(pair[1])\n",
        "\n",
        "# we join tokens, if they are not special ones\n",
        "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
        "print(str_rep)\n",
        "print(word_level_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f866cb",
      "metadata": {
        "id": "79f866cb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b316609",
      "metadata": {
        "id": "0b316609"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}