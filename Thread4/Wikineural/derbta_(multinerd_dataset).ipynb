{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEBdvK_nGr3w",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report\n",
        "import random ,json\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import transformers\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, Dataset\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hskApG2OGr3x"
      },
      "source": [
        "## Setting Basic Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlnriKCUGr3y",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    batch_size = 4\n",
        "    epochs = 1\n",
        "    lr = 1e-5\n",
        "    seed = 123\n",
        "\n",
        "\n",
        "    # Can only have one True\n",
        "    # only_use_standard_linear_layer=True, use linear layer\n",
        "    only_use_standard_linear_layer = True\n",
        "    # Setting the linear layer number\n",
        "    linear_layer_num = 0\n",
        "    linear_layer = [512, 512, 512]\n",
        "\n",
        "\n",
        "    # if only_use_standard_linear_layer is False, only_use_dropout is True, it means just use dropout.\n",
        "    only_use_dropout = False\n",
        "    dropout_prob = [0.05, 0, 0.05]\n",
        "\n",
        "\n",
        "    # if only_use_standard_linear_layer is False, only_use_residual = True, just use resdiual\n",
        "    only_use_residual = False\n",
        "    # if only_use_standard_linear_layer is False, only_use_residual_and_dropout = True, use residual and dropout together.\n",
        "    only_use_residual_and_dropout = False\n",
        "\n",
        "\n",
        "\n",
        "    assert sum([1 if only_use_standard_linear_layer else 0,\n",
        "                1 if only_use_dropout else 0,\n",
        "                1 if only_use_residual else 0,\n",
        "                1 if only_use_residual_and_dropout else 0]) == 1\n",
        "\n",
        "\n",
        "\n",
        "    # if lstm layer is 0, then not using the lstm layer. Setting the lstm layer based on layers number required\n",
        "    lstm_layer_num = 0\n",
        "    bi_lstm=True\n",
        "\n",
        "\n",
        "    # Internet resource; download from Internet\n",
        "    # model_name = \"microsoft/deberta-v3-base\"\n",
        "\n",
        "    model_name = \"microsoft/deberta-base\"\n",
        "    # model_name = \"deberta-base\"\n",
        "\n",
        "    hidden_size=768\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_data_name = \"multinerd\" # conll2003,  ner_datasetreference, broad_twitter_corpus, wnut, wikineural, multinerd\n",
        "\n",
        "    @classmethod\n",
        "    def describe(cls):\n",
        "        parm = {\"train_data_name\": cls.train_data_name,\n",
        "                \"encoder_name\": cls.model_name,\n",
        "                \"batch_size\": cls.batch_size,\n",
        "                \"epochs\": cls.epochs,\n",
        "                \"lr\": cls.lr,\n",
        "                \"seed\": cls.seed,\n",
        "                \"bi_lstm\": cls.bi_lstm,\n",
        "                \"lstm_layer_num\": cls.lstm_layer_num,\n",
        "                \"linear_layer\": cls.linear_layer,\n",
        "                \"linear_layer_num\":cls.linear_layer_num,\n",
        "                \"dropout_prob\": cls.dropout_prob,\n",
        "                \"only_use_standard_linear_layer\": cls.only_use_standard_linear_layer,\n",
        "                \"only_use_dropout\": cls.only_use_dropout,\n",
        "                \"only_use_residual\": cls.only_use_residual,\n",
        "                \"only_use_residual_and_dropout\": cls.only_use_residual_and_dropout}\n",
        "        return json.dumps(parm , ensure_ascii=False, indent=2)\n",
        "\n",
        "random.seed(Config.seed)\n",
        "np.random.seed(Config.seed)\n",
        "torch.manual_seed(Config.seed)\n",
        "torch.cuda.manual_seed_all(Config.seed)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQGJgAySrwEr"
      },
      "source": [
        "## given configuration result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BObln4RIGr3y",
        "outputId": "fa9aaf65-d98e-49f9-b3d9-b364d9b0119f",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"train_data_name\": \"multinerd\",\n",
            "  \"encoder_name\": \"microsoft/deberta-base\",\n",
            "  \"batch_size\": 4,\n",
            "  \"epochs\": 1,\n",
            "  \"lr\": 1e-05,\n",
            "  \"seed\": 123,\n",
            "  \"bi_lstm\": true,\n",
            "  \"lstm_layer_num\": 0,\n",
            "  \"linear_layer\": [\n",
            "    512,\n",
            "    512,\n",
            "    512\n",
            "  ],\n",
            "  \"linear_layer_num\": 0,\n",
            "  \"dropout_prob\": [\n",
            "    0.05,\n",
            "    0,\n",
            "    0.05\n",
            "  ],\n",
            "  \"only_use_standard_linear_layer\": true,\n",
            "  \"only_use_dropout\": false,\n",
            "  \"only_use_residual\": false,\n",
            "  \"only_use_residual_and_dropout\": false\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(Config.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9ig_SZXGr3z"
      },
      "source": [
        "## Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "7CY8ivunDRSs"
      },
      "outputs": [],
      "source": [
        "def read_broad_twitter_corpus(data_dir):\n",
        "    ret, sample  = [], []\n",
        "    for file in sorted(os.listdir(data_dir)):\n",
        "        if file.endswith(\".conll\"):\n",
        "            file = os.path.join(data_dir, file)\n",
        "            for idx,line in  enumerate(open(file, \"r\", encoding=\"utf-8\")):\n",
        "                line = line.strip()\n",
        "                if line == \"\":\n",
        "                    if len(sample) > 0 :\n",
        "                        ret.append({\"word\": [i[0] for i in sample], \"tag\": [i[1] for i in sample]})\n",
        "                    sample = []\n",
        "                else:\n",
        "                    tokens = line.split(\"\\t\")\n",
        "                    if len(tokens) != 2:\n",
        "                        continue\n",
        "                    else:\n",
        "                        sample.append(tokens)\n",
        "            if len(sample) > 0:\n",
        "                ret.append({\"word\": [i[0] for i in sample], \"tag\": [i[1] for i in sample]})\n",
        "\n",
        "    return pd.DataFrame(ret)\n",
        "\n",
        "def read_wnut(file_path):\n",
        "    data = []\n",
        "    sample = []\n",
        "    for idx, line in enumerate(open(file_path)):\n",
        "        if idx == 0:\n",
        "            continue\n",
        "        line = line.strip()\n",
        "        if line == \"\":\n",
        "            if len(sample) != 0:\n",
        "                data.append(sample)\n",
        "            sample = []\n",
        "        else:\n",
        "            line = line.split()\n",
        "            assert len(line) == 2\n",
        "            sample.append([line[0], line[-1]])\n",
        "    if len(sample) != 0:\n",
        "        data.append(sample)\n",
        "    data = [{\"word\": [i[0] for i in sample], \"tag\": [i[1] for i in sample]} for sample in data]\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "def read_multinerd(file_path):\n",
        "    labels = {\n",
        "    \"O\": 0,\n",
        "    \"B-PER\": 1,\n",
        "    \"I-PER\": 2,\n",
        "    \"B-ORG\": 3,\n",
        "    \"I-ORG\": 4,\n",
        "    \"B-LOC\": 5,\n",
        "    \"I-LOC\": 6,\n",
        "    \"B-ANIM\": 7,\n",
        "    \"I-ANIM\": 8,\n",
        "    \"B-BIO\": 9,\n",
        "    \"I-BIO\": 10,\n",
        "    \"B-CEL\": 11,\n",
        "    \"I-CEL\": 12,\n",
        "    \"B-DIS\": 13,\n",
        "    \"I-DIS\": 14,\n",
        "    \"B-EVE\": 15,\n",
        "    \"I-EVE\": 16,\n",
        "    \"B-FOOD\": 17,\n",
        "    \"I-FOOD\": 18,\n",
        "    \"B-INST\": 19,\n",
        "    \"I-INST\": 20,\n",
        "    \"B-MEDIA\": 21,\n",
        "    \"I-MEDIA\": 22,\n",
        "    \"B-MYTH\": 23,\n",
        "    \"I-MYTH\": 24,\n",
        "    \"B-PLANT\": 25,\n",
        "    \"I-PLANT\": 26,\n",
        "    \"B-TIME\": 27,\n",
        "    \"I-TIME\": 28,\n",
        "    \"B-VEHI\": 29,\n",
        "    \"I-VEHI\": 30,\n",
        "  }\n",
        "    id2label = dict([[v,k] for k,v in labels.items()])\n",
        "    data = []\n",
        "    for line in open(file_path, \"r\", encoding=\"utf-8\"):\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            line = json.loads(line)\n",
        "            tokens = line['tokens']\n",
        "            tags = [id2label[i] for i in line['ner_tags']]\n",
        "            assert line['lang'] == 'en'\n",
        "            data.append([[i,j] for i,j in zip(tokens, tags)])\n",
        "    data = [{\"word\": [i[0] for i in sample], \"tag\": [i[1] for i in sample]} for sample in data]\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "def read_wikineural(file_path):\n",
        "    labels = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
        "    id2label = dict([[v,k] for k,v in labels.items()])\n",
        "    data = []\n",
        "    for line in open(file_path, \"r\", encoding=\"utf-8\"):\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            line = json.loads(line)\n",
        "            tokens = line['tokens']\n",
        "            tags = [id2label[i] for i in line['ner_tags']]\n",
        "            assert line['lang'] == 'en'\n",
        "            data.append([[i,j] for i,j in zip(tokens, tags)])\n",
        "    data = [{\"word\": [i[0] for i in sample], \"tag\": [i[1] for i in sample]} for sample in data]\n",
        "    return pd.DataFrame(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGZ_d-HrGr3z",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def read_conll2003(file_path):\n",
        "    data = []\n",
        "    sample = []\n",
        "    for idx, line in enumerate(open(file_path)):\n",
        "        if idx == 0:\n",
        "            continue\n",
        "        line = line.strip()\n",
        "        if line == \"\":\n",
        "            if len(sample) != 0:\n",
        "                data.append(sample)\n",
        "            sample = []\n",
        "        else:\n",
        "            line = line.split()\n",
        "            assert len(line) == 4\n",
        "            sample.append([line[0], line[-1]])\n",
        "    if len(sample) != 0:\n",
        "        data.append(sample)\n",
        "    data = [{\"word\": [i[0] for i in sample], \"tag\": [i[1] for i in sample]} for sample in data]\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Setting the chosen dataset, conll2003 or ner_datasetreference.\n",
        "if Config.train_data_name == \"conll2003\":\n",
        "    train_path = os.path.join(Config.train_data_name, 'train.txt')\n",
        "    dev_path = os.path.join(Config.train_data_name, 'valid.txt')\n",
        "    test_path = os.path.join(Config.train_data_name, 'test.txt')\n",
        "    train_df = read_conll2003(train_path)\n",
        "    valid_df = read_conll2003(dev_path)\n",
        "    test_df = read_conll2003(test_path)\n",
        "    print(train_df.shape, valid_df.shape, test_df.shape)\n",
        "elif Config.train_data_name == \"ner_datasetreference\":\n",
        "    df = pd.read_csv(\"ner_datasetreference.csv\", encoding='iso-8859-1')\n",
        "    data = []\n",
        "    word, tag = [], []\n",
        "    for i,j,k in zip(df['Sentence #'], df['Word'], df['Tag']):\n",
        "        if not pd.isnull(i):\n",
        "            assert i.startswith('Sentence')\n",
        "            if len(word) > 0:\n",
        "                data.append({\"word\":word, \"tag\":tag})\n",
        "            word, tag = [], []\n",
        "        if isinstance(j, str) and isinstance(k, str):\n",
        "            # remove 'art', 'eve', 'nat' label for better macro results\n",
        "            if any( t in k for t in ['art', 'eve', 'nat']):\n",
        "                continue\n",
        "            word.append(j)\n",
        "            tag.append(k)\n",
        "    if len(word) > 0:\n",
        "        data.append({\"word\":word, \"tag\":tag})\n",
        "        word, tag = [], []\n",
        "    print(data[0], data[-1])\n",
        "    df = pd.DataFrame(data)\n",
        "    train_df, temp_df = train_test_split(df, test_size=0.4, random_state=42)\n",
        "    valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "    print(df.shape, train_df.shape, valid_df.shape, test_df.shape)\n",
        "elif Config.train_data_name == 'broad_twitter_corpus':\n",
        "    train_df = read_broad_twitter_corpus(os.path.join(Config.train_data_name, 'train'))\n",
        "    valid_df = read_broad_twitter_corpus(os.path.join(Config.train_data_name, 'dev'))\n",
        "    test_df = read_broad_twitter_corpus(os.path.join(Config.train_data_name, 'test'))\n",
        "    print(train_df.shape, valid_df.shape, test_df.shape)\n",
        "elif Config.train_data_name == \"wikineural\":\n",
        "    train_path = os.path.join(Config.train_data_name, 'train_en.jsonl')\n",
        "    dev_path = os.path.join(Config.train_data_name, 'val_en.jsonl')\n",
        "    test_path = os.path.join(Config.train_data_name, 'test_en.jsonl')\n",
        "    train_df = read_wikineural(train_path)\n",
        "    valid_df = read_wikineural(dev_path)\n",
        "    test_df = read_wikineural(test_path)\n",
        "elif Config.train_data_name == \"multinerd\":\n",
        "    train_path = os.path.join(Config.train_data_name, 'train_en.jsonl')\n",
        "    dev_path = os.path.join(Config.train_data_name, 'val_val_en.jsonl')\n",
        "    test_path = os.path.join(Config.train_data_name, 'test_test_en.jsonl')\n",
        "    train_df = read_multinerd(train_path)\n",
        "    valid_df = read_multinerd(dev_path)\n",
        "    test_df = read_multinerd(test_path)\n",
        "elif Config.train_data_name == \"wnut\":\n",
        "    train_path = os.path.join(Config.train_data_name, 'train')\n",
        "    dev_path = os.path.join(Config.train_data_name, 'dev')\n",
        "    test_path = os.path.join(Config.train_data_name, 'test')\n",
        "    train_df = read_wnut(train_path)\n",
        "    valid_df = read_wnut(dev_path)\n",
        "    test_df = read_wnut(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BYJxdEf9Gr30",
        "outputId": "241ef958-76a3-4498-bcf0-468c5e29d8d3",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     word  \\\n",
              "0                   [The, type, locality, is, Kīlauea, .]   \n",
              "1       [Common, components, of, the, herb, layer, in,...   \n",
              "2       [The, film, starred, Tito, Lusiardo, and, a, 1...   \n",
              "3       [Created, by, James, Cameron, and, Charles, H....   \n",
              "4       [The, song, was, written, by, Sarah, Buxton, ,...   \n",
              "...                                                   ...   \n",
              "131275  [Extreme, cases, of, selenosis, can, result, i...   \n",
              "131276  [Although, New, Zealand, has, low, levels, of,...   \n",
              "131277  [Dietary, selenium, comes, from, nuts, ,, cere...   \n",
              "131278          [It, was, narrated, by, Amanda, Bynes, .]   \n",
              "131279  [The, human, rights, record, in, Taiwan, is, g...   \n",
              "\n",
              "                                                      tag  \n",
              "0                                  [O, O, O, O, B-LOC, O]  \n",
              "1       [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "2       [O, O, O, B-PER, I-PER, O, O, O, O, O, B-PER, ...  \n",
              "3       [O, O, B-PER, I-PER, O, B-PER, I-PER, I-PER, O...  \n",
              "4       [O, O, O, O, O, B-PER, I-PER, O, B-PER, I-PER,...  \n",
              "...                                                   ...  \n",
              "131275  [O, O, O, O, O, O, O, O, O, O, O, O, B-DIS, I-...  \n",
              "131276  [O, B-LOC, I-LOC, O, O, O, O, O, O, O, O, O, O...  \n",
              "131277  [O, O, O, O, O, O, O, O, B-FOOD, O, O, O, B-AN...  \n",
              "131278                      [O, O, O, O, B-PER, I-PER, O]  \n",
              "131279  [O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O,...  \n",
              "\n",
              "[131280 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4b9c35d-e21a-4e94-85b8-ea04a1cc9f93\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[The, type, locality, is, Kīlauea, .]</td>\n",
              "      <td>[O, O, O, O, B-LOC, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Common, components, of, the, herb, layer, in,...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[The, film, starred, Tito, Lusiardo, and, a, 1...</td>\n",
              "      <td>[O, O, O, B-PER, I-PER, O, O, O, O, O, B-PER, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Created, by, James, Cameron, and, Charles, H....</td>\n",
              "      <td>[O, O, B-PER, I-PER, O, B-PER, I-PER, I-PER, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[The, song, was, written, by, Sarah, Buxton, ,...</td>\n",
              "      <td>[O, O, O, O, O, B-PER, I-PER, O, B-PER, I-PER,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131275</th>\n",
              "      <td>[Extreme, cases, of, selenosis, can, result, i...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-DIS, I-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131276</th>\n",
              "      <td>[Although, New, Zealand, has, low, levels, of,...</td>\n",
              "      <td>[O, B-LOC, I-LOC, O, O, O, O, O, O, O, O, O, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131277</th>\n",
              "      <td>[Dietary, selenium, comes, from, nuts, ,, cere...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-FOOD, O, O, O, B-AN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131278</th>\n",
              "      <td>[It, was, narrated, by, Amanda, Bynes, .]</td>\n",
              "      <td>[O, O, O, O, B-PER, I-PER, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131279</th>\n",
              "      <td>[The, human, rights, record, in, Taiwan, is, g...</td>\n",
              "      <td>[O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>131280 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4b9c35d-e21a-4e94-85b8-ea04a1cc9f93')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f4b9c35d-e21a-4e94-85b8-ea04a1cc9f93 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f4b9c35d-e21a-4e94-85b8-ea04a1cc9f93');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-65fb9e7e-1ebc-47f3-a600-0d4db96d6c04\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-65fb9e7e-1ebc-47f3-a600-0d4db96d6c04')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-65fb9e7e-1ebc-47f3-a600-0d4db96d6c04 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bd8e13fa-4fb6-4cac-a1aa-f855eac2d161\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bd8e13fa-4fb6-4cac-a1aa-f855eac2d161 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qNmakWvLGr30",
        "outputId": "c2687aab-bebf-4778-e195-34d06cdfb2ad",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    word  \\\n",
              "0      [His, father, was, a, surveyor, and, tavern, o...   \n",
              "1      [His, family, moved, to, Ohio, and, settled, n...   \n",
              "2      [His, family, moved, to, Covington, during, hi...   \n",
              "3      [The, first, verse, is, shared, by, Jo, O'Mear...   \n",
              "4      [Within, city, limits, ,, the, southwestern, f...   \n",
              "...                                                  ...   \n",
              "16449  [The, protesters, are, calling, for, an, end, ...   \n",
              "16450  [\", The, fact, is, that, much, of, the, eviden...   \n",
              "16451  [The, is, expected, to, vote, later, today, on...   \n",
              "16452  [The, five, permanent, members, of, the, counc...   \n",
              "16453  [The, New, England, Patriots, hired, him, as, ...   \n",
              "\n",
              "                                                     tag  \n",
              "0      [O, O, O, O, O, O, O, O, O, O, O, O, O, B-PER,...  \n",
              "1      [O, O, O, O, B-LOC, O, O, O, B-LOC, O, O, O, O...  \n",
              "2                        [O, O, O, O, B-LOC, O, O, O, O]  \n",
              "3      [O, O, O, O, O, O, B-PER, I-PER, O, B-PER, I-P...  \n",
              "4           [O, O, O, O, O, O, O, O, O, B-ANIM, O, O, O]  \n",
              "...                                                  ...  \n",
              "16449  [O, O, O, O, O, O, O, O, O, O, O, B-PER, I-PER...  \n",
              "16450  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
              "16451  [O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, I-...  \n",
              "16452  [O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O,...  \n",
              "16453  [O, B-ORG, I-ORG, I-ORG, O, O, O, O, O, O, O, ...  \n",
              "\n",
              "[16454 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75271661-f7e1-486c-ad30-c552c3aea3b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[His, father, was, a, surveyor, and, tavern, o...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-PER,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[His, family, moved, to, Ohio, and, settled, n...</td>\n",
              "      <td>[O, O, O, O, B-LOC, O, O, O, B-LOC, O, O, O, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[His, family, moved, to, Covington, during, hi...</td>\n",
              "      <td>[O, O, O, O, B-LOC, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[The, first, verse, is, shared, by, Jo, O'Mear...</td>\n",
              "      <td>[O, O, O, O, O, O, B-PER, I-PER, O, B-PER, I-P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Within, city, limits, ,, the, southwestern, f...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-ANIM, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16449</th>\n",
              "      <td>[The, protesters, are, calling, for, an, end, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-PER, I-PER...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16450</th>\n",
              "      <td>[\", The, fact, is, that, much, of, the, eviden...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16451</th>\n",
              "      <td>[The, is, expected, to, vote, later, today, on...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, I-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16452</th>\n",
              "      <td>[The, five, permanent, members, of, the, counc...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16453</th>\n",
              "      <td>[The, New, England, Patriots, hired, him, as, ...</td>\n",
              "      <td>[O, B-ORG, I-ORG, I-ORG, O, O, O, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16454 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75271661-f7e1-486c-ad30-c552c3aea3b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-75271661-f7e1-486c-ad30-c552c3aea3b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-75271661-f7e1-486c-ad30-c552c3aea3b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e66e1913-d74f-48d7-9334-70a81f472bd6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e66e1913-d74f-48d7-9334-70a81f472bd6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e66e1913-d74f-48d7-9334-70a81f472bd6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1222a656-fe6f-49ec-9a3f-ec2a33d1359f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1222a656-fe6f-49ec-9a3f-ec2a33d1359f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 16454,\n  \"fields\": [\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wdv02qIvGr30",
        "outputId": "4c7e2ea6-6c49-4573-bd99-599019eb74d3",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    word  \\\n",
              "0      [Between, the, end, of, World, War, II, and, t...   \n",
              "1      [These, ideas, were, prevalent, among, many, i...   \n",
              "2      [Most, are, from, Indonesia, ,, Vietnam, ,, an...   \n",
              "3      [\", ,, \", The, Wild, Thornberrys, \", ,, and, \"...   \n",
              "4      [Rash, guards, are, thought, to, have, origina...   \n",
              "...                                                  ...   \n",
              "16405  [There, are, regular, passenger, train, servic...   \n",
              "16406  [It, still, hosts, the, annual, meeting, of, t...   \n",
              "16407  [Sydney, Wooderson, set, a, world, 3, /, 4-mil...   \n",
              "16408        [They, have, a, son, ,, Suchindra, Bali, .]   \n",
              "16409  [\", Rock, n, Roll, Jesus, \", and, \", Born, Fre...   \n",
              "\n",
              "                                                     tag  \n",
              "0      [O, O, O, O, B-EVE, I-EVE, I-EVE, O, O, O, O, ...  \n",
              "1      [O, O, O, O, O, O, O, O, O, B-LOC, O, B-LOC, O...  \n",
              "2          [O, O, O, B-LOC, O, B-LOC, O, O, O, B-LOC, O]  \n",
              "3      [O, O, O, B-MEDIA, I-MEDIA, I-MEDIA, O, O, O, ...  \n",
              "4      [O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O,...  \n",
              "...                                                  ...  \n",
              "16405          [O, O, O, O, O, O, O, B-LOC, O, B-LOC, O]  \n",
              "16406          [O, O, O, O, O, O, O, O, B-EVE, I-EVE, O]  \n",
              "16407  [B-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O...  \n",
              "16408                   [O, O, O, O, O, B-PER, I-PER, O]  \n",
              "16409  [O, B-MEDIA, I-MEDIA, I-MEDIA, I-MEDIA, O, O, ...  \n",
              "\n",
              "[16410 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce7c057c-d7e7-463e-825b-c11822523dba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Between, the, end, of, World, War, II, and, t...</td>\n",
              "      <td>[O, O, O, O, B-EVE, I-EVE, I-EVE, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[These, ideas, were, prevalent, among, many, i...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-LOC, O, B-LOC, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Most, are, from, Indonesia, ,, Vietnam, ,, an...</td>\n",
              "      <td>[O, O, O, B-LOC, O, B-LOC, O, O, O, B-LOC, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[\", ,, \", The, Wild, Thornberrys, \", ,, and, \"...</td>\n",
              "      <td>[O, O, O, B-MEDIA, I-MEDIA, I-MEDIA, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Rash, guards, are, thought, to, have, origina...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16405</th>\n",
              "      <td>[There, are, regular, passenger, train, servic...</td>\n",
              "      <td>[O, O, O, O, O, O, O, B-LOC, O, B-LOC, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16406</th>\n",
              "      <td>[It, still, hosts, the, annual, meeting, of, t...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-EVE, I-EVE, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16407</th>\n",
              "      <td>[Sydney, Wooderson, set, a, world, 3, /, 4-mil...</td>\n",
              "      <td>[B-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16408</th>\n",
              "      <td>[They, have, a, son, ,, Suchindra, Bali, .]</td>\n",
              "      <td>[O, O, O, O, O, B-PER, I-PER, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16409</th>\n",
              "      <td>[\", Rock, n, Roll, Jesus, \", and, \", Born, Fre...</td>\n",
              "      <td>[O, B-MEDIA, I-MEDIA, I-MEDIA, I-MEDIA, O, O, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16410 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce7c057c-d7e7-463e-825b-c11822523dba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce7c057c-d7e7-463e-825b-c11822523dba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce7c057c-d7e7-463e-825b-c11822523dba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-96330a9b-e65d-4903-92a3-4c91d68b3a4a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96330a9b-e65d-4903-92a3-4c91d68b3a4a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-96330a9b-e65d-4903-92a3-4c91d68b3a4a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3dc99948-f8c8-4207-86d8-98bf32f0ace4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('valid_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3dc99948-f8c8-4207-86d8-98bf32f0ace4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('valid_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "valid_df",
              "summary": "{\n  \"name\": \"valid_df\",\n  \"rows\": 16410,\n  \"fields\": [\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "valid_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5vlJtg-Gr31",
        "outputId": "59ce4858-4ced-4cb5-9752-f776c1f96996",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ner category ['ANIM', 'BIO', 'CEL', 'DIS', 'EVE', 'FOOD', 'INST', 'LOC', 'MEDIA', 'MYTH', 'ORG', 'PER', 'PLANT', 'TIME', 'VEHI'] .\n",
            "\n",
            "label list ['O', 'B-ANIM', 'I-ANIM', 'B-BIO', 'I-BIO', 'B-CEL', 'I-CEL', 'B-DIS', 'I-DIS', 'B-EVE', 'I-EVE', 'B-FOOD', 'I-FOOD', 'B-INST', 'I-INST', 'B-LOC', 'I-LOC', 'B-MEDIA', 'I-MEDIA', 'B-MYTH', 'I-MYTH', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER', 'B-PLANT', 'I-PLANT', 'B-TIME', 'I-TIME', 'B-VEHI', 'I-VEHI'] .\n",
            "\n",
            "label2id {'O': 0, 'B-ANIM': 1, 'I-ANIM': 2, 'B-BIO': 3, 'I-BIO': 4, 'B-CEL': 5, 'I-CEL': 6, 'B-DIS': 7, 'I-DIS': 8, 'B-EVE': 9, 'I-EVE': 10, 'B-FOOD': 11, 'I-FOOD': 12, 'B-INST': 13, 'I-INST': 14, 'B-LOC': 15, 'I-LOC': 16, 'B-MEDIA': 17, 'I-MEDIA': 18, 'B-MYTH': 19, 'I-MYTH': 20, 'B-ORG': 21, 'I-ORG': 22, 'B-PER': 23, 'I-PER': 24, 'B-PLANT': 25, 'I-PLANT': 26, 'B-TIME': 27, 'I-TIME': 28, 'B-VEHI': 29, 'I-VEHI': 30} .\n",
            "\n",
            "id2label {0: 'O', 1: 'B-ANIM', 2: 'I-ANIM', 3: 'B-BIO', 4: 'I-BIO', 5: 'B-CEL', 6: 'I-CEL', 7: 'B-DIS', 8: 'I-DIS', 9: 'B-EVE', 10: 'I-EVE', 11: 'B-FOOD', 12: 'I-FOOD', 13: 'B-INST', 14: 'I-INST', 15: 'B-LOC', 16: 'I-LOC', 17: 'B-MEDIA', 18: 'I-MEDIA', 19: 'B-MYTH', 20: 'I-MYTH', 21: 'B-ORG', 22: 'I-ORG', 23: 'B-PER', 24: 'I-PER', 25: 'B-PLANT', 26: 'I-PLANT', 27: 'B-TIME', 28: 'I-TIME', 29: 'B-VEHI', 30: 'I-VEHI'}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def collect_label(df_list):\n",
        "    ret = set()\n",
        "    for df in df_list:\n",
        "        for labels in df['tag']:\n",
        "            for l in labels:\n",
        "                if l == \"O\":\n",
        "                    continue\n",
        "                assert l.startswith(\"B-\") or l.startswith(\"I-\")\n",
        "                ret.add(l[2:])\n",
        "    return sorted(list(ret))\n",
        "\n",
        "ner_category = collect_label([train_df, valid_df, test_df])\n",
        "label_list = []\n",
        "for l in ner_category:\n",
        "    label_list.append(\"B-\" + l)\n",
        "    label_list.append(\"I-\" + l)\n",
        "label_list = ['O'] + label_list\n",
        "label2id = dict([(v, idx) for idx, v in enumerate(label_list)])\n",
        "id2label = dict([(idx, v) for idx, v in enumerate(label_list)])\n",
        "print(f\"ner category {ner_category} .\\n\\nlabel list {label_list} .\\n\\nlabel2id {label2id} .\\n\\nid2label {id2label}\\n\\n\")\n",
        "label_list = label_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLLN7xMQGr31"
      },
      "source": [
        "## Import Reberta Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290,
          "referenced_widgets": [
            "e7cf939d9ee347029e5e8aebe122746f",
            "ea688d97b8534806810ba4554614018b",
            "fa0fbf29c6e74b0496274460e7f918db",
            "71c00ab2aa194ba6af8680865904af55",
            "1691560fe61545ba968b02f40952caf3",
            "17bb8cdfe4ed43f89f1d651bff4aa772",
            "49ab97c280ee425c9d82a5700807189a",
            "e6048ae45e7e4b40907103d2736dfc1e",
            "9d27df46cb0540fdaabe842fb1a5e13e",
            "663f9f9c11014bceaaf729ee1cd66cd7",
            "431eb6f2ad154284a45a86665e194af1",
            "3373aa0612b744c39e1567bd5087083d",
            "454033d718684b93b49a6d2745c7fae8",
            "c88634852504431caee3893c214b6da4",
            "f37b7f79be3b413095716b9908dd54dd",
            "9192b0332e16483faca5bde28078f707",
            "2dbd0e531d384d67905727fd3ad64618",
            "3978b2780427401ca63e4cbd30b238de",
            "ffb14f208d5e49789f85d06dbf82d99a",
            "50706c9bcac140028d5674d0f40a4488",
            "87560f22138b4bdc99d3042ea4d1d42e",
            "54e7e98c45b14ee2885e11b6da29b43d",
            "d8eec36c3d7f4b1b8f8dd5d474b3c9ab",
            "356a2257137a49a69205a79404b70255",
            "3a35855fa80548939f93cb5260d60c10",
            "9361a395a26a4d45b3f093e6550efa69",
            "8ff28817aca242df8b78d822fc61e3a8",
            "c9d686bdc9f44531b108d994ee9095ee",
            "dbfbed96628748cf8f9e6892811d93fb",
            "e3efac9f2a5946928786eb0362c673ff",
            "6c02ffaf8e58435aabb268ef4ffc9c59",
            "e35ebc90417b4f94a68d6eb9240582ae",
            "fb74b3485167460bb130774ad87cdd22",
            "5a75d3b2f15c4e0ebce08471c4d0ff34",
            "ee4d94d8f1d646909910b9bcca2558e5",
            "21aa8b6aac9d4a3aad75ea73f2e3dcee",
            "77bf0d276ba74a21b499684ee1b8f9d5",
            "95e4a7a3537542589cf2af5cb039275e",
            "78aeba80651c4379891747735f260a8b",
            "48e14a01ebbb4edb80d560144fc37b97",
            "3bb99885b51743c3a85ff356ae826e2c",
            "7e07fbb53ead452eb29a3f351d70510d",
            "8953bae3e5d343d1b4a6422ba19bdff7",
            "73c88947c60c4225af8721c097bc6226"
          ]
        },
        "id": "Sy1aItuvGr31",
        "outputId": "1ebd4ea4-92f5-4bdf-f250-0bf75c5812a2",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7cf939d9ee347029e5e8aebe122746f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/474 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3373aa0612b744c39e1567bd5087083d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8eec36c3d7f4b1b8f8dd5d474b3c9ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a75d3b2f15c4e0ebce08471c4d0ff34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(Config.model_name, add_prefix_space=True)\n",
        "print(tokenizer.is_fast)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvXSJptjGr31"
      },
      "source": [
        "## tokenize and build Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G49tIcsZGr31",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def align(tag, word_ids):\n",
        "    aligned_tag = []\n",
        "    i = 0\n",
        "    while i < len(word_ids):\n",
        "        if word_ids[i] is None:\n",
        "            aligned_tag.append(None)\n",
        "            i += 1\n",
        "        elif tag[word_ids[i]] == \"O\":\n",
        "            aligned_tag.append(tag[word_ids[i]])\n",
        "            i += 1\n",
        "        elif tag[word_ids[i]].startswith(\"B-\"):\n",
        "            n = 0\n",
        "            while (i+n) < len(word_ids) and word_ids[i]  == word_ids[i+n]:\n",
        "                n += 1\n",
        "            aligned_tag.append(tag[word_ids[i]])\n",
        "            if n > 1:\n",
        "                aligned_tag.extend([\"I-\" + tag[word_ids[i]][2:] ] * (n-1))\n",
        "            i = i + n\n",
        "        else:\n",
        "            aligned_tag.append(tag[word_ids[i]])\n",
        "            i += 1\n",
        "    return aligned_tag\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LldB9JC9Gr31",
        "outputId": "a4924a01-f825-4936-e66a-688f06044907",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', '1996-08-22', '1996-08-22', 'I'] ['O', 'B-LOC', 'B-ORG', 'O']\n",
            "   tokens   tags  word-index\n",
            "0   [CLS]   None         NaN\n",
            "1      ĠI      O         0.0\n",
            "2   Ġ1996  B-LOC         1.0\n",
            "3       -  I-LOC         1.0\n",
            "4      08  I-LOC         1.0\n",
            "5       -  I-LOC         1.0\n",
            "6      22  I-LOC         1.0\n",
            "7   Ġ1996  B-ORG         2.0\n",
            "8       -  I-ORG         2.0\n",
            "9      08  I-ORG         2.0\n",
            "10      -  I-ORG         2.0\n",
            "11     22  I-ORG         2.0\n",
            "12     ĠI      O         3.0\n",
            "13  [SEP]   None         NaN\n"
          ]
        }
      ],
      "source": [
        "#words = train_df.iloc[2][\"word\"]\n",
        "#tag = train_df.iloc[2][\"label\"]\n",
        "words = ['I', '1996-08-22', '1996-08-22', 'I']\n",
        "tag = [\"O\", \"B-LOC\", \"B-ORG\", \"O\"]\n",
        "print(words, tag)\n",
        "s = tokenizer(words, truncation=True, is_split_into_words=True)\n",
        "word_ids = s.word_ids()\n",
        "# align tokens and words\n",
        "tokens = tokenizer.convert_ids_to_tokens(s['input_ids'])\n",
        "tags = align(tag, s.word_ids())\n",
        "print(pd.DataFrame(list(zip(tokens, tags, word_ids)), columns=['tokens', 'tags', 'word-index']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3i02DNiGr31",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def preprocess(x):\n",
        "    word = x['word']\n",
        "    r = tokenizer(word, truncation=True, is_split_into_words=True)\n",
        "    word_ids = r.word_ids()\n",
        "    tokens = tokenizer.convert_ids_to_tokens(r['input_ids'])\n",
        "    align_label = align(x['tag'], word_ids)\n",
        "    return tokens, align_label, r['input_ids'], [label2id[i] if i is not None else -100  for i in align_label], word_ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmnu0LUoGr31",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_df[['token', 'label', 'id', 'label_id', 'word_ids']] = train_df.apply(lambda x: pd.Series(preprocess(x)), axis=1)\n",
        "valid_df[['token', 'label', 'id', 'label_id', 'word_ids']] = valid_df.apply(lambda x: pd.Series(preprocess(x)), axis=1)\n",
        "test_df[['token', 'label', 'id', 'label_id', 'word_ids']] = test_df.apply(lambda x: pd.Series(preprocess(x)), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "id": "LHAT0xb_Gr32",
        "outputId": "14803a38-04f5-480d-8e3f-3e349bae774b",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    word  \\\n",
              "0      [His, father, was, a, surveyor, and, tavern, o...   \n",
              "1      [His, family, moved, to, Ohio, and, settled, n...   \n",
              "2      [His, family, moved, to, Covington, during, hi...   \n",
              "3      [The, first, verse, is, shared, by, Jo, O'Mear...   \n",
              "4      [Within, city, limits, ,, the, southwestern, f...   \n",
              "...                                                  ...   \n",
              "16449  [The, protesters, are, calling, for, an, end, ...   \n",
              "16450  [\", The, fact, is, that, much, of, the, eviden...   \n",
              "16451  [The, is, expected, to, vote, later, today, on...   \n",
              "16452  [The, five, permanent, members, of, the, counc...   \n",
              "16453  [The, New, England, Patriots, hired, him, as, ...   \n",
              "\n",
              "                                                     tag  \\\n",
              "0      [O, O, O, O, O, O, O, O, O, O, O, O, O, B-PER,...   \n",
              "1      [O, O, O, O, B-LOC, O, O, O, B-LOC, O, O, O, O...   \n",
              "2                        [O, O, O, O, B-LOC, O, O, O, O]   \n",
              "3      [O, O, O, O, O, O, B-PER, I-PER, O, B-PER, I-P...   \n",
              "4           [O, O, O, O, O, O, O, O, O, B-ANIM, O, O, O]   \n",
              "...                                                  ...   \n",
              "16449  [O, O, O, O, O, O, O, O, O, O, O, B-PER, I-PER...   \n",
              "16450  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "16451  [O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, I-...   \n",
              "16452  [O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O,...   \n",
              "16453  [O, B-ORG, I-ORG, I-ORG, O, O, O, O, O, O, O, ...   \n",
              "\n",
              "                                                   token  \\\n",
              "0      [[CLS], ĠHis, Ġfather, Ġwas, Ġa, Ġsurvey, or, ...   \n",
              "1      [[CLS], ĠHis, Ġfamily, Ġmoved, Ġto, ĠOhio, Ġan...   \n",
              "2      [[CLS], ĠHis, Ġfamily, Ġmoved, Ġto, ĠC, oving,...   \n",
              "3      [[CLS], ĠThe, Ġfirst, Ġverse, Ġis, Ġshared, Ġb...   \n",
              "4      [[CLS], ĠWithin, Ġcity, Ġlimits, Ġ,, Ġthe, Ġso...   \n",
              "...                                                  ...   \n",
              "16449  [[CLS], ĠThe, Ġprotesters, Ġare, Ġcalling, Ġfo...   \n",
              "16450  [[CLS], Ġ\", ĠThe, Ġfact, Ġis, Ġthat, Ġmuch, Ġo...   \n",
              "16451  [[CLS], ĠThe, Ġis, Ġexpected, Ġto, Ġvote, Ġlat...   \n",
              "16452  [[CLS], ĠThe, Ġfive, Ġpermanent, Ġmembers, Ġof...   \n",
              "16453  [[CLS], ĠThe, ĠNew, ĠEngland, ĠPatriots, Ġhire...   \n",
              "\n",
              "                                                   label  \\\n",
              "0      [None, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "1      [None, O, O, O, O, B-LOC, O, O, O, B-LOC, O, O...   \n",
              "2      [None, O, O, O, O, B-LOC, I-LOC, I-LOC, O, O, ...   \n",
              "3      [None, O, O, O, O, O, O, B-PER, I-PER, I-PER, ...   \n",
              "4      [None, O, O, O, O, O, O, O, O, O, B-ANIM, I-AN...   \n",
              "...                                                  ...   \n",
              "16449  [None, O, O, O, O, O, O, O, O, O, O, O, B-PER,...   \n",
              "16450  [None, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "16451  [None, O, O, O, O, O, O, O, O, O, O, O, O, B-L...   \n",
              "16452  [None, O, O, O, O, O, O, O, O, B-LOC, O, O, O,...   \n",
              "16453  [None, O, B-ORG, I-ORG, I-ORG, O, O, O, O, O, ...   \n",
              "\n",
              "                                                      id  \\\n",
              "0      [1, 832, 1150, 21, 10, 2658, 368, 8, 40128, 19...   \n",
              "1      [1, 832, 284, 1410, 7, 2042, 8, 5668, 583, 632...   \n",
              "2      [1, 832, 284, 1410, 7, 230, 13871, 1054, 148, ...   \n",
              "3      [1, 20, 78, 26346, 16, 1373, 30, 3889, 384, 10...   \n",
              "4      [1, 9842, 343, 4971, 2156, 5, 20431, 8146, 417...   \n",
              "...                                                  ...   \n",
              "16449  [1, 20, 4800, 32, 1765, 13, 41, 253, 9, 5, 430...   \n",
              "16450  [1, 22, 20, 754, 16, 14, 203, 9, 5, 1283, 115,...   \n",
              "16451  [1, 20, 16, 421, 7, 900, 423, 452, 15, 549, 7,...   \n",
              "16452  [1, 20, 292, 4398, 453, 9, 5, 1676, 8, 1429, 1...   \n",
              "16453  [1, 20, 188, 1156, 4314, 4547, 123, 25, 49, 32...   \n",
              "\n",
              "                                                label_id  \\\n",
              "0      [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "1      [-100, 0, 0, 0, 0, 15, 0, 0, 0, 15, 0, 0, 0, 0...   \n",
              "2       [-100, 0, 0, 0, 0, 15, 16, 16, 0, 0, 0, 0, -100]   \n",
              "3      [-100, 0, 0, 0, 0, 0, 0, 23, 24, 24, 24, 24, 2...   \n",
              "4      [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, ...   \n",
              "...                                                  ...   \n",
              "16449  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23, 24...   \n",
              "16450  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "16451  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15,...   \n",
              "16452  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 15, 0, 0, 0, 0,...   \n",
              "16453  [-100, 0, 21, 22, 22, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                                word_ids  \n",
              "0      [None, 0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11...  \n",
              "1      [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1...  \n",
              "2          [None, 0, 1, 2, 3, 4, 4, 4, 5, 6, 7, 8, None]  \n",
              "3      [None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 8, ...  \n",
              "4      [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 10,...  \n",
              "...                                                  ...  \n",
              "16449  [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1...  \n",
              "16450  [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1...  \n",
              "16451  [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1...  \n",
              "16452  [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1...  \n",
              "16453  [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1...  \n",
              "\n",
              "[16454 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb736ee0-5664-4d2e-8076-564a69f01fcd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>token</th>\n",
              "      <th>label</th>\n",
              "      <th>id</th>\n",
              "      <th>label_id</th>\n",
              "      <th>word_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[His, father, was, a, surveyor, and, tavern, o...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-PER,...</td>\n",
              "      <td>[[CLS], ĠHis, Ġfather, Ġwas, Ġa, Ġsurvey, or, ...</td>\n",
              "      <td>[None, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[1, 832, 1150, 21, 10, 2658, 368, 8, 40128, 19...</td>\n",
              "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[None, 0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[His, family, moved, to, Ohio, and, settled, n...</td>\n",
              "      <td>[O, O, O, O, B-LOC, O, O, O, B-LOC, O, O, O, O...</td>\n",
              "      <td>[[CLS], ĠHis, Ġfamily, Ġmoved, Ġto, ĠOhio, Ġan...</td>\n",
              "      <td>[None, O, O, O, O, B-LOC, O, O, O, B-LOC, O, O...</td>\n",
              "      <td>[1, 832, 284, 1410, 7, 2042, 8, 5668, 583, 632...</td>\n",
              "      <td>[-100, 0, 0, 0, 0, 15, 0, 0, 0, 15, 0, 0, 0, 0...</td>\n",
              "      <td>[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[His, family, moved, to, Covington, during, hi...</td>\n",
              "      <td>[O, O, O, O, B-LOC, O, O, O, O]</td>\n",
              "      <td>[[CLS], ĠHis, Ġfamily, Ġmoved, Ġto, ĠC, oving,...</td>\n",
              "      <td>[None, O, O, O, O, B-LOC, I-LOC, I-LOC, O, O, ...</td>\n",
              "      <td>[1, 832, 284, 1410, 7, 230, 13871, 1054, 148, ...</td>\n",
              "      <td>[-100, 0, 0, 0, 0, 15, 16, 16, 0, 0, 0, 0, -100]</td>\n",
              "      <td>[None, 0, 1, 2, 3, 4, 4, 4, 5, 6, 7, 8, None]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[The, first, verse, is, shared, by, Jo, O'Mear...</td>\n",
              "      <td>[O, O, O, O, O, O, B-PER, I-PER, O, B-PER, I-P...</td>\n",
              "      <td>[[CLS], ĠThe, Ġfirst, Ġverse, Ġis, Ġshared, Ġb...</td>\n",
              "      <td>[None, O, O, O, O, O, O, B-PER, I-PER, I-PER, ...</td>\n",
              "      <td>[1, 20, 78, 26346, 16, 1373, 30, 3889, 384, 10...</td>\n",
              "      <td>[-100, 0, 0, 0, 0, 0, 0, 23, 24, 24, 24, 24, 2...</td>\n",
              "      <td>[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 8, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Within, city, limits, ,, the, southwestern, f...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-ANIM, O, O, O]</td>\n",
              "      <td>[[CLS], ĠWithin, Ġcity, Ġlimits, Ġ,, Ġthe, Ġso...</td>\n",
              "      <td>[None, O, O, O, O, O, O, O, O, O, B-ANIM, I-AN...</td>\n",
              "      <td>[1, 9842, 343, 4971, 2156, 5, 20431, 8146, 417...</td>\n",
              "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, ...</td>\n",
              "      <td>[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 10,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16449</th>\n",
              "      <td>[The, protesters, are, calling, for, an, end, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-PER, I-PER...</td>\n",
              "      <td>[[CLS], ĠThe, Ġprotesters, Ġare, Ġcalling, Ġfo...</td>\n",
              "      <td>[None, O, O, O, O, O, O, O, O, O, O, O, B-PER,...</td>\n",
              "      <td>[1, 20, 4800, 32, 1765, 13, 41, 253, 9, 5, 430...</td>\n",
              "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23, 24...</td>\n",
              "      <td>[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16450</th>\n",
              "      <td>[\", The, fact, is, that, much, of, the, eviden...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[[CLS], Ġ\", ĠThe, Ġfact, Ġis, Ġthat, Ġmuch, Ġo...</td>\n",
              "      <td>[None, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[1, 22, 20, 754, 16, 14, 203, 9, 5, 1283, 115,...</td>\n",
              "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16451</th>\n",
              "      <td>[The, is, expected, to, vote, later, today, on...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, I-...</td>\n",
              "      <td>[[CLS], ĠThe, Ġis, Ġexpected, Ġto, Ġvote, Ġlat...</td>\n",
              "      <td>[None, O, O, O, O, O, O, O, O, O, O, O, O, B-L...</td>\n",
              "      <td>[1, 20, 16, 421, 7, 900, 423, 452, 15, 549, 7,...</td>\n",
              "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15,...</td>\n",
              "      <td>[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16452</th>\n",
              "      <td>[The, five, permanent, members, of, the, counc...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O,...</td>\n",
              "      <td>[[CLS], ĠThe, Ġfive, Ġpermanent, Ġmembers, Ġof...</td>\n",
              "      <td>[None, O, O, O, O, O, O, O, O, B-LOC, O, O, O,...</td>\n",
              "      <td>[1, 20, 292, 4398, 453, 9, 5, 1676, 8, 1429, 1...</td>\n",
              "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 15, 0, 0, 0, 0,...</td>\n",
              "      <td>[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16453</th>\n",
              "      <td>[The, New, England, Patriots, hired, him, as, ...</td>\n",
              "      <td>[O, B-ORG, I-ORG, I-ORG, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[[CLS], ĠThe, ĠNew, ĠEngland, ĠPatriots, Ġhire...</td>\n",
              "      <td>[None, O, B-ORG, I-ORG, I-ORG, O, O, O, O, O, ...</td>\n",
              "      <td>[1, 20, 188, 1156, 4314, 4547, 123, 25, 49, 32...</td>\n",
              "      <td>[-100, 0, 21, 22, 22, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16454 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb736ee0-5664-4d2e-8076-564a69f01fcd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb736ee0-5664-4d2e-8076-564a69f01fcd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb736ee0-5664-4d2e-8076-564a69f01fcd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-97641039-3713-45ff-bbac-11d594fe9ce7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97641039-3713-45ff-bbac-11d594fe9ce7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-97641039-3713-45ff-bbac-11d594fe9ce7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_25d4ef89-7752-4fb9-91e9-24b0016c0f8c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_25d4ef89-7752-4fb9-91e9-24b0016c0f8c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 16454,\n  \"fields\": [\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"token\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_id\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWRSGLs4Gr32"
      },
      "source": [
        "## Building Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNHgo_2cGr32",
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "class NerDataset(Dataset):\n",
        "    def __init__(self, df, device):\n",
        "        self.data = df.to_dict(orient='records')\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.data[item]\n",
        "\n",
        "    def collate_to_max_length(self, batch):\n",
        "        max_seq_length = max([len(s['id']) for s in batch])\n",
        "        batch = sorted(batch, key=lambda x: -len(x['id']))\n",
        "        seq_length = torch.tensor([len(x['id']) for x in batch])\n",
        "        input_ids = torch.tensor([x[\"id\"] + [0] * (max_seq_length - len(x['id'])) for x in batch]).to(self.device)\n",
        "        labels = torch.tensor([x[\"label_id\"] + [-100] * (max_seq_length - len(x['label_id'])) for x in batch]).to(self.device)\n",
        "        return {\"id\": input_ids, \"label_id\": labels, 'seq_length':seq_length, \"sample\":batch}\n",
        "\n",
        "\n",
        "dataset_train = NerDataset(train_df, Config.device)\n",
        "\n",
        "train_dataloader = DataLoader(dataset_train,\n",
        "                              sampler=RandomSampler(dataset_train),\n",
        "                              batch_size=Config.batch_size,\n",
        "                              drop_last=False,\n",
        "                              collate_fn=dataset_train.collate_to_max_length)\n",
        "\n",
        "\n",
        "\n",
        "dataset_valid = NerDataset(valid_df, Config.device)\n",
        "\n",
        "valid_dataloader = DataLoader(dataset_valid,\n",
        "                              sampler=RandomSampler(dataset_valid),\n",
        "                              batch_size=Config.batch_size,\n",
        "                              drop_last=False,\n",
        "                              collate_fn=dataset_valid.collate_to_max_length)\n",
        "\n",
        "\n",
        "dataset_test = NerDataset(test_df, Config.device)\n",
        "\n",
        "test_dataloader = DataLoader(dataset_test,\n",
        "                              sampler=RandomSampler(dataset_test),\n",
        "                              batch_size=Config.batch_size,\n",
        "                              drop_last=False,\n",
        "                              collate_fn=dataset_test.collate_to_max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5B33GkMGr32"
      },
      "source": [
        "## Building Custom loss functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp_D66RpGr32",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "class L1_Loss:\n",
        "    def __init__(self):\n",
        "        self.l1_loss = nn.L1Loss()\n",
        "    def loss(self, target, logit, label_num):\n",
        "\n",
        "        target = target.view(-1)\n",
        "        logit = logit.view(-1, label_num)\n",
        "        mask = target.ne(-100).to(logit.device)\n",
        "        logit = torch.masked_select(logit, mask.unsqueeze(-1).expand_as(logit)).reshape(-1, label_num)\n",
        "        target = torch.masked_select(target, mask)\n",
        "\n",
        "        target = F.one_hot(target, num_classes=label_num)\n",
        "        return self.l1_loss(logit, target.float())\n",
        "\n",
        "\n",
        "class L2_Loss:\n",
        "    def __init__(self):\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "    def loss(self, target, logit,label_num):\n",
        "        target = target.view(-1)\n",
        "        logit = logit.view(-1, label_num)\n",
        "        mask = target.ne(-100).to(logit.device)\n",
        "        logit = torch.masked_select(logit, mask.unsqueeze(-1).expand_as(logit)).reshape(-1, label_num)\n",
        "        target = torch.masked_select(target, mask)\n",
        "\n",
        "        target = F.one_hot(target, num_classes=label_num)\n",
        "        loss = self.mse_loss(logit, target.float())\n",
        "        return loss\n",
        "\n",
        "class CE_Loss:\n",
        "    def __init__(self):\n",
        "        self.ce_loss = nn.CrossEntropyLoss(ignore_index=-100, reduce='mean')\n",
        "    def loss(self, target, logit, label_num):\n",
        "        return self.ce_loss(logit.reshape(-1, label_num), target.reshape(-1) )\n",
        "\n",
        "class KLDivergenceLoss:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def loss(self, target, logit, label_num):\n",
        "        target = target.view(-1)\n",
        "        logit = logit.view(-1, label_num)\n",
        "\n",
        "        mask = target.ne(-100).to(logit.device)\n",
        "        logit = torch.masked_select(logit, mask.unsqueeze(-1).expand_as(logit)).reshape(-1, label_num)\n",
        "        target = torch.masked_select(target, mask)\n",
        "\n",
        "        probs = F.softmax(logit, dim=-1)\n",
        "\n",
        "        # One-hot encode the targets to get true probabilities\n",
        "        true_probs = F.one_hot(target, num_classes=label_num).float()\n",
        "\n",
        "        mask_true_probs = true_probs > 0\n",
        "\n",
        "        # Calculate g function for non-zero elements using the mask\n",
        "        kl_values = torch.zeros_like(probs)\n",
        "        kl_values[mask_true_probs] = true_probs[mask_true_probs] * torch.log(true_probs[mask_true_probs]/probs[mask_true_probs])\n",
        "\n",
        "        # Sum over all classes and average over the batch size\n",
        "        loss = kl_values.sum(dim=-1).mean()\n",
        "\n",
        "        return loss\n",
        "\n",
        "# DLITE Loss function\n",
        "class DLITELoss:\n",
        "    def __init__(self):\n",
        "        super(DLITELoss, self).__init__()\n",
        "\n",
        "    def loss(self, targets, logits, label_num, epsilon=1e-10):\n",
        "        targets = targets.view(-1)\n",
        "        logits = logits.view(-1, label_num)\n",
        "\n",
        "        mask = targets.ne(-100).to(logits.device)\n",
        "        logits = torch.masked_select(logits, mask.unsqueeze(-1).expand_as(logits)).reshape(-1, label_num)\n",
        "        targets = torch.masked_select(targets, mask)\n",
        "\n",
        "        # Convert logits to probabilities using softmax\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        # One-hot encode the targets to get true probabilities\n",
        "        true_probs = F.one_hot(targets, num_classes=probs.size(-1)).float()\n",
        "\n",
        "        # Define the g function\n",
        "        g_values = torch.abs(probs * (1 - torch.log(probs + epsilon)) - true_probs * (1 - torch.log(true_probs + epsilon)))\n",
        "\n",
        "        # Define the delta_h function\n",
        "        delta_h_values = torch.abs(probs**2 * (1 - 2 * torch.log(probs + epsilon)) - true_probs**2 * (1 - 2 * torch.log(true_probs + epsilon))) / (2 * (probs + true_probs))\n",
        "\n",
        "        # Compute DLITE loss for each class\n",
        "        dl_values = g_values - delta_h_values\n",
        "\n",
        "        # Sum over all classes and average over batch size\n",
        "        loss = dl_values.sum(dim=-1).mean()\n",
        "\n",
        "        return loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0x9wjATtD7Y"
      },
      "source": [
        "## Adding Custom Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bf_rR5pGr32",
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "class LSTMEncoder(nn.Module):\n",
        "    \"\"\"lstm encoder\n",
        "    \"\"\"\n",
        "    def __init__(self, config, hidden_size):\n",
        "        super(LSTMEncoder, self).__init__()\n",
        "        self.lstm = torch.nn.LSTM(hidden_size, hidden_size,\n",
        "                                  num_layers=config.lstm_layer_num, bidirectional=config.bi_lstm,\n",
        "                                  batch_first=True)\n",
        "\n",
        "    def forward(self, hidden_state, seq_length):\n",
        "        sequence_output = pack_padded_sequence(hidden_state, seq_length, batch_first=True)\n",
        "        sequence_output, (h_n, c_n) = self.lstm(sequence_output)\n",
        "        sequence_output, _ = pad_packed_sequence(sequence_output, batch_first=True)\n",
        "        return sequence_output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LinearResidualLayer(nn.Module):\n",
        "    def __init__(self, config, hidden_size, output_dim):\n",
        "        super(LinearResidualLayer, self).__init__()\n",
        "        self.config = config\n",
        "        self.linear_layer1 = nn.Linear(in_features=hidden_size, out_features=output_dim)\n",
        "        self.linear_layer2 = nn.Linear(in_features=output_dim, out_features=output_dim)\n",
        "        self.linear_layer3 = nn.Linear(in_features=output_dim, out_features=output_dim)\n",
        "        self.act_func = nn.ReLU()\n",
        "        if not self.config.only_use_residual:\n",
        "            self.dropout1 = nn.Dropout(config.dropout_prob[0])\n",
        "        self.ln_1 = nn.LayerNorm(output_dim)\n",
        "        if not self.config.only_use_residual:\n",
        "            self.dropout2 = nn.Dropout(config.dropout_prob[1])\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.act_func(self.linear_layer1(x))\n",
        "        # x = self.ln_1(x)\n",
        "\n",
        "        # y = self.dropout1(x) + self.dropout1(self.act_func(self.linear_layer2(x) )  )\n",
        "        # y = self.ln_2(y)\n",
        "        # z = self.dropout2(x) + self.dropout1(y) + self.dropout2(self.act_func(self.linear_layer3(y) )  )\n",
        "\n",
        "        x = self.act_func(self.linear_layer1(x))\n",
        "        x = self.ln_1(x)\n",
        "\n",
        "        if self.config.only_use_residual:\n",
        "            y = x + self.act_func(self.linear_layer2(x) )\n",
        "            z = x + y + self.act_func(self.linear_layer3(y) )\n",
        "        elif self.config.only_use_residual_and_dropout:\n",
        "            y = self.dropout1(x) + self.act_func(self.linear_layer2(x) )\n",
        "            z = self.dropout2(x) + self.dropout1(y) + self.act_func(self.linear_layer3(y) )\n",
        "        else:\n",
        "            assert ValueError(\"config error\")\n",
        "        return z\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Ner_Model(nn.Module):\n",
        "    def __init__(self,config, label_num, loss_name):\n",
        "        super(Ner_Model, self).__init__()\n",
        "        self.config = config\n",
        "        # deberat model\n",
        "        self.model = transformers.AutoModel.from_pretrained(config.model_name)\n",
        "\n",
        "        hidden_size = config.hidden_size\n",
        "\n",
        "        # using linear layer\n",
        "        linear_layer = []\n",
        "        if self.config.linear_layer_num  > 0:\n",
        "            # using linear layer\n",
        "            if self.config.only_use_standard_linear_layer:\n",
        "                for out_dim in config.linear_layer[0:config.linear_layer_num]:\n",
        "                    linear_layer.append( nn.Linear(in_features=hidden_size, out_features=out_dim) )\n",
        "                    linear_layer.append( nn.ReLU() )\n",
        "                    hidden_size = out_dim\n",
        "                self.linear_model = nn.Sequential(*linear_layer)\n",
        "            # just use dropout\n",
        "            elif self.config.only_use_dropout:\n",
        "                for i, out_dim in enumerate(config.linear_layer[0:config.linear_layer_num]):\n",
        "                    linear_layer.append( nn.Linear(in_features=hidden_size, out_features=out_dim) )\n",
        "                    linear_layer.append( nn.ReLU() )\n",
        "                    linear_layer.append( nn.Dropout(config.dropout_prob[i]) )\n",
        "                    hidden_size = out_dim\n",
        "                self.linear_model = nn.Sequential(*linear_layer)\n",
        "            else:\n",
        "                # use 3 linear layer for skip 2 dropout\n",
        "                assert config.linear_layer[0] == config.linear_layer[1] == config.linear_layer[2]\n",
        "                assert len(config.dropout_prob) == 2\n",
        "                self.linear_model = LinearResidualLayer(config, hidden_size,config.linear_layer[0])\n",
        "                hidden_size = config.linear_layer[0]\n",
        "\n",
        "        # whether to use lstm layer\n",
        "        if config.lstm_layer_num > 0:\n",
        "            self.lstm = LSTMEncoder(config,hidden_size)\n",
        "\n",
        "        # identify label number\n",
        "        self.label_num = label_num\n",
        "\n",
        "        # whether to use bi-lstm layer\n",
        "        if config.bi_lstm and config.lstm_layer_num > 0:\n",
        "            hidden_size = hidden_size * 2\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_size, label_num)\n",
        "\n",
        "        if loss_name == 'ce':\n",
        "            self.loss_func = CE_Loss()\n",
        "        elif loss_name == 'l1':\n",
        "            self.loss_func = L1_Loss()\n",
        "        elif loss_name == 'l2':\n",
        "            self.loss_func = L2_Loss()\n",
        "        elif loss_name == 'kl':\n",
        "            self.loss_func = KLDivergenceLoss()\n",
        "        elif loss_name == 'dlite':\n",
        "            self.loss_func = DLITELoss()\n",
        "        else:\n",
        "            assert 1==0\n",
        "\n",
        "        print(\"model configuration\")\n",
        "        print(\"%\" * 20)\n",
        "        print(self)\n",
        "        print(\"%\" * 20)\n",
        "\n",
        "    def forward(self, input_ids, seq_length, attention_mask, labels):\n",
        "        output = self.model(input_ids, attention_mask)\n",
        "        sequence_output = output[0]\n",
        "        if self.config.linear_layer_num > 0:\n",
        "            sequence_output = self.linear_model(sequence_output)\n",
        "\n",
        "        if self.config.lstm_layer_num > 0:\n",
        "            sequence_output = self.lstm(sequence_output, seq_length)\n",
        "\n",
        "        logit = self.classifier(sequence_output)\n",
        "        loss = self.loss_func.loss(labels, logit, len(label2id))\n",
        "        return loss, logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8F51tFmwGr32",
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Building optimizer\n",
        "def get_optimizer(model, config):\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "\n",
        "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.1},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "\n",
        "    optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                      betas=(0.9, 0.98),\n",
        "                      lr=config.lr)\n",
        "    return optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uXq2R_yGr32"
      },
      "source": [
        "## Defining the training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDIJoYpWGr33",
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate(model, data_loader, mode=\"Validation\"):\n",
        "    ground_truth, predict = [], []\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples = 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for step, batch in enumerate(data_loader):\n",
        "            attention_mask = batch[\"id\"].ne(0)\n",
        "            targets = batch['label_id']\n",
        "            loss, logit = model(batch[\"id\"], batch['seq_length'], attention_mask=attention_mask,\n",
        "                                             labels=targets)\n",
        "            eval_loss += loss.cpu().item()\n",
        "            if (step+1) % 100==0:\n",
        "                loss_step = eval_loss / (step+1)\n",
        "                print(f\"{mode} loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "            # compute training accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = logit.view(-1, len(label2id)) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            active_accuracy = flattened_targets.ne(-100) # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "            eval_preds.extend(predictions.tolist())\n",
        "            eval_labels.extend(targets.tolist())\n",
        "\n",
        "    eval_loss = eval_loss / (step+1)\n",
        "    eval_accuracy = eval_accuracy / (step+1)\n",
        "    eval_labels,eval_preds = [id2label[i] for i in eval_labels], [id2label[i] for i in eval_preds]\n",
        "\n",
        "\n",
        "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(eval_labels, eval_preds, average='micro')\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(eval_labels, eval_preds, average='macro')\n",
        "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(eval_labels, eval_preds,average='weighted')\n",
        "\n",
        "    p_r_f1 = [[round(precision_micro,4), round(recall_micro,4), round(f1_micro,4)],\n",
        "              [round(precision_macro,4), round(recall_macro,4), round(f1_macro,4)],\n",
        "              [round(precision_weighted,4), round(recall_weighted,4), round(f1_weighted,4)]]\n",
        "\n",
        "    p_r_f1 = pd.DataFrame(p_r_f1, columns=['precision', 'recall', 'f1'], index=['micro', 'macro', 'weighted'])\n",
        "\n",
        "    print(f\"{mode} Loss: {eval_loss}\")\n",
        "    print(f\"{mode} Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    p_r_f1_each_label = classification_report(eval_labels, eval_preds)\n",
        "    print(f\"{mode} P-R-F1 for each label: \\n{p_r_f1_each_label}\")\n",
        "    print(f\"{mode} P-R-F1 tor all label: \\n{p_r_f1}\")\n",
        "    print(f\"{mode} steps: {(step+1)}\")\n",
        "    return eval_loss, p_r_f1, p_r_f1_each_label\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMapwwmhGr33"
      },
      "source": [
        "## Running under 5 custom loss functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzSeh-WWGr33",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "loss_list = ['l1', 'l2', 'ce', 'kl', 'dlite']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b39c00b74f694027bf1612220844ca84",
            "41eb080f04ef43e7ba983c3736c85a91",
            "42df3774479f4e358cf371d2a69c07cf",
            "d75e64d99b794a92997bc1c16657f220",
            "98be5ad67d484e09861ae49fff07a7b4",
            "04e365082e01489f9e307cfefcf230be",
            "cf0044d481f5469fa2a736687d22ab49",
            "21562caa166a4440903175911dab6e91",
            "f3f1c97a80a346c0af630c091c91be67",
            "a9ade83b2ccf4923a7afc52580bcdfaa",
            "7d4258b7a8fd47bf95be0c33eeeaccf5"
          ]
        },
        "id": "n6U0QqPKGr33",
        "outputId": "2ddd95e1-17f5-4465-ec59-4e36295fc8f0",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "loss_name: l1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/559M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b39c00b74f694027bf1612220844ca84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model configuration\n",
            "%%%%%%%%%%%%%%%%%%%%\n",
            "Ner_Model(\n",
            "  (model): DebertaModel(\n",
            "    (embeddings): DebertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
            "      (LayerNorm): DebertaLayerNorm()\n",
            "      (dropout): StableDropout()\n",
            "    )\n",
            "    (encoder): DebertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x DebertaLayer(\n",
            "          (attention): DebertaAttention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): DebertaLayerNorm()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): DebertaLayerNorm()\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (rel_embeddings): Embedding(1024, 768)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Linear(in_features=768, out_features=31, bias=True)\n",
            ")\n",
            "%%%%%%%%%%%%%%%%%%%%\n",
            "Training epoch: 1\n",
            "Training loss per 100 training steps: 0.17184671353548764\n",
            "Training loss per 100 training steps: 0.11047852605581283\n",
            "Training loss per 100 training steps: 0.08658582995335261\n",
            "Training loss per 100 training steps: 0.07354705608915538\n",
            "Training loss per 100 training steps: 0.06505286959558726\n",
            "Training loss per 100 training steps: 0.05909484507516027\n",
            "Training loss per 100 training steps: 0.05453220608511141\n",
            "Training loss per 100 training steps: 0.051036015546415\n",
            "Training loss per 100 training steps: 0.04792430096616348\n",
            "Training loss per 100 training steps: 0.04521461743116379\n",
            "Training loss per 100 training steps: 0.042899930052120575\n",
            "Training loss per 100 training steps: 0.0409454978397116\n",
            "Training loss per 100 training steps: 0.03920423031139832\n",
            "Training loss per 100 training steps: 0.037704711060172744\n",
            "Training loss per 100 training steps: 0.03638481154106557\n",
            "Training loss per 100 training steps: 0.035172620430821554\n",
            "Training loss per 100 training steps: 0.03407851442475529\n",
            "Training loss per 100 training steps: 0.03309982328934388\n",
            "Training loss per 100 training steps: 0.03218952600795187\n",
            "Training loss per 100 training steps: 0.03134742839261889\n",
            "Training loss per 100 training steps: 0.030563342098944953\n",
            "Training loss per 100 training steps: 0.029827365884980694\n",
            "Training loss per 100 training steps: 0.029136947781333456\n",
            "Training loss per 100 training steps: 0.028497100904739153\n",
            "Training loss per 100 training steps: 0.027892896988242863\n",
            "Training loss per 100 training steps: 0.027298499253005364\n",
            "Training loss per 100 training steps: 0.026759350916922643\n",
            "Training loss per 100 training steps: 0.02625805275082322\n",
            "Training loss per 100 training steps: 0.025781675667084496\n",
            "Training loss per 100 training steps: 0.025310081084569294\n",
            "Training loss per 100 training steps: 0.024884392778959968\n",
            "Training loss per 100 training steps: 0.024478159690042956\n",
            "Training loss per 100 training steps: 0.024108367611682325\n",
            "Training loss per 100 training steps: 0.02375248852185905\n",
            "Training loss per 100 training steps: 0.02339159819111228\n",
            "Training loss per 100 training steps: 0.023052479926393265\n",
            "Training loss per 100 training steps: 0.02273379667599157\n",
            "Training loss per 100 training steps: 0.02242805722365646\n",
            "Training loss per 100 training steps: 0.02213196870500747\n",
            "Training loss per 100 training steps: 0.02185352153365966\n",
            "Training loss per 100 training steps: 0.021582838553685424\n",
            "Training loss per 100 training steps: 0.0213078910783155\n",
            "Training loss per 100 training steps: 0.02106375451221369\n",
            "Training loss per 100 training steps: 0.020817973847416314\n",
            "Training loss per 100 training steps: 0.020575288920663296\n",
            "Training loss per 100 training steps: 0.020346271902343015\n",
            "Training loss per 100 training steps: 0.020128970147863506\n",
            "Training loss per 100 training steps: 0.0199095420584005\n",
            "Training loss per 100 training steps: 0.019706352228792953\n",
            "Training loss per 100 training steps: 0.01951990222251043\n",
            "Training loss per 100 training steps: 0.019324431550031638\n",
            "Training loss per 100 training steps: 0.019132067993229543\n",
            "Training loss per 100 training steps: 0.018942461633562762\n",
            "Training loss per 100 training steps: 0.01877188748895639\n",
            "Training loss per 100 training steps: 0.018595465766858648\n",
            "Training loss per 100 training steps: 0.0184271138153937\n",
            "Training loss per 100 training steps: 0.01826404449595302\n",
            "Training loss per 100 training steps: 0.01811728118517404\n",
            "Training loss per 100 training steps: 0.017971273959866897\n",
            "Training loss per 100 training steps: 0.017824470597086476\n",
            "Training loss per 100 training steps: 0.017680475452960635\n",
            "Training loss per 100 training steps: 0.017534768882117444\n",
            "Training loss per 100 training steps: 0.017401093827220538\n",
            "Training loss per 100 training steps: 0.017269625759290648\n",
            "Training loss per 100 training steps: 0.017140966821963397\n",
            "Training loss per 100 training steps: 0.017009117604219214\n",
            "Training loss per 100 training steps: 0.01688808083965151\n",
            "Training loss per 100 training steps: 0.01676563227946377\n",
            "Training loss per 100 training steps: 0.016649580342708616\n",
            "Training loss per 100 training steps: 0.0165324729842666\n",
            "Training loss per 100 training steps: 0.01641937503204222\n",
            "Training loss per 100 training steps: 0.016312196234034168\n",
            "Training loss per 100 training steps: 0.01620744299864371\n",
            "Training loss per 100 training steps: 0.016100347058570667\n",
            "Training loss per 100 training steps: 0.015996383693379662\n",
            "Training loss per 100 training steps: 0.015896964812418445\n",
            "Training loss per 100 training steps: 0.01580110009983424\n",
            "Training loss per 100 training steps: 0.01571440704841501\n",
            "Training loss per 100 training steps: 0.01561924325060571\n",
            "Training loss per 100 training steps: 0.015531059556698892\n",
            "Training loss per 100 training steps: 0.015443359803074947\n",
            "Training loss per 100 training steps: 0.015355386253412267\n",
            "Training loss per 100 training steps: 0.01526850619785353\n",
            "Training loss per 100 training steps: 0.015185760584038992\n",
            "Training loss per 100 training steps: 0.015104111210497864\n",
            "Training loss per 100 training steps: 0.015016290146781694\n",
            "Training loss per 100 training steps: 0.014935162914435154\n",
            "Training loss per 100 training steps: 0.014854884154867085\n",
            "Training loss per 100 training steps: 0.014776600974198598\n",
            "Training loss per 100 training steps: 0.014705501215506551\n",
            "Training loss per 100 training steps: 0.01462828305286386\n",
            "Training loss per 100 training steps: 0.014551784753693146\n",
            "Training loss per 100 training steps: 0.014476655188131756\n",
            "Training loss per 100 training steps: 0.014405651468055402\n",
            "Training loss per 100 training steps: 0.01433883547246162\n",
            "Training loss per 100 training steps: 0.014270003813314058\n",
            "Training loss per 100 training steps: 0.014199075692299676\n",
            "Training loss per 100 training steps: 0.014137188061853224\n",
            "Training loss per 100 training steps: 0.014074408061322615\n",
            "Training loss per 100 training steps: 0.014012260616547428\n",
            "Training loss per 100 training steps: 0.013955051312522759\n",
            "Training loss per 100 training steps: 0.013894606335933193\n",
            "Training loss per 100 training steps: 0.013837027515180735\n",
            "Training loss per 100 training steps: 0.013778032994081374\n",
            "Training loss per 100 training steps: 0.013723694068845362\n",
            "Training loss per 100 training steps: 0.013667718587566238\n",
            "Training loss per 100 training steps: 0.01360779133560049\n",
            "Training loss per 100 training steps: 0.01355626715694261\n",
            "Training loss per 100 training steps: 0.013506158472876142\n",
            "Training loss per 100 training steps: 0.01344817687386901\n",
            "Training loss per 100 training steps: 0.013398977449973457\n",
            "Training loss per 100 training steps: 0.013350064315808206\n",
            "Training loss per 100 training steps: 0.013296877676456244\n",
            "Training loss per 100 training steps: 0.013246157813098347\n",
            "Training loss per 100 training steps: 0.013193405399119238\n",
            "Training loss per 100 training steps: 0.01314026585204029\n",
            "Training loss per 100 training steps: 0.013092703810200477\n",
            "Training loss per 100 training steps: 0.01304351343362892\n",
            "Training loss per 100 training steps: 0.012997273451633\n",
            "Training loss per 100 training steps: 0.012951755746713995\n",
            "Training loss per 100 training steps: 0.012905464862234706\n",
            "Training loss per 100 training steps: 0.012858104651591542\n",
            "Training loss per 100 training steps: 0.012816211499871943\n",
            "Training loss per 100 training steps: 0.012772197102876229\n",
            "Training loss per 100 training steps: 0.012731548507027329\n",
            "Training loss per 100 training steps: 0.012685787114628871\n",
            "Training loss per 100 training steps: 0.012641601469606073\n",
            "Training loss per 100 training steps: 0.012600821279738739\n",
            "Training loss per 100 training steps: 0.012561075648531145\n",
            "Training loss per 100 training steps: 0.012520230824862106\n",
            "Training loss per 100 training steps: 0.012480056742579456\n",
            "Training loss per 100 training steps: 0.01244111613975485\n",
            "Training loss per 100 training steps: 0.012405820111148899\n",
            "Training loss per 100 training steps: 0.01236912395521901\n",
            "Training loss per 100 training steps: 0.012328988029862995\n",
            "Training loss per 100 training steps: 0.012288837143072776\n",
            "Training loss per 100 training steps: 0.012252395089195674\n",
            "Training loss per 100 training steps: 0.01221352803989894\n",
            "Training loss per 100 training steps: 0.012175914432598854\n",
            "Training loss per 100 training steps: 0.012138159016945533\n",
            "Training loss per 100 training steps: 0.012103304018659503\n",
            "Training loss per 100 training steps: 0.012069644307320885\n",
            "Training loss per 100 training steps: 0.012037430397720057\n",
            "Training loss per 100 training steps: 0.01200693880754342\n",
            "Training loss per 100 training steps: 0.011973522623663704\n",
            "Training loss per 100 training steps: 0.011941457093973989\n",
            "Training loss per 100 training steps: 0.011906923539128762\n",
            "Training loss per 100 training steps: 0.011870913823604005\n",
            "Training loss per 100 training steps: 0.011840624222750682\n",
            "Training loss per 100 training steps: 0.011810372301749885\n",
            "Training loss per 100 training steps: 0.011778665791614141\n",
            "Training loss per 100 training steps: 0.011745198354872532\n",
            "Training loss per 100 training steps: 0.011715206036304604\n",
            "Training loss per 100 training steps: 0.011684380518332994\n",
            "Training loss per 100 training steps: 0.01165206995624448\n",
            "Training loss per 100 training steps: 0.01162437656070464\n",
            "Training loss per 100 training steps: 0.011596245228559086\n",
            "Training loss per 100 training steps: 0.011567430867860683\n",
            "Training loss per 100 training steps: 0.011539918822236359\n",
            "Training loss per 100 training steps: 0.011512571331229992\n",
            "Training loss per 100 training steps: 0.011485599677891164\n",
            "Training loss per 100 training steps: 0.011461593689465964\n",
            "Training loss per 100 training steps: 0.011432796913496236\n",
            "Training loss per 100 training steps: 0.011406425739505056\n",
            "Training loss per 100 training steps: 0.011381429376518072\n",
            "Training loss per 100 training steps: 0.011352292138308915\n",
            "Training loss per 100 training steps: 0.01132505053867625\n",
            "Training loss per 100 training steps: 0.011299996187555648\n",
            "Training loss per 100 training steps: 0.011273829100402788\n",
            "Training loss per 100 training steps: 0.011246722085127498\n",
            "Training loss per 100 training steps: 0.011219908627586123\n",
            "Training loss per 100 training steps: 0.011194711206900498\n",
            "Training loss per 100 training steps: 0.011171650772515921\n",
            "Training loss per 100 training steps: 0.01114738634663056\n",
            "Training loss per 100 training steps: 0.011123377189106706\n",
            "Training loss per 100 training steps: 0.011097323105575263\n",
            "Training loss per 100 training steps: 0.011072421033635189\n",
            "Training loss per 100 training steps: 0.011048702585780366\n",
            "Training loss per 100 training steps: 0.011025004500520607\n",
            "Training loss per 100 training steps: 0.010999946332769468\n",
            "Training loss per 100 training steps: 0.010976559988644942\n",
            "Training loss per 100 training steps: 0.010955375586444471\n",
            "Training loss per 100 training steps: 0.010932485676368016\n",
            "Training loss per 100 training steps: 0.010912482016251685\n",
            "Training loss per 100 training steps: 0.010891297897298795\n",
            "Training loss per 100 training steps: 0.010868971389743388\n",
            "Training loss per 100 training steps: 0.010846369558893005\n",
            "Training loss per 100 training steps: 0.010824142033903007\n",
            "Training loss per 100 training steps: 0.010800824767525589\n",
            "Training loss per 100 training steps: 0.010777685793312756\n",
            "Training loss per 100 training steps: 0.010755635722533005\n",
            "Training loss per 100 training steps: 0.010736093696311096\n",
            "Training loss per 100 training steps: 0.010715186680387224\n",
            "Training loss per 100 training steps: 0.010694301209854174\n",
            "Training loss per 100 training steps: 0.01067440585948479\n",
            "Training loss per 100 training steps: 0.010653440253916006\n",
            "Training loss per 100 training steps: 0.010633549233981252\n",
            "Training loss per 100 training steps: 0.010611441048212595\n",
            "Training loss per 100 training steps: 0.01059117945153313\n",
            "Training loss per 100 training steps: 0.010574137940525544\n",
            "Training loss per 100 training steps: 0.010553317153061837\n",
            "Training loss per 100 training steps: 0.010532972766985508\n",
            "Training loss per 100 training steps: 0.010513075439963637\n",
            "Training loss per 100 training steps: 0.010493889494454397\n",
            "Training loss per 100 training steps: 0.010475448337133701\n",
            "Training loss per 100 training steps: 0.010455491387633407\n",
            "Training loss per 100 training steps: 0.010436811400757392\n",
            "Training loss per 100 training steps: 0.01041493638614506\n",
            "Training loss per 100 training steps: 0.010394135402018676\n",
            "Training loss per 100 training steps: 0.010376165309189153\n",
            "Training loss per 100 training steps: 0.010355487869129962\n",
            "Training loss per 100 training steps: 0.010336142051075409\n",
            "Training loss per 100 training steps: 0.010315676936278549\n",
            "Training loss per 100 training steps: 0.010296890479196994\n",
            "Training loss per 100 training steps: 0.010277700620963302\n",
            "Training loss per 100 training steps: 0.010258291107807222\n",
            "Training loss per 100 training steps: 0.010238970875716446\n",
            "Training loss per 100 training steps: 0.010219980894626383\n",
            "Training loss per 100 training steps: 0.010200526027782868\n",
            "Training loss per 100 training steps: 0.010184452338144183\n",
            "Training loss per 100 training steps: 0.010168672680456563\n",
            "Training loss per 100 training steps: 0.010150599156827289\n",
            "Training loss per 100 training steps: 0.010132288081130857\n",
            "Training loss per 100 training steps: 0.010114816484648535\n",
            "Training loss per 100 training steps: 0.010097387786313064\n",
            "Training loss per 100 training steps: 0.010078617077263121\n",
            "Training loss per 100 training steps: 0.010059312011427061\n",
            "Training loss per 100 training steps: 0.010041119777046047\n",
            "Training loss per 100 training steps: 0.010023085815134544\n",
            "Training loss per 100 training steps: 0.010002292231352919\n",
            "Training loss per 100 training steps: 0.009982945093899175\n",
            "Training loss per 100 training steps: 0.009965709188505445\n",
            "Training loss per 100 training steps: 0.00994876069102692\n",
            "Training loss per 100 training steps: 0.009930217871551888\n",
            "Training loss per 100 training steps: 0.00991302499156247\n",
            "Training loss per 100 training steps: 0.009893427115669711\n",
            "Training loss per 100 training steps: 0.009875347246494505\n",
            "Training loss per 100 training steps: 0.009858920361725379\n",
            "Training loss per 100 training steps: 0.009841197055158553\n",
            "Training loss per 100 training steps: 0.009821992412995315\n",
            "Training loss per 100 training steps: 0.009805444897166008\n",
            "Training loss per 100 training steps: 0.009788719111118343\n",
            "Training loss per 100 training steps: 0.009772777722366614\n",
            "Training loss per 100 training steps: 0.00975456046109416\n",
            "Training loss per 100 training steps: 0.009737348296061843\n",
            "Training loss per 100 training steps: 0.00972018779471244\n",
            "Training loss per 100 training steps: 0.00970320174243369\n",
            "Training loss per 100 training steps: 0.009685587691201362\n",
            "Training loss per 100 training steps: 0.009668877840483463\n",
            "Training loss per 100 training steps: 0.009652870728736744\n",
            "Training loss per 100 training steps: 0.00963667495281944\n",
            "Training loss per 100 training steps: 0.009620349466909714\n",
            "Training loss per 100 training steps: 0.009605688084213233\n",
            "Training loss per 100 training steps: 0.009589314888383622\n",
            "Training loss per 100 training steps: 0.009573608794395684\n",
            "Training loss per 100 training steps: 0.00955765115786562\n",
            "Training loss per 100 training steps: 0.009541443756343035\n",
            "Training loss per 100 training steps: 0.009526678426335602\n",
            "Training loss per 100 training steps: 0.009512049867492888\n",
            "Training loss per 100 training steps: 0.009495886698221932\n",
            "Training loss per 100 training steps: 0.00948283384466665\n",
            "Training loss per 100 training steps: 0.009467739249661366\n",
            "Training loss per 100 training steps: 0.009451815826816576\n",
            "Training loss per 100 training steps: 0.009436956065262413\n",
            "Training loss per 100 training steps: 0.009421571023226277\n",
            "Training loss per 100 training steps: 0.009406172094334449\n",
            "Training loss per 100 training steps: 0.00939097923665283\n",
            "Training loss per 100 training steps: 0.009376847192266289\n",
            "Training loss per 100 training steps: 0.009362277323942715\n",
            "Training loss per 100 training steps: 0.009347621082785298\n",
            "Training loss per 100 training steps: 0.009332680793417225\n",
            "Training loss per 100 training steps: 0.009317279902161852\n",
            "Training loss per 100 training steps: 0.009302786626169056\n",
            "Training loss per 100 training steps: 0.009290215706445929\n",
            "Training loss per 100 training steps: 0.009276640777649697\n",
            "Training loss per 100 training steps: 0.009264215161012439\n",
            "Training loss per 100 training steps: 0.009250970333280876\n",
            "Training loss per 100 training steps: 0.009237012911873548\n",
            "Training loss per 100 training steps: 0.009223360691238762\n",
            "Training loss per 100 training steps: 0.009207897932696921\n",
            "Training loss per 100 training steps: 0.009192537426450572\n",
            "Training loss per 100 training steps: 0.00917680385679829\n",
            "Training loss per 100 training steps: 0.009162490256587308\n",
            "Training loss per 100 training steps: 0.009148391973629797\n",
            "Training loss per 100 training steps: 0.009134463449225255\n",
            "Training loss per 100 training steps: 0.00912059447393098\n",
            "Training loss per 100 training steps: 0.009105208530532883\n",
            "Training loss per 100 training steps: 0.009090888674759804\n",
            "Training loss per 100 training steps: 0.009077087043938437\n",
            "Training loss per 100 training steps: 0.009061558289457402\n",
            "Training loss per 100 training steps: 0.00904892383304527\n",
            "Training loss per 100 training steps: 0.009035802966375255\n",
            "Training loss per 100 training steps: 0.009023281599942487\n",
            "Training loss per 100 training steps: 0.0090098427927999\n",
            "Training loss per 100 training steps: 0.008996163000218507\n",
            "Training loss per 100 training steps: 0.00898261424283044\n",
            "Training loss per 100 training steps: 0.008969323252921968\n",
            "Training loss per 100 training steps: 0.008955024153278554\n",
            "Training loss per 100 training steps: 0.008942752828826213\n",
            "Training loss per 100 training steps: 0.008929491990067375\n",
            "Training loss per 100 training steps: 0.008916163298183823\n",
            "Training loss per 100 training steps: 0.00890235206061382\n",
            "Training loss per 100 training steps: 0.008890798612937283\n",
            "Training loss per 100 training steps: 0.008878261046208391\n",
            "Training loss per 100 training steps: 0.008864774220943695\n",
            "Training loss per 100 training steps: 0.008851776199622286\n",
            "Training loss per 100 training steps: 0.008838539493402181\n",
            "Training loss per 100 training steps: 0.008826224530692508\n",
            "Training loss per 100 training steps: 0.008813255060253917\n",
            "Training loss per 100 training steps: 0.008800295153989517\n",
            "Training loss per 100 training steps: 0.008788247726647292\n",
            "Training loss per 100 training steps: 0.0087751620511699\n",
            "Training loss per 100 training steps: 0.0087626144027571\n",
            "Training loss per 100 training steps: 0.00875037363315873\n",
            "Training loss per 100 training steps: 0.008738412421824972\n",
            "Training loss per 100 training steps: 0.008725965279788132\n",
            "Training loss per 100 training steps: 0.008713489711836967\n",
            "Training loss per 100 training steps: 0.008701636891470894\n",
            "Training loss per 100 training steps: 0.008690439537466798\n",
            "Training loss per 100 training steps: 0.00867876483375585\n",
            "Training loss per 100 training steps: 0.008665406510220823\n",
            "Training loss per 100 training steps: 0.008654934632528996\n",
            "Training loss per 100 training steps: 0.00864410931631943\n",
            "Training loss per 100 training steps: 0.008632327600962188\n",
            "Training loss per 100 training steps: 0.008621650347475392\n",
            "Training loss per 100 training steps: 0.008611344598077289\n",
            "Training loss per 100 training steps: 0.008599815004240346\n",
            "Training loss per 100 training steps: 0.008586226468330828\n",
            "Training loss epoch: 0.008584055726850288\n",
            "Training accuracy epoch: 0.9144062851398134\n",
            "Training steps: 32820\n",
            "\n",
            "\n",
            "\n",
            "Validation loss per 100 evaluation steps: 0.004457909390330314\n",
            "Validation loss per 100 evaluation steps: 0.004457449120236561\n",
            "Validation loss per 100 evaluation steps: 0.004473267662106082\n",
            "Validation loss per 100 evaluation steps: 0.0044477126805577425\n",
            "Validation loss per 100 evaluation steps: 0.004456667307997123\n",
            "Validation loss per 100 evaluation steps: 0.004422094779826391\n",
            "Validation loss per 100 evaluation steps: 0.004393220490144034\n",
            "Validation loss per 100 evaluation steps: 0.004421212316665333\n",
            "Validation loss per 100 evaluation steps: 0.004388174592620797\n",
            "Validation loss per 100 evaluation steps: 0.004366527332575061\n",
            "Validation loss per 100 evaluation steps: 0.004381931622046978\n",
            "Validation loss per 100 evaluation steps: 0.004396444784651976\n",
            "Validation loss per 100 evaluation steps: 0.004386501538997086\n",
            "Validation loss per 100 evaluation steps: 0.0044061713856977545\n",
            "Validation loss per 100 evaluation steps: 0.004423082755335296\n",
            "Validation loss per 100 evaluation steps: 0.004435707361117238\n",
            "Validation loss per 100 evaluation steps: 0.0044426946540582265\n",
            "Validation loss per 100 evaluation steps: 0.004461057835206803\n",
            "Validation loss per 100 evaluation steps: 0.004473353774397094\n",
            "Validation loss per 100 evaluation steps: 0.0044750392478308644\n",
            "Validation loss per 100 evaluation steps: 0.0044658391857298006\n",
            "Validation loss per 100 evaluation steps: 0.004461353983708912\n",
            "Validation loss per 100 evaluation steps: 0.004468083977648665\n",
            "Validation loss per 100 evaluation steps: 0.004478528437709126\n",
            "Validation loss per 100 evaluation steps: 0.0044766736780293285\n",
            "Validation loss per 100 evaluation steps: 0.004482269323735426\n",
            "Validation loss per 100 evaluation steps: 0.004481554158566588\n",
            "Validation loss per 100 evaluation steps: 0.004484494356230633\n",
            "Validation loss per 100 evaluation steps: 0.004483232649268004\n",
            "Validation loss per 100 evaluation steps: 0.004483815427403897\n",
            "Validation loss per 100 evaluation steps: 0.004473691817763592\n",
            "Validation loss per 100 evaluation steps: 0.004469362553827523\n",
            "Validation loss per 100 evaluation steps: 0.00446715741298359\n",
            "Validation loss per 100 evaluation steps: 0.0044559987479998895\n",
            "Validation loss per 100 evaluation steps: 0.004451254200955321\n",
            "Validation loss per 100 evaluation steps: 0.00445684948020951\n",
            "Validation loss per 100 evaluation steps: 0.004456122838451552\n",
            "Validation loss per 100 evaluation steps: 0.0044473938991952885\n",
            "Validation loss per 100 evaluation steps: 0.004448271565652715\n",
            "Validation loss per 100 evaluation steps: 0.0044389188628119886\n",
            "Validation loss per 100 evaluation steps: 0.004436049963483905\n",
            "Validation Loss: 0.00443735029708999\n",
            "Validation Accuracy: 0.9444290663769683\n",
            "Validation P-R-F1 for each label: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      B-ANIM       0.00      0.00      0.00      1134\n",
            "       B-BIO       0.00      0.00      0.00        14\n",
            "       B-CEL       0.00      0.00      0.00        94\n",
            "       B-DIS       0.00      0.00      0.00      1695\n",
            "       B-EVE       0.00      0.00      0.00       299\n",
            "      B-FOOD       0.00      0.00      0.00      2120\n",
            "      B-INST       0.00      0.12      0.00        34\n",
            "       B-LOC       0.99      0.99      0.99      7850\n",
            "     B-MEDIA       0.00      0.00      0.00       919\n",
            "      B-MYTH       0.00      0.00      0.00        56\n",
            "       B-ORG       0.90      0.93      0.91      2737\n",
            "       B-PER       0.86      1.00      0.92      7507\n",
            "     B-PLANT       0.00      0.00      0.00      1180\n",
            "      B-TIME       0.01      0.39      0.03       322\n",
            "      B-VEHI       0.00      0.00      0.00        80\n",
            "      I-ANIM       0.00      0.00      0.00      2207\n",
            "       I-BIO       0.00      0.00      0.00        37\n",
            "       I-CEL       0.00      0.00      0.00        42\n",
            "       I-DIS       0.00      0.00      0.00      3301\n",
            "       I-EVE       0.00      0.00      0.00       676\n",
            "      I-FOOD       0.00      0.00      0.00      2237\n",
            "      I-INST       0.00      0.00      0.00        53\n",
            "       I-LOC       0.96      0.98      0.97      9206\n",
            "     I-MEDIA       1.00      0.01      0.01      2456\n",
            "      I-MYTH       0.00      0.00      0.00        58\n",
            "       I-ORG       0.90      0.95      0.92      5897\n",
            "       I-PER       0.99      1.00      0.99     18465\n",
            "     I-PLANT       0.00      0.00      0.00      1954\n",
            "      I-TIME       0.00      0.00      0.00       371\n",
            "      I-VEHI       0.00      0.00      0.00       211\n",
            "           O       0.98      0.99      0.99    364321\n",
            "\n",
            "    accuracy                           0.94    437533\n",
            "   macro avg       0.24      0.24      0.22    437533\n",
            "weighted avg       0.93      0.94      0.93    437533\n",
            "\n",
            "Validation P-R-F1 tor all label: \n",
            "          precision  recall      f1\n",
            "micro        0.9444  0.9444  0.9444\n",
            "macro        0.2445  0.2371  0.2172\n",
            "weighted     0.9305  0.9444  0.9344\n",
            "Validation steps: 4103\n",
            "\n",
            "\n",
            "\n",
            "Test loss per 100 evaluation steps: 0.0040692289650905876\n",
            "Test loss per 100 evaluation steps: 0.004014060646295547\n",
            "Test loss per 100 evaluation steps: 0.0039040833222679793\n",
            "Test loss per 100 evaluation steps: 0.003991509422485251\n",
            "Test loss per 100 evaluation steps: 0.003886976747540757\n",
            "Test loss per 100 evaluation steps: 0.0038664558213592198\n",
            "Test loss per 100 evaluation steps: 0.003859955056936347\n",
            "Test loss per 100 evaluation steps: 0.003889907734846929\n",
            "Test loss per 100 evaluation steps: 0.003889360612310055\n",
            "Test loss per 100 evaluation steps: 0.0038538039564155043\n",
            "Test loss per 100 evaluation steps: 0.0038517244648061354\n",
            "Test loss per 100 evaluation steps: 0.003864563764752044\n",
            "Test loss per 100 evaluation steps: 0.0038971264131116468\n",
            "Test loss per 100 evaluation steps: 0.0038928664811620755\n",
            "Test loss per 100 evaluation steps: 0.003902233843691647\n",
            "Test loss per 100 evaluation steps: 0.0038845533698622604\n",
            "Test loss per 100 evaluation steps: 0.0038860882896080834\n",
            "Test loss per 100 evaluation steps: 0.0038946720104690432\n",
            "Test loss per 100 evaluation steps: 0.003905304922955111\n",
            "Test loss per 100 evaluation steps: 0.003913674253039062\n",
            "Test loss per 100 evaluation steps: 0.0039135847216849\n",
            "Test loss per 100 evaluation steps: 0.003934707072171891\n",
            "Test loss per 100 evaluation steps: 0.003941932979404279\n",
            "Test loss per 100 evaluation steps: 0.003937865123249746\n",
            "Test loss per 100 evaluation steps: 0.003933681150898338\n",
            "Test loss per 100 evaluation steps: 0.003934071434733386\n",
            "Test loss per 100 evaluation steps: 0.003938151899449251\n",
            "Test loss per 100 evaluation steps: 0.00392617197108588\n",
            "Test loss per 100 evaluation steps: 0.00393062053444988\n",
            "Test loss per 100 evaluation steps: 0.003935601313016377\n",
            "Test loss per 100 evaluation steps: 0.003926968828459541\n",
            "Test loss per 100 evaluation steps: 0.003927230560584576\n",
            "Test loss per 100 evaluation steps: 0.003919390014400988\n",
            "Test loss per 100 evaluation steps: 0.003914637486690052\n",
            "Test loss per 100 evaluation steps: 0.003911281365834709\n",
            "Test loss per 100 evaluation steps: 0.003914003525537232\n",
            "Test loss per 100 evaluation steps: 0.0039063797509171876\n",
            "Test loss per 100 evaluation steps: 0.0039139019440259095\n",
            "Test loss per 100 evaluation steps: 0.003910890244848978\n",
            "Test loss per 100 evaluation steps: 0.0039155546700931155\n",
            "Test loss per 100 evaluation steps: 0.003921627571363366\n",
            "Test Loss: 0.003918839249651024\n",
            "Test Accuracy: 0.9577867735855214\n",
            "Test P-R-F1 for each label: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      B-ANIM       0.00      0.00      0.00      1604\n",
            "       B-BIO       0.00      0.00      0.00         8\n",
            "       B-CEL       0.00      0.00      0.00        41\n",
            "       B-DIS       0.00      0.00      0.00       759\n",
            "       B-EVE       0.00      0.00      0.00       352\n",
            "      B-FOOD       0.00      0.00      0.00       566\n",
            "      B-INST       0.00      0.17      0.00        12\n",
            "       B-LOC       0.99      0.99      0.99     12024\n",
            "     B-MEDIA       0.00      0.00      0.00       458\n",
            "      B-MYTH       0.00      0.00      0.00        32\n",
            "       B-ORG       0.92      0.94      0.93      3309\n",
            "       B-PER       0.85      1.00      0.92      5265\n",
            "     B-PLANT       0.00      0.00      0.00       894\n",
            "      B-TIME       0.02      0.39      0.03       289\n",
            "      B-VEHI       0.00      0.00      0.00        32\n",
            "      I-ANIM       0.00      0.00      0.00      3187\n",
            "       I-BIO       0.00      0.00      0.00        24\n",
            "       I-CEL       0.00      0.00      0.00        31\n",
            "       I-DIS       0.00      0.00      0.00      1564\n",
            "       I-EVE       0.00      0.00      0.00       798\n",
            "      I-FOOD       0.00      0.00      0.00       590\n",
            "      I-INST       0.00      0.00      0.00        20\n",
            "       I-LOC       0.98      0.98      0.98     15066\n",
            "     I-MEDIA       1.00      0.01      0.02      1179\n",
            "      I-MYTH       0.00      0.00      0.00        34\n",
            "       I-ORG       0.92      0.96      0.94      7477\n",
            "       I-PER       0.98      1.00      0.99     13073\n",
            "     I-PLANT       0.00      0.00      0.00      1781\n",
            "      I-TIME       0.00      0.00      0.00       350\n",
            "      I-VEHI       0.00      0.00      0.00        79\n",
            "           O       0.98      0.99      0.99    326281\n",
            "\n",
            "    accuracy                           0.96    397179\n",
            "   macro avg       0.25      0.24      0.22    397179\n",
            "weighted avg       0.95      0.96      0.95    397179\n",
            "\n",
            "Test P-R-F1 tor all label: \n",
            "          precision  recall      f1\n",
            "micro        0.9563  0.9563  0.9563\n",
            "macro        0.2463  0.2395  0.2188\n",
            "weighted     0.9465  0.9563  0.9497\n",
            "Test steps: 4114\n",
            "====================================================================================================\n",
            "loss_name: l2\n",
            "model configuration\n",
            "%%%%%%%%%%%%%%%%%%%%\n",
            "Ner_Model(\n",
            "  (model): DebertaModel(\n",
            "    (embeddings): DebertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
            "      (LayerNorm): DebertaLayerNorm()\n",
            "      (dropout): StableDropout()\n",
            "    )\n",
            "    (encoder): DebertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x DebertaLayer(\n",
            "          (attention): DebertaAttention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): DebertaLayerNorm()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): DebertaLayerNorm()\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (rel_embeddings): Embedding(1024, 768)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Linear(in_features=768, out_features=31, bias=True)\n",
            ")\n",
            "%%%%%%%%%%%%%%%%%%%%\n",
            "Training epoch: 1\n",
            "Training loss per 100 training steps: 0.06859127464704215\n",
            "Training loss per 100 training steps: 0.039661621996201574\n",
            "Training loss per 100 training steps: 0.0290364432373705\n",
            "Training loss per 100 training steps: 0.023245176077471116\n",
            "Training loss per 100 training steps: 0.019536311492091046\n",
            "Training loss per 100 training steps: 0.016948089547804558\n",
            "Training loss per 100 training steps: 0.015085217126844717\n",
            "Training loss per 100 training steps: 0.01364037390681915\n",
            "Training loss per 100 training steps: 0.012436413777823974\n",
            "Training loss per 100 training steps: 0.01151477048319066\n",
            "Training loss per 100 training steps: 0.010713082086665302\n",
            "Training loss per 100 training steps: 0.010061117428946697\n",
            "Training loss per 100 training steps: 0.009493590379536797\n",
            "Training loss per 100 training steps: 0.008987750905549288\n",
            "Training loss per 100 training steps: 0.008548802600009366\n",
            "Training loss per 100 training steps: 0.008170803805915056\n",
            "Training loss per 100 training steps: 0.007824782162976643\n",
            "Training loss per 100 training steps: 0.00751623223582606\n",
            "Training loss per 100 training steps: 0.00723993993967796\n",
            "Training loss per 100 training steps: 0.00699247778255085\n",
            "Training loss per 100 training steps: 0.006762371982539272\n",
            "Training loss per 100 training steps: 0.006553896759287454\n",
            "Training loss per 100 training steps: 0.006361190551441446\n",
            "Training loss per 100 training steps: 0.006175432456244986\n",
            "Training loss per 100 training steps: 0.0060092551570385695\n",
            "Training loss per 100 training steps: 0.005862622539694153\n",
            "Training loss per 100 training steps: 0.005718017391228824\n",
            "Training loss per 100 training steps: 0.005576290641859357\n",
            "Training loss per 100 training steps: 0.005446543500604156\n",
            "Training loss per 100 training steps: 0.005323805992428485\n",
            "Training loss per 100 training steps: 0.005218802566134048\n",
            "Training loss per 100 training steps: 0.005118301117740884\n",
            "Training loss per 100 training steps: 0.005016156872050929\n",
            "Training loss per 100 training steps: 0.004925678941187524\n",
            "Training loss per 100 training steps: 0.004837671050660511\n",
            "Training loss per 100 training steps: 0.004752926683751058\n",
            "Training loss per 100 training steps: 0.0046728484134537455\n",
            "Training loss per 100 training steps: 0.004595890115087969\n",
            "Training loss per 100 training steps: 0.0045220424031028345\n",
            "Training loss per 100 training steps: 0.004455984492753487\n",
            "Training loss per 100 training steps: 0.004390084646009022\n",
            "Training loss per 100 training steps: 0.004327638236981806\n",
            "Training loss per 100 training steps: 0.004259221345561199\n",
            "Training loss per 100 training steps: 0.004201744374804548\n",
            "Training loss per 100 training steps: 0.004137212733042866\n",
            "Training loss per 100 training steps: 0.004081652439076013\n",
            "Training loss per 100 training steps: 0.0040263443914467486\n",
            "Training loss per 100 training steps: 0.003972078237217526\n",
            "Training loss per 100 training steps: 0.003920349606033058\n",
            "Training loss per 100 training steps: 0.0038739280586654787\n",
            "Training loss per 100 training steps: 0.0038260227961433757\n",
            "Training loss per 100 training steps: 0.0037838278119614608\n",
            "Training loss per 100 training steps: 0.0037411512664402833\n",
            "Training loss per 100 training steps: 0.003699153666721368\n",
            "Training loss per 100 training steps: 0.0036569308338300537\n",
            "Training loss per 100 training steps: 0.003619205497582568\n",
            "Training loss per 100 training steps: 0.003577754843531773\n",
            "Training loss per 100 training steps: 0.003544152387147388\n",
            "Training loss per 100 training steps: 0.003507638120487573\n",
            "Training loss per 100 training steps: 0.003475169842919665\n",
            "Training loss per 100 training steps: 0.0034431448984308145\n",
            "Training loss per 100 training steps: 0.0034094865128023347\n",
            "Training loss per 100 training steps: 0.003378560580534949\n",
            "Training loss per 100 training steps: 0.00334698154814987\n",
            "Training loss per 100 training steps: 0.003319220945010714\n",
            "Training loss per 100 training steps: 0.003286878079683943\n",
            "Training loss per 100 training steps: 0.003257710264188606\n",
            "Training loss per 100 training steps: 0.003229214078571257\n",
            "Training loss per 100 training steps: 0.0032045854037784484\n",
            "Training loss per 100 training steps: 0.0031769284635291633\n",
            "Training loss per 100 training steps: 0.003150215575034553\n",
            "Training loss per 100 training steps: 0.0031283895386251164\n",
            "Training loss per 100 training steps: 0.0031045652711197847\n",
            "Training loss per 100 training steps: 0.0030803258692813453\n",
            "Training loss per 100 training steps: 0.003056563855595111\n",
            "Training loss per 100 training steps: 0.003033969224726254\n",
            "Training loss per 100 training steps: 0.003011789223675876\n",
            "Training loss per 100 training steps: 0.0029882751783271745\n",
            "Training loss per 100 training steps: 0.002967099635717216\n",
            "Training loss per 100 training steps: 0.0029479012624642562\n",
            "Training loss per 100 training steps: 0.002929533229908873\n",
            "Training loss per 100 training steps: 0.002909733412455286\n",
            "Training loss per 100 training steps: 0.002892056779182237\n",
            "Training loss per 100 training steps: 0.002874513969151546\n",
            "Training loss per 100 training steps: 0.002858756193135324\n",
            "Training loss per 100 training steps: 0.0028435647882005745\n",
            "Training loss per 100 training steps: 0.0028251200631013657\n",
            "Training loss per 100 training steps: 0.0028067163873939454\n",
            "Training loss per 100 training steps: 0.002791273508325881\n",
            "Training loss per 100 training steps: 0.0027760465025906643\n",
            "Training loss per 100 training steps: 0.0027601289586475885\n",
            "Training loss per 100 training steps: 0.0027451371053338453\n",
            "Training loss per 100 training steps: 0.002727830838883028\n",
            "Training loss per 100 training steps: 0.002712820215369612\n",
            "Training loss per 100 training steps: 0.0026959590784313868\n",
            "Training loss per 100 training steps: 0.002679578761413571\n",
            "Training loss per 100 training steps: 0.002667477826400181\n",
            "Training loss per 100 training steps: 0.002653736369531395\n",
            "Training loss per 100 training steps: 0.0026394955244427136\n",
            "Training loss per 100 training steps: 0.0026231527911659215\n",
            "Training loss per 100 training steps: 0.0026082996050917975\n",
            "Training loss per 100 training steps: 0.002597409087075885\n",
            "Training loss per 100 training steps: 0.002584626061879426\n",
            "Training loss per 100 training steps: 0.0025716522438352304\n",
            "Training loss per 100 training steps: 0.0025593873206990318\n",
            "Training loss per 100 training steps: 0.0025470603712103254\n",
            "Training loss per 100 training steps: 0.002536546313043392\n",
            "Training loss per 100 training steps: 0.0025244987875326103\n",
            "Training loss per 100 training steps: 0.0025111251864257888\n",
            "Training loss per 100 training steps: 0.002498756394493367\n",
            "Training loss per 100 training steps: 0.0024880557453427895\n",
            "Training loss per 100 training steps: 0.00247811372097658\n",
            "Training loss per 100 training steps: 0.002467917513606588\n",
            "Training loss per 100 training steps: 0.0024578695068582118\n",
            "Training loss per 100 training steps: 0.0024479546740830815\n",
            "Training loss per 100 training steps: 0.0024364462829537937\n",
            "Training loss per 100 training steps: 0.0024286673236425626\n",
            "Training loss per 100 training steps: 0.0024180496130442007\n",
            "Training loss per 100 training steps: 0.0024077811078002144\n",
            "Training loss per 100 training steps: 0.0023954808836788286\n",
            "Training loss per 100 training steps: 0.002385772514572629\n",
            "Training loss per 100 training steps: 0.002375719979722444\n",
            "Training loss per 100 training steps: 0.002365854105861158\n",
            "Training loss per 100 training steps: 0.0023567667535796992\n",
            "Training loss per 100 training steps: 0.0023487755385687343\n",
            "Training loss per 100 training steps: 0.0023394591232701917\n",
            "Training loss per 100 training steps: 0.002329263874596259\n",
            "Training loss per 100 training steps: 0.002318747500282825\n",
            "Training loss per 100 training steps: 0.00231104116183568\n",
            "Training loss per 100 training steps: 0.00230170840446338\n",
            "Training loss per 100 training steps: 0.0022942151308356505\n",
            "Training loss per 100 training steps: 0.0022880338613581307\n",
            "Training loss per 100 training steps: 0.0022778637028468642\n",
            "Training loss per 100 training steps: 0.002271460358328955\n",
            "Training loss per 100 training steps: 0.002262618750693811\n",
            "Training loss per 100 training steps: 0.002254554179326078\n",
            "Training loss per 100 training steps: 0.002247648711344329\n",
            "Training loss per 100 training steps: 0.0022384578872805686\n",
            "Training loss per 100 training steps: 0.0022313386721267672\n",
            "Training loss per 100 training steps: 0.002224397753713544\n",
            "Training loss per 100 training steps: 0.002217278940870851\n",
            "Training loss per 100 training steps: 0.002209137777979162\n",
            "Training loss per 100 training steps: 0.0022021194464809765\n",
            "Training loss per 100 training steps: 0.002196351519340472\n",
            "Training loss per 100 training steps: 0.002190122615667421\n",
            "Training loss per 100 training steps: 0.002185062066702115\n",
            "Training loss per 100 training steps: 0.002176804511643432\n",
            "Training loss per 100 training steps: 0.0021714271753714726\n",
            "Training loss per 100 training steps: 0.0021638664147660726\n",
            "Training loss per 100 training steps: 0.0021565460537414766\n",
            "Training loss per 100 training steps: 0.0021518123933868304\n",
            "Training loss per 100 training steps: 0.002144187020022448\n",
            "Training loss per 100 training steps: 0.0021384150553842795\n",
            "Training loss per 100 training steps: 0.0021302365090032963\n",
            "Training loss per 100 training steps: 0.0021237714554705645\n",
            "Training loss per 100 training steps: 0.0021180100286006236\n",
            "Training loss per 100 training steps: 0.0021119027139092435\n",
            "Training loss per 100 training steps: 0.002103562557269608\n",
            "Training loss per 100 training steps: 0.0020980052350431885\n",
            "Training loss per 100 training steps: 0.002093335110938597\n",
            "Training loss per 100 training steps: 0.00208761400058805\n",
            "Training loss per 100 training steps: 0.0020824188976749374\n",
            "Training loss per 100 training steps: 0.002077698983134696\n",
            "Training loss per 100 training steps: 0.0020719138000494263\n",
            "Training loss per 100 training steps: 0.00206566167932099\n",
            "Training loss per 100 training steps: 0.002060606227960635\n",
            "Training loss per 100 training steps: 0.002055004550539505\n",
            "Training loss per 100 training steps: 0.002050112449048486\n",
            "Training loss per 100 training steps: 0.002043509840329464\n",
            "Training loss per 100 training steps: 0.0020379934884091626\n",
            "Training loss per 100 training steps: 0.0020331034386022137\n",
            "Training loss per 100 training steps: 0.002026781452127897\n",
            "Training loss per 100 training steps: 0.0020213060275777856\n",
            "Training loss per 100 training steps: 0.002015608291447321\n",
            "Training loss per 100 training steps: 0.0020093129021541765\n",
            "Training loss per 100 training steps: 0.0020031378979966908\n",
            "Training loss per 100 training steps: 0.0019986846136555866\n",
            "Training loss per 100 training steps: 0.001993399616753113\n",
            "Training loss per 100 training steps: 0.0019879246506610414\n",
            "Training loss per 100 training steps: 0.0019825790381558664\n",
            "Training loss per 100 training steps: 0.0019776487599989013\n",
            "Training loss per 100 training steps: 0.0019728897331031596\n",
            "Training loss per 100 training steps: 0.001967973646271991\n",
            "Training loss per 100 training steps: 0.0019629086981924207\n",
            "Training loss per 100 training steps: 0.0019585352347836504\n",
            "Training loss per 100 training steps: 0.0019542102516978597\n",
            "Training loss per 100 training steps: 0.0019493821108438505\n",
            "Training loss per 100 training steps: 0.0019452751020404282\n",
            "Training loss per 100 training steps: 0.0019418478862378776\n",
            "Training loss per 100 training steps: 0.0019357734293158789\n",
            "Training loss per 100 training steps: 0.0019312616217044439\n",
            "Training loss per 100 training steps: 0.001928788715116904\n",
            "Training loss per 100 training steps: 0.0019249224106995617\n",
            "Training loss per 100 training steps: 0.001920630191761467\n",
            "Training loss per 100 training steps: 0.0019159642747311946\n",
            "Training loss per 100 training steps: 0.00191188087551196\n",
            "Training loss per 100 training steps: 0.0019075103104419235\n",
            "Training loss per 100 training steps: 0.0019038629790792574\n",
            "Training loss per 100 training steps: 0.0018997593414563532\n",
            "Training loss per 100 training steps: 0.0018948240230747615\n",
            "Training loss per 100 training steps: 0.0018908148933155984\n",
            "Training loss per 100 training steps: 0.0018853597957782804\n",
            "Training loss per 100 training steps: 0.0018820531079978232\n",
            "Training loss per 100 training steps: 0.001878421840497764\n",
            "Training loss per 100 training steps: 0.0018746628981921609\n",
            "Training loss per 100 training steps: 0.0018709605345666382\n",
            "Training loss per 100 training steps: 0.0018674260089023122\n",
            "Training loss per 100 training steps: 0.0018636185640341933\n",
            "Training loss per 100 training steps: 0.0018609007799089093\n",
            "Training loss per 100 training steps: 0.001857065132858441\n",
            "Training loss per 100 training steps: 0.0018532333930112808\n",
            "Training loss per 100 training steps: 0.0018501890542338172\n",
            "Training loss per 100 training steps: 0.0018479199800174068\n",
            "Training loss per 100 training steps: 0.0018441507636925622\n",
            "Training loss per 100 training steps: 0.0018405794137188634\n",
            "Training loss per 100 training steps: 0.0018382423754425231\n",
            "Training loss per 100 training steps: 0.001834183199273359\n",
            "Training loss per 100 training steps: 0.0018320739827649625\n",
            "Training loss per 100 training steps: 0.0018298025331119731\n",
            "Training loss per 100 training steps: 0.0018267466801685673\n",
            "Training loss per 100 training steps: 0.0018230794243957944\n",
            "Training loss per 100 training steps: 0.001820248966965779\n",
            "Training loss per 100 training steps: 0.0018164477059156936\n",
            "Training loss per 100 training steps: 0.0018130402808105828\n",
            "Training loss per 100 training steps: 0.0018097268590009966\n",
            "Training loss per 100 training steps: 0.0018065845806264824\n",
            "Training loss per 100 training steps: 0.0018038117928314216\n",
            "Training loss per 100 training steps: 0.0018007422061062945\n",
            "Training loss per 100 training steps: 0.0017984724253182914\n",
            "Training loss per 100 training steps: 0.001794753271588295\n",
            "Training loss per 100 training steps: 0.0017918599358633452\n",
            "Training loss per 100 training steps: 0.0017878761461041246\n",
            "Training loss per 100 training steps: 0.001784134372158097\n",
            "Training loss per 100 training steps: 0.0017812453784596368\n",
            "Training loss per 100 training steps: 0.0017776191481262164\n",
            "Training loss per 100 training steps: 0.0017756678844868428\n",
            "Training loss per 100 training steps: 0.0017729046335426969\n",
            "Training loss per 100 training steps: 0.0017694368184451943\n",
            "Training loss per 100 training steps: 0.0017649908747775058\n",
            "Training loss per 100 training steps: 0.0017619562703537971\n",
            "Training loss per 100 training steps: 0.0017587197815088355\n",
            "Training loss per 100 training steps: 0.0017557197752845722\n",
            "Training loss per 100 training steps: 0.0017528821523066856\n",
            "Training loss per 100 training steps: 0.0017493315190536944\n",
            "Training loss per 100 training steps: 0.0017469598846164074\n",
            "Training loss per 100 training steps: 0.0017447727247837783\n",
            "Training loss per 100 training steps: 0.0017423263818280336\n",
            "Training loss per 100 training steps: 0.0017390475737902894\n",
            "Training loss per 100 training steps: 0.0017364121841270375\n",
            "Training loss per 100 training steps: 0.0017333974326960743\n",
            "Training loss per 100 training steps: 0.0017301507363789502\n",
            "Training loss per 100 training steps: 0.0017264410591246455\n",
            "Training loss per 100 training steps: 0.0017235970879819398\n",
            "Training loss per 100 training steps: 0.0017218630864334146\n",
            "Training loss per 100 training steps: 0.0017198808726347587\n",
            "Training loss per 100 training steps: 0.0017164940654792816\n",
            "Training loss per 100 training steps: 0.0017146435989671854\n",
            "Training loss per 100 training steps: 0.0017121042639049594\n",
            "Training loss per 100 training steps: 0.0017091700651449297\n",
            "Training loss per 100 training steps: 0.001707236403578813\n",
            "Training loss per 100 training steps: 0.0017058297066107249\n",
            "Training loss per 100 training steps: 0.0017036842101341937\n",
            "Training loss per 100 training steps: 0.0017007169422332852\n",
            "Training loss per 100 training steps: 0.0016983024292586846\n",
            "Training loss per 100 training steps: 0.0016954944403446718\n",
            "Training loss per 100 training steps: 0.0016926327291526776\n",
            "Training loss per 100 training steps: 0.001690510365596164\n",
            "Training loss per 100 training steps: 0.0016887170139444376\n",
            "Training loss per 100 training steps: 0.001685777932448235\n",
            "Training loss per 100 training steps: 0.0016828893272631156\n",
            "Training loss per 100 training steps: 0.0016807616109119367\n",
            "Training loss per 100 training steps: 0.0016786382152126327\n",
            "Training loss per 100 training steps: 0.0016762431221530399\n",
            "Training loss per 100 training steps: 0.0016734706905379053\n",
            "Training loss per 100 training steps: 0.0016710907043891812\n",
            "Training loss per 100 training steps: 0.0016684748478178666\n",
            "Training loss per 100 training steps: 0.0016662636761891536\n",
            "Training loss per 100 training steps: 0.0016635545370338163\n",
            "Training loss per 100 training steps: 0.0016623895292248946\n",
            "Training loss per 100 training steps: 0.0016609018434415443\n",
            "Training loss per 100 training steps: 0.0016596991325938278\n",
            "Training loss per 100 training steps: 0.0016576035476975177\n",
            "Training loss per 100 training steps: 0.0016553567475313022\n",
            "Training loss per 100 training steps: 0.00165264595511295\n",
            "Training loss per 100 training steps: 0.001649891612558062\n",
            "Training loss per 100 training steps: 0.0016478661990454479\n",
            "Training loss per 100 training steps: 0.0016457790206685903\n",
            "Training loss per 100 training steps: 0.0016440107776120132\n",
            "Training loss per 100 training steps: 0.0016420268988826968\n",
            "Training loss per 100 training steps: 0.0016401167454458683\n",
            "Training loss per 100 training steps: 0.0016393049531544012\n",
            "Training loss per 100 training steps: 0.0016373453314923135\n",
            "Training loss per 100 training steps: 0.001635633050142387\n",
            "Training loss per 100 training steps: 0.0016328550716648382\n",
            "Training loss per 100 training steps: 0.0016304975904579697\n",
            "Training loss per 100 training steps: 0.001628603353619899\n",
            "Training loss per 100 training steps: 0.0016270070369501512\n",
            "Training loss per 100 training steps: 0.0016250714206058705\n",
            "Training loss per 100 training steps: 0.0016223123107523144\n",
            "Training loss per 100 training steps: 0.001619713247682436\n",
            "Training loss per 100 training steps: 0.0016175079650218268\n",
            "Training loss per 100 training steps: 0.0016152554929088345\n",
            "Training loss per 100 training steps: 0.0016139910469224776\n",
            "Training loss per 100 training steps: 0.001612682302560176\n",
            "Training loss per 100 training steps: 0.001610157276712538\n",
            "Training loss per 100 training steps: 0.0016075794331577734\n",
            "Training loss per 100 training steps: 0.0016056131209387097\n",
            "Training loss per 100 training steps: 0.0016036786597839058\n",
            "Training loss per 100 training steps: 0.0016013193676310661\n",
            "Training loss per 100 training steps: 0.0015994851679924098\n",
            "Training loss per 100 training steps: 0.00159729384417947\n",
            "Training loss per 100 training steps: 0.0015961173243784123\n",
            "Training loss per 100 training steps: 0.0015948099640995781\n",
            "Training loss per 100 training steps: 0.0015930626965388916\n",
            "Training loss per 100 training steps: 0.00159136600783954\n",
            "Training loss per 100 training steps: 0.0015892577816840699\n",
            "Training loss per 100 training steps: 0.0015873077475135064\n",
            "Training loss per 100 training steps: 0.0015854653167086024\n",
            "Training loss per 100 training steps: 0.0015836043548056453\n",
            "Training loss per 100 training steps: 0.0015822942113491649\n",
            "Training loss per 100 training steps: 0.0015808146720219525\n",
            "Training loss per 100 training steps: 0.0015787714637109439\n",
            "Training loss per 100 training steps: 0.0015771561656852423\n",
            "Training loss per 100 training steps: 0.0015750319779304104\n",
            "Training loss per 100 training steps: 0.0015730438222771156\n",
            "Training loss per 100 training steps: 0.0015715899099484362\n",
            "Training loss per 100 training steps: 0.0015701213495039703\n",
            "Training loss per 100 training steps: 0.001568747361791061\n",
            "Training loss epoch: 0.001568481508961859\n",
            "Training accuracy epoch: 0.974994442181727\n",
            "Training steps: 32820\n",
            "\n",
            "\n",
            "\n",
            "Validation loss per 100 evaluation steps: 0.0012435607117731707\n",
            "Validation loss per 100 evaluation steps: 0.001189844358141272\n",
            "Validation loss per 100 evaluation steps: 0.0011588559781739605\n",
            "Validation loss per 100 evaluation steps: 0.001183656742960011\n",
            "Validation loss per 100 evaluation steps: 0.0011728420502113296\n",
            "Validation loss per 100 evaluation steps: 0.0012081165635330156\n",
            "Validation loss per 100 evaluation steps: 0.0011819551589048517\n",
            "Validation loss per 100 evaluation steps: 0.001191290205288169\n",
            "Validation loss per 100 evaluation steps: 0.001171236364704479\n",
            "Validation loss per 100 evaluation steps: 0.001150418717003049\n",
            "Validation loss per 100 evaluation steps: 0.0011744012767700373\n",
            "Validation loss per 100 evaluation steps: 0.0011960197234141864\n",
            "Validation loss per 100 evaluation steps: 0.0011791465860537405\n",
            "Validation loss per 100 evaluation steps: 0.0011695020689694502\n",
            "Validation loss per 100 evaluation steps: 0.0011594719936983892\n",
            "Validation loss per 100 evaluation steps: 0.001144942908460962\n",
            "Validation loss per 100 evaluation steps: 0.0011498522569030791\n",
            "Validation loss per 100 evaluation steps: 0.0011326354156719592\n",
            "Validation loss per 100 evaluation steps: 0.0011419586539590167\n",
            "Validation loss per 100 evaluation steps: 0.0011345377473789995\n",
            "Validation loss per 100 evaluation steps: 0.0011489542949805452\n",
            "Validation loss per 100 evaluation steps: 0.001138323835657502\n",
            "Validation loss per 100 evaluation steps: 0.0011336617531829372\n",
            "Validation loss per 100 evaluation steps: 0.0011409660122232404\n",
            "Validation loss per 100 evaluation steps: 0.0011374388550582809\n",
            "Validation loss per 100 evaluation steps: 0.0011332644457713915\n",
            "Validation loss per 100 evaluation steps: 0.001146308358402166\n",
            "Validation loss per 100 evaluation steps: 0.0011385930763325243\n",
            "Validation loss per 100 evaluation steps: 0.0011338991304339664\n",
            "Validation loss per 100 evaluation steps: 0.0011326959774523857\n",
            "Validation loss per 100 evaluation steps: 0.0011288953573708686\n",
            "Validation loss per 100 evaluation steps: 0.0011221863430705525\n",
            "Validation loss per 100 evaluation steps: 0.0011218507928082765\n",
            "Validation loss per 100 evaluation steps: 0.0011224385398771334\n",
            "Validation loss per 100 evaluation steps: 0.0011264625520717734\n",
            "Validation loss per 100 evaluation steps: 0.0011262870008360753\n",
            "Validation loss per 100 evaluation steps: 0.0011244569128079141\n",
            "Validation loss per 100 evaluation steps: 0.0011284829998830421\n",
            "Validation loss per 100 evaluation steps: 0.0011270884787872768\n",
            "Validation loss per 100 evaluation steps: 0.0011283616087021074\n",
            "Validation loss per 100 evaluation steps: 0.001129441167262174\n",
            "Validation Loss: 0.0011293168981069384\n",
            "Validation Accuracy: 0.9772907236757287\n",
            "Validation P-R-F1 for each label: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      B-ANIM       0.73      0.73      0.73      1134\n",
            "       B-BIO       0.00      0.00      0.00        14\n",
            "       B-CEL       0.89      0.90      0.90        94\n",
            "       B-DIS       0.68      0.81      0.74      1695\n",
            "       B-EVE       0.95      0.97      0.96       299\n",
            "      B-FOOD       0.68      0.53      0.59      2120\n",
            "      B-INST       0.45      0.71      0.55        34\n",
            "       B-LOC       0.99      0.99      0.99      7850\n",
            "     B-MEDIA       0.97      0.96      0.97       919\n",
            "      B-MYTH       0.85      0.73      0.79        56\n",
            "       B-ORG       0.97      0.98      0.98      2737\n",
            "       B-PER       0.99      1.00      1.00      7507\n",
            "     B-PLANT       0.59      0.77      0.67      1180\n",
            "      B-TIME       0.87      0.79      0.83       322\n",
            "      B-VEHI       0.93      0.78      0.84        80\n",
            "      I-ANIM       0.76      0.61      0.68      2207\n",
            "       I-BIO       0.00      0.00      0.00        37\n",
            "       I-CEL       0.70      0.90      0.79        42\n",
            "       I-DIS       0.69      0.85      0.76      3301\n",
            "       I-EVE       0.95      0.97      0.96       676\n",
            "      I-FOOD       0.73      0.48      0.58      2237\n",
            "      I-INST       0.41      0.70      0.52        53\n",
            "       I-LOC       0.99      0.99      0.99      9206\n",
            "     I-MEDIA       0.98      0.97      0.98      2456\n",
            "      I-MYTH       0.86      0.53      0.66        58\n",
            "       I-ORG       0.97      0.98      0.97      5897\n",
            "       I-PER       0.99      1.00      1.00     18465\n",
            "     I-PLANT       0.69      0.55      0.61      1954\n",
            "      I-TIME       0.91      0.70      0.79       371\n",
            "      I-VEHI       0.89      0.80      0.84       211\n",
            "           O       0.99      0.99      0.99    364321\n",
            "\n",
            "    accuracy                           0.98    437533\n",
            "   macro avg       0.78      0.76      0.76    437533\n",
            "weighted avg       0.98      0.98      0.98    437533\n",
            "\n",
            "Validation P-R-F1 tor all label: \n",
            "          precision  recall      f1\n",
            "micro        0.9763  0.9763  0.9763\n",
            "macro        0.7766  0.7634  0.7627\n",
            "weighted     0.9761  0.9763  0.9758\n",
            "Validation steps: 4103\n",
            "\n",
            "\n",
            "\n",
            "Test loss per 100 evaluation steps: 0.0007000466371391667\n",
            "Test loss per 100 evaluation steps: 0.0007376857122289948\n",
            "Test loss per 100 evaluation steps: 0.0007273132375363882\n",
            "Test loss per 100 evaluation steps: 0.0007009644908794144\n",
            "Test loss per 100 evaluation steps: 0.000781086523020349\n",
            "Test loss per 100 evaluation steps: 0.0008158583207599197\n",
            "Test loss per 100 evaluation steps: 0.0008319161087066666\n",
            "Test loss per 100 evaluation steps: 0.0008482726686816022\n",
            "Test loss per 100 evaluation steps: 0.0008581417959915901\n",
            "Test loss per 100 evaluation steps: 0.0008609644672105787\n",
            "Test loss per 100 evaluation steps: 0.0008637816731226684\n",
            "Test loss per 100 evaluation steps: 0.0008587548531734986\n",
            "Test loss per 100 evaluation steps: 0.000849650145733344\n",
            "Test loss per 100 evaluation steps: 0.0008292635552632938\n",
            "Test loss per 100 evaluation steps: 0.0008214818923249064\n",
            "Test loss per 100 evaluation steps: 0.000807432470128333\n",
            "Test loss per 100 evaluation steps: 0.000806615180847396\n",
            "Test loss per 100 evaluation steps: 0.0008111703137951231\n",
            "Test loss per 100 evaluation steps: 0.0007990010776790624\n",
            "Test loss per 100 evaluation steps: 0.0007985096372576663\n",
            "Test loss per 100 evaluation steps: 0.0008049907322284915\n",
            "Test loss per 100 evaluation steps: 0.000804892095177572\n",
            "Test loss per 100 evaluation steps: 0.0008035506670026022\n",
            "Test loss per 100 evaluation steps: 0.0008029468352378899\n",
            "Test loss per 100 evaluation steps: 0.0007978990254734527\n",
            "Test loss per 100 evaluation steps: 0.0008018935629717397\n",
            "Test loss per 100 evaluation steps: 0.0008052138601541864\n",
            "Test loss per 100 evaluation steps: 0.0008036506830519231\n",
            "Test loss per 100 evaluation steps: 0.0008163482205242777\n",
            "Test loss per 100 evaluation steps: 0.0008124473300073684\n",
            "Test loss per 100 evaluation steps: 0.0008141270428173049\n",
            "Test loss per 100 evaluation steps: 0.0008176887487286421\n",
            "Test loss per 100 evaluation steps: 0.000817287980474551\n",
            "Test loss per 100 evaluation steps: 0.000820915981034084\n",
            "Test loss per 100 evaluation steps: 0.0008242062840540062\n",
            "Test loss per 100 evaluation steps: 0.0008247193558771768\n",
            "Test loss per 100 evaluation steps: 0.0008215213148257651\n",
            "Test loss per 100 evaluation steps: 0.0008240719419432264\n",
            "Test loss per 100 evaluation steps: 0.0008210799053696787\n",
            "Test loss per 100 evaluation steps: 0.0008222396509627288\n",
            "Test loss per 100 evaluation steps: 0.0008179528212367142\n",
            "Test Loss: 0.0008163700895052734\n",
            "Test Accuracy: 0.9838999513014156\n",
            "Test P-R-F1 for each label: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      B-ANIM       0.74      0.77      0.75      1604\n",
            "       B-BIO       0.00      0.00      0.00         8\n",
            "       B-CEL       0.81      0.85      0.83        41\n",
            "       B-DIS       0.69      0.83      0.75       759\n",
            "       B-EVE       0.95      0.96      0.96       352\n",
            "      B-FOOD       0.76      0.53      0.63       566\n",
            "      B-INST       0.50      0.75      0.60        12\n",
            "       B-LOC       1.00      0.99      0.99     12024\n",
            "     B-MEDIA       0.97      0.97      0.97       458\n",
            "      B-MYTH       0.88      0.72      0.79        32\n",
            "       B-ORG       0.97      0.98      0.98      3309\n",
            "       B-PER       0.99      1.00      0.99      5265\n",
            "     B-PLANT       0.63      0.74      0.68       894\n",
            "      B-TIME       0.87      0.83      0.85       289\n",
            "      B-VEHI       0.83      0.75      0.79        32\n",
            "      I-ANIM       0.77      0.65      0.71      3187\n",
            "       I-BIO       0.00      0.00      0.00        24\n",
            "       I-CEL       0.68      0.87      0.76        31\n",
            "       I-DIS       0.73      0.84      0.78      1564\n",
            "       I-EVE       0.95      0.95      0.95       798\n",
            "      I-FOOD       0.76      0.50      0.60       590\n",
            "      I-INST       0.41      0.90      0.56        20\n",
            "       I-LOC       0.99      0.99      0.99     15066\n",
            "     I-MEDIA       0.97      0.97      0.97      1179\n",
            "      I-MYTH       0.96      0.68      0.79        34\n",
            "       I-ORG       0.97      0.98      0.98      7477\n",
            "       I-PER       0.99      1.00      0.99     13073\n",
            "     I-PLANT       0.70      0.55      0.62      1781\n",
            "      I-TIME       0.87      0.77      0.82       350\n",
            "      I-VEHI       0.92      0.73      0.82        79\n",
            "           O       0.99      0.99      0.99    326281\n",
            "\n",
            "    accuracy                           0.98    397179\n",
            "   macro avg       0.78      0.78      0.77    397179\n",
            "weighted avg       0.98      0.98      0.98    397179\n",
            "\n",
            "Test P-R-F1 tor all label: \n",
            "          precision  recall      f1\n",
            "micro        0.9827  0.9827  0.9827\n",
            "macro        0.7822  0.7759  0.7708\n",
            "weighted     0.9823  0.9827  0.9823\n",
            "Test steps: 4114\n",
            "====================================================================================================\n",
            "loss_name: ce\n",
            "model configuration\n",
            "%%%%%%%%%%%%%%%%%%%%\n",
            "Ner_Model(\n",
            "  (model): DebertaModel(\n",
            "    (embeddings): DebertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
            "      (LayerNorm): DebertaLayerNorm()\n",
            "      (dropout): StableDropout()\n",
            "    )\n",
            "    (encoder): DebertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x DebertaLayer(\n",
            "          (attention): DebertaAttention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): DebertaLayerNorm()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): DebertaLayerNorm()\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (rel_embeddings): Embedding(1024, 768)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Linear(in_features=768, out_features=31, bias=True)\n",
            ")\n",
            "%%%%%%%%%%%%%%%%%%%%\n",
            "Training epoch: 1\n",
            "Training loss per 100 training steps: 1.0402289088070393\n",
            "Training loss per 100 training steps: 0.7030319930240512\n",
            "Training loss per 100 training steps: 0.5525740888280173\n",
            "Training loss per 100 training steps: 0.45800909558311104\n",
            "Training loss per 100 training steps: 0.4009426097534597\n",
            "Training loss per 100 training steps: 0.3553031890730684\n",
            "Training loss per 100 training steps: 0.3229432432213798\n",
            "Training loss per 100 training steps: 0.30155141402676233\n",
            "Training loss per 100 training steps: 0.2821115672096817\n",
            "Training loss per 100 training steps: 0.2657175409914926\n",
            "Training loss per 100 training steps: 0.25212740189099514\n",
            "Training loss per 100 training steps: 0.24002148473480095\n",
            "Training loss per 100 training steps: 0.23077234845751754\n",
            "Training loss per 100 training steps: 0.22259616356742168\n",
            "Training loss per 100 training steps: 0.21401004525561196\n",
            "Training loss per 100 training steps: 0.20670276815864783\n",
            "Training loss per 100 training steps: 0.19997995056958376\n",
            "Training loss per 100 training steps: 0.19371851797416134\n",
            "Training loss per 100 training steps: 0.18786090944231928\n",
            "Training loss per 100 training steps: 0.18296171665436123\n",
            "Training loss per 100 training steps: 0.17884710039461166\n",
            "Training loss per 100 training steps: 0.17411345268970102\n",
            "Training loss per 100 training steps: 0.16953547059603885\n",
            "Training loss per 100 training steps: 0.16566090067574502\n",
            "Training loss per 100 training steps: 0.16237448264707346\n",
            "Training loss per 100 training steps: 0.15999945532729795\n",
            "Training loss per 100 training steps: 0.15698481566313638\n",
            "Training loss per 100 training steps: 0.15432049530389902\n",
            "Training loss per 100 training steps: 0.15192850224384716\n",
            "Training loss per 100 training steps: 0.15013152812297145\n",
            "Training loss per 100 training steps: 0.14886627407616845\n",
            "Training loss per 100 training steps: 0.1462565528848063\n",
            "Training loss per 100 training steps: 0.14473509205955037\n",
            "Training loss per 100 training steps: 0.14279662402817528\n",
            "Training loss per 100 training steps: 0.14105698908147002\n",
            "Training loss per 100 training steps: 0.1395701897116669\n",
            "Training loss per 100 training steps: 0.1374931250493879\n",
            "Training loss per 100 training steps: 0.13621523473750322\n",
            "Training loss per 100 training steps: 0.13435607721348508\n",
            "Training loss per 100 training steps: 0.13336772785500217\n",
            "Training loss per 100 training steps: 0.13198773852954107\n",
            "Training loss per 100 training steps: 0.13059730231055125\n",
            "Training loss per 100 training steps: 0.1295693132683207\n",
            "Training loss per 100 training steps: 0.1280141745924828\n",
            "Training loss per 100 training steps: 0.12736768593424413\n",
            "Training loss per 100 training steps: 0.12624763320287458\n",
            "Training loss per 100 training steps: 0.12506228582195422\n",
            "Training loss per 100 training steps: 0.12429191705682266\n",
            "Training loss per 100 training steps: 0.12308158253039214\n",
            "Training loss per 100 training steps: 0.12254047380215488\n",
            "Training loss per 100 training steps: 0.12158333457345553\n",
            "Training loss per 100 training steps: 0.12068723918011529\n",
            "Training loss per 100 training steps: 0.1197125118299506\n",
            "Training loss per 100 training steps: 0.1190205910651356\n",
            "Training loss per 100 training steps: 0.11838351055502955\n",
            "Training loss per 100 training steps: 0.11763687041676998\n",
            "Training loss per 100 training steps: 0.11682646217717169\n",
            "Training loss per 100 training steps: 0.11611731182440617\n",
            "Training loss per 100 training steps: 0.11537506485009127\n",
            "Training loss per 100 training steps: 0.11437385436762028\n",
            "Training loss per 100 training steps: 0.11395444553374069\n",
            "Training loss per 100 training steps: 0.11336365154938727\n",
            "Training loss per 100 training steps: 0.11259417378280814\n",
            "Training loss per 100 training steps: 0.11200270865670973\n",
            "Training loss per 100 training steps: 0.11174833775043058\n",
            "Training loss per 100 training steps: 0.11124632831779309\n",
            "Training loss per 100 training steps: 0.11054132340807787\n",
            "Training loss per 100 training steps: 0.11018734981028555\n",
            "Training loss per 100 training steps: 0.10956180459952178\n",
            "Training loss per 100 training steps: 0.10888192387503971\n",
            "Training loss per 100 training steps: 0.10831262571954835\n",
            "Training loss per 100 training steps: 0.10788649054909102\n",
            "Training loss per 100 training steps: 0.10741065672949221\n",
            "Training loss per 100 training steps: 0.10672928112524017\n",
            "Training loss per 100 training steps: 0.1061936390741379\n",
            "Training loss per 100 training steps: 0.10568457399000947\n",
            "Training loss per 100 training steps: 0.10511076605578283\n",
            "Training loss per 100 training steps: 0.10476560699468768\n",
            "Training loss per 100 training steps: 0.10436183513498783\n",
            "Training loss per 100 training steps: 0.1039580718504949\n",
            "Training loss per 100 training steps: 0.10365586004116469\n",
            "Training loss per 100 training steps: 0.10328038380690709\n",
            "Training loss per 100 training steps: 0.10277170686026353\n",
            "Training loss per 100 training steps: 0.1023517392454267\n",
            "Training loss per 100 training steps: 0.10186058818326359\n",
            "Training loss per 100 training steps: 0.10152553855004615\n",
            "Training loss per 100 training steps: 0.10120050406853044\n",
            "Training loss per 100 training steps: 0.10081367856983145\n",
            "Training loss per 100 training steps: 0.10052733144775038\n",
            "Training loss per 100 training steps: 0.10010074598946246\n",
            "Training loss per 100 training steps: 0.09985267272769796\n",
            "Training loss per 100 training steps: 0.09947653483278966\n",
            "Training loss per 100 training steps: 0.0991410638202828\n",
            "Training loss per 100 training steps: 0.09884555098167534\n",
            "Training loss per 100 training steps: 0.09850583030919753\n",
            "Training loss per 100 training steps: 0.09807338228343118\n",
            "Training loss per 100 training steps: 0.09784800864323151\n",
            "Training loss per 100 training steps: 0.09743603084308847\n",
            "Training loss per 100 training steps: 0.09700914456025607\n",
            "Training loss per 100 training steps: 0.09670349605751981\n",
            "Training loss per 100 training steps: 0.09640554009710547\n",
            "Training loss per 100 training steps: 0.09621076139997219\n",
            "Training loss per 100 training steps: 0.0959756524430433\n",
            "Training loss per 100 training steps: 0.09559080729518778\n",
            "Training loss per 100 training steps: 0.09519967018981974\n",
            "Training loss per 100 training steps: 0.09498627527991974\n",
            "Training loss per 100 training steps: 0.09482702558673592\n",
            "Training loss per 100 training steps: 0.09455781147211383\n",
            "Training loss per 100 training steps: 0.09425744802424302\n",
            "Training loss per 100 training steps: 0.09397195126808683\n",
            "Training loss per 100 training steps: 0.09383718221201635\n",
            "Training loss per 100 training steps: 0.0937010989069131\n",
            "Training loss per 100 training steps: 0.09339270632529366\n",
            "Training loss per 100 training steps: 0.0931578153701948\n",
            "Training loss per 100 training steps: 0.09290826851099543\n",
            "Training loss per 100 training steps: 0.09270428443752939\n",
            "Training loss per 100 training steps: 0.09242264005066116\n",
            "Training loss per 100 training steps: 0.09219139031602304\n",
            "Training loss per 100 training steps: 0.09199264366728153\n",
            "Training loss per 100 training steps: 0.09165195251256106\n",
            "Training loss per 100 training steps: 0.09158972725415172\n",
            "Training loss per 100 training steps: 0.09129668573567526\n",
            "Training loss per 100 training steps: 0.09110418884454288\n",
            "Training loss per 100 training steps: 0.09086679139424837\n",
            "Training loss per 100 training steps: 0.09053085247970885\n",
            "Training loss per 100 training steps: 0.09026736836658125\n",
            "Training loss per 100 training steps: 0.09007236612016196\n",
            "Training loss per 100 training steps: 0.08974051630162308\n",
            "Training loss per 100 training steps: 0.08952034673164982\n",
            "Training loss per 100 training steps: 0.08923435158134985\n",
            "Training loss per 100 training steps: 0.08895313450779463\n",
            "Training loss per 100 training steps: 0.08879037479584054\n",
            "Training loss per 100 training steps: 0.08854809442564146\n",
            "Training loss per 100 training steps: 0.08841261216817874\n",
            "Training loss per 100 training steps: 0.0882158281580433\n",
            "Training loss per 100 training steps: 0.08800009790665868\n",
            "Training loss per 100 training steps: 0.08773806687431383\n",
            "Training loss per 100 training steps: 0.0875446599636105\n",
            "Training loss per 100 training steps: 0.08735935020095417\n",
            "Training loss per 100 training steps: 0.08722582021888126\n",
            "Training loss per 100 training steps: 0.08707605072232033\n",
            "Training loss per 100 training steps: 0.08691038183923577\n",
            "Training loss per 100 training steps: 0.08677942522034583\n",
            "Training loss per 100 training steps: 0.08662293739737935\n",
            "Training loss per 100 training steps: 0.0864882403382859\n",
            "Training loss per 100 training steps: 0.08633278191819618\n",
            "Training loss per 100 training steps: 0.08615449535921588\n",
            "Training loss per 100 training steps: 0.08603573501116567\n",
            "Training loss per 100 training steps: 0.08590027037668495\n",
            "Training loss per 100 training steps: 0.0857024741158132\n",
            "Training loss per 100 training steps: 0.08551665217630794\n",
            "Training loss per 100 training steps: 0.0853490931694394\n",
            "Training loss per 100 training steps: 0.08516805063269167\n",
            "Training loss per 100 training steps: 0.08490241423807982\n",
            "Training loss per 100 training steps: 0.08480701818003511\n",
            "Training loss per 100 training steps: 0.08465545449545925\n",
            "Training loss per 100 training steps: 0.08462983260861695\n",
            "Training loss per 100 training steps: 0.08461407457859918\n",
            "Training loss per 100 training steps: 0.08448728276446404\n",
            "Training loss per 100 training steps: 0.08431869318277586\n",
            "Training loss per 100 training steps: 0.08423606708770823\n",
            "Training loss per 100 training steps: 0.08406296404208942\n",
            "Training loss per 100 training steps: 0.0837818705390857\n",
            "Training loss per 100 training steps: 0.08368854164828851\n",
            "Training loss per 100 training steps: 0.08353262911326954\n",
            "Training loss per 100 training steps: 0.08332292875628207\n",
            "Training loss per 100 training steps: 0.08312977973425507\n",
            "Training loss per 100 training steps: 0.08292637470037117\n",
            "Training loss per 100 training steps: 0.08277169338636549\n",
            "Training loss per 100 training steps: 0.08269985947257373\n",
            "Training loss per 100 training steps: 0.08247374220291522\n",
            "Training loss per 100 training steps: 0.08227952901305269\n",
            "Training loss per 100 training steps: 0.08217790601466012\n",
            "Training loss per 100 training steps: 0.08202632936011083\n",
            "Training loss per 100 training steps: 0.08193687917398722\n",
            "Training loss per 100 training steps: 0.08193285852763935\n",
            "Training loss per 100 training steps: 0.08175056328931574\n",
            "Training loss per 100 training steps: 0.08162537686234266\n",
            "Training loss per 100 training steps: 0.08147318677109466\n",
            "Training loss per 100 training steps: 0.08131098917031097\n",
            "Training loss per 100 training steps: 0.08130124064360472\n",
            "Training loss per 100 training steps: 0.08120688744733502\n",
            "Training loss per 100 training steps: 0.08109378358894305\n",
            "Training loss per 100 training steps: 0.08090108880191269\n",
            "Training loss per 100 training steps: 0.08077942212999364\n",
            "Training loss per 100 training steps: 0.08068286324298399\n",
            "Training loss per 100 training steps: 0.0805248524110419\n",
            "Training loss per 100 training steps: 0.08044845878002153\n",
            "Training loss per 100 training steps: 0.08031070626828257\n",
            "Training loss per 100 training steps: 0.08014129835278895\n",
            "Training loss per 100 training steps: 0.0799925784403219\n",
            "Training loss per 100 training steps: 0.07983211695112687\n",
            "Training loss per 100 training steps: 0.07971233439515722\n",
            "Training loss per 100 training steps: 0.07957624377256599\n",
            "Training loss per 100 training steps: 0.07940282943728678\n",
            "Training loss per 100 training steps: 0.0793111556237213\n",
            "Training loss per 100 training steps: 0.07917236653844285\n",
            "Training loss per 100 training steps: 0.07902561465675946\n",
            "Training loss per 100 training steps: 0.07901343642114766\n",
            "Training loss per 100 training steps: 0.07894065119743172\n",
            "Training loss per 100 training steps: 0.07886259634685787\n",
            "Training loss per 100 training steps: 0.07875879351714152\n",
            "Training loss per 100 training steps: 0.07868517604940818\n",
            "Training loss per 100 training steps: 0.0786145368519404\n",
            "Training loss per 100 training steps: 0.07850579041466343\n",
            "Training loss per 100 training steps: 0.07835723214123841\n",
            "Training loss per 100 training steps: 0.07824152831485114\n",
            "Training loss per 100 training steps: 0.07816388968737556\n",
            "Training loss per 100 training steps: 0.07800767120680537\n",
            "Training loss per 100 training steps: 0.07793063119784971\n",
            "Training loss per 100 training steps: 0.07787821859323119\n",
            "Training loss per 100 training steps: 0.07781778601008107\n",
            "Training loss per 100 training steps: 0.07771547333740994\n",
            "Training loss per 100 training steps: 0.07759481564304513\n",
            "Training loss per 100 training steps: 0.07746367040810752\n",
            "Training loss per 100 training steps: 0.07737092766534799\n",
            "Training loss per 100 training steps: 0.07741076486626645\n",
            "Training loss per 100 training steps: 0.07726574950840953\n",
            "Training loss per 100 training steps: 0.07720607989777324\n",
            "Training loss per 100 training steps: 0.07710777425217086\n",
            "Training loss per 100 training steps: 0.0770595513400355\n",
            "Training loss per 100 training steps: 0.07696505297650366\n",
            "Training loss per 100 training steps: 0.07687621350954851\n",
            "Training loss per 100 training steps: 0.07676049836391842\n",
            "Training loss per 100 training steps: 0.07670027738338006\n",
            "Training loss per 100 training steps: 0.0766045983060922\n",
            "Training loss per 100 training steps: 0.0765955238830389\n",
            "Training loss per 100 training steps: 0.07651374590636024\n",
            "Training loss per 100 training steps: 0.0764875775922574\n",
            "Training loss per 100 training steps: 0.07641519156131804\n",
            "Training loss per 100 training steps: 0.07630608003167265\n",
            "Training loss per 100 training steps: 0.07621965321158752\n",
            "Training loss per 100 training steps: 0.07618219577230353\n",
            "Training loss per 100 training steps: 0.07610280754434226\n",
            "Training loss per 100 training steps: 0.07602105332974393\n",
            "Training loss per 100 training steps: 0.07588573668168835\n",
            "Training loss per 100 training steps: 0.07586700929322014\n",
            "Training loss per 100 training steps: 0.0758109803516773\n",
            "Training loss per 100 training steps: 0.07571391486421379\n",
            "Training loss per 100 training steps: 0.07561456120016707\n",
            "Training loss per 100 training steps: 0.07561151019053569\n",
            "Training loss per 100 training steps: 0.07554038720647606\n",
            "Training loss per 100 training steps: 0.07549470962076875\n",
            "Training loss per 100 training steps: 0.07537521713178827\n",
            "Training loss per 100 training steps: 0.07523290674198313\n",
            "Training loss per 100 training steps: 0.07513171476036294\n",
            "Training loss per 100 training steps: 0.0750500278202246\n",
            "Training loss per 100 training steps: 0.07496362329740658\n",
            "Training loss per 100 training steps: 0.07496205013729444\n",
            "Training loss per 100 training steps: 0.07480175793332688\n",
            "Training loss per 100 training steps: 0.07474065314258244\n",
            "Training loss per 100 training steps: 0.074676167249808\n",
            "Training loss per 100 training steps: 0.07463343666414565\n",
            "Training loss per 100 training steps: 0.0745676992320665\n",
            "Training loss per 100 training steps: 0.074497355406604\n",
            "Training loss per 100 training steps: 0.07442810076228909\n",
            "Training loss per 100 training steps: 0.0743558624648167\n",
            "Training loss per 100 training steps: 0.07428428952375915\n",
            "Training loss per 100 training steps: 0.07420225105056183\n",
            "Training loss per 100 training steps: 0.07417625025238354\n",
            "Training loss per 100 training steps: 0.07414587858460743\n",
            "Training loss per 100 training steps: 0.0740854656997883\n",
            "Training loss per 100 training steps: 0.07406104854384203\n",
            "Training loss per 100 training steps: 0.07394014405436158\n",
            "Training loss per 100 training steps: 0.0738657825466296\n",
            "Training loss per 100 training steps: 0.07377414202795074\n",
            "Training loss per 100 training steps: 0.0737018433874583\n",
            "Training loss per 100 training steps: 0.07362764516433276\n",
            "Training loss per 100 training steps: 0.07360585813024279\n",
            "Training loss per 100 training steps: 0.07351755947481488\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "def train(config,loss_name):\n",
        "    print(\"=\" * 100)\n",
        "    print(f\"loss_name: {loss_name}\")\n",
        "    model = Ner_Model(config, len(label2id), loss_name).to(config.device)\n",
        "    optimizer = get_optimizer(model, config)\n",
        "\n",
        "    valid_each_label_p_r_f1_list = []\n",
        "    valid_p_r_f1_list = []\n",
        "    test_each_label_p_r_f1_list = []\n",
        "    test_p_r_f1_list = []\n",
        "\n",
        "    valid_loss_list = []\n",
        "    test_loss_list = []\n",
        "\n",
        "    model.train()\n",
        "    interval = 100\n",
        "    for epoch in range(config.epochs):\n",
        "        print(f\"Training epoch: {epoch + 1}\")\n",
        "        tr_preds,tr_labels = [], []\n",
        "        total_loss = 0.0\n",
        "        tr_accuracy = 0.0\n",
        "        # print(\"\\n\" + \"-\" * 30 + \"\\n\")\n",
        "        # print(f\"epoch: {epoch},  train dataloader size: {len(train_dataloader)}\")\n",
        "        # print(f\"epoch: {epoch},  valid dataloader size: {len(valid_dataloader)}\")\n",
        "        # print(f\"epoch: {epoch},  test dataloader size: {len(test_dataloader)}\")\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            attention_mask = batch[\"id\"].ne(0)\n",
        "            targets = batch['label_id']\n",
        "            loss, logit= model(batch[\"id\"], batch['seq_length'], attention_mask=attention_mask,\n",
        "                                             labels=targets)\n",
        "\n",
        "            # compute training accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = logit.view(-1, len(label2id)) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            active_accuracy = flattened_targets.ne(-100) # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "            tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            tr_accuracy += tmp_tr_accuracy\n",
        "            tr_preds.extend(predictions)\n",
        "            tr_labels.extend(targets)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            if (step + 1) % interval == 0:\n",
        "                print(f\"Training loss per 100 training steps: {total_loss / (step+1)}\")\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f\"Training loss epoch: {total_loss / (step+1)}\")\n",
        "        print(f\"Training accuracy epoch: {tr_accuracy / (step+1)}\")\n",
        "        print(f\"Training steps: {step+1}\")\n",
        "        print(\"\\n\\n\")\n",
        "        model.eval()\n",
        "\n",
        "\n",
        "        valid_loss, valid_p_r_f1,  valid_each_label_p_r_f1 = evaluate(model,valid_dataloader, \"Validation\")\n",
        "        valid_loss_list.append(valid_loss)\n",
        "        valid_p_r_f1_list.append(valid_p_r_f1)\n",
        "        valid_each_label_p_r_f1_list.append(valid_each_label_p_r_f1)\n",
        "\n",
        "        print(\"\\n\\n\")\n",
        "        test_loss, test_p_r_f1,test_each_label_p_r_f1  = evaluate(model,test_dataloader, \"Test\")\n",
        "        test_loss_list.append(test_loss)\n",
        "        test_p_r_f1_list.append(test_p_r_f1)\n",
        "        test_each_label_p_r_f1_list.append(test_each_label_p_r_f1)\n",
        "\n",
        "\n",
        "        #print(f\"epoch: {epoch}, train_loss: {train_loss}, \\n{train_p_r_f1}\")\n",
        "        #print(f\"epoch: {epoch}, valid_loss: {valid_loss}, \\n{valid_p_r_f1}\")\n",
        "        #print(f\"epoch: {epoch}, test_loss: {test_loss},  \\n {test_p_r_f1}\")\n",
        "        model.train()\n",
        "    return   {\n",
        "              \"valid_loss_list\":valid_loss_list,\n",
        "              \"test_loss_list\":test_loss_list,\n",
        "\n",
        "              \"valid_p_r_f1_list\":valid_p_r_f1_list,\n",
        "              \"valid_each_label_p_r_f1_list\":valid_each_label_p_r_f1_list,\n",
        "\n",
        "              \"test_p_r_f1_list\":test_p_r_f1_list,\n",
        "              \"test_each_label_p_r_f1_list\": test_each_label_p_r_f1_list}\n",
        "\n",
        "\n",
        "result = {}\n",
        "for loss_name in ['l1', 'l2', 'ce', 'kl', 'dlite']:\n",
        "    r = train(Config, loss_name)\n",
        "    result[loss_name] = r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS1O-MxfGr33",
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "tags": []
      },
      "source": [
        "## Result Comparison after cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciR0WOCJGr33",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"result.pkl\", \"wb\") as f:\n",
        "    pickle.dump(result, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYodcFxGGr33"
      },
      "source": [
        "#### Overall Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgKkKD11Gr33",
        "tags": []
      },
      "outputs": [],
      "source": [
        "columns = ['loss', 'precision', 'recall', 'f1']\n",
        "for t in ['micro', 'macro', 'weighted']:\n",
        "    df = []\n",
        "    for loss_name in loss_list:\n",
        "        row = {'loss': loss_name}\n",
        "        row['precision'] = result[loss_name]['test_p_r_f1_list'][-1].loc[t, 'precision']\n",
        "        row['recall'] = result[loss_name]['test_p_r_f1_list'][-1].loc[t, 'recall']\n",
        "        row['f1'] = result[loss_name]['test_p_r_f1_list'][-1].loc[t, 'f1']\n",
        "        df.append(row)\n",
        "    print(\"=\"*100)\n",
        "    print(t)\n",
        "    print(pd.DataFrame(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKeZYzqvGr33"
      },
      "source": [
        "#### Each label Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejx5I88-Gr34",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"test dataset\")\n",
        "for loss_name in loss_list:\n",
        "    print(\"-\"*50)\n",
        "    print(loss_name)\n",
        "    print(result[loss_name]['test_each_label_p_r_f1_list'][-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqfxwsPKGr38"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OsiRbqeDRTI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e7cf939d9ee347029e5e8aebe122746f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea688d97b8534806810ba4554614018b",
              "IPY_MODEL_fa0fbf29c6e74b0496274460e7f918db",
              "IPY_MODEL_71c00ab2aa194ba6af8680865904af55"
            ],
            "layout": "IPY_MODEL_1691560fe61545ba968b02f40952caf3"
          }
        },
        "ea688d97b8534806810ba4554614018b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17bb8cdfe4ed43f89f1d651bff4aa772",
            "placeholder": "​",
            "style": "IPY_MODEL_49ab97c280ee425c9d82a5700807189a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "fa0fbf29c6e74b0496274460e7f918db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6048ae45e7e4b40907103d2736dfc1e",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d27df46cb0540fdaabe842fb1a5e13e",
            "value": 52
          }
        },
        "71c00ab2aa194ba6af8680865904af55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_663f9f9c11014bceaaf729ee1cd66cd7",
            "placeholder": "​",
            "style": "IPY_MODEL_431eb6f2ad154284a45a86665e194af1",
            "value": " 52.0/52.0 [00:00&lt;00:00, 4.42kB/s]"
          }
        },
        "1691560fe61545ba968b02f40952caf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17bb8cdfe4ed43f89f1d651bff4aa772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49ab97c280ee425c9d82a5700807189a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6048ae45e7e4b40907103d2736dfc1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d27df46cb0540fdaabe842fb1a5e13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "663f9f9c11014bceaaf729ee1cd66cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "431eb6f2ad154284a45a86665e194af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3373aa0612b744c39e1567bd5087083d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_454033d718684b93b49a6d2745c7fae8",
              "IPY_MODEL_c88634852504431caee3893c214b6da4",
              "IPY_MODEL_f37b7f79be3b413095716b9908dd54dd"
            ],
            "layout": "IPY_MODEL_9192b0332e16483faca5bde28078f707"
          }
        },
        "454033d718684b93b49a6d2745c7fae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dbd0e531d384d67905727fd3ad64618",
            "placeholder": "​",
            "style": "IPY_MODEL_3978b2780427401ca63e4cbd30b238de",
            "value": "config.json: 100%"
          }
        },
        "c88634852504431caee3893c214b6da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffb14f208d5e49789f85d06dbf82d99a",
            "max": 474,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50706c9bcac140028d5674d0f40a4488",
            "value": 474
          }
        },
        "f37b7f79be3b413095716b9908dd54dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87560f22138b4bdc99d3042ea4d1d42e",
            "placeholder": "​",
            "style": "IPY_MODEL_54e7e98c45b14ee2885e11b6da29b43d",
            "value": " 474/474 [00:00&lt;00:00, 39.1kB/s]"
          }
        },
        "9192b0332e16483faca5bde28078f707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dbd0e531d384d67905727fd3ad64618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3978b2780427401ca63e4cbd30b238de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffb14f208d5e49789f85d06dbf82d99a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50706c9bcac140028d5674d0f40a4488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87560f22138b4bdc99d3042ea4d1d42e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54e7e98c45b14ee2885e11b6da29b43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8eec36c3d7f4b1b8f8dd5d474b3c9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_356a2257137a49a69205a79404b70255",
              "IPY_MODEL_3a35855fa80548939f93cb5260d60c10",
              "IPY_MODEL_9361a395a26a4d45b3f093e6550efa69"
            ],
            "layout": "IPY_MODEL_8ff28817aca242df8b78d822fc61e3a8"
          }
        },
        "356a2257137a49a69205a79404b70255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9d686bdc9f44531b108d994ee9095ee",
            "placeholder": "​",
            "style": "IPY_MODEL_dbfbed96628748cf8f9e6892811d93fb",
            "value": "vocab.json: 100%"
          }
        },
        "3a35855fa80548939f93cb5260d60c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3efac9f2a5946928786eb0362c673ff",
            "max": 898825,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c02ffaf8e58435aabb268ef4ffc9c59",
            "value": 898825
          }
        },
        "9361a395a26a4d45b3f093e6550efa69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e35ebc90417b4f94a68d6eb9240582ae",
            "placeholder": "​",
            "style": "IPY_MODEL_fb74b3485167460bb130774ad87cdd22",
            "value": " 899k/899k [00:00&lt;00:00, 20.0MB/s]"
          }
        },
        "8ff28817aca242df8b78d822fc61e3a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9d686bdc9f44531b108d994ee9095ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbfbed96628748cf8f9e6892811d93fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3efac9f2a5946928786eb0362c673ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c02ffaf8e58435aabb268ef4ffc9c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e35ebc90417b4f94a68d6eb9240582ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb74b3485167460bb130774ad87cdd22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a75d3b2f15c4e0ebce08471c4d0ff34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee4d94d8f1d646909910b9bcca2558e5",
              "IPY_MODEL_21aa8b6aac9d4a3aad75ea73f2e3dcee",
              "IPY_MODEL_77bf0d276ba74a21b499684ee1b8f9d5"
            ],
            "layout": "IPY_MODEL_95e4a7a3537542589cf2af5cb039275e"
          }
        },
        "ee4d94d8f1d646909910b9bcca2558e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78aeba80651c4379891747735f260a8b",
            "placeholder": "​",
            "style": "IPY_MODEL_48e14a01ebbb4edb80d560144fc37b97",
            "value": "merges.txt: 100%"
          }
        },
        "21aa8b6aac9d4a3aad75ea73f2e3dcee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bb99885b51743c3a85ff356ae826e2c",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e07fbb53ead452eb29a3f351d70510d",
            "value": 456318
          }
        },
        "77bf0d276ba74a21b499684ee1b8f9d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8953bae3e5d343d1b4a6422ba19bdff7",
            "placeholder": "​",
            "style": "IPY_MODEL_73c88947c60c4225af8721c097bc6226",
            "value": " 456k/456k [00:00&lt;00:00, 2.14MB/s]"
          }
        },
        "95e4a7a3537542589cf2af5cb039275e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78aeba80651c4379891747735f260a8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e14a01ebbb4edb80d560144fc37b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bb99885b51743c3a85ff356ae826e2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e07fbb53ead452eb29a3f351d70510d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8953bae3e5d343d1b4a6422ba19bdff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73c88947c60c4225af8721c097bc6226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b39c00b74f694027bf1612220844ca84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41eb080f04ef43e7ba983c3736c85a91",
              "IPY_MODEL_42df3774479f4e358cf371d2a69c07cf",
              "IPY_MODEL_d75e64d99b794a92997bc1c16657f220"
            ],
            "layout": "IPY_MODEL_98be5ad67d484e09861ae49fff07a7b4"
          }
        },
        "41eb080f04ef43e7ba983c3736c85a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04e365082e01489f9e307cfefcf230be",
            "placeholder": "​",
            "style": "IPY_MODEL_cf0044d481f5469fa2a736687d22ab49",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "42df3774479f4e358cf371d2a69c07cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21562caa166a4440903175911dab6e91",
            "max": 558614189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3f1c97a80a346c0af630c091c91be67",
            "value": 558614189
          }
        },
        "d75e64d99b794a92997bc1c16657f220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9ade83b2ccf4923a7afc52580bcdfaa",
            "placeholder": "​",
            "style": "IPY_MODEL_7d4258b7a8fd47bf95be0c33eeeaccf5",
            "value": " 559M/559M [00:01&lt;00:00, 432MB/s]"
          }
        },
        "98be5ad67d484e09861ae49fff07a7b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04e365082e01489f9e307cfefcf230be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf0044d481f5469fa2a736687d22ab49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21562caa166a4440903175911dab6e91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3f1c97a80a346c0af630c091c91be67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9ade83b2ccf4923a7afc52580bcdfaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d4258b7a8fd47bf95be0c33eeeaccf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}