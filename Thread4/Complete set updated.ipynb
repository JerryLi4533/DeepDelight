{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82fdcbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertConfig, BertForTokenClassification\n",
    "# Using the dlite function\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f8d35a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\25141\\anaconda3\\lib\\site-packages (2.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement gpu (from versions: none)\n",
      "ERROR: No matching distribution found for gpu\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c8951f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ner dataset website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/datasets/namanj27/ner-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8328f08",
   "metadata": {},
   "source": [
    "# Data preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf2e5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags: 17\n",
      "[('geo', 45058), ('org', 36927), ('per', 34241), ('tim', 26861), ('gpe', 16068), ('art', 699), ('eve', 561), ('nat', 252)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'B-gpe,O,O,B-tim,O,B-per,I-per,O,O,O,B-geo,O,O,O,O,O,O,O,O'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"ner_datasetreference.csv\", encoding='unicode_escape')\n",
    "data.head()\n",
    "\n",
    "data.count()\n",
    "\n",
    "print(\"Number of tags: {}\".format(len(data.Tag.unique())))\n",
    "frequencies = data.Tag.value_counts()\n",
    "frequencies\n",
    "\n",
    "tags = {}\n",
    "for tag, count in zip(frequencies.index, frequencies):\n",
    "    if tag != \"O\":\n",
    "        if tag[2:5] not in tags.keys():\n",
    "            tags[tag[2:5]] = count\n",
    "        else:\n",
    "            tags[tag[2:5]] += count\n",
    "    continue\n",
    "\n",
    "print(sorted(tags.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "entities_to_remove = [\"B-art\", \"I-art\", \"B-eve\", \"I-eve\", \"B-nat\", \"I-nat\"]\n",
    "data = data[~data.Tag.isin(entities_to_remove)]\n",
    "data.head()\n",
    "\n",
    "# pandas has a very handy \"forward fill\" function to fill missing values based on the last upper non-nan value\n",
    "data = data.fillna(method='ffill')\n",
    "data.head()\n",
    "\n",
    "# let's create a new column called \"sentence\" which groups the words by sentence \n",
    "data['sentence'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Word'].transform(lambda x: ' '.join(x))\n",
    "# let's also create a new column called \"word_labels\" which groups the tags by sentence \n",
    "data['word_labels'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Tag'].transform(lambda x: ','.join(x))\n",
    "data.head()\n",
    "\n",
    "label2id = {k: v for v, k in enumerate(data.Tag.unique())}\n",
    "id2label = {v: k for v, k in enumerate(data.Tag.unique())}\n",
    "label2id\n",
    "\n",
    "data = data[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n",
    "data.head()\n",
    "\n",
    "\n",
    "\n",
    "len(data)\n",
    "\n",
    "data.iloc[41].sentence\n",
    "\n",
    "data.iloc[41].word_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374ae95e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b1ea60b",
   "metadata": {},
   "source": [
    "# Data preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4905bf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (47571, 2)\n",
      "TRAIN Dataset: (38057, 2)\n",
      "TEST Dataset: (9514, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 5e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# tokenization\n",
    "\n",
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "    \"\"\"\n",
    "    Word piece tokenization makes it difficult to match word labels\n",
    "    back up with individual word pieces. This function tokenizes each\n",
    "    word one at a time so that it is easier to preserve the correct\n",
    "    label for each subword. It is, of course, a bit slower in processing\n",
    "    time, but it will help our model achieve higher accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels\n",
    "\n",
    "# Bert imput\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # step 1: tokenize (and adapt corresponding labels)\n",
    "        sentence = self.data.sentence[index]  \n",
    "        word_labels = self.data.word_labels[index]  \n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "        \n",
    "        # step 2: add special tokens (and corresponding labels)\n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
    "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "\n",
    "        # step 3: truncating/padding\n",
    "        maxlen = self.max_len\n",
    "\n",
    "        if (len(tokenized_sentence) > maxlen):\n",
    "          # truncate\n",
    "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
    "          labels = labels[:maxlen]\n",
    "        else:\n",
    "          # pad\n",
    "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
    "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
    "\n",
    "        # step 4: obtain the attention mask\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "        \n",
    "        # step 5: convert tokens to input ids\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "        # the following line is deprecated\n",
    "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
    "        \n",
    "        return {\n",
    "              'ids': torch.tensor(ids, dtype=torch.long),\n",
    "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# define training size 80/20 split\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
    "\n",
    "# pyTorch dataloaders\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', \n",
    "                                                   num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                   label2id=label2id)\n",
    "model.to(device)\n",
    "\n",
    "# Train the model \n",
    "\n",
    "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
    "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
    "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "mask = mask.to(device)\n",
    "targets = targets.to(device)\n",
    "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7c632e",
   "metadata": {},
   "source": [
    "# Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9efa25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "        \n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d46c2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training loss per 100 training steps: 2.3727476596832275\n",
      "Training loss per 100 training steps: 0.18574057703856195\n",
      "Training loss per 100 training steps: 0.12546068689419856\n",
      "Training loss per 100 training steps: 0.0987082476189292\n",
      "Training loss per 100 training steps: 0.08669843241001045\n",
      "Training loss per 100 training steps: 0.07771627727371758\n",
      "Training loss per 100 training steps: 0.07119039212897445\n",
      "Training loss per 100 training steps: 0.06617570807692327\n",
      "Training loss per 100 training steps: 0.06294496543589194\n",
      "Training loss per 100 training steps: 0.060403338875805034\n",
      "Training loss per 100 training steps: 0.057924846149145996\n",
      "Training loss per 100 training steps: 0.056219674313627434\n",
      "Training loss per 100 training steps: 0.05461481107317639\n",
      "Training loss per 100 training steps: 0.05323568511712934\n",
      "Training loss per 100 training steps: 0.051763345931680256\n",
      "Training loss per 100 training steps: 0.05072563553315375\n",
      "Training loss per 100 training steps: 0.04936054930951331\n",
      "Training loss per 100 training steps: 0.048654375995723816\n",
      "Training loss per 100 training steps: 0.04776008528599276\n",
      "Training loss per 100 training steps: 0.047074490056790465\n",
      "Training loss per 100 training steps: 0.04640583798887316\n",
      "Training loss per 100 training steps: 0.04581746465688261\n",
      "Training loss per 100 training steps: 0.045094050006999245\n",
      "Training loss per 100 training steps: 0.044513973717571986\n",
      "Training loss per 100 training steps: 0.04394772677290911\n",
      "Training loss per 100 training steps: 0.04350514256426633\n",
      "Training loss per 100 training steps: 0.04316293963363227\n",
      "Training loss per 100 training steps: 0.04282063054520958\n",
      "Training loss per 100 training steps: 0.04238593469885552\n",
      "Training loss per 100 training steps: 0.042126530821146466\n",
      "Training loss per 100 training steps: 0.041691302756663065\n",
      "Training loss per 100 training steps: 0.04131221446507747\n",
      "Training loss per 100 training steps: 0.04099512595494911\n",
      "Training loss per 100 training steps: 0.0406097778482235\n",
      "Training loss per 100 training steps: 0.04021002358985237\n",
      "Training loss per 100 training steps: 0.0398989512327949\n",
      "Training loss per 100 training steps: 0.03973909776301203\n",
      "Training loss per 100 training steps: 0.039486795338800215\n",
      "Training loss per 100 training steps: 0.03918840308944259\n",
      "Training loss per 100 training steps: 0.03893068138193376\n",
      "Training loss per 100 training steps: 0.03876458319209687\n",
      "Training loss per 100 training steps: 0.038528394937454996\n",
      "Training loss per 100 training steps: 0.03837218005463235\n",
      "Training loss per 100 training steps: 0.038203111590534695\n",
      "Training loss per 100 training steps: 0.037943109078277894\n",
      "Training loss per 100 training steps: 0.0378225923547081\n",
      "Training loss per 100 training steps: 0.037676104294205925\n",
      "Training loss per 100 training steps: 0.037449207837809216\n",
      "Training loss per 100 training steps: 0.037239563405970524\n",
      "Training loss per 100 training steps: 0.03711573067899903\n",
      "Training loss per 100 training steps: 0.03692245911745891\n",
      "Training loss per 100 training steps: 0.03682674641297978\n",
      "Training loss per 100 training steps: 0.036756819061927626\n",
      "Training loss per 100 training steps: 0.036636193263744\n",
      "Training loss per 100 training steps: 0.03650924788200097\n",
      "Training loss per 100 training steps: 0.036452879869100965\n",
      "Training loss per 100 training steps: 0.03627810553520936\n",
      "Training loss per 100 training steps: 0.036157554822618884\n",
      "Training loss per 100 training steps: 0.036069473290788134\n",
      "Training loss per 100 training steps: 0.03595652837096887\n",
      "Training loss per 100 training steps: 0.035800378172166185\n",
      "Training loss per 100 training steps: 0.03566312976092779\n",
      "Training loss per 100 training steps: 0.03565793176337398\n",
      "Training loss per 100 training steps: 0.03550770778939019\n",
      "Training loss per 100 training steps: 0.03536664571292181\n",
      "Training loss per 100 training steps: 0.03525352605457442\n",
      "Training loss per 100 training steps: 0.03514285138342953\n",
      "Training loss per 100 training steps: 0.035010337287557605\n",
      "Training loss per 100 training steps: 0.03490317998982696\n",
      "Training loss per 100 training steps: 0.03480798769233471\n",
      "Training loss per 100 training steps: 0.03471937622806167\n",
      "Training loss per 100 training steps: 0.03461292781702325\n",
      "Training loss per 100 training steps: 0.034558191760583154\n",
      "Training loss per 100 training steps: 0.034491380004532377\n",
      "Training loss per 100 training steps: 0.034432998301412325\n",
      "Training loss per 100 training steps: 0.03432837953722145\n",
      "Training loss per 100 training steps: 0.034273735254467474\n",
      "Training loss per 100 training steps: 0.03420811344359934\n",
      "Training loss per 100 training steps: 0.03413347587111593\n",
      "Training loss per 100 training steps: 0.034028564585103935\n",
      "Training loss per 100 training steps: 0.03394447680907179\n",
      "Training loss per 100 training steps: 0.033891935389939565\n",
      "Training loss per 100 training steps: 0.03380712870523238\n",
      "Training loss per 100 training steps: 0.03375096084186332\n",
      "Training loss per 100 training steps: 0.033683915924729274\n",
      "Training loss per 100 training steps: 0.03361197170371829\n",
      "Training loss per 100 training steps: 0.03353757053744912\n",
      "Training loss per 100 training steps: 0.033434723386873595\n",
      "Training loss per 100 training steps: 0.0333419330597508\n",
      "Training loss per 100 training steps: 0.03328785258962597\n",
      "Training loss per 100 training steps: 0.03325893936616188\n",
      "Training loss per 100 training steps: 0.03315781906467044\n",
      "Training loss per 100 training steps: 0.033090991354934034\n",
      "Training loss per 100 training steps: 0.03303443220047196\n",
      "Training loss per 100 training steps: 0.032971327030214784\n",
      "Training loss per 100 training steps: 0.03290263839730071\n",
      "Training loss epoch: 0.032893175355492334\n",
      "Training accuracy epoch: 0.9533922908334069\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9e097d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.long)\n",
    "            \n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += targets.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(targets)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    #print(eval_labels)\n",
    "    #print(eval_preds)\n",
    "\n",
    "    labels = [id2label[id.item()] for id in eval_labels]\n",
    "    predictions = [id2label[id.item()] for id in eval_preds]\n",
    "\n",
    "    #print(labels)\n",
    "    #print(predictions)\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a520c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 0.007336726412177086\n",
      "Validation loss per 100 evaluation steps: 0.02792147647688571\n",
      "Validation loss per 100 evaluation steps: 0.02805037380924329\n",
      "Validation loss per 100 evaluation steps: 0.027973322214159775\n",
      "Validation loss per 100 evaluation steps: 0.028688459222044875\n",
      "Validation loss per 100 evaluation steps: 0.028909725480215802\n",
      "Validation loss per 100 evaluation steps: 0.02796043216640615\n",
      "Validation loss per 100 evaluation steps: 0.02733076691095496\n",
      "Validation loss per 100 evaluation steps: 0.027363499507367814\n",
      "Validation loss per 100 evaluation steps: 0.027861596022150933\n",
      "Validation loss per 100 evaluation steps: 0.02771181472388372\n",
      "Validation loss per 100 evaluation steps: 0.02794294132599862\n",
      "Validation loss per 100 evaluation steps: 0.02777294901360764\n",
      "Validation loss per 100 evaluation steps: 0.027999056874507787\n",
      "Validation loss per 100 evaluation steps: 0.027906305398562065\n",
      "Validation loss per 100 evaluation steps: 0.027566596894413656\n",
      "Validation loss per 100 evaluation steps: 0.02768194020413498\n",
      "Validation loss per 100 evaluation steps: 0.027725836662395777\n",
      "Validation loss per 100 evaluation steps: 0.02781728167466886\n",
      "Validation loss per 100 evaluation steps: 0.027494735568579794\n",
      "Validation loss per 100 evaluation steps: 0.02725318908743447\n",
      "Validation loss per 100 evaluation steps: 0.027165784718901145\n",
      "Validation loss per 100 evaluation steps: 0.026882474035674182\n",
      "Validation loss per 100 evaluation steps: 0.02696578359396262\n",
      "Validation loss per 100 evaluation steps: 0.02674154099536999\n",
      "Validation loss per 100 evaluation steps: 0.026847095160370794\n",
      "Validation loss per 100 evaluation steps: 0.026656725384813597\n",
      "Validation loss per 100 evaluation steps: 0.026827771803831155\n",
      "Validation loss per 100 evaluation steps: 0.026601850398445145\n",
      "Validation loss per 100 evaluation steps: 0.026608108859135476\n",
      "Validation loss per 100 evaluation steps: 0.026567767310235878\n",
      "Validation loss per 100 evaluation steps: 0.026451111392658152\n",
      "Validation loss per 100 evaluation steps: 0.026653915016351497\n",
      "Validation loss per 100 evaluation steps: 0.026812145596978882\n",
      "Validation loss per 100 evaluation steps: 0.026817071857750868\n",
      "Validation loss per 100 evaluation steps: 0.026921200193908878\n",
      "Validation loss per 100 evaluation steps: 0.026882793385507166\n",
      "Validation loss per 100 evaluation steps: 0.027032247154388234\n",
      "Validation loss per 100 evaluation steps: 0.027010668866410105\n",
      "Validation loss per 100 evaluation steps: 0.027019251823487016\n",
      "Validation loss per 100 evaluation steps: 0.027024477180240356\n",
      "Validation loss per 100 evaluation steps: 0.02705493681343727\n",
      "Validation loss per 100 evaluation steps: 0.027015078606444438\n",
      "Validation loss per 100 evaluation steps: 0.0269748580342448\n",
      "Validation loss per 100 evaluation steps: 0.02686611493544398\n",
      "Validation loss per 100 evaluation steps: 0.026903246246791388\n",
      "Validation loss per 100 evaluation steps: 0.026949673590702976\n",
      "Validation loss per 100 evaluation steps: 0.026855053025675268\n",
      "Validation Loss: 0.026933261608328485\n",
      "Validation Accuracy: 0.9596900556495882\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92b96e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         geo       0.84      0.86      0.85     11232\n",
      "         gpe       0.95      0.92      0.94      3293\n",
      "         org       0.59      0.70      0.64      6531\n",
      "         per       0.78      0.73      0.76      5196\n",
      "         tim       0.85      0.83      0.84      4360\n",
      "\n",
      "   micro avg       0.78      0.81      0.79     30612\n",
      "   macro avg       0.80      0.81      0.81     30612\n",
      "weighted avg       0.79      0.81      0.80     30612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(classification_report([labels], [predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "955c0d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india has a capital called mumbai . on wednesday , the president will give a presentation\n",
      "['B-geo', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"India has a capital called Mumbai. On Wednesday, the president will give a presentation\"\n",
    "\n",
    "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "# move to gpu\n",
    "ids = inputs[\"input_ids\"].to(device)\n",
    "mask = inputs[\"attention_mask\"].to(device)\n",
    "# forward pass\n",
    "outputs = model(ids, mask)\n",
    "logits = outputs[0]\n",
    "\n",
    "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
    "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "word_level_predictions = []\n",
    "for pair in wp_preds:\n",
    "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
    "    # skip prediction\n",
    "    continue\n",
    "  else:\n",
    "    word_level_predictions.append(pair[1])\n",
    "\n",
    "# we join tokens, if they are not special ones\n",
    "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
    "print(str_rep)\n",
    "print(word_level_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09cf3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a28eb627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d582914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (47571, 2)\n",
      "TRAIN Dataset: (38057, 2)\n",
      "TEST Dataset: (9514, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 5e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# tokenization\n",
    "\n",
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "    \"\"\"\n",
    "    Word piece tokenization makes it difficult to match word labels\n",
    "    back up with individual word pieces. This function tokenizes each\n",
    "    word one at a time so that it is easier to preserve the correct\n",
    "    label for each subword. It is, of course, a bit slower in processing\n",
    "    time, but it will help our model achieve higher accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels\n",
    "\n",
    "# Bert imput\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # step 1: tokenize (and adapt corresponding labels)\n",
    "        sentence = self.data.sentence[index]  \n",
    "        word_labels = self.data.word_labels[index]  \n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "        \n",
    "        # step 2: add special tokens (and corresponding labels)\n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
    "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "\n",
    "        # step 3: truncating/padding\n",
    "        maxlen = self.max_len\n",
    "\n",
    "        if (len(tokenized_sentence) > maxlen):\n",
    "          # truncate\n",
    "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
    "          labels = labels[:maxlen]\n",
    "        else:\n",
    "          # pad\n",
    "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
    "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
    "\n",
    "        # step 4: obtain the attention mask\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "        \n",
    "        # step 5: convert tokens to input ids\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "        # the following line is deprecated\n",
    "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
    "        \n",
    "        return {\n",
    "              'ids': torch.tensor(ids, dtype=torch.long),\n",
    "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# define training size 80/20 split\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
    "\n",
    "# pyTorch dataloaders\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', \n",
    "                                                   num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                   label2id=label2id)\n",
    "model.to(device)\n",
    "\n",
    "# Train the model \n",
    "\n",
    "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
    "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
    "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "mask = mask.to(device)\n",
    "targets = targets.to(device)\n",
    "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66fefe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(targets, num_classes):\n",
    "    \"\"\"\n",
    "    One-hot encode a tensor of class indices.\n",
    "\n",
    "    Arguments:\n",
    "    - targets (torch.Tensor): A tensor of class indices, shape [N].\n",
    "    - num_classes (int): The number of classes.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: The one-hot encoded tensor, shape [N, num_classes].\n",
    "    \"\"\"\n",
    "    return F.one_hot(targets, num_classes=num_classes).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4db7e09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_loss_fn = nn.L1Loss()\n",
    "\n",
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "        \n",
    "        # implement l1 loss function\n",
    "        flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        flatten_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        \n",
    "        targets_one_hot = one_hot_encode(flatten_targets, num_classes= flatten_logits.size(-1))\n",
    "        loss = l1_loss_fn(flatten_logits, targets_one_hot)\n",
    "        \n",
    "        \n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training l1 loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "        \n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9792cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training l1 loss per 100 training steps: 0.282701700925827\n",
      "Training l1 loss per 100 training steps: 0.056126541946784105\n",
      "Training l1 loss per 100 training steps: 0.04622972830759352\n",
      "Training l1 loss per 100 training steps: 0.04167744626238497\n",
      "Training l1 loss per 100 training steps: 0.038935704630546436\n",
      "Training l1 loss per 100 training steps: 0.036500575243980586\n",
      "Training l1 loss per 100 training steps: 0.03449269758844237\n",
      "Training l1 loss per 100 training steps: 0.03278140765953591\n",
      "Training l1 loss per 100 training steps: 0.03127847332391102\n",
      "Training l1 loss per 100 training steps: 0.02995710966738559\n",
      "Training l1 loss per 100 training steps: 0.028810201630509878\n",
      "Training l1 loss per 100 training steps: 0.027789062528543643\n",
      "Training l1 loss per 100 training steps: 0.02688908245070193\n",
      "Training l1 loss per 100 training steps: 0.0260158029852362\n",
      "Training l1 loss per 100 training steps: 0.02523642163830068\n",
      "Training l1 loss per 100 training steps: 0.02452367933766096\n",
      "Training l1 loss per 100 training steps: 0.02384273853062243\n",
      "Training l1 loss per 100 training steps: 0.023217153794590443\n",
      "Training l1 loss per 100 training steps: 0.022629156562891158\n",
      "Training l1 loss per 100 training steps: 0.02213257648195799\n",
      "Training l1 loss per 100 training steps: 0.021625198043141884\n",
      "Training l1 loss per 100 training steps: 0.021153520759033737\n",
      "Training l1 loss per 100 training steps: 0.020719956347244075\n",
      "Training l1 loss per 100 training steps: 0.020299057657144372\n",
      "Training l1 loss per 100 training steps: 0.01989672753862146\n",
      "Training l1 loss per 100 training steps: 0.019525253158643608\n",
      "Training l1 loss per 100 training steps: 0.01915908382932689\n",
      "Training l1 loss per 100 training steps: 0.018813301770168954\n",
      "Training l1 loss per 100 training steps: 0.018481318312718726\n",
      "Training l1 loss per 100 training steps: 0.018164497248954258\n",
      "Training l1 loss per 100 training steps: 0.0178518291816962\n",
      "Training l1 loss per 100 training steps: 0.017552204845159024\n",
      "Training l1 loss per 100 training steps: 0.017262049781036952\n",
      "Training l1 loss per 100 training steps: 0.016989599535158776\n",
      "Training l1 loss per 100 training steps: 0.016738167822621688\n",
      "Training l1 loss per 100 training steps: 0.016502179201959424\n",
      "Training l1 loss per 100 training steps: 0.016269440232380146\n",
      "Training l1 loss per 100 training steps: 0.016042155276186777\n",
      "Training l1 loss per 100 training steps: 0.015824263187096413\n",
      "Training l1 loss per 100 training steps: 0.015608658011042019\n",
      "Training l1 loss per 100 training steps: 0.015409970759155527\n",
      "Training l1 loss per 100 training steps: 0.01521595940595664\n",
      "Training l1 loss per 100 training steps: 0.015043220119415593\n",
      "Training l1 loss per 100 training steps: 0.01486438306009969\n",
      "Training l1 loss per 100 training steps: 0.014694197627025262\n",
      "Training l1 loss per 100 training steps: 0.014528114202982107\n",
      "Training l1 loss per 100 training steps: 0.014360800800026045\n",
      "Training l1 loss per 100 training steps: 0.014208989963569405\n",
      "Training l1 loss per 100 training steps: 0.014054453014781192\n",
      "Training l1 loss per 100 training steps: 0.013909085627308526\n",
      "Training l1 loss per 100 training steps: 0.013759293595794123\n",
      "Training l1 loss per 100 training steps: 0.013621546675510802\n",
      "Training l1 loss per 100 training steps: 0.013481363526507324\n",
      "Training l1 loss per 100 training steps: 0.013345700029961566\n",
      "Training l1 loss per 100 training steps: 0.01321856470174544\n",
      "Training l1 loss per 100 training steps: 0.013092614397336487\n",
      "Training l1 loss per 100 training steps: 0.01297341768078305\n",
      "Training l1 loss per 100 training steps: 0.012854509208929018\n",
      "Training l1 loss per 100 training steps: 0.012745316536579178\n",
      "Training l1 loss per 100 training steps: 0.012633747264406369\n",
      "Training l1 loss per 100 training steps: 0.0125241495545974\n",
      "Training l1 loss per 100 training steps: 0.012420141935431553\n",
      "Training l1 loss per 100 training steps: 0.012311988218899691\n",
      "Training l1 loss per 100 training steps: 0.01220901134026906\n",
      "Training l1 loss per 100 training steps: 0.012114620378039866\n",
      "Training l1 loss per 100 training steps: 0.012019760914718788\n",
      "Training l1 loss per 100 training steps: 0.011929800845736235\n",
      "Training l1 loss per 100 training steps: 0.011832066123900411\n",
      "Training l1 loss per 100 training steps: 0.011750510649770934\n",
      "Training l1 loss per 100 training steps: 0.011660345975571963\n",
      "Training l1 loss per 100 training steps: 0.01157224018704995\n",
      "Training l1 loss per 100 training steps: 0.011489271077139486\n",
      "Training l1 loss per 100 training steps: 0.011407819951560729\n",
      "Training l1 loss per 100 training steps: 0.011321065873938331\n",
      "Training l1 loss per 100 training steps: 0.01123773109471334\n",
      "Training l1 loss per 100 training steps: 0.011162584042909146\n",
      "Training l1 loss per 100 training steps: 0.011084488251162827\n",
      "Training l1 loss per 100 training steps: 0.011008688608960135\n",
      "Training l1 loss per 100 training steps: 0.010935473378809544\n",
      "Training l1 loss per 100 training steps: 0.010867446881979789\n",
      "Training l1 loss per 100 training steps: 0.010794997196734173\n",
      "Training l1 loss per 100 training steps: 0.01072415255439863\n",
      "Training l1 loss per 100 training steps: 0.010653819766949688\n",
      "Training l1 loss per 100 training steps: 0.010587772631322353\n",
      "Training l1 loss per 100 training steps: 0.010525396010526825\n",
      "Training l1 loss per 100 training steps: 0.0104601006475498\n",
      "Training l1 loss per 100 training steps: 0.010396320266082169\n",
      "Training l1 loss per 100 training steps: 0.010331927201720381\n",
      "Training l1 loss per 100 training steps: 0.010271182314764402\n",
      "Training l1 loss per 100 training steps: 0.010211625111506641\n",
      "Training l1 loss per 100 training steps: 0.010151064707045538\n",
      "Training l1 loss per 100 training steps: 0.010091252148428922\n",
      "Training l1 loss per 100 training steps: 0.010031031288790413\n",
      "Training l1 loss per 100 training steps: 0.009974320028670138\n",
      "Training l1 loss per 100 training steps: 0.009918461233545275\n",
      "Training l1 loss per 100 training steps: 0.009864361119103606\n",
      "Training loss epoch: 0.009856982666145594\n",
      "Training accuracy epoch: 0.9086559723854806\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e363015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.long)\n",
    "            \n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "            \n",
    "            \n",
    "            # implement l1 loss\n",
    "            flatten_targets = targets.view(-1) \n",
    "            flatten_logits = eval_logits.view(-1, model.num_labels) \n",
    "            targets_one_hot = one_hot_encode(flatten_targets, num_classes= flatten_logits.size(-1))\n",
    "            loss = l1_loss_fn(flatten_logits, targets_one_hot)            \n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += targets.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation l1 loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(targets)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    #print(eval_labels)\n",
    "    #print(eval_preds)\n",
    "\n",
    "    labels = [id2label[id.item()] for id in eval_labels]\n",
    "    predictions = [id2label[id.item()] for id in eval_preds]\n",
    "\n",
    "    #print(labels)\n",
    "    #print(predictions)\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f817764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation l1 loss per 100 evaluation steps: 0.0010443563805893064\n",
      "Validation l1 loss per 100 evaluation steps: 0.003331941989882121\n",
      "Validation l1 loss per 100 evaluation steps: 0.003124259564613191\n",
      "Validation l1 loss per 100 evaluation steps: 0.0030663156832809687\n",
      "Validation l1 loss per 100 evaluation steps: 0.0030654816402870223\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031167842495857466\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031354822988967457\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031425936310983844\n",
      "Validation l1 loss per 100 evaluation steps: 0.003111113423610062\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031530496105009053\n",
      "Validation l1 loss per 100 evaluation steps: 0.003149060277872115\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031425666152736466\n",
      "Validation l1 loss per 100 evaluation steps: 0.003151190082407281\n",
      "Validation l1 loss per 100 evaluation steps: 0.003138787465776352\n",
      "Validation l1 loss per 100 evaluation steps: 0.00315533964760099\n",
      "Validation l1 loss per 100 evaluation steps: 0.003168123467098785\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031546015128944716\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031635872414349296\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031686022318628145\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031906424414465447\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031931465830542668\n",
      "Validation l1 loss per 100 evaluation steps: 0.003205780127312481\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031979887311555013\n",
      "Validation l1 loss per 100 evaluation steps: 0.003212592910202354\n",
      "Validation l1 loss per 100 evaluation steps: 0.003206036861377711\n",
      "Validation l1 loss per 100 evaluation steps: 0.0032176713770177617\n",
      "Validation l1 loss per 100 evaluation steps: 0.003221804389435768\n",
      "Validation l1 loss per 100 evaluation steps: 0.003221468116522769\n",
      "Validation l1 loss per 100 evaluation steps: 0.003221871138943352\n",
      "Validation l1 loss per 100 evaluation steps: 0.00321412246536816\n",
      "Validation l1 loss per 100 evaluation steps: 0.003218529534771181\n",
      "Validation l1 loss per 100 evaluation steps: 0.0032067158127043506\n",
      "Validation l1 loss per 100 evaluation steps: 0.003209735428885624\n",
      "Validation l1 loss per 100 evaluation steps: 0.0032039552238999486\n",
      "Validation l1 loss per 100 evaluation steps: 0.003200866692914181\n",
      "Validation l1 loss per 100 evaluation steps: 0.003201938075640858\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031924768958246697\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031866814037431377\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031858715812650663\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031781676087044544\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031668984320308473\n",
      "Validation l1 loss per 100 evaluation steps: 0.003159560017963684\n",
      "Validation l1 loss per 100 evaluation steps: 0.003161489829173082\n",
      "Validation l1 loss per 100 evaluation steps: 0.003154131214620952\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031624178328086643\n",
      "Validation l1 loss per 100 evaluation steps: 0.0031613707218339456\n",
      "Validation l1 loss per 100 evaluation steps: 0.003156303191904976\n",
      "Validation l1 loss per 100 evaluation steps: 0.003149868348460142\n",
      "Validation Loss: 0.003154478643554215\n",
      "Validation Accuracy: 0.9403955296843316\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "889fd862",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         geo       0.76      0.75      0.76     11232\n",
      "         gpe       0.70      0.91      0.79      3293\n",
      "         org       0.52      0.43      0.47      6531\n",
      "         per       0.55      0.73      0.63      5196\n",
      "         tim       0.65      0.68      0.66      4360\n",
      "\n",
      "   micro avg       0.65      0.69      0.67     30612\n",
      "   macro avg       0.64      0.70      0.66     30612\n",
      "weighted avg       0.65      0.69      0.66     30612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(classification_report([labels], [predictions]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd307163",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb278f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india has a capital called mumbai . on wednesday , the president will give a presentation\n",
      "['B-geo', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"India has a capital called Mumbai. On Wednesday, the president will give a presentation\"\n",
    "\n",
    "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "# move to gpu\n",
    "ids = inputs[\"input_ids\"].to(device)\n",
    "mask = inputs[\"attention_mask\"].to(device)\n",
    "# forward pass\n",
    "outputs = model(ids, mask)\n",
    "logits = outputs[0]\n",
    "\n",
    "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
    "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "word_level_predictions = []\n",
    "for pair in wp_preds:\n",
    "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
    "    # skip prediction\n",
    "    continue\n",
    "  else:\n",
    "    word_level_predictions.append(pair[1])\n",
    "\n",
    "# we join tokens, if they are not special ones\n",
    "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
    "print(str_rep)\n",
    "print(word_level_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5659cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dlite loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be6377da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (47571, 2)\n",
      "TRAIN Dataset: (38057, 2)\n",
      "TEST Dataset: (9514, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 5e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# tokenization\n",
    "\n",
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "    \"\"\"\n",
    "    Word piece tokenization makes it difficult to match word labels\n",
    "    back up with individual word pieces. This function tokenizes each\n",
    "    word one at a time so that it is easier to preserve the correct\n",
    "    label for each subword. It is, of course, a bit slower in processing\n",
    "    time, but it will help our model achieve higher accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels\n",
    "\n",
    "# Bert imput\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # step 1: tokenize (and adapt corresponding labels)\n",
    "        sentence = self.data.sentence[index]  \n",
    "        word_labels = self.data.word_labels[index]  \n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "        \n",
    "        # step 2: add special tokens (and corresponding labels)\n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
    "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "\n",
    "        # step 3: truncating/padding\n",
    "        maxlen = self.max_len\n",
    "\n",
    "        if (len(tokenized_sentence) > maxlen):\n",
    "          # truncate\n",
    "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
    "          labels = labels[:maxlen]\n",
    "        else:\n",
    "          # pad\n",
    "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
    "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
    "\n",
    "        # step 4: obtain the attention mask\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "        \n",
    "        # step 5: convert tokens to input ids\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "        # the following line is deprecated\n",
    "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
    "        \n",
    "        return {\n",
    "              'ids': torch.tensor(ids, dtype=torch.long),\n",
    "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# define training size 80/20 split\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
    "\n",
    "# pyTorch dataloaders\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', \n",
    "                                                   num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                   label2id=label2id)\n",
    "model.to(device)\n",
    "\n",
    "# Train the model \n",
    "\n",
    "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
    "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
    "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "mask = mask.to(device)\n",
    "targets = targets.to(device)\n",
    "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a113a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DLITE Loss function\n",
    "class DLITELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DLITELoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, targets, epsilon=1e-10):\n",
    "        # Convert logits to probabilities using softmax\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        # One-hot encode the targets to get true probabilities\n",
    "        true_probs = F.one_hot(targets, num_classes=probs.size(-1)).float()\n",
    "\n",
    "        # Define the g function\n",
    "        g_values = torch.abs(probs * (1 - torch.log(probs + epsilon)) - true_probs * (1 - torch.log(true_probs + epsilon)))\n",
    "\n",
    "        # Define the delta_h function\n",
    "        delta_h_values = torch.abs(probs**2 * (1 - 2 * torch.log(probs + epsilon)) - true_probs**2 * (1 - 2 * torch.log(true_probs + epsilon))) / (2 * (probs + true_probs))\n",
    "\n",
    "        # Compute DLITE loss for each class\n",
    "        dl_values = g_values - delta_h_values\n",
    "\n",
    "        # Sum over all classes and average over batch size\n",
    "        loss = dl_values.sum(dim=-1).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56a99bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlite_loss_fn = DLITELoss()\n",
    "\n",
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    for idx, batch in enumerate(training_loader):\n",
    "\n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "\n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # implement dlite loss function\n",
    "\n",
    "        loss = dlite_loss_fn(active_logits, flattened_targets)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "\n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training dlite loss per 100 training steps: {loss_step}\")\n",
    "            \n",
    "            \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb554fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training dlite loss per 100 training steps: 0.7658721804618835\n",
      "Training dlite loss per 100 training steps: 0.06475145738608766\n",
      "Training dlite loss per 100 training steps: 0.05043889521458997\n",
      "Training dlite loss per 100 training steps: 0.0461329589829938\n",
      "Training dlite loss per 100 training steps: 0.0438589745890953\n",
      "Training dlite loss per 100 training steps: 0.042764898345893074\n",
      "Training dlite loss per 100 training steps: 0.04164548062590786\n",
      "Training dlite loss per 100 training steps: 0.0411693340362702\n",
      "Training dlite loss per 100 training steps: 0.04018913693993484\n",
      "Training dlite loss per 100 training steps: 0.039819894095450704\n",
      "Training dlite loss per 100 training steps: 0.039535402259384685\n",
      "Training dlite loss per 100 training steps: 0.03946337172064548\n",
      "Training dlite loss per 100 training steps: 0.039124854454603425\n",
      "Training dlite loss per 100 training steps: 0.03879747269189811\n",
      "Training dlite loss per 100 training steps: 0.038727002711162486\n",
      "Training dlite loss per 100 training steps: 0.038538182615038996\n",
      "Training dlite loss per 100 training steps: 0.03867038205353856\n",
      "Training dlite loss per 100 training steps: 0.0385400425104633\n",
      "Training dlite loss per 100 training steps: 0.03851946151580084\n",
      "Training dlite loss per 100 training steps: 0.03853277563682328\n",
      "Training dlite loss per 100 training steps: 0.03835922971742055\n",
      "Training dlite loss per 100 training steps: 0.038269048694686225\n",
      "Training dlite loss per 100 training steps: 0.03820385135637473\n",
      "Training dlite loss per 100 training steps: 0.03814595790069947\n",
      "Training dlite loss per 100 training steps: 0.0379830245476765\n",
      "Training dlite loss per 100 training steps: 0.037890078275114925\n",
      "Training dlite loss per 100 training steps: 0.03779748253040213\n",
      "Training dlite loss per 100 training steps: 0.03776955224656377\n",
      "Training dlite loss per 100 training steps: 0.03774986193181544\n",
      "Training dlite loss per 100 training steps: 0.03773554068228567\n",
      "Training dlite loss per 100 training steps: 0.03776119981217433\n",
      "Training dlite loss per 100 training steps: 0.037692600857383664\n",
      "Training dlite loss per 100 training steps: 0.0376929440862398\n",
      "Training dlite loss per 100 training steps: 0.03765893365452862\n",
      "Training dlite loss per 100 training steps: 0.037581541349183685\n",
      "Training dlite loss per 100 training steps: 0.03756545857461462\n",
      "Training dlite loss per 100 training steps: 0.03754754415985336\n",
      "Training dlite loss per 100 training steps: 0.03746409518233292\n",
      "Training dlite loss per 100 training steps: 0.03747648970466786\n",
      "Training dlite loss per 100 training steps: 0.03749224440013948\n",
      "Training dlite loss per 100 training steps: 0.03742275487066861\n",
      "Training dlite loss per 100 training steps: 0.037440465829936806\n",
      "Training dlite loss per 100 training steps: 0.03739456406182407\n",
      "Training dlite loss per 100 training steps: 0.037388027387930435\n",
      "Training dlite loss per 100 training steps: 0.03741373472948627\n",
      "Training dlite loss per 100 training steps: 0.03738275242778832\n",
      "Training dlite loss per 100 training steps: 0.03736330027861652\n",
      "Training dlite loss per 100 training steps: 0.03734508654810542\n",
      "Training dlite loss per 100 training steps: 0.03727921739980853\n",
      "Training dlite loss per 100 training steps: 0.03724472537773772\n",
      "Training dlite loss per 100 training steps: 0.03726120828270435\n",
      "Training dlite loss per 100 training steps: 0.03725828060097786\n",
      "Training dlite loss per 100 training steps: 0.037242319277002306\n",
      "Training dlite loss per 100 training steps: 0.037198587923235736\n",
      "Training dlite loss per 100 training steps: 0.03719516671584623\n",
      "Training dlite loss per 100 training steps: 0.037211750358278166\n",
      "Training dlite loss per 100 training steps: 0.037216930078730705\n",
      "Training dlite loss per 100 training steps: 0.03721404654743477\n",
      "Training dlite loss per 100 training steps: 0.03716412495372193\n",
      "Training dlite loss per 100 training steps: 0.037143364974781046\n",
      "Training dlite loss per 100 training steps: 0.037162351110042895\n",
      "Training dlite loss per 100 training steps: 0.03715990516135327\n",
      "Training dlite loss per 100 training steps: 0.03716478110440807\n",
      "Training dlite loss per 100 training steps: 0.037107197451914466\n",
      "Training dlite loss per 100 training steps: 0.037113962802698464\n",
      "Training dlite loss per 100 training steps: 0.03714455357272629\n",
      "Training dlite loss per 100 training steps: 0.03713782324506841\n",
      "Training dlite loss per 100 training steps: 0.037109141475234905\n",
      "Training dlite loss per 100 training steps: 0.037117774240623715\n",
      "Training dlite loss per 100 training steps: 0.03710577879606566\n",
      "Training dlite loss per 100 training steps: 0.037171122773137014\n",
      "Training dlite loss per 100 training steps: 0.037154586828986334\n",
      "Training dlite loss per 100 training steps: 0.037190856620738566\n",
      "Training dlite loss per 100 training steps: 0.03721168660958142\n",
      "Training dlite loss per 100 training steps: 0.037195271173321574\n",
      "Training dlite loss per 100 training steps: 0.037203508345552895\n",
      "Training dlite loss per 100 training steps: 0.03721692443258364\n",
      "Training dlite loss per 100 training steps: 0.03721553537138632\n",
      "Training dlite loss per 100 training steps: 0.03720516830602517\n",
      "Training dlite loss per 100 training steps: 0.03720865922767001\n",
      "Training dlite loss per 100 training steps: 0.037207180374632325\n",
      "Training dlite loss per 100 training steps: 0.03722116784616943\n",
      "Training dlite loss per 100 training steps: 0.037209331169263296\n",
      "Training dlite loss per 100 training steps: 0.03722766089517334\n",
      "Training dlite loss per 100 training steps: 0.03723323221361537\n",
      "Training dlite loss per 100 training steps: 0.037215467278554425\n",
      "Training dlite loss per 100 training steps: 0.037215827479263275\n",
      "Training dlite loss per 100 training steps: 0.0372110163792924\n",
      "Training dlite loss per 100 training steps: 0.037234276358941186\n",
      "Training dlite loss per 100 training steps: 0.03722431888407657\n",
      "Training dlite loss per 100 training steps: 0.037248215825710224\n",
      "Training dlite loss per 100 training steps: 0.03724540562506313\n",
      "Training dlite loss per 100 training steps: 0.03724074587740063\n",
      "Training dlite loss per 100 training steps: 0.03721665707431305\n",
      "Training dlite loss per 100 training steps: 0.03723130787715488\n",
      "Training dlite loss per 100 training steps: 0.03722776552856686\n",
      "Training loss epoch: 0.03722266522279679\n",
      "Training accuracy epoch: 0.8245677112304727\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb6661bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.long)\n",
    "            \n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "            \n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(targets)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "            # implement dlite loss\n",
    "            loss = dlite_loss_fn(active_logits, flattened_targets)           \n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += targets.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation dlite loss per 100 evaluation steps: {loss_step}\")\n",
    "    \n",
    "    #print(eval_labels)\n",
    "    #print(eval_preds)\n",
    "\n",
    "    labels = [id2label[id.item()] for id in eval_labels]\n",
    "    predictions = [id2label[id.item()] for id in eval_preds]\n",
    "\n",
    "    #print(labels)\n",
    "    #print(predictions)\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af598b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dlite loss per 100 evaluation steps: 0.015625150874257088\n",
      "Validation dlite loss per 100 evaluation steps: 0.03952673751764369\n",
      "Validation dlite loss per 100 evaluation steps: 0.03605034958086151\n",
      "Validation dlite loss per 100 evaluation steps: 0.037414478452068196\n",
      "Validation dlite loss per 100 evaluation steps: 0.03717282386367344\n",
      "Validation dlite loss per 100 evaluation steps: 0.03745646751094124\n",
      "Validation dlite loss per 100 evaluation steps: 0.03667078404581485\n",
      "Validation dlite loss per 100 evaluation steps: 0.03658291454965714\n",
      "Validation dlite loss per 100 evaluation steps: 0.03670230008232162\n",
      "Validation dlite loss per 100 evaluation steps: 0.037059647795127125\n",
      "Validation dlite loss per 100 evaluation steps: 0.03739242542140729\n",
      "Validation dlite loss per 100 evaluation steps: 0.03723900414451815\n",
      "Validation dlite loss per 100 evaluation steps: 0.037068849373295895\n",
      "Validation dlite loss per 100 evaluation steps: 0.03661259258155984\n",
      "Validation dlite loss per 100 evaluation steps: 0.03654768642637209\n",
      "Validation dlite loss per 100 evaluation steps: 0.036413355797580614\n",
      "Validation dlite loss per 100 evaluation steps: 0.03623724886758918\n",
      "Validation dlite loss per 100 evaluation steps: 0.036070366025588\n",
      "Validation dlite loss per 100 evaluation steps: 0.035943704771199424\n",
      "Validation dlite loss per 100 evaluation steps: 0.036194075556341965\n",
      "Validation dlite loss per 100 evaluation steps: 0.03619492477025143\n",
      "Validation dlite loss per 100 evaluation steps: 0.03625518861501256\n",
      "Validation dlite loss per 100 evaluation steps: 0.036388065837201125\n",
      "Validation dlite loss per 100 evaluation steps: 0.03640923339024167\n",
      "Validation dlite loss per 100 evaluation steps: 0.036454668481272996\n",
      "Validation dlite loss per 100 evaluation steps: 0.03647148027510465\n",
      "Validation dlite loss per 100 evaluation steps: 0.03648699935548985\n",
      "Validation dlite loss per 100 evaluation steps: 0.0365838039348618\n",
      "Validation dlite loss per 100 evaluation steps: 0.036641620821666214\n",
      "Validation dlite loss per 100 evaluation steps: 0.03671564945076654\n",
      "Validation dlite loss per 100 evaluation steps: 0.03668061261911004\n",
      "Validation dlite loss per 100 evaluation steps: 0.0366654709326005\n",
      "Validation dlite loss per 100 evaluation steps: 0.03662320793329104\n",
      "Validation dlite loss per 100 evaluation steps: 0.036742074751930094\n",
      "Validation dlite loss per 100 evaluation steps: 0.03674024422957147\n",
      "Validation dlite loss per 100 evaluation steps: 0.03674521279445705\n",
      "Validation dlite loss per 100 evaluation steps: 0.0367574987635077\n",
      "Validation dlite loss per 100 evaluation steps: 0.03665618689575567\n",
      "Validation dlite loss per 100 evaluation steps: 0.03670099926657031\n",
      "Validation dlite loss per 100 evaluation steps: 0.03670145765560256\n",
      "Validation dlite loss per 100 evaluation steps: 0.03667260360565777\n",
      "Validation dlite loss per 100 evaluation steps: 0.03665944436415138\n",
      "Validation dlite loss per 100 evaluation steps: 0.036605068939241966\n",
      "Validation dlite loss per 100 evaluation steps: 0.03655231380083866\n",
      "Validation dlite loss per 100 evaluation steps: 0.036602252817605874\n",
      "Validation dlite loss per 100 evaluation steps: 0.03652239709511418\n",
      "Validation dlite loss per 100 evaluation steps: 0.03645704959350273\n",
      "Validation dlite loss per 100 evaluation steps: 0.03638617287119441\n",
      "Validation Loss: 0.03642917664614345\n",
      "Validation Accuracy: 0.8291219467804714\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c838bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         geo       0.00      0.00      0.00     11232\n",
      "         gpe       0.00      0.00      0.00      3293\n",
      "         org       0.00      0.00      0.00      6531\n",
      "         per       0.00      0.00      0.00      5196\n",
      "         tim       0.00      0.00      0.00      4360\n",
      "\n",
      "   micro avg       0.00      0.00      0.00     30612\n",
      "   macro avg       0.00      0.00      0.00     30612\n",
      "weighted avg       0.00      0.00      0.00     30612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always') \n",
    "\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(classification_report([labels], [predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6007f4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india has a capital called mumbai . on wednesday , the president will give a presentation\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"India has a capital called Mumbai. On Wednesday, the president will give a presentation\"\n",
    "\n",
    "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "# move to gpu\n",
    "ids = inputs[\"input_ids\"].to(device)\n",
    "mask = inputs[\"attention_mask\"].to(device)\n",
    "# forward pass\n",
    "outputs = model(ids, mask)\n",
    "logits = outputs[0]\n",
    "\n",
    "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
    "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "word_level_predictions = []\n",
    "for pair in wp_preds:\n",
    "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
    "    # skip prediction\n",
    "    continue\n",
    "  else:\n",
    "    word_level_predictions.append(pair[1])\n",
    "\n",
    "# we join tokens, if they are not special ones\n",
    "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
    "print(str_rep)\n",
    "print(word_level_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c0812b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using preferred function, dlite loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a1f32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e10b7ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (47571, 2)\n",
      "TRAIN Dataset: (38057, 2)\n",
      "TEST Dataset: (9514, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 5e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# tokenization\n",
    "\n",
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "    \"\"\"\n",
    "    Word piece tokenization makes it difficult to match word labels\n",
    "    back up with individual word pieces. This function tokenizes each\n",
    "    word one at a time so that it is easier to preserve the correct\n",
    "    label for each subword. It is, of course, a bit slower in processing\n",
    "    time, but it will help our model achieve higher accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels\n",
    "\n",
    "# Bert imput\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # step 1: tokenize (and adapt corresponding labels)\n",
    "        sentence = self.data.sentence[index]  \n",
    "        word_labels = self.data.word_labels[index]  \n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "        \n",
    "        # step 2: add special tokens (and corresponding labels)\n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
    "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "\n",
    "        # step 3: truncating/padding\n",
    "        maxlen = self.max_len\n",
    "\n",
    "        if (len(tokenized_sentence) > maxlen):\n",
    "          # truncate\n",
    "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
    "          labels = labels[:maxlen]\n",
    "        else:\n",
    "          # pad\n",
    "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
    "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
    "\n",
    "        # step 4: obtain the attention mask\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "        \n",
    "        # step 5: convert tokens to input ids\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "        # the following line is deprecated\n",
    "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
    "        \n",
    "        return {\n",
    "              'ids': torch.tensor(ids, dtype=torch.long),\n",
    "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# define training size 80/20 split\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
    "\n",
    "# pyTorch dataloaders\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', \n",
    "                                                   num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                   label2id=label2id)\n",
    "model.to(device)\n",
    "\n",
    "# Train the model \n",
    "\n",
    "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
    "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
    "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "mask = mask.to(device)\n",
    "targets = targets.to(device)\n",
    "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7df515e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DLITELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DLITELoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # Convert logits to probabilities using softmax\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        # One-hot encode the targets to get true probabilities\n",
    "        true_probs = F.one_hot(targets, num_classes=probs.size(-1)).float()\n",
    "\n",
    "        # Masks for non-zero elements of probs and true_probs\n",
    "        mask_probs = probs > 0\n",
    "        mask_true_probs = true_probs > 0\n",
    "\n",
    "        # Calculate g function for non-zero elements using the mask\n",
    "        g_probs = torch.zeros_like(probs)\n",
    "        g_true_probs = torch.zeros_like(true_probs)\n",
    "        g_probs[mask_probs] = probs[mask_probs] * (1 - torch.log(probs[mask_probs]))\n",
    "        g_true_probs[mask_true_probs] = true_probs[mask_true_probs] * (1 - torch.log(true_probs[mask_true_probs]))\n",
    "        g_values = torch.abs(g_probs - g_true_probs)\n",
    "\n",
    "        # Calculate delta_h function for non-zero elements using the mask\n",
    "        delta_h_probs = torch.zeros_like(probs)\n",
    "        delta_h_true_probs = torch.zeros_like(true_probs)\n",
    "        delta_h_probs[mask_probs] = probs[mask_probs]**2 * (1 - 2 * torch.log(probs[mask_probs]))\n",
    "        delta_h_true_probs[mask_true_probs] = true_probs[mask_true_probs]**2 * (1 - 2 * torch.log(true_probs[mask_true_probs]))\n",
    "        delta_h_values = torch.abs(delta_h_probs - delta_h_true_probs) / (2 * (probs + true_probs))\n",
    "\n",
    "        # Compute DLITE loss for each class\n",
    "        dl_values = g_values - delta_h_values\n",
    "\n",
    "        # Sum over all classes and average over the batch size\n",
    "        loss = dl_values.sum(dim=-1).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b3dfbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlite_loss_fn = DLITELoss()\n",
    "\n",
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    for idx, batch in enumerate(training_loader):\n",
    "\n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "\n",
    "        # implement dlite loss function\n",
    "        flatten_targets = targets.view(-1) \n",
    "        flatten_logits = tr_logits.view(-1, model.num_labels)      \n",
    "\n",
    "        loss = dlite_loss_fn(flatten_logits, flatten_targets)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "\n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training dlite loss per 100 training steps: {loss_step}\")\n",
    "\n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa08c800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training dlite loss per 100 training steps: 0.7499504685401917\n",
      "Training dlite loss per 100 training steps: 0.06523774893456462\n",
      "Training dlite loss per 100 training steps: 0.05051617313231995\n",
      "Training dlite loss per 100 training steps: 0.04596067673257518\n",
      "Training dlite loss per 100 training steps: 0.04318558136953454\n",
      "Training dlite loss per 100 training steps: 0.04222626909948216\n",
      "Training dlite loss per 100 training steps: 0.041030900135245824\n",
      "Training dlite loss per 100 training steps: 0.04046692791927643\n",
      "Training dlite loss per 100 training steps: 0.03991557843339147\n",
      "Training dlite loss per 100 training steps: 0.039455198893152924\n",
      "Training dlite loss per 100 training steps: 0.03927717783199069\n",
      "Training dlite loss per 100 training steps: 0.0389428948052743\n",
      "Training dlite loss per 100 training steps: 0.03884429567731636\n",
      "Training dlite loss per 100 training steps: 0.0390591837581552\n",
      "Training dlite loss per 100 training steps: 0.03882216843139901\n",
      "Training dlite loss per 100 training steps: 0.03885978633352679\n",
      "Training dlite loss per 100 training steps: 0.03893277194601967\n",
      "Training dlite loss per 100 training steps: 0.03879725287164967\n",
      "Training dlite loss per 100 training steps: 0.03884038787281119\n",
      "Training dlite loss per 100 training steps: 0.038862436878698725\n",
      "Training dlite loss per 100 training steps: 0.03871139404202194\n",
      "Training dlite loss per 100 training steps: 0.03862112644377844\n",
      "Training dlite loss per 100 training steps: 0.03863127637028936\n",
      "Training dlite loss per 100 training steps: 0.038501288848224846\n",
      "Training dlite loss per 100 training steps: 0.03847643646481612\n",
      "Training dlite loss per 100 training steps: 0.03844181208236211\n",
      "Training dlite loss per 100 training steps: 0.03830919738282277\n",
      "Training dlite loss per 100 training steps: 0.03828109152385257\n",
      "Training dlite loss per 100 training steps: 0.03819360519478896\n",
      "Training dlite loss per 100 training steps: 0.03817473440316289\n",
      "Training dlite loss per 100 training steps: 0.038176623664283364\n",
      "Training dlite loss per 100 training steps: 0.03814751049124518\n",
      "Training dlite loss per 100 training steps: 0.03814399358194545\n",
      "Training dlite loss per 100 training steps: 0.03822942262808703\n",
      "Training dlite loss per 100 training steps: 0.03821965529582984\n",
      "Training dlite loss per 100 training steps: 0.03814906927175587\n",
      "Training dlite loss per 100 training steps: 0.038140968507900885\n",
      "Training dlite loss per 100 training steps: 0.03813065654665239\n",
      "Training dlite loss per 100 training steps: 0.03814297253375624\n",
      "Training dlite loss per 100 training steps: 0.038082553528652016\n",
      "Training dlite loss per 100 training steps: 0.03799732324381081\n",
      "Training dlite loss per 100 training steps: 0.03801863525474185\n",
      "Training dlite loss per 100 training steps: 0.03797802393450704\n",
      "Training dlite loss per 100 training steps: 0.03795927542472794\n",
      "Training dlite loss per 100 training steps: 0.037884125779607196\n",
      "Training dlite loss per 100 training steps: 0.03785006250042205\n",
      "Training dlite loss per 100 training steps: 0.037792854881124806\n",
      "Training dlite loss per 100 training steps: 0.037803305251848954\n",
      "Training dlite loss per 100 training steps: 0.03781779160361017\n",
      "Training dlite loss per 100 training steps: 0.03780578038375597\n",
      "Training dlite loss per 100 training steps: 0.03779424645281435\n",
      "Training dlite loss per 100 training steps: 0.037768612117672705\n",
      "Training dlite loss per 100 training steps: 0.037727062623166954\n",
      "Training dlite loss per 100 training steps: 0.03771729049072287\n",
      "Training dlite loss per 100 training steps: 0.03770353877397471\n",
      "Training dlite loss per 100 training steps: 0.03768850978169898\n",
      "Training dlite loss per 100 training steps: 0.03768377930972721\n",
      "Training dlite loss per 100 training steps: 0.03763364880446474\n",
      "Training dlite loss per 100 training steps: 0.037630360706602084\n",
      "Training dlite loss per 100 training steps: 0.03761626017825444\n",
      "Training dlite loss per 100 training steps: 0.03759481728173078\n",
      "Training dlite loss per 100 training steps: 0.03760576897047456\n",
      "Training dlite loss per 100 training steps: 0.03757825530148935\n",
      "Training dlite loss per 100 training steps: 0.03755223378241627\n",
      "Training dlite loss per 100 training steps: 0.03751939618479521\n",
      "Training dlite loss per 100 training steps: 0.03753022938679017\n",
      "Training dlite loss per 100 training steps: 0.03755493583758341\n",
      "Training dlite loss per 100 training steps: 0.03754276221018972\n",
      "Training dlite loss per 100 training steps: 0.03753152035433583\n",
      "Training dlite loss per 100 training steps: 0.03750333940756243\n",
      "Training dlite loss per 100 training steps: 0.03746647757084365\n",
      "Training dlite loss per 100 training steps: 0.037490063815190364\n",
      "Training dlite loss per 100 training steps: 0.03741236868067226\n",
      "Training dlite loss per 100 training steps: 0.037370508133683526\n",
      "Training dlite loss per 100 training steps: 0.03731368043980101\n",
      "Training dlite loss per 100 training steps: 0.037297164271328634\n",
      "Training dlite loss per 100 training steps: 0.03730883348962372\n",
      "Training dlite loss per 100 training steps: 0.037319945589019576\n",
      "Training dlite loss per 100 training steps: 0.03730248088491841\n",
      "Training dlite loss per 100 training steps: 0.03733242577819243\n",
      "Training dlite loss per 100 training steps: 0.03731377639959606\n",
      "Training dlite loss per 100 training steps: 0.03732837619658131\n",
      "Training dlite loss per 100 training steps: 0.0373130883272891\n",
      "Training dlite loss per 100 training steps: 0.03728475713476737\n",
      "Training dlite loss per 100 training steps: 0.037280813840674845\n",
      "Training dlite loss per 100 training steps: 0.037280639111659915\n",
      "Training dlite loss per 100 training steps: 0.03727683494155922\n",
      "Training dlite loss per 100 training steps: 0.037296687489195755\n",
      "Training dlite loss per 100 training steps: 0.03730965301849436\n",
      "Training dlite loss per 100 training steps: 0.03728326899309482\n",
      "Training dlite loss per 100 training steps: 0.037306293706412114\n",
      "Training dlite loss per 100 training steps: 0.03727408796044091\n",
      "Training dlite loss per 100 training steps: 0.03726614438443062\n",
      "Training dlite loss per 100 training steps: 0.037281260489439694\n",
      "Training dlite loss per 100 training steps: 0.037289198897227684\n",
      "Training dlite loss per 100 training steps: 0.037249072233079016\n",
      "Training loss epoch: 0.03724701955773306\n",
      "Training accuracy epoch: 0.8244738682601764\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11a7c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.long)\n",
    "            \n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "            \n",
    "            \n",
    "            # implement dlite loss\n",
    "            flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            flatten_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            loss = dlite_loss_fn(flatten_logits, flatten_targets)           \n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += targets.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation dlite loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(targets)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    #print(eval_labels)\n",
    "    #print(eval_preds)\n",
    "\n",
    "    labels = [id2label[id.item()] for id in eval_labels]\n",
    "    predictions = [id2label[id.item()] for id in eval_preds]\n",
    "\n",
    "    #print(labels)\n",
    "    #print(predictions)\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1af54ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dlite loss per 100 evaluation steps: 0.019531380385160446\n",
      "Validation dlite loss per 100 evaluation steps: 0.03643266099684798\n",
      "Validation dlite loss per 100 evaluation steps: 0.03571995073514669\n",
      "Validation dlite loss per 100 evaluation steps: 0.035091474906371975\n",
      "Validation dlite loss per 100 evaluation steps: 0.035166104025730865\n",
      "Validation dlite loss per 100 evaluation steps: 0.03542145732292023\n",
      "Validation dlite loss per 100 evaluation steps: 0.03607930301779463\n",
      "Validation dlite loss per 100 evaluation steps: 0.03612595906987366\n",
      "Validation dlite loss per 100 evaluation steps: 0.03645844512092455\n",
      "Validation dlite loss per 100 evaluation steps: 0.03652636731111042\n",
      "Validation dlite loss per 100 evaluation steps: 0.03668217958417473\n",
      "Validation dlite loss per 100 evaluation steps: 0.036440705591008045\n",
      "Validation dlite loss per 100 evaluation steps: 0.03632075615260685\n",
      "Validation dlite loss per 100 evaluation steps: 0.03650448339932321\n",
      "Validation dlite loss per 100 evaluation steps: 0.03639989326074938\n",
      "Validation dlite loss per 100 evaluation steps: 0.036447167978604346\n",
      "Validation dlite loss per 100 evaluation steps: 0.03645193886608316\n",
      "Validation dlite loss per 100 evaluation steps: 0.036355105392265906\n",
      "Validation dlite loss per 100 evaluation steps: 0.03651411453305831\n",
      "Validation dlite loss per 100 evaluation steps: 0.036360498007565724\n",
      "Validation dlite loss per 100 evaluation steps: 0.03620271399171035\n",
      "Validation dlite loss per 100 evaluation steps: 0.036221703047372183\n",
      "Validation dlite loss per 100 evaluation steps: 0.03624429090806197\n",
      "Validation dlite loss per 100 evaluation steps: 0.0364160045537995\n",
      "Validation dlite loss per 100 evaluation steps: 0.036477426096098435\n",
      "Validation dlite loss per 100 evaluation steps: 0.03642460469338937\n",
      "Validation dlite loss per 100 evaluation steps: 0.03656357302959504\n",
      "Validation dlite loss per 100 evaluation steps: 0.036429038755816726\n",
      "Validation dlite loss per 100 evaluation steps: 0.03657326653630922\n",
      "Validation dlite loss per 100 evaluation steps: 0.036531157235251584\n",
      "Validation dlite loss per 100 evaluation steps: 0.03651007734556455\n",
      "Validation dlite loss per 100 evaluation steps: 0.0363933621670665\n",
      "Validation dlite loss per 100 evaluation steps: 0.03644136079675608\n",
      "Validation dlite loss per 100 evaluation steps: 0.036475801131492944\n",
      "Validation dlite loss per 100 evaluation steps: 0.036526593090811875\n",
      "Validation dlite loss per 100 evaluation steps: 0.03666597512855964\n",
      "Validation dlite loss per 100 evaluation steps: 0.0367021563573881\n",
      "Validation dlite loss per 100 evaluation steps: 0.03664561304145961\n",
      "Validation dlite loss per 100 evaluation steps: 0.036682481573425386\n",
      "Validation dlite loss per 100 evaluation steps: 0.03658928773971738\n",
      "Validation dlite loss per 100 evaluation steps: 0.03653199458409825\n",
      "Validation dlite loss per 100 evaluation steps: 0.03653274117013878\n",
      "Validation dlite loss per 100 evaluation steps: 0.03655018927587091\n",
      "Validation dlite loss per 100 evaluation steps: 0.03655411097918461\n",
      "Validation dlite loss per 100 evaluation steps: 0.036541877993630394\n",
      "Validation dlite loss per 100 evaluation steps: 0.03649807767802166\n",
      "Validation dlite loss per 100 evaluation steps: 0.03656315525835728\n",
      "Validation dlite loss per 100 evaluation steps: 0.036434348039926116\n",
      "Validation Loss: 0.036429157329055134\n",
      "Validation Accuracy: 0.8290128931350179\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8334c303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         geo       0.00      0.00      0.00     11232\n",
      "         gpe       0.00      0.00      0.00      3293\n",
      "         org       0.00      0.00      0.00      6531\n",
      "         per       0.00      0.00      0.00      5196\n",
      "         tim       0.00      0.00      0.00      4360\n",
      "\n",
      "   micro avg       0.00      0.00      0.00     30612\n",
      "   macro avg       0.00      0.00      0.00     30612\n",
      "weighted avg       0.00      0.00      0.00     30612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(classification_report([labels], [predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f7d3aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india has a capital called mumbai . on wednesday , the president will give a presentation\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"India has a capital called Mumbai. On Wednesday, the president will give a presentation\"\n",
    "\n",
    "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "# move to gpu\n",
    "ids = inputs[\"input_ids\"].to(device)\n",
    "mask = inputs[\"attention_mask\"].to(device)\n",
    "# forward pass\n",
    "outputs = model(ids, mask)\n",
    "logits = outputs[0]\n",
    "\n",
    "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
    "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "word_level_predictions = []\n",
    "for pair in wp_preds:\n",
    "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
    "    # skip prediction\n",
    "    continue\n",
    "  else:\n",
    "    word_level_predictions.append(pair[1])\n",
    "\n",
    "# we join tokens, if they are not special ones\n",
    "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
    "print(str_rep)\n",
    "print(word_level_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1282ab63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2531e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a852a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (47571, 2)\n",
      "TRAIN Dataset: (38057, 2)\n",
      "TEST Dataset: (9514, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 5e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# tokenization\n",
    "\n",
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "    \"\"\"\n",
    "    Word piece tokenization makes it difficult to match word labels\n",
    "    back up with individual word pieces. This function tokenizes each\n",
    "    word one at a time so that it is easier to preserve the correct\n",
    "    label for each subword. It is, of course, a bit slower in processing\n",
    "    time, but it will help our model achieve higher accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels\n",
    "\n",
    "# Bert imput\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # step 1: tokenize (and adapt corresponding labels)\n",
    "        sentence = self.data.sentence[index]\n",
    "        word_labels = self.data.word_labels[index]\n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "\n",
    "        # step 2: add special tokens (and corresponding labels)\n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
    "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "\n",
    "        # step 3: truncating/padding\n",
    "        maxlen = self.max_len\n",
    "\n",
    "        if (len(tokenized_sentence) > maxlen):\n",
    "          # truncate\n",
    "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
    "          labels = labels[:maxlen]\n",
    "        else:\n",
    "          # pad\n",
    "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
    "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
    "\n",
    "        # step 4: obtain the attention mask\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "\n",
    "        # step 5: convert tokens to input ids\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "        # the following line is deprecated\n",
    "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
    "\n",
    "        return {\n",
    "              'ids': torch.tensor(ids, dtype=torch.long),\n",
    "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# define training size 80/20 split\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
    "\n",
    "# pyTorch dataloaders\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
    "                                                   num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                   label2id=label2id)\n",
    "model.to(device)\n",
    "\n",
    "# Train the model\n",
    "\n",
    "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
    "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
    "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "mask = mask.to(device)\n",
    "targets = targets.to(device)\n",
    "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25c70987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04286153",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDivergenceLoss(nn.Module):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(KLDivergenceLoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # Convert logits to probabilities using softmax\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        # One-hot encode the targets to get true probabilities\n",
    "        true_probs = F.one_hot(targets, num_classes=probs.size(-1)).float()\n",
    "\n",
    "        # Masks for non-zero elements of probs and true_probs\n",
    "        mask_probs = probs > 0\n",
    "        mask_true_probs = true_probs > 0\n",
    "\n",
    "        # Calculate g function for non-zero elements using the mask\n",
    "        kl_values = torch.zeros_like(probs)\n",
    "        kl_values[mask_true_probs] = true_probs[mask_true_probs] * torch.log(true_probs[mask_true_probs]/probs[mask_true_probs])\n",
    "\n",
    "        # Sum over all classes and average over the batch size\n",
    "        loss = kl_values.sum(dim=-1).mean()\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bc21367",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_loss_fn = KLDivergenceLoss()\n",
    "\n",
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    for idx, batch in enumerate(training_loader):\n",
    "\n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "\n",
    "        # implement dlite loss function\n",
    "        flatten_targets = targets.view(-1)\n",
    "        flatten_logits = tr_logits.view(-1, model.num_labels)\n",
    "\n",
    "        loss = kl_loss_fn(flatten_logits, flatten_targets)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "\n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training dlite loss per 100 training steps: {loss_step}\")\n",
    "\n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "778adc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training dlite loss per 100 training steps: 2.7201387882232666\n",
      "Training dlite loss per 100 training steps: 0.20385241034523685\n",
      "Training dlite loss per 100 training steps: 0.13226515310237286\n",
      "Training dlite loss per 100 training steps: 0.10420462333495138\n",
      "Training dlite loss per 100 training steps: 0.09054889655648789\n",
      "Training dlite loss per 100 training steps: 0.08047186379495659\n",
      "Training dlite loss per 100 training steps: 0.07330874471999581\n",
      "Training dlite loss per 100 training steps: 0.06788528070336051\n",
      "Training dlite loss per 100 training steps: 0.06437507456098189\n",
      "Training dlite loss per 100 training steps: 0.06167467081462954\n",
      "Training dlite loss per 100 training steps: 0.05981813345793412\n",
      "Training dlite loss per 100 training steps: 0.057894317311958855\n",
      "Training dlite loss per 100 training steps: 0.055916334380458524\n",
      "Training dlite loss per 100 training steps: 0.05414983364058155\n",
      "Training dlite loss per 100 training steps: 0.05255522582764577\n",
      "Training dlite loss per 100 training steps: 0.05165817005486742\n",
      "Training dlite loss per 100 training steps: 0.050748680274141575\n",
      "Training dlite loss per 100 training steps: 0.049755360233795384\n",
      "Training dlite loss per 100 training steps: 0.04894073769843324\n",
      "Training dlite loss per 100 training steps: 0.0481926137933898\n",
      "Training dlite loss per 100 training steps: 0.04731928210387049\n",
      "Training dlite loss per 100 training steps: 0.04669219935662501\n",
      "Training dlite loss per 100 training steps: 0.04607790501123194\n",
      "Training dlite loss per 100 training steps: 0.045754276711263225\n",
      "Training dlite loss per 100 training steps: 0.04524701107171667\n",
      "Training dlite loss per 100 training steps: 0.04470678562357439\n",
      "Training dlite loss per 100 training steps: 0.0443482486738278\n",
      "Training dlite loss per 100 training steps: 0.043917730928445906\n",
      "Training dlite loss per 100 training steps: 0.04331411296211736\n",
      "Training dlite loss per 100 training steps: 0.043000818496329696\n",
      "Training dlite loss per 100 training steps: 0.04258290935751601\n",
      "Training dlite loss per 100 training steps: 0.04216071773774009\n",
      "Training dlite loss per 100 training steps: 0.0418354644378761\n",
      "Training dlite loss per 100 training steps: 0.041431691985972616\n",
      "Training dlite loss per 100 training steps: 0.04114809002274\n",
      "Training dlite loss per 100 training steps: 0.04087826811536065\n",
      "Training dlite loss per 100 training steps: 0.040646312476857495\n",
      "Training dlite loss per 100 training steps: 0.04033143066530805\n",
      "Training dlite loss per 100 training steps: 0.039917653598601215\n",
      "Training dlite loss per 100 training steps: 0.039636238729464555\n",
      "Training dlite loss per 100 training steps: 0.03938059605170483\n",
      "Training dlite loss per 100 training steps: 0.03923834493868531\n",
      "Training dlite loss per 100 training steps: 0.03904873851053484\n",
      "Training dlite loss per 100 training steps: 0.038880076133113665\n",
      "Training dlite loss per 100 training steps: 0.03868147136599328\n",
      "Training dlite loss per 100 training steps: 0.03845521308207868\n",
      "Training dlite loss per 100 training steps: 0.03835244745861722\n",
      "Training dlite loss per 100 training steps: 0.038157898769333815\n",
      "Training dlite loss per 100 training steps: 0.037985472760987536\n",
      "Training dlite loss per 100 training steps: 0.03786667495968642\n",
      "Training dlite loss per 100 training steps: 0.03772451530079826\n",
      "Training dlite loss per 100 training steps: 0.03762186557333565\n",
      "Training dlite loss per 100 training steps: 0.037391505071167806\n",
      "Training dlite loss per 100 training steps: 0.03725343627557149\n",
      "Training dlite loss per 100 training steps: 0.037127318339688284\n",
      "Training dlite loss per 100 training steps: 0.03696967808546898\n",
      "Training dlite loss per 100 training steps: 0.0368200169142236\n",
      "Training dlite loss per 100 training steps: 0.036706656478100556\n",
      "Training dlite loss per 100 training steps: 0.03656558598211761\n",
      "Training dlite loss per 100 training steps: 0.036435826118155254\n",
      "Training dlite loss per 100 training steps: 0.03625916136167347\n",
      "Training dlite loss per 100 training steps: 0.03608370695364641\n",
      "Training dlite loss per 100 training steps: 0.03598210176126539\n",
      "Training dlite loss per 100 training steps: 0.035845995240457645\n",
      "Training dlite loss per 100 training steps: 0.03576850495356203\n",
      "Training dlite loss per 100 training steps: 0.03565769576149594\n",
      "Training dlite loss per 100 training steps: 0.0355049894883353\n",
      "Training dlite loss per 100 training steps: 0.03542004372019216\n",
      "Training dlite loss per 100 training steps: 0.035298669334254226\n",
      "Training dlite loss per 100 training steps: 0.03517200358141582\n",
      "Training dlite loss per 100 training steps: 0.03509737547155816\n",
      "Training dlite loss per 100 training steps: 0.03497386373384747\n",
      "Training dlite loss per 100 training steps: 0.03493450655832785\n",
      "Training dlite loss per 100 training steps: 0.03484071630032836\n",
      "Training dlite loss per 100 training steps: 0.03478781690302814\n",
      "Training dlite loss per 100 training steps: 0.03468186644077643\n",
      "Training dlite loss per 100 training steps: 0.03454198682342025\n",
      "Training dlite loss per 100 training steps: 0.034448449388211934\n",
      "Training dlite loss per 100 training steps: 0.03440060095082888\n",
      "Training dlite loss per 100 training steps: 0.03428627820665136\n",
      "Training dlite loss per 100 training steps: 0.034220013754143866\n",
      "Training dlite loss per 100 training steps: 0.03415217215382352\n",
      "Training dlite loss per 100 training steps: 0.034062022956969154\n",
      "Training dlite loss per 100 training steps: 0.0339587972280431\n",
      "Training dlite loss per 100 training steps: 0.03386092685630352\n",
      "Training dlite loss per 100 training steps: 0.033829451638770575\n",
      "Training dlite loss per 100 training steps: 0.033795211357565955\n",
      "Training dlite loss per 100 training steps: 0.03372257316688904\n",
      "Training dlite loss per 100 training steps: 0.03365135008654363\n",
      "Training dlite loss per 100 training steps: 0.033527999904170845\n",
      "Training dlite loss per 100 training steps: 0.03341868150982261\n",
      "Training dlite loss per 100 training steps: 0.03336801666972329\n",
      "Training dlite loss per 100 training steps: 0.03333502893715331\n",
      "Training dlite loss per 100 training steps: 0.03325284768012734\n",
      "Training dlite loss per 100 training steps: 0.033223799638936596\n",
      "Training dlite loss per 100 training steps: 0.03317056313235127\n",
      "Training loss epoch: 0.03316127102768935\n",
      "Training accuracy epoch: 0.9533369231927168\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea3e77df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "\n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "\n",
    "\n",
    "            # implement dlite loss\n",
    "            flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            flatten_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            loss = kl_loss_fn(flatten_logits, flatten_targets)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += targets.size(0)\n",
    "\n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation dlite loss per 100 evaluation steps: {loss_step}\")\n",
    "\n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "            eval_labels.extend(targets)\n",
    "            eval_preds.extend(predictions)\n",
    "\n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    #print(eval_labels)\n",
    "    #print(eval_preds)\n",
    "\n",
    "    labels = [id2label[id.item()] for id in eval_labels]\n",
    "    predictions = [id2label[id.item()] for id in eval_preds]\n",
    "\n",
    "    #print(labels)\n",
    "    #print(predictions)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a2f9aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dlite loss per 100 evaluation steps: 0.026410069316625595\n",
      "Validation dlite loss per 100 evaluation steps: 0.03133465253156126\n",
      "Validation dlite loss per 100 evaluation steps: 0.027424135155392583\n",
      "Validation dlite loss per 100 evaluation steps: 0.02738883650715291\n",
      "Validation dlite loss per 100 evaluation steps: 0.027022196189921344\n",
      "Validation dlite loss per 100 evaluation steps: 0.02649905138263377\n",
      "Validation dlite loss per 100 evaluation steps: 0.02561306404267287\n",
      "Validation dlite loss per 100 evaluation steps: 0.025729416197193\n",
      "Validation dlite loss per 100 evaluation steps: 0.025903394183333785\n",
      "Validation dlite loss per 100 evaluation steps: 0.025233635334050583\n",
      "Validation dlite loss per 100 evaluation steps: 0.025378998926029014\n",
      "Validation dlite loss per 100 evaluation steps: 0.025515976326462554\n",
      "Validation dlite loss per 100 evaluation steps: 0.025462628427050972\n",
      "Validation dlite loss per 100 evaluation steps: 0.025236277311033128\n",
      "Validation dlite loss per 100 evaluation steps: 0.0254578643403637\n",
      "Validation dlite loss per 100 evaluation steps: 0.025552959999819057\n",
      "Validation dlite loss per 100 evaluation steps: 0.025599085292604032\n",
      "Validation dlite loss per 100 evaluation steps: 0.025766495968014502\n",
      "Validation dlite loss per 100 evaluation steps: 0.026144434133633314\n",
      "Validation dlite loss per 100 evaluation steps: 0.026222456462818712\n",
      "Validation dlite loss per 100 evaluation steps: 0.026266639448254882\n",
      "Validation dlite loss per 100 evaluation steps: 0.026051632024094756\n",
      "Validation dlite loss per 100 evaluation steps: 0.026169200113780582\n",
      "Validation dlite loss per 100 evaluation steps: 0.026087487181231342\n",
      "Validation dlite loss per 100 evaluation steps: 0.026125796901797595\n",
      "Validation dlite loss per 100 evaluation steps: 0.02604914634993424\n",
      "Validation dlite loss per 100 evaluation steps: 0.02619589803079778\n",
      "Validation dlite loss per 100 evaluation steps: 0.026279920841496662\n",
      "Validation dlite loss per 100 evaluation steps: 0.02616423595662316\n",
      "Validation dlite loss per 100 evaluation steps: 0.026237188323442007\n",
      "Validation dlite loss per 100 evaluation steps: 0.026341288253487527\n",
      "Validation dlite loss per 100 evaluation steps: 0.026213645141891225\n",
      "Validation dlite loss per 100 evaluation steps: 0.026205635532989567\n",
      "Validation dlite loss per 100 evaluation steps: 0.02616064580654082\n",
      "Validation dlite loss per 100 evaluation steps: 0.02625930802170542\n",
      "Validation dlite loss per 100 evaluation steps: 0.026265822500795826\n",
      "Validation dlite loss per 100 evaluation steps: 0.026109348706310445\n",
      "Validation dlite loss per 100 evaluation steps: 0.02617359312844068\n",
      "Validation dlite loss per 100 evaluation steps: 0.02613632056190308\n",
      "Validation dlite loss per 100 evaluation steps: 0.02611461542079454\n",
      "Validation dlite loss per 100 evaluation steps: 0.026144909334931774\n",
      "Validation dlite loss per 100 evaluation steps: 0.026087079465259268\n",
      "Validation dlite loss per 100 evaluation steps: 0.0260814652648107\n",
      "Validation dlite loss per 100 evaluation steps: 0.02598900152899799\n",
      "Validation dlite loss per 100 evaluation steps: 0.0261051847686216\n",
      "Validation dlite loss per 100 evaluation steps: 0.026046548076208997\n",
      "Validation dlite loss per 100 evaluation steps: 0.025941401511668537\n",
      "Validation dlite loss per 100 evaluation steps: 0.026008089176016495\n",
      "Validation Loss: 0.026073132973738693\n",
      "Validation Accuracy: 0.9613027206718417\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "302b2264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         geo       0.79      0.91      0.85     11232\n",
      "         gpe       0.95      0.92      0.93      3293\n",
      "         org       0.74      0.54      0.63      6531\n",
      "         per       0.78      0.74      0.76      5196\n",
      "         tim       0.86      0.81      0.84      4360\n",
      "\n",
      "   micro avg       0.81      0.79      0.80     30612\n",
      "   macro avg       0.82      0.78      0.80     30612\n",
      "weighted avg       0.81      0.79      0.79     30612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "print(classification_report([labels], [predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1517dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d1498fe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a234d279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india has a capital called mumbai . on wednesday , the president will give a presentation\n",
      "['B-geo', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'B-tim', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"India has a capital called Mumbai. On Wednesday, the president will give a presentation\"\n",
    "\n",
    "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "# move to gpu\n",
    "ids = inputs[\"input_ids\"].to(device)\n",
    "mask = inputs[\"attention_mask\"].to(device)\n",
    "# forward pass\n",
    "outputs = model(ids, mask)\n",
    "logits = outputs[0]\n",
    "\n",
    "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
    "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "word_level_predictions = []\n",
    "for pair in wp_preds:\n",
    "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
    "    # skip prediction\n",
    "    continue\n",
    "  else:\n",
    "    word_level_predictions.append(pair[1])\n",
    "\n",
    "# we join tokens, if they are not special ones\n",
    "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
    "print(str_rep)\n",
    "print(word_level_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f866cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f827354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dlite 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb51de62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (47571, 2)\n",
      "TRAIN Dataset: (38057, 2)\n",
      "TEST Dataset: (9514, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 5e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# tokenization\n",
    "\n",
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "    \"\"\"\n",
    "    Word piece tokenization makes it difficult to match word labels\n",
    "    back up with individual word pieces. This function tokenizes each\n",
    "    word one at a time so that it is easier to preserve the correct\n",
    "    label for each subword. It is, of course, a bit slower in processing\n",
    "    time, but it will help our model achieve higher accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels\n",
    "\n",
    "# Bert imput\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # step 1: tokenize (and adapt corresponding labels)\n",
    "        sentence = self.data.sentence[index]\n",
    "        word_labels = self.data.word_labels[index]\n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "\n",
    "        # step 2: add special tokens (and corresponding labels)\n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
    "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "\n",
    "        # step 3: truncating/padding\n",
    "        maxlen = self.max_len\n",
    "\n",
    "        if (len(tokenized_sentence) > maxlen):\n",
    "          # truncate\n",
    "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
    "          labels = labels[:maxlen]\n",
    "        else:\n",
    "          # pad\n",
    "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
    "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
    "\n",
    "        # step 4: obtain the attention mask\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "\n",
    "        # step 5: convert tokens to input ids\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "        # the following line is deprecated\n",
    "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
    "\n",
    "        return {\n",
    "              'ids': torch.tensor(ids, dtype=torch.long),\n",
    "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# define training size 80/20 split\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
    "\n",
    "# pyTorch dataloaders\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
    "                                                   num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                   label2id=label2id)\n",
    "model.to(device)\n",
    "\n",
    "# Train the model\n",
    "\n",
    "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
    "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
    "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "mask = mask.to(device)\n",
    "targets = targets.to(device)\n",
    "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e06870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DLITE Cube Root Loss function\n",
    "class DLITECubeRootLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DLITECubeRootLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # Convert logits to probabilities using softmax\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        # One-hot encode the targets to get true probabilities\n",
    "        true_probs = F.one_hot(targets, num_classes=probs.size(-1)).float()\n",
    "\n",
    "        # Masks for non-zero elements of probs and true_probs\n",
    "        mask_probs = probs > 0\n",
    "        mask_true_probs = true_probs > 0\n",
    "\n",
    "        # Calculate g function for non-zero elements using the mask\n",
    "        g_probs = torch.zeros_like(probs)\n",
    "        g_true_probs = torch.zeros_like(true_probs)\n",
    "        g_probs[mask_probs] = probs[mask_probs] * (1 - torch.log(probs[mask_probs]))\n",
    "        g_true_probs[mask_true_probs] = true_probs[mask_true_probs] * (1 - torch.log(true_probs[mask_true_probs]))\n",
    "        g_values = torch.abs(g_probs - g_true_probs)\n",
    "\n",
    "        # Calculate delta_h function for non-zero elements using the mask\n",
    "        delta_h_probs = torch.zeros_like(probs)\n",
    "        delta_h_true_probs = torch.zeros_like(true_probs)\n",
    "        delta_h_probs[mask_probs] = probs[mask_probs]**2 * (1 - 2 * torch.log(probs[mask_probs]))\n",
    "        delta_h_true_probs[mask_true_probs] = true_probs[mask_true_probs]**2 * (1 - 2 * torch.log(true_probs[mask_true_probs]))\n",
    "        delta_h_values = torch.abs(delta_h_probs - delta_h_true_probs) / (2 * (probs + true_probs))\n",
    "\n",
    "        # Compute DLITE loss for each class\n",
    "        dl_values = g_values - delta_h_values\n",
    "\n",
    "        # Sum over all classes and average over the batch size\n",
    "        loss = dl_values.sum(dim=-1).mean() ** 1/3\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d17f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_loss_cube_fn = DLITECubeRootLoss()\n",
    "\n",
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    for idx, batch in enumerate(training_loader):\n",
    "\n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "\n",
    "        # implement dlite loss function\n",
    "        flatten_targets = targets.view(-1)\n",
    "        flatten_logits = tr_logits.view(-1, model.num_labels)\n",
    "\n",
    "        loss = dl_loss_cube_fn(flatten_logits, flatten_targets)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "\n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training dlite loss per 100 training steps: {loss_step}\")\n",
    "\n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "925a3b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training dlite loss per 100 training steps: 0.2325703650712967\n",
      "Training dlite loss per 100 training steps: 0.01968819149401002\n",
      "Training dlite loss per 100 training steps: 0.016133559601316554\n",
      "Training dlite loss per 100 training steps: 0.0149342078232884\n",
      "Training dlite loss per 100 training steps: 0.014576146827936358\n",
      "Training dlite loss per 100 training steps: 0.014081241101019099\n",
      "Training dlite loss per 100 training steps: 0.013946889358465739\n",
      "Training dlite loss per 100 training steps: 0.01363380546827725\n",
      "Training dlite loss per 100 training steps: 0.013334935712110665\n",
      "Training dlite loss per 100 training steps: 0.013256572905078232\n",
      "Training dlite loss per 100 training steps: 0.013083034555247569\n",
      "Training dlite loss per 100 training steps: 0.013019403145997348\n",
      "Training dlite loss per 100 training steps: 0.012969444132444389\n",
      "Training dlite loss per 100 training steps: 0.012925021244755142\n",
      "Training dlite loss per 100 training steps: 0.012931892839501944\n",
      "Training dlite loss per 100 training steps: 0.012852325194419959\n",
      "Training dlite loss per 100 training steps: 0.012848085695135033\n",
      "Training dlite loss per 100 training steps: 0.012819026301428981\n",
      "Training dlite loss per 100 training steps: 0.01283362636798396\n",
      "Training dlite loss per 100 training steps: 0.012841852944094113\n",
      "Training dlite loss per 100 training steps: 0.012819616665650067\n",
      "Training dlite loss per 100 training steps: 0.012782735502872348\n",
      "Training dlite loss per 100 training steps: 0.012749474389180194\n",
      "Training dlite loss per 100 training steps: 0.012734360061132934\n",
      "Training dlite loss per 100 training steps: 0.012727534428354793\n",
      "Training dlite loss per 100 training steps: 0.01268896239995914\n",
      "Training dlite loss per 100 training steps: 0.012659348372166396\n",
      "Training dlite loss per 100 training steps: 0.012622032391066487\n",
      "Training dlite loss per 100 training steps: 0.012619908404544645\n",
      "Training dlite loss per 100 training steps: 0.012582688930125105\n",
      "Training dlite loss per 100 training steps: 0.012590676192333367\n",
      "Training dlite loss per 100 training steps: 0.012579456790437281\n",
      "Training dlite loss per 100 training steps: 0.012578083629155289\n",
      "Training dlite loss per 100 training steps: 0.012539513267243878\n",
      "Training dlite loss per 100 training steps: 0.012572690734334807\n",
      "Training dlite loss per 100 training steps: 0.012542046474980622\n",
      "Training dlite loss per 100 training steps: 0.012524308570754884\n",
      "Training dlite loss per 100 training steps: 0.01251966267673273\n",
      "Training dlite loss per 100 training steps: 0.012513202340706783\n",
      "Training dlite loss per 100 training steps: 0.012508238372961954\n",
      "Training dlite loss per 100 training steps: 0.012484319244418634\n",
      "Training dlite loss per 100 training steps: 0.012470929798104498\n",
      "Training dlite loss per 100 training steps: 0.01245027227144518\n",
      "Training dlite loss per 100 training steps: 0.012433449118854667\n",
      "Training dlite loss per 100 training steps: 0.012452595098403211\n",
      "Training dlite loss per 100 training steps: 0.012438923004006956\n",
      "Training dlite loss per 100 training steps: 0.012458670814234352\n",
      "Training dlite loss per 100 training steps: 0.012467190381241715\n",
      "Training dlite loss per 100 training steps: 0.012448233204026432\n",
      "Training dlite loss per 100 training steps: 0.012464851332144278\n",
      "Training dlite loss per 100 training steps: 0.012446176002029538\n",
      "Training dlite loss per 100 training steps: 0.012445333917406588\n",
      "Training dlite loss per 100 training steps: 0.012449279892776628\n",
      "Training dlite loss per 100 training steps: 0.012440917584852433\n",
      "Training dlite loss per 100 training steps: 0.01243744457921237\n",
      "Training dlite loss per 100 training steps: 0.012442026414939173\n",
      "Training dlite loss per 100 training steps: 0.012453766700453416\n",
      "Training dlite loss per 100 training steps: 0.012443853929508558\n",
      "Training dlite loss per 100 training steps: 0.012437985793384834\n",
      "Training dlite loss per 100 training steps: 0.012430440351382362\n",
      "Training dlite loss per 100 training steps: 0.012434320099743166\n",
      "Training dlite loss per 100 training steps: 0.0124129953988174\n",
      "Training dlite loss per 100 training steps: 0.01241251551707912\n",
      "Training dlite loss per 100 training steps: 0.01241647298920324\n",
      "Training dlite loss per 100 training steps: 0.012418608853782341\n",
      "Training dlite loss per 100 training steps: 0.012407753506433705\n",
      "Training dlite loss per 100 training steps: 0.012413498396199955\n",
      "Training dlite loss per 100 training steps: 0.012412852729373855\n",
      "Training dlite loss per 100 training steps: 0.012409640667438191\n",
      "Training dlite loss per 100 training steps: 0.012408407960316366\n",
      "Training dlite loss per 100 training steps: 0.012399491662271122\n",
      "Training dlite loss per 100 training steps: 0.012392476461218235\n",
      "Training dlite loss per 100 training steps: 0.01238240103130795\n",
      "Training dlite loss per 100 training steps: 0.012379824247885968\n",
      "Training dlite loss per 100 training steps: 0.012396845419028517\n",
      "Training dlite loss per 100 training steps: 0.01240707664373662\n",
      "Training dlite loss per 100 training steps: 0.012411556772762072\n",
      "Training dlite loss per 100 training steps: 0.012430714833660645\n",
      "Training dlite loss per 100 training steps: 0.012433524997376336\n",
      "Training dlite loss per 100 training steps: 0.012427694318588171\n",
      "Training dlite loss per 100 training steps: 0.012419649554354453\n",
      "Training dlite loss per 100 training steps: 0.012420000572276574\n",
      "Training dlite loss per 100 training steps: 0.012424867894173052\n",
      "Training dlite loss per 100 training steps: 0.01241769663901389\n",
      "Training dlite loss per 100 training steps: 0.012415810725250111\n",
      "Training dlite loss per 100 training steps: 0.012409756984031179\n",
      "Training dlite loss per 100 training steps: 0.012426627700616585\n",
      "Training dlite loss per 100 training steps: 0.012421262066082902\n",
      "Training dlite loss per 100 training steps: 0.012428149937358362\n",
      "Training dlite loss per 100 training steps: 0.012427276188691369\n",
      "Training dlite loss per 100 training steps: 0.0124106538914673\n",
      "Training dlite loss per 100 training steps: 0.012408846903264848\n",
      "Training dlite loss per 100 training steps: 0.012400710964530886\n",
      "Training dlite loss per 100 training steps: 0.012396949729785067\n",
      "Training dlite loss per 100 training steps: 0.012393614727537992\n",
      "Training dlite loss per 100 training steps: 0.012398778262582028\n",
      "Training loss epoch: 0.012404962193480492\n",
      "Training accuracy epoch: 0.8247121459115753\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f778ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "\n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "\n",
    "\n",
    "            # implement dlite loss\n",
    "            flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            flatten_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            loss = dl_loss_cube_fn(flatten_logits, flatten_targets)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += targets.size(0)\n",
    "\n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation dlite loss per 100 evaluation steps: {loss_step}\")\n",
    "\n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "            eval_labels.extend(targets)\n",
    "            eval_preds.extend(predictions)\n",
    "\n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    #print(eval_labels)\n",
    "    #print(eval_preds)\n",
    "\n",
    "    labels = [id2label[id.item()] for id in eval_labels]\n",
    "    predictions = [id2label[id.item()] for id in eval_preds]\n",
    "\n",
    "    #print(labels)\n",
    "    #print(predictions)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "896a9286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dlite loss per 100 evaluation steps: 0.013020872138440609\n",
      "Validation dlite loss per 100 evaluation steps: 0.012634115910181933\n",
      "Validation dlite loss per 100 evaluation steps: 0.012904268744646617\n",
      "Validation dlite loss per 100 evaluation steps: 0.012605591143860654\n",
      "Validation dlite loss per 100 evaluation steps: 0.012472115365172816\n",
      "Validation dlite loss per 100 evaluation steps: 0.012389324354086347\n",
      "Validation dlite loss per 100 evaluation steps: 0.012262589036322713\n",
      "Validation dlite loss per 100 evaluation steps: 0.012487781069438684\n",
      "Validation dlite loss per 100 evaluation steps: 0.01231374989937367\n",
      "Validation dlite loss per 100 evaluation steps: 0.012280955239488056\n",
      "Validation dlite loss per 100 evaluation steps: 0.012041384773437917\n",
      "Validation dlite loss per 100 evaluation steps: 0.012109060854364008\n",
      "Validation dlite loss per 100 evaluation steps: 0.01207873377476976\n",
      "Validation dlite loss per 100 evaluation steps: 0.012023043852738693\n",
      "Validation dlite loss per 100 evaluation steps: 0.012066384658422132\n",
      "Validation dlite loss per 100 evaluation steps: 0.012139517066629526\n",
      "Validation dlite loss per 100 evaluation steps: 0.0121376369265075\n",
      "Validation dlite loss per 100 evaluation steps: 0.012210994895583992\n",
      "Validation dlite loss per 100 evaluation steps: 0.012181496482644518\n",
      "Validation dlite loss per 100 evaluation steps: 0.012124963916665992\n",
      "Validation dlite loss per 100 evaluation steps: 0.012148263386564278\n",
      "Validation dlite loss per 100 evaluation steps: 0.012148273604317998\n",
      "Validation dlite loss per 100 evaluation steps: 0.01218377809680725\n",
      "Validation dlite loss per 100 evaluation steps: 0.012150554884719266\n",
      "Validation dlite loss per 100 evaluation steps: 0.012111964502335034\n",
      "Validation dlite loss per 100 evaluation steps: 0.012126440074524425\n",
      "Validation dlite loss per 100 evaluation steps: 0.012121280070898554\n",
      "Validation dlite loss per 100 evaluation steps: 0.012097219171607328\n",
      "Validation dlite loss per 100 evaluation steps: 0.012065114176832727\n",
      "Validation dlite loss per 100 evaluation steps: 0.012065743609325334\n",
      "Validation dlite loss per 100 evaluation steps: 0.012059388965061845\n",
      "Validation dlite loss per 100 evaluation steps: 0.012037908199987643\n",
      "Validation dlite loss per 100 evaluation steps: 0.01205885369636954\n",
      "Validation dlite loss per 100 evaluation steps: 0.012071824492428778\n",
      "Validation dlite loss per 100 evaluation steps: 0.012068718409060134\n",
      "Validation dlite loss per 100 evaluation steps: 0.012111907507913727\n",
      "Validation dlite loss per 100 evaluation steps: 0.012124493931275375\n",
      "Validation dlite loss per 100 evaluation steps: 0.012106495570146111\n",
      "Validation dlite loss per 100 evaluation steps: 0.012110340592714512\n",
      "Validation dlite loss per 100 evaluation steps: 0.012125670833922693\n",
      "Validation dlite loss per 100 evaluation steps: 0.01213209877756031\n",
      "Validation dlite loss per 100 evaluation steps: 0.012122973070593545\n",
      "Validation dlite loss per 100 evaluation steps: 0.012125749813595819\n",
      "Validation dlite loss per 100 evaluation steps: 0.012130213863893874\n",
      "Validation dlite loss per 100 evaluation steps: 0.012129445428545094\n",
      "Validation dlite loss per 100 evaluation steps: 0.012118586077553698\n",
      "Validation dlite loss per 100 evaluation steps: 0.012132536755983147\n",
      "Validation dlite loss per 100 evaluation steps: 0.01212678230494941\n",
      "Validation Loss: 0.012143055760406614\n",
      "Validation Accuracy: 0.8287094042019463\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2fd9426a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         geo       0.00      0.00      0.00     11232\n",
      "         gpe       0.00      0.00      0.00      3293\n",
      "         org       0.00      0.00      0.00      6531\n",
      "         per       0.00      0.00      0.00      5196\n",
      "         tim       0.00      0.00      0.00      4360\n",
      "\n",
      "   micro avg       0.00      0.00      0.00     30612\n",
      "   macro avg       0.00      0.00      0.00     30612\n",
      "weighted avg       0.00      0.00      0.00     30612\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "print(classification_report([labels], [predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "277f2b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india has a capital called mumbai . on wednesday , the president will give a presentation\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"India has a capital called Mumbai. On Wednesday, the president will give a presentation\"\n",
    "\n",
    "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "# move to gpu\n",
    "ids = inputs[\"input_ids\"].to(device)\n",
    "mask = inputs[\"attention_mask\"].to(device)\n",
    "# forward pass\n",
    "outputs = model(ids, mask)\n",
    "logits = outputs[0]\n",
    "\n",
    "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
    "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "word_level_predictions = []\n",
    "for pair in wp_preds:\n",
    "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
    "    # skip prediction\n",
    "    continue\n",
    "  else:\n",
    "    word_level_predictions.append(pair[1])\n",
    "\n",
    "# we join tokens, if they are not special ones\n",
    "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
    "print(str_rep)\n",
    "print(word_level_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b316609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b013592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIT implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "369bb63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (47571, 2)\n",
      "TRAIN Dataset: (38057, 2)\n",
      "TEST Dataset: (9514, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 5e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# tokenization\n",
    "\n",
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "    \"\"\"\n",
    "    Word piece tokenization makes it difficult to match word labels\n",
    "    back up with individual word pieces. This function tokenizes each\n",
    "    word one at a time so that it is easier to preserve the correct\n",
    "    label for each subword. It is, of course, a bit slower in processing\n",
    "    time, but it will help our model achieve higher accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels\n",
    "\n",
    "# Bert imput\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # step 1: tokenize (and adapt corresponding labels)\n",
    "        sentence = self.data.sentence[index]\n",
    "        word_labels = self.data.word_labels[index]\n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "\n",
    "        # step 2: add special tokens (and corresponding labels)\n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
    "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "\n",
    "        # step 3: truncating/padding\n",
    "        maxlen = self.max_len\n",
    "\n",
    "        if (len(tokenized_sentence) > maxlen):\n",
    "          # truncate\n",
    "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
    "          labels = labels[:maxlen]\n",
    "        else:\n",
    "          # pad\n",
    "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
    "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
    "\n",
    "        # step 4: obtain the attention mask\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "\n",
    "        # step 5: convert tokens to input ids\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "        # the following line is deprecated\n",
    "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
    "\n",
    "        return {\n",
    "              'ids': torch.tensor(ids, dtype=torch.long),\n",
    "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# define training size 80/20 split\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
    "\n",
    "# pyTorch dataloaders\n",
    "\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
    "                                                   num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                   label2id=label2id)\n",
    "model.to(device)\n",
    "\n",
    "# Train the model\n",
    "\n",
    "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
    "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
    "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "mask = mask.to(device)\n",
    "targets = targets.to(device)\n",
    "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "63a41faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIT Loss function\n",
    "class LITLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LITLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # Convert logits to probabilities using softmax\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        # One-hot encode the targets to get true probabilities\n",
    "        true_probs = F.one_hot(targets, num_classes=probs.size(-1)).float()\n",
    "\n",
    "        # Masks for non-zero elements of probs and true_probs\n",
    "        mask_probs = probs > 0\n",
    "        mask_true_probs = true_probs > 0\n",
    "\n",
    "        # Calculate g function for non-zero elements using the mask\n",
    "        g_probs = torch.zeros_like(probs)\n",
    "        g_true_probs = torch.zeros_like(true_probs)\n",
    "        g_probs[mask_probs] = probs[mask_probs] * (1 - torch.log(probs[mask_probs]))\n",
    "        g_true_probs[mask_true_probs] = true_probs[mask_true_probs] * (1 - torch.log(true_probs[mask_true_probs]))\n",
    "        g_values = torch.abs(g_probs - g_true_probs)\n",
    "\n",
    "\n",
    "        # Sum over all classes and average over the batch size\n",
    "        loss = g_values.sum(dim=-1).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fae227bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_loss_fn = LITLoss()\n",
    "\n",
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    for idx, batch in enumerate(training_loader):\n",
    "\n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "\n",
    "        # implement dlite loss function\n",
    "        flatten_targets = targets.view(-1)\n",
    "        flatten_logits = tr_logits.view(-1, model.num_labels)\n",
    "\n",
    "        loss = lit_loss_fn(flatten_logits, flatten_targets)\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "\n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training dlite loss per 100 training steps: {loss_step}\")\n",
    "\n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "\n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c8a50bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training dlite loss per 100 training steps: 3.758822202682495\n",
      "Training dlite loss per 100 training steps: 0.22549149052857761\n",
      "Training dlite loss per 100 training steps: 0.1503626963040277\n",
      "Training dlite loss per 100 training steps: 0.1256279113928345\n",
      "Training dlite loss per 100 training steps: 0.11287898548816022\n",
      "Training dlite loss per 100 training steps: 0.1050523526886638\n",
      "Training dlite loss per 100 training steps: 0.10024108449090118\n",
      "Training dlite loss per 100 training steps: 0.097100244041701\n",
      "Training dlite loss per 100 training steps: 0.0948030946067896\n",
      "Training dlite loss per 100 training steps: 0.09271807707812571\n",
      "Training dlite loss per 100 training steps: 0.09099547208538493\n",
      "Training dlite loss per 100 training steps: 0.0894071899960748\n",
      "Training dlite loss per 100 training steps: 0.0881163177810738\n",
      "Training dlite loss per 100 training steps: 0.08699526371630116\n",
      "Training dlite loss per 100 training steps: 0.08592475299082955\n",
      "Training dlite loss per 100 training steps: 0.08478846863992723\n",
      "Training dlite loss per 100 training steps: 0.08422619297652262\n",
      "Training dlite loss per 100 training steps: 0.08379029851758044\n",
      "Training dlite loss per 100 training steps: 0.08331892555645475\n",
      "Training dlite loss per 100 training steps: 0.08309118252761734\n",
      "Training dlite loss per 100 training steps: 0.08240108570936408\n",
      "Training dlite loss per 100 training steps: 0.08199526317858016\n",
      "Training dlite loss per 100 training steps: 0.08183681787299911\n",
      "Training dlite loss per 100 training steps: 0.0815676348969427\n",
      "Training dlite loss per 100 training steps: 0.08140824338019179\n",
      "Training dlite loss per 100 training steps: 0.08120338919391741\n",
      "Training dlite loss per 100 training steps: 0.08090129005852499\n",
      "Training dlite loss per 100 training steps: 0.0807629794060204\n",
      "Training dlite loss per 100 training steps: 0.08059939660971652\n",
      "Training dlite loss per 100 training steps: 0.08038223220733845\n",
      "Training dlite loss per 100 training steps: 0.08017413521439838\n",
      "Training dlite loss per 100 training steps: 0.08006492323202034\n",
      "Training dlite loss per 100 training steps: 0.07991111995031873\n",
      "Training dlite loss per 100 training steps: 0.07991677282122887\n",
      "Training dlite loss per 100 training steps: 0.0796612504080978\n",
      "Training dlite loss per 100 training steps: 0.07949831667697359\n",
      "Training dlite loss per 100 training steps: 0.07942243518964023\n",
      "Training dlite loss per 100 training steps: 0.07923657436424907\n",
      "Training dlite loss per 100 training steps: 0.07907068980081015\n",
      "Training dlite loss per 100 training steps: 0.07894828637488428\n",
      "Training dlite loss per 100 training steps: 0.07896471790661182\n",
      "Training dlite loss per 100 training steps: 0.07891456675015152\n",
      "Training dlite loss per 100 training steps: 0.078765397735332\n",
      "Training dlite loss per 100 training steps: 0.07860313728148578\n",
      "Training dlite loss per 100 training steps: 0.07852453985830256\n",
      "Training dlite loss per 100 training steps: 0.07834438760006555\n",
      "Training dlite loss per 100 training steps: 0.07824504188302613\n",
      "Training dlite loss per 100 training steps: 0.07802026589052191\n",
      "Training dlite loss per 100 training steps: 0.0778674725986283\n",
      "Training dlite loss per 100 training steps: 0.07774400255830768\n",
      "Training dlite loss per 100 training steps: 0.07759420248856547\n",
      "Training dlite loss per 100 training steps: 0.07758426485143907\n",
      "Training dlite loss per 100 training steps: 0.07750258757038928\n",
      "Training dlite loss per 100 training steps: 0.077401866831189\n",
      "Training dlite loss per 100 training steps: 0.07730847539235693\n",
      "Training dlite loss per 100 training steps: 0.07718366826262268\n",
      "Training dlite loss per 100 training steps: 0.0770528424686525\n",
      "Training dlite loss per 100 training steps: 0.07695263038916879\n",
      "Training dlite loss per 100 training steps: 0.07687606270492611\n",
      "Training dlite loss per 100 training steps: 0.07688747188324162\n",
      "Training dlite loss per 100 training steps: 0.076822982248061\n",
      "Training dlite loss per 100 training steps: 0.076802855011621\n",
      "Training dlite loss per 100 training steps: 0.07681990431003193\n",
      "Training dlite loss per 100 training steps: 0.07679424855510449\n",
      "Training dlite loss per 100 training steps: 0.07672972065088009\n",
      "Training dlite loss per 100 training steps: 0.07670081980251964\n",
      "Training dlite loss per 100 training steps: 0.07665976962274136\n",
      "Training dlite loss per 100 training steps: 0.07655814730218566\n",
      "Training dlite loss per 100 training steps: 0.07649454430121982\n",
      "Training dlite loss per 100 training steps: 0.07646674198597678\n",
      "Training dlite loss per 100 training steps: 0.07641964309756125\n",
      "Training dlite loss per 100 training steps: 0.07643437736814979\n",
      "Training dlite loss per 100 training steps: 0.07647636396544763\n",
      "Training dlite loss per 100 training steps: 0.07643373198082694\n",
      "Training dlite loss per 100 training steps: 0.07631730107067576\n",
      "Training dlite loss per 100 training steps: 0.07631697725667783\n",
      "Training dlite loss per 100 training steps: 0.07628068508954768\n",
      "Training dlite loss per 100 training steps: 0.07620678266249829\n",
      "Training dlite loss per 100 training steps: 0.07620487550670568\n",
      "Training dlite loss per 100 training steps: 0.07622971186973276\n",
      "Training dlite loss per 100 training steps: 0.0761675103977011\n",
      "Training dlite loss per 100 training steps: 0.07603933549158297\n",
      "Training dlite loss per 100 training steps: 0.0760371732321316\n",
      "Training dlite loss per 100 training steps: 0.07596588699990987\n",
      "Training dlite loss per 100 training steps: 0.07595069801459889\n",
      "Training dlite loss per 100 training steps: 0.075943676427952\n",
      "Training dlite loss per 100 training steps: 0.07590911277538065\n",
      "Training dlite loss per 100 training steps: 0.07587668910640968\n",
      "Training dlite loss per 100 training steps: 0.0758583162534915\n",
      "Training dlite loss per 100 training steps: 0.07580656325191125\n",
      "Training dlite loss per 100 training steps: 0.07580369682667774\n",
      "Training dlite loss per 100 training steps: 0.07576655555687543\n",
      "Training dlite loss per 100 training steps: 0.07572427689544063\n",
      "Training dlite loss per 100 training steps: 0.07575430346245295\n",
      "Training dlite loss per 100 training steps: 0.07574255454558128\n",
      "Training dlite loss per 100 training steps: 0.07571008392322116\n",
      "Training loss epoch: 0.07571281787907327\n",
      "Training accuracy epoch: 0.8246635680592085\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1cebf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "\n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "\n",
    "\n",
    "            # implement dlite loss\n",
    "            flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            flatten_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            loss = lit_loss_fn(flatten_logits, flatten_targets)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += targets.size(0)\n",
    "\n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation dlite loss per 100 evaluation steps: {loss_step}\")\n",
    "\n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "\n",
    "            eval_labels.extend(targets)\n",
    "            eval_preds.extend(predictions)\n",
    "\n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    #print(eval_labels)\n",
    "    #print(eval_preds)\n",
    "\n",
    "    labels = [id2label[id.item()] for id in eval_labels]\n",
    "    predictions = [id2label[id.item()] for id in eval_preds]\n",
    "\n",
    "    #print(labels)\n",
    "    #print(predictions)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "43e1df93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation dlite loss per 100 evaluation steps: 0.06250065565109253\n",
      "Validation dlite loss per 100 evaluation steps: 0.07433543404424496\n",
      "Validation dlite loss per 100 evaluation steps: 0.07198448802303764\n",
      "Validation dlite loss per 100 evaluation steps: 0.07070248428364242\n",
      "Validation dlite loss per 100 evaluation steps: 0.07080022067737005\n",
      "Validation dlite loss per 100 evaluation steps: 0.07084334652906803\n",
      "Validation dlite loss per 100 evaluation steps: 0.07072913024283776\n",
      "Validation dlite loss per 100 evaluation steps: 0.07159480797624275\n",
      "Validation dlite loss per 100 evaluation steps: 0.07243940501880228\n",
      "Validation dlite loss per 100 evaluation steps: 0.07184790958397957\n",
      "Validation dlite loss per 100 evaluation steps: 0.07171019698379531\n",
      "Validation dlite loss per 100 evaluation steps: 0.0718245665415421\n",
      "Validation dlite loss per 100 evaluation steps: 0.07188086027532131\n",
      "Validation dlite loss per 100 evaluation steps: 0.07203659025912565\n",
      "Validation dlite loss per 100 evaluation steps: 0.07217008880936372\n",
      "Validation dlite loss per 100 evaluation steps: 0.07250440367640526\n",
      "Validation dlite loss per 100 evaluation steps: 0.0723870552980308\n",
      "Validation dlite loss per 100 evaluation steps: 0.07242129109301405\n",
      "Validation dlite loss per 100 evaluation steps: 0.07252980665831534\n",
      "Validation dlite loss per 100 evaluation steps: 0.07215429244432175\n",
      "Validation dlite loss per 100 evaluation steps: 0.07226920932078494\n",
      "Validation dlite loss per 100 evaluation steps: 0.072239322195404\n",
      "Validation dlite loss per 100 evaluation steps: 0.07244286983116519\n",
      "Validation dlite loss per 100 evaluation steps: 0.07248612437329334\n",
      "Validation dlite loss per 100 evaluation steps: 0.07254855281891237\n",
      "Validation dlite loss per 100 evaluation steps: 0.07269657774449828\n",
      "Validation dlite loss per 100 evaluation steps: 0.0730825235982938\n",
      "Validation dlite loss per 100 evaluation steps: 0.0732345276782175\n",
      "Validation dlite loss per 100 evaluation steps: 0.07340357003085402\n",
      "Validation dlite loss per 100 evaluation steps: 0.07332397118298895\n",
      "Validation dlite loss per 100 evaluation steps: 0.0733486024443727\n",
      "Validation dlite loss per 100 evaluation steps: 0.07341699341361961\n",
      "Validation dlite loss per 100 evaluation steps: 0.07326877530163582\n",
      "Validation dlite loss per 100 evaluation steps: 0.07301830217736227\n",
      "Validation dlite loss per 100 evaluation steps: 0.0731018578490016\n",
      "Validation dlite loss per 100 evaluation steps: 0.07308245402266483\n",
      "Validation dlite loss per 100 evaluation steps: 0.07291009083163301\n",
      "Validation dlite loss per 100 evaluation steps: 0.07304257027369937\n",
      "Validation dlite loss per 100 evaluation steps: 0.07342294607756522\n",
      "Validation dlite loss per 100 evaluation steps: 0.07324709916848349\n",
      "Validation dlite loss per 100 evaluation steps: 0.07305856341087844\n",
      "Validation dlite loss per 100 evaluation steps: 0.07290017747862872\n",
      "Validation dlite loss per 100 evaluation steps: 0.07300596724947249\n",
      "Validation dlite loss per 100 evaluation steps: 0.07286706793647914\n",
      "Validation dlite loss per 100 evaluation steps: 0.07284276581275853\n",
      "Validation dlite loss per 100 evaluation steps: 0.07281433635407446\n",
      "Validation dlite loss per 100 evaluation steps: 0.07280751869251517\n",
      "Validation dlite loss per 100 evaluation steps: 0.0729206464501366\n",
      "Validation Loss: 0.072858746758514\n",
      "Validation Accuracy: 0.8298549670617551\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "187ccfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\25141\\anaconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         geo       0.00      0.00      0.00     11232\n",
      "         gpe       0.00      0.00      0.00      3293\n",
      "         org       0.00      0.00      0.00      6531\n",
      "         per       0.00      0.00      0.00      5196\n",
      "         tim       0.00      0.00      0.00      4360\n",
      "\n",
      "   micro avg       0.00      0.00      0.00     30612\n",
      "   macro avg       0.00      0.00      0.00     30612\n",
      "weighted avg       0.00      0.00      0.00     30612\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "print(classification_report([labels], [predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f13bdfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india has a capital called mumbai . on wednesday , the president will give a presentation\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"India has a capital called Mumbai. On Wednesday, the president will give a presentation\"\n",
    "\n",
    "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "# move to gpu\n",
    "ids = inputs[\"input_ids\"].to(device)\n",
    "mask = inputs[\"attention_mask\"].to(device)\n",
    "# forward pass\n",
    "outputs = model(ids, mask)\n",
    "logits = outputs[0]\n",
    "\n",
    "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
    "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "word_level_predictions = []\n",
    "for pair in wp_preds:\n",
    "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
    "    # skip prediction\n",
    "    continue\n",
    "  else:\n",
    "    word_level_predictions.append(pair[1])\n",
    "\n",
    "# we join tokens, if they are not special ones\n",
    "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
    "print(str_rep)\n",
    "print(word_level_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4270ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
