{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82fdcbca"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertConfig, BertForTokenClassification\n",
        "# Using the dlite function\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "from sklearn.metrics import cohen_kappa_score"
      ],
      "id": "82fdcbca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f8d35a4",
        "outputId": "fb88b952-7f69-4749-d041-baac89948a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement gpu (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for gpu\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow gpu"
      ],
      "id": "8f8d35a4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c8951f4",
        "outputId": "a916e78e-dbf8-4ef6-a3e5-784606c7c3ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "id": "7c8951f4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49cf5d5d"
      },
      "source": [
        "# Data Website"
      ],
      "id": "49cf5d5d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ca0954"
      },
      "source": [
        "Ner dataset website (https://www.kaggle.com/datasets/namanj27/ner-dataset)"
      ],
      "id": "e1ca0954"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dujgPdKUOsdH"
      },
      "id": "dujgPdKUOsdH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5e45b42"
      },
      "source": [
        "# CoNLL-2003(english) Named Entity Recognition (NER)\n",
        "\n",
        "The  **`CoNLL 2003`** shared task consists of data from the Reuters 1996 news corpus with annotations for 4 types of `Named Entities` (persons, locations, organizations, and miscellaneous entities). The data is in a [IOB2](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) format.  Each token enitity has a `'B-'` or `'I-'` tag indicating if it is the start of the entity or if the token is inside the annotation.\n",
        "\n",
        "* **`Person`**: `'B-PER'` and  `'I-PER'`\n",
        "\n",
        "\n",
        "* **`Organization`**: `'B-ORG'` and `'I-ORG'`\n",
        "\n",
        "\n",
        "* **`Location`**: `'B-LOC'`  and `'I-LOC'`\n",
        "\n",
        "\n",
        "* **`Miscellaneous`**: `'B-MISC'` and `'I-MISC'`\n",
        "\n",
        "\n",
        "* **`Other(non-named entity)`**: `'O'`\n",
        "\n"
      ],
      "id": "b5e45b42"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a4f36f2"
      },
      "source": [
        "# Reseult"
      ],
      "id": "2a4f36f2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cbdcc27"
      },
      "source": [
        "# Original\n",
        "\n",
        "## Micro Table\n",
        "\n",
        "| Loss | Train Iteration | Precision | Recall | F1-score | Training time |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| CE | 3747 | 0.930 | 0.930 | 0.930 | 3 min 24s |\n",
        "| DLITE | 3747 | 0.850 | 0.850 | 0.850 | 3 min 24s |\n",
        "| L1 | 3747 | 0.886 | 0.886 | 0.886 | 3 min 18s |\n",
        "| L2 | 3747 | 0.930 | 0.930 | 0.930 | 3 min 19s |\n",
        "| KL | 3747 | 0.959 | 0.959 | 0.959 | 3 min 26s |\n",
        "\n",
        "\n",
        "## Macro Table\n",
        "\n",
        "| Loss | Train Iteration | Precision | Recall | F1-score | Training time |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| CE | 3747 | 0.705 | 0.661 | 0.663 | 3 min 24s |\n",
        "| DLITE | 3747 | 0.983 | 0.111 | 0.102 | 3 min 24s |\n",
        "| L1 | 3747 | 0.619 | 0.271 | 0.312 | 3 min 18s |\n",
        "| L2 | 3747 | 0.682 | 0.600 | 0.625 | 3 min 19s |\n",
        "| KL | 3747 | 0.714 | 0.593 | 0.627 | 3 min 26s |\n",
        "\n",
        "## Weighted Table\n",
        "\n",
        "| Loss | Train Iteration | Precision | Recall | F1-score | Training time |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| CE | 3747 | 0.936 | 0.938 | 0.937 | 3 min 24s |\n",
        "| DLITE | 3747 | 0.846 | 0.849 | 0.847 | 3 min 24s |\n",
        "| L1 | 3747 | 0.856 | 0.856 | 0.852 | 3 min 18s |\n",
        "| L2 | 3747 | 0.927 | 0.928 | 0.926 | 3 min 19s |\n",
        "| KL | 3747 | 0.933 | 0.932 | 0.937 | 3 min 26s |\n",
        "\n",
        "\n",
        "\n",
        "# with an additional layer\n",
        "\n",
        "## Micro Table\n",
        "\n",
        "| Loss | Train Iteration | Precision | Recall | F1-score | Training time |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| CE | 3747 | 0.940 | 0.940 | 0.940 | 3 min 38s |\n",
        "| DLITE | 3747 | 0.850 | 0.850 | 0.850 | 3 min 36s |\n",
        "| L1 | 3747 | 0.890 | 0.890 | 0.890 | 3 min 29s |\n",
        "| L2 | 3747 | 0.927 | 0.927 | 0.927 | 3 min 29s |\n",
        "| KL | 3747 | 0.928 | 0.928 | 0.928 | 3 min 42s |\n",
        "\n",
        "\n",
        "## Macro Table\n",
        "\n",
        "| Loss | Train Iteration | Precision | Recall | F1-score | Training time |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| CE | 3747 | 0.721 | 0.676 | 0.693 | 3 min 38s |\n",
        "| DLITE | 3747 | 0.983 | 0.111 | 0.102 | 3 min 36s |\n",
        "| L1 | 3747 | 0.612 | 0.309 | 0.331 | 3 min 29s |\n",
        "| L2 | 3747 | 0.688 | 0.585 | 0.611 | 3 min 29s |\n",
        "| KL | 3747 | 0.675 | 0.615 | 0.636 | 3 min 42s |\n",
        "\n",
        "## Weighted Table\n",
        "\n",
        "| Loss | Train Iteration | Precision | Recall | F1-score | Training time |\n",
        "| --- | --- | --- | --- | --- | --- |\n",
        "| CE | 3747 | 0.938 | 0.940 | 0.938 | 3 min 38s |\n",
        "| DLITE | 3747 | 0.872 | 0.850 | 0.781 | 3 min 36s |\n",
        "| L1 | 3747 | 0.860 | 0.890 | 0.867 | 3 min 29s |\n",
        "| L2 | 3747 | 0.922 | 0.927 | 0.923 | 3 min 29s |\n",
        "| KL | 3747 | 0.925 | 0.928 | 0.925 | 3 min 42s |\n"
      ],
      "id": "6cbdcc27"
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 and CE LOSS are slightly better from overall outcome\n",
        "L2 and KL are slightly worse, probably because of the logistical layer?\n",
        "DLITE has no overall change, probably still bug even on different models."
      ],
      "metadata": {
        "id": "jXDoBJEpyivQ"
      },
      "id": "jXDoBJEpyivQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSZfXfY3P-9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3136a301-e564-40d3-8444-7a385dba10ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating ner_english dir\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--2024-03-08 19:58:17--  https://raw.githubusercontent.com/mxhofer/Named-Entity-Recognition-BidirectionalLSTM-CNN-CoNLL/master/data/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3283420 (3.1M) [text/plain]\n",
            "Saving to: ‘train.txt’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  1% 4.06M 1s\n",
            "    50K .......... .......... .......... .......... ..........  3% 5.15M 1s\n",
            "   100K .......... .......... .......... .......... ..........  4% 13.4M 1s\n",
            "   150K .......... .......... .......... .......... ..........  6% 42.3M 0s\n",
            "   200K .......... .......... .......... .......... ..........  7% 7.40M 0s\n",
            "   250K .......... .......... .......... .......... ..........  9% 46.2M 0s\n",
            "   300K .......... .......... .......... .......... .......... 10% 37.3M 0s\n",
            "   350K .......... .......... .......... .......... .......... 12% 29.5M 0s\n",
            "   400K .......... .......... .......... .......... .......... 14% 69.2M 0s\n",
            "   450K .......... .......... .......... .......... .......... 15% 8.81M 0s\n",
            "   500K .......... .......... .......... .......... .......... 17% 98.6M 0s\n",
            "   550K .......... .......... .......... .......... .......... 18% 48.6M 0s\n",
            "   600K .......... .......... .......... .......... .......... 20% 89.9M 0s\n",
            "   650K .......... .......... .......... .......... .......... 21% 49.8M 0s\n",
            "   700K .......... .......... .......... .......... .......... 23% 60.0M 0s\n",
            "   750K .......... .......... .......... .......... .......... 24%  234M 0s\n",
            "   800K .......... .......... .......... .......... .......... 26% 63.2M 0s\n",
            "   850K .......... .......... .......... .......... .......... 28% 96.7M 0s\n",
            "   900K .......... .......... .......... .......... .......... 29% 73.7M 0s\n",
            "   950K .......... .......... .......... .......... .......... 31% 10.1M 0s\n",
            "  1000K .......... .......... .......... .......... .......... 32%  175M 0s\n",
            "  1050K .......... .......... .......... .......... .......... 34%  173M 0s\n",
            "  1100K .......... .......... .......... .......... .......... 35% 49.0M 0s\n",
            "  1150K .......... .......... .......... .......... .......... 37%  156M 0s\n",
            "  1200K .......... .......... .......... .......... .......... 38%  146M 0s\n",
            "  1250K .......... .......... .......... .......... .......... 40%  258M 0s\n",
            "  1300K .......... .......... .......... .......... .......... 42%  117M 0s\n",
            "  1350K .......... .......... .......... .......... .......... 43%  109M 0s\n",
            "  1400K .......... .......... .......... .......... .......... 45%  148M 0s\n",
            "  1450K .......... .......... .......... .......... .......... 46%  206M 0s\n",
            "  1500K .......... .......... .......... .......... .......... 48%  122M 0s\n",
            "  1550K .......... .......... .......... .......... .......... 49% 55.2M 0s\n",
            "  1600K .......... .......... .......... .......... .......... 51%  135M 0s\n",
            "  1650K .......... .......... .......... .......... .......... 53%  171M 0s\n",
            "  1700K .......... .......... .......... .......... .......... 54%  152M 0s\n",
            "  1750K .......... .......... .......... .......... .......... 56%  216M 0s\n",
            "  1800K .......... .......... .......... .......... .......... 57%  193M 0s\n",
            "  1850K .......... .......... .......... .......... .......... 59%  148M 0s\n",
            "  1900K .......... .......... .......... .......... .......... 60% 63.0M 0s\n",
            "  1950K .......... .......... .......... .......... .......... 62% 63.8M 0s\n",
            "  2000K .......... .......... .......... .......... .......... 63% 9.33M 0s\n",
            "  2050K .......... .......... .......... .......... .......... 65% 47.8M 0s\n",
            "  2100K .......... .......... .......... .......... .......... 67% 45.6M 0s\n",
            "  2150K .......... .......... .......... .......... .......... 68% 12.4M 0s\n",
            "  2200K .......... .......... .......... .......... .......... 70% 47.2M 0s\n",
            "  2250K .......... .......... .......... .......... .......... 71% 51.8M 0s\n",
            "  2300K .......... .......... .......... .......... .......... 73% 91.0M 0s\n",
            "  2350K .......... .......... .......... .......... .......... 74%  248M 0s\n",
            "  2400K .......... .......... .......... .......... .......... 76%  269M 0s\n",
            "  2450K .......... .......... .......... .......... .......... 77%  228M 0s\n",
            "  2500K .......... .......... .......... .......... .......... 79%  242M 0s\n",
            "  2550K .......... .......... .......... .......... .......... 81%  274M 0s\n",
            "  2600K .......... .......... .......... .......... .......... 82%  277M 0s\n",
            "  2650K .......... .......... .......... .......... .......... 84%  233M 0s\n",
            "  2700K .......... .......... .......... .......... .......... 85%  264M 0s\n",
            "  2750K .......... .......... .......... .......... .......... 87% 4.88M 0s\n",
            "  2800K .......... .......... .......... .......... .......... 88% 57.9M 0s\n",
            "  2850K .......... .......... .......... .......... .......... 90% 16.1M 0s\n",
            "  2900K .......... .......... .......... .......... .......... 92% 12.9M 0s\n",
            "  2950K .......... .......... .......... .......... .......... 93% 48.6M 0s\n",
            "  3000K .......... .......... .......... .......... .......... 95% 20.8M 0s\n",
            "  3050K .......... .......... .......... .......... .......... 96% 30.3M 0s\n",
            "  3100K .......... .......... .......... .......... .......... 98% 12.6M 0s\n",
            "  3150K .......... .......... .......... .......... .......... 99% 46.8M 0s\n",
            "  3200K ......                                                100% 36.4M=0.1s\n",
            "\n",
            "2024-03-08 19:58:17 (29.7 MB/s) - ‘train.txt’ saved [3283420/3283420]\n",
            "\n",
            "--2024-03-08 19:58:17--  https://raw.githubusercontent.com/mxhofer/Named-Entity-Recognition-BidirectionalLSTM-CNN-CoNLL/master/data/test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 748095 (731K) [text/plain]\n",
            "Saving to: ‘test.txt’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  6% 3.95M 0s\n",
            "    50K .......... .......... .......... .......... .......... 13% 5.57M 0s\n",
            "   100K .......... .......... .......... .......... .......... 20% 23.9M 0s\n",
            "   150K .......... .......... .......... .......... .......... 27% 17.4M 0s\n",
            "   200K .......... .......... .......... .......... .......... 34% 8.35M 0s\n",
            "   250K .......... .......... .......... .......... .......... 41% 22.7M 0s\n",
            "   300K .......... .......... .......... .......... .......... 47% 14.3M 0s\n",
            "   350K .......... .......... .......... .......... .......... 54%  206M 0s\n",
            "   400K .......... .......... .......... .......... .......... 61%  253M 0s\n",
            "   450K .......... .......... .......... .......... .......... 68%  258M 0s\n",
            "   500K .......... .......... .......... .......... .......... 75% 9.41M 0s\n",
            "   550K .......... .......... .......... .......... .......... 82% 53.6M 0s\n",
            "   600K .......... .......... .......... .......... .......... 88%  215M 0s\n",
            "   650K .......... .......... .......... .......... .......... 95% 83.0M 0s\n",
            "   700K .......... .......... ..........                      100% 63.5M=0.05s\n",
            "\n",
            "2024-03-08 19:58:17 (15.7 MB/s) - ‘test.txt’ saved [748095/748095]\n",
            "\n",
            "--2024-03-08 19:58:17--  https://raw.githubusercontent.com/mxhofer/Named-Entity-Recognition-BidirectionalLSTM-CNN-CoNLL/master/data/dev.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 827443 (808K) [text/plain]\n",
            "Saving to: ‘dev.txt’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  6% 4.07M 0s\n",
            "    50K .......... .......... .......... .......... .......... 12% 5.58M 0s\n",
            "   100K .......... .......... .......... .......... .......... 18% 25.1M 0s\n",
            "   150K .......... .......... .......... .......... .......... 24% 17.8M 0s\n",
            "   200K .......... .......... .......... .......... .......... 30% 8.09M 0s\n",
            "   250K .......... .......... .......... .......... .......... 37% 65.4M 0s\n",
            "   300K .......... .......... .......... .......... .......... 43% 30.1M 0s\n",
            "   350K .......... .......... .......... .......... .......... 49% 30.4M 0s\n",
            "   400K .......... .......... .......... .......... .......... 55% 34.7M 0s\n",
            "   450K .......... .......... .......... .......... .......... 61%  263M 0s\n",
            "   500K .......... .......... .......... .......... .......... 68% 6.03M 0s\n",
            "   550K .......... .......... .......... .......... .......... 74%  272M 0s\n",
            "   600K .......... .......... .......... .......... .......... 80%  232M 0s\n",
            "   650K .......... .......... .......... .......... .......... 86%  186M 0s\n",
            "   700K .......... .......... .......... .......... .......... 92%  226M 0s\n",
            "   750K .......... .......... .......... .......... .......... 99%  254M 0s\n",
            "   800K ........                                              100%  284M=0.05s\n",
            "\n",
            "2024-03-08 19:58:17 (17.1 MB/s) - ‘dev.txt’ saved [827443/827443]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "DATADIR=\"ner_english\"\n",
        "if test ! -d \"$DATADIR\";then\n",
        "    echo \"Creating $DATADIR dir\"\n",
        "    mkdir \"$DATADIR\"\n",
        "    cd \"$DATADIR\"\n",
        "    wget https://raw.githubusercontent.com/mxhofer/Named-Entity-Recognition-BidirectionalLSTM-CNN-CoNLL/master/data/train.txt\n",
        "    wget https://raw.githubusercontent.com/mxhofer/Named-Entity-Recognition-BidirectionalLSTM-CNN-CoNLL/master/data/test.txt\n",
        "    wget https://raw.githubusercontent.com/mxhofer/Named-Entity-Recognition-BidirectionalLSTM-CNN-CoNLL/master/data/dev.txt\n",
        "fi"
      ],
      "id": "WSZfXfY3P-9V"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e09772c"
      },
      "source": [
        "# Data Preview"
      ],
      "id": "7e09772c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06c28e45",
        "outputId": "e978f6a8-5802-4a1e-9163-f994904687dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: 14987 sentences, 204567 tokens\n",
            "Dev data: 3466 sentences, 51578 tokens\n",
            "Test data: 3684 sentences, 46666 tokens\n",
            "\n",
            "NER tags: ['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Train data: 14987 sentences, 204567 tokens\n",
        "Dev data: 3466 sentences, 51578 tokens\n",
        "Test data: 3684 sentences, 46666 tokens\n",
        "\"\"\"\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "sys.path.append(\"../\")\n",
        "\n",
        "\n",
        "def flatten(l):\n",
        "    return [item for sublist in l for item in sublist]\n",
        "\n",
        "def read_CoNLL2003_format(filename, idx=3):\n",
        "    \"\"\"Read file in CoNLL-2003 shared task format\"\"\"\n",
        "\n",
        "    lines =  open(filename).read().strip()\n",
        "\n",
        "    # find sentence-like boundaries\n",
        "    lines = lines.split(\"\\n\\n\")\n",
        "\n",
        "    # throw out -DOCSTART- lines\n",
        "    #lines = [line for line in lines if not line.startswith(\"-DOCSTART-\")]\n",
        "\n",
        "     # split on newlines\n",
        "    lines = [line.split(\"\\n\") for line in lines]\n",
        "\n",
        "    # get tokens\n",
        "    tokens = [[l.split()[0] for l in line] for line in lines]\n",
        "\n",
        "    # get labels/tags\n",
        "    labels = [[l.split()[idx] for l in line] for line in lines]\n",
        "\n",
        "    data= {'tokens': tokens, 'labels': labels}\n",
        "    df=pd.DataFrame(data=data)\n",
        "\n",
        "    return df\n",
        "\n",
        "DATADIR = \"./ner_english/\"\n",
        "\n",
        "def get_conll2003_data(trainfile=DATADIR + \"train.txt\",\n",
        "                  devfile=DATADIR + \"dev.txt\",\n",
        "                  testfile=DATADIR + \"test.txt\"):\n",
        "\n",
        "    train = read_CoNLL2003_format(trainfile)\n",
        "    print(\"Train data: %d sentences, %d tokens\"%(len(train),len(flatten(train.tokens))))\n",
        "\n",
        "    dev = read_CoNLL2003_format(devfile)\n",
        "    print(\"Dev data: %d sentences, %d tokens\"%(len(dev),len(flatten(dev.tokens))))\n",
        "\n",
        "    test = read_CoNLL2003_format(testfile)\n",
        "    print(\"Test data: %d sentences, %d tokens\"%(len(test),len(flatten(test.tokens))))\n",
        "\n",
        "    return train, dev, test\n",
        "\n",
        "train, dev, test = get_conll2003_data()\n",
        "\n",
        "X_train, y_train = train.tokens, train.labels\n",
        "X_dev, y_dev = dev.tokens, dev.labels\n",
        "X_test, y_test = test.tokens, test.labels\n",
        "\n",
        "\n",
        "label_list = np.unique(flatten(y_train))\n",
        "label_list = list(label_list)\n",
        "print(\"\\nNER tags:\",label_list)"
      ],
      "id": "06c28e45"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72665d1e",
        "outputId": "0f4c627f-043a-4088-aa77-b224c60cd274"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-LOC': 0,\n",
              " 'B-MISC': 1,\n",
              " 'B-ORG': 2,\n",
              " 'B-PER': 3,\n",
              " 'I-LOC': 4,\n",
              " 'I-MISC': 5,\n",
              " 'I-ORG': 6,\n",
              " 'I-PER': 7,\n",
              " 'O': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "label2id = {k: v for v, k in enumerate(label_list)}\n",
        "id2label = {v: k for v, k in enumerate(label_list)}\n",
        "label2id"
      ],
      "id": "72665d1e"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig, AutoModel,AutoConfig"
      ],
      "metadata": {
        "id": "LFHOL2gdNMRk"
      },
      "id": "LFHOL2gdNMRk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertConfig, BertForTokenClassification,AutoTokenizer,AutoModelForTokenClassification"
      ],
      "metadata": {
        "id": "0Xpq6EYOhjGJ"
      },
      "id": "0Xpq6EYOhjGJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "          super(CustomBERTModel, self).__init__()\n",
        "          self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "          # add your additional layers here, for example a dropout layer followed by a linear classification head\n",
        "          self.dropout = nn.Dropout(0.3)\n",
        "          self.out = nn.Linear(768, 2)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "          sequence_output, pooled_output = self.bert(\n",
        "               ids,\n",
        "               attention_mask=mask,\n",
        "               token_type_ids=token_type_ids\n",
        "          )\n",
        "\n",
        "          # we apply dropout to the sequence output, tensor has shape (batch_size, sequence_length, 768)\n",
        "          sequence_output = self.dropout(sequence_output)\n",
        "\n",
        "          # next, we apply the linear layer. The linear layer (which applies a linear transformation)\n",
        "          # takes as input the hidden states of all tokens (so seq_len times a vector of size 768, each corresponding to\n",
        "          # a single token in the input sequence) and outputs 2 numbers (scores, or logits) for every token\n",
        "          # so the logits are of shape (batch_size, sequence_length, 2)\n",
        "          logits = self.out(sequence_output)\n",
        "\n",
        "          return logits"
      ],
      "metadata": {
        "id": "0K2ypMNTzlrw"
      },
      "id": "0K2ypMNTzlrw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyTaskSpecificCustomModel(nn.Module):\n",
        "    \"\"\"\n",
        "    A task-specific custom transformer model. This model loads a pre-trained transformer model and adds a new dropout\n",
        "    and linear layer at the end for fine-tuning and prediction on specific tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, checkpoint, num_labels ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            checkpoint (str): The name of the pre-trained model or path to the model weights.\n",
        "            num_labels (int): The number of output labels in the final classification layer.\n",
        "        \"\"\"\n",
        "        super(MyTaskSpecificCustomModel, self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        self.model = model = AutoModel.from_pretrained(checkpoint, config = AutoConfig.from_pretrained(checkpoint,\n",
        "                                                                                                       output_attention = True,\n",
        "                                                                                                       output_hidden_state = True))\n",
        "        # New Layer\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768, num_labels)\n",
        "\n",
        "    def forward(self, input_ids = None, attention_mask=None, labels = None):\n",
        "        \"\"\"\n",
        "        Forward pass for the model.\n",
        "\n",
        "        Args:\n",
        "            input_ids (torch.Tensor, optional): Tensor of input IDs. Defaults to None.\n",
        "            attention_mask (torch.Tensor, optional): Tensor for attention masks. Defaults to None.\n",
        "            labels (torch.Tensor, optional): Tensor for labels. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            TokenClassifierOutput: A named tuple with the following fields:\n",
        "            - loss (torch.FloatTensor of shape (1,), optional, returned when label_ids is provided) – Classification loss.\n",
        "            - logits (torch.FloatTensor of shape (batch_size, num_labels)) – Classification scores before SoftMax.\n",
        "            - hidden_states (tuple(torch.FloatTensor), optional, returned when output_hidden_states=True is passed or when config.output_hidden_states=True) – Tuple of torch.FloatTensor (one for the output of the embeddings + one for the output of each layer) of shape (batch_size, sequence_length, hidden_size).\n",
        "            - attentions (tuple(torch.FloatTensor), optional, returned when output_attentions=True is passed or when config.output_attentions=True) – Tuple of torch.FloatTensor (one for each layer) of shape (batch_size, num_heads, sequence_length, sequence_length).\n",
        "        \"\"\"\n",
        "        outputs = self.model(input_ids = input_ids, attention_mask = attention_mask)\n",
        "\n",
        "        last_hidden_state = outputs[0]\n",
        "\n",
        "        sequence_outputs = self.dropouts(last_hidden_state)\n",
        "\n",
        "        logits = self.classifier(sequence_outputs[:, 0, : ].view(-1, 768 ))\n",
        "\n",
        "        loss = None\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_func = nn.CrossEntropyLoss()\n",
        "            loss = loss_func(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "            return logits\n",
        "\n"
      ],
      "metadata": {
        "id": "YP7a8xJOXg5B"
      },
      "id": "YP7a8xJOXg5B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers import BertForTokenClassification\n",
        "\n",
        "class CoNLLClassifier(BertForTokenClassification):\n",
        "    def __init__(self, config):\n",
        "        super(CoNLLClassifier, self).__init__(config)\n",
        "        # Assuming `config.hidden_size` is the size of the hidden layers in the BERT model\n",
        "        # Define an additional dense layer\n",
        "        self.additional_layer = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        # Define ReLU activation function\n",
        "        self.activation_fn = nn.ReLU()\n",
        "        # It's also common to include dropout for regularization\n",
        "        self.additional_dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        # Ensure the classifier layer is defined correctly following the added layer\n",
        "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None,\n",
        "                position_ids=None, head_mask=None, labels=None, label_masks=None):\n",
        "        outputs = self.bert(input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            token_type_ids=token_type_ids,\n",
        "                            position_ids=position_ids,\n",
        "                            head_mask=head_mask)\n",
        "\n",
        "        sequence_output = outputs[0]  # (b, MAX_LEN, 768)\n",
        "        token_reprs = [embedding[mask] for mask, embedding in zip(label_masks, sequence_output)]\n",
        "        token_reprs = pad_sequence(sequences=token_reprs, batch_first=True, padding_value=-1)  # (b, local_max_len, 768)\n",
        "\n",
        "        # Apply the additional layer and activation function\n",
        "        sequence_output = self.additional_layer(token_reprs)\n",
        "        sequence_output = self.activation_fn(sequence_output)\n",
        "        sequence_output = self.additional_dropout(sequence_output)\n",
        "\n",
        "        # Dropout and classifier layer remain unchanged\n",
        "        logits = self.classifier(sequence_output)  # (b, local_max_len, num_labels)\n",
        "        outputs = (logits,)\n",
        "        if labels is not None:\n",
        "            labels = [label[mask] for mask, label in zip(label_masks, labels)]\n",
        "            labels = pad_sequence(labels, batch_first=True, padding_value=-1)  # (b, local_max_len)\n",
        "            loss_fct = CrossEntropyLoss(ignore_index=-1, reduction='sum')\n",
        "            mask = labels != -1\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            loss /= mask.float().sum()\n",
        "            outputs = (loss,) + outputs + (labels, )\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "ViFwnJCPlcJF"
      },
      "id": "ViFwnJCPlcJF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b1ea60b"
      },
      "source": [
        "# Data preparing"
      ],
      "id": "0b1ea60b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351,
          "referenced_widgets": [
            "307e131a7dbd4c71a5101f30ddeb830b",
            "9b54ef4426b148648a43e65df62fa8ae",
            "629268c4bc2f448aa6a68db3e851649b",
            "3836250ecac643cd90c3358b753cee26",
            "39e354b8f898486998314da9e897be41",
            "0c333267d9ad48dd9e3f897c509d4a7f",
            "2048f491f7d44a128beb635198c93349",
            "ae089c7060354546b26519b76adff4d4",
            "df19fc9c62b344a7a108f81bce553cb2",
            "5036cf06da2c4072a6a2c9829f4b19e8",
            "a8739a0b8a3e40cc8a8787d4a13da012",
            "4b8489f554804d4b99865f3e9e440c7c",
            "9bf65fd56ad74da2bc77852625c898ce",
            "40efcd9f87c94b12a7daf38bd3455f5a",
            "c8904cf564514afb96abc4301fb73daa",
            "54d55c50888c4605843aa608201db62d",
            "010f3e3feca9465fa7a3e4433e9e52dd",
            "f8dd686a634142719284b67d0ae4db41",
            "bb1e0ceff6b744cf9373f6d2782a500d",
            "bbca5e2451e14bfab31612a36d31335d",
            "907525741dd9470a93539177ea6a422d",
            "dd77d7066eb6411fae0442e6738a114d",
            "ae91d751795a4fd2b4d056eba6533605",
            "f7ae5f51267e41e09b47e58918dde082",
            "d2f96090169849f28bf28865a77cfdb1",
            "a7c15eeb0e9b458d8087fb67437d560e",
            "32bd5c603deb4bb483874d67463e66f2",
            "77bc33ba7df44827a6240be12f14a875",
            "ca42d1a65565452cb18cc2466e4abb7b",
            "6d4105727def471fbb7bd93898778106",
            "ec49be2dc6d14acdb2c704c075f54870",
            "6c25ed2540cd402d9dbf21b892c8376c",
            "74fa0b81c7474c0c8cc6f6b160cee131",
            "e33c61c94dff419c8bffebb3b73a329e",
            "a04a6cf1b95845ceaa47ce387e00097f",
            "fb32aa5b834147c7b959b497fb97719a",
            "26ca55ecf44749cb849e1135af72d9c2",
            "fe8e32c17bdb487e94b210d7a0bd6fce",
            "572063b9bf274c18baf2cea616a9f491",
            "69f845e5b05c4b53a2ff174f7584b99a",
            "84c5f5b112f644a195f853eaf1c7e774",
            "b4cba8b1447b4f3aae0280a9aefa87eb",
            "2bb45c09bdc340878108b63e7667619e",
            "c478f797cd9c4477a8f111788cb6cf84",
            "29e162b6d47b42e799ac3a2f3625182d",
            "e9aaf2698d2b4399b3a834f826b373af",
            "b278e18a9f4546cbbd15f581125acef3",
            "1e609721cbc54731b509133f49ab9e35",
            "2264e3f14eae412591937905117840ee",
            "a6e6afe431fb4bd0971c8024f80a8f7a",
            "d727f0ce52e247c493a761e07b21b4dc",
            "e72108dbb6e947879bd1fbce5af644c0",
            "4376bf5d62c64b8c9ee288457d9f334a",
            "186431652c664778af10c479201d41ab",
            "33c27e4c9b4f47609ffd4349a200a134"
          ]
        },
        "id": "4905bf7d",
        "outputId": "3404fb27-666f-4861-bda3-ce9b8de13154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "307e131a7dbd4c71a5101f30ddeb830b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b8489f554804d4b99865f3e9e440c7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae91d751795a4fd2b4d056eba6533605"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e33c61c94dff419c8bffebb3b73a329e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN Dataset: (14987, 2)\n",
            "TEST Dataset: (3466, 2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29e162b6d47b42e799ac3a2f3625182d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 173\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 5e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenization (it is not needed in this case)\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "# Bert imput\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        tokens = self.data.tokens[index]\n",
        "        labels = self.data.labels[index]\n",
        "        tokenized_sentence, labels = tokens, labels\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# define training size 80/20 split\n",
        "\n",
        "\n",
        "train_dataset = train\n",
        "test_dataset = dev\n",
        "\n",
        "\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "# pyTorch dataloaders\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id,\n",
        "                                                   output_hidden_states=True)\n",
        "\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = len(id2label),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False)\n",
        "\n",
        "model.to(device)\n",
        "# Train the model\n",
        "\n",
        "\n",
        "ids = training_set[0][\"ids\"].unsqueeze(1)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(1)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(1)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n"
      ],
      "id": "4905bf7d"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install activations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye1pdd72u9ok",
        "outputId": "5ebdc1e8-8a60-46e7-b26a-cfa688a9fe1a"
      },
      "id": "ye1pdd72u9ok",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting activations\n",
            "  Downloading activations-0.1.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from activations) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->activations) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->activations) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->activations) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->activations) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->activations) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->activations) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->activations) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->activations) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->activations) (1.3.0)\n",
            "Installing collected packages: activations\n",
            "Successfully installed activations-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CluWWa6dm0t7",
        "outputId": "1ad44fec-4fe6-4511-9fc7-05bdc19b01fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN Dataset: (14987, 2)\n",
            "TEST Dataset: (3466, 2)\n"
          ]
        }
      ],
      "source": [
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))"
      ],
      "id": "CluWWa6dm0t7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6mIoRWEm7qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73aca9d-045d-42b6-af0f-80cc4e6cf97c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([173, 1])\n",
            "torch.Size([173, 1])\n",
            "torch.Size([173, 1])\n"
          ]
        }
      ],
      "source": [
        "print(ids.shape)\n",
        "print(mask.shape)\n",
        "print(targets.shape)"
      ],
      "id": "Z6mIoRWEm7qa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCvEZTGEmiBL",
        "outputId": "74f9d47f-1db3-4841-a188-53a24d330010"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.5892, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss"
      ],
      "id": "sCvEZTGEmiBL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMmW-ZhWnJ7M",
        "outputId": "05966270-8227-4b45-89c5-02f3bf47530e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 173, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "tr_logits = outputs[1]\n",
        "tr_logits.shape"
      ],
      "id": "pMmW-ZhWnJ7M"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d7c632e"
      },
      "source": [
        "# Training set"
      ],
      "id": "7d7c632e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9efa25b"
      },
      "outputs": [],
      "source": [
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "    print(f\"Training steps: {nb_tr_steps}\")\n",
        "\n",
        "    tr_loss = []\n"
      ],
      "id": "f9efa25b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d46c2d4",
        "outputId": "cd31ba71-f2fb-4ba4-bcbe-5fb286fc6818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training loss per 100 training steps: 2.4579179286956787\n",
            "Training loss per 100 training steps: 0.10002840675487376\n",
            "Training loss per 100 training steps: 0.07105343869947527\n",
            "Training loss per 100 training steps: 0.059391982497591714\n",
            "Training loss per 100 training steps: 0.05136037542614761\n",
            "Training loss per 100 training steps: 0.046543968673200604\n",
            "Training loss per 100 training steps: 0.043137705006238425\n",
            "Training loss per 100 training steps: 0.04020655651914936\n",
            "Training loss per 100 training steps: 0.03798564405255508\n",
            "Training loss per 100 training steps: 0.036379697325367576\n",
            "Training loss per 100 training steps: 0.035105001386399236\n",
            "Training loss per 100 training steps: 0.03361987866353215\n",
            "Training loss per 100 training steps: 0.03240862152683428\n",
            "Training loss per 100 training steps: 0.0313416259349603\n",
            "Training loss per 100 training steps: 0.030689103183641347\n",
            "Training loss per 100 training steps: 0.02985696064688012\n",
            "Training loss per 100 training steps: 0.029396416933108807\n",
            "Training loss per 100 training steps: 0.028640036760104754\n",
            "Training loss per 100 training steps: 0.028092319615532244\n",
            "Training loss per 100 training steps: 0.027573858335715126\n",
            "Training loss per 100 training steps: 0.027204885897608284\n",
            "Training loss per 100 training steps: 0.026755747846136005\n",
            "Training loss per 100 training steps: 0.026381620607680106\n",
            "Training loss per 100 training steps: 0.02608802266690519\n",
            "Training loss per 100 training steps: 0.025845070825505696\n",
            "Training loss per 100 training steps: 0.02565562281432133\n",
            "Training loss per 100 training steps: 0.02536088658107523\n",
            "Training loss per 100 training steps: 0.025137799799448152\n",
            "Training loss per 100 training steps: 0.02492722853591286\n",
            "Training loss per 100 training steps: 0.024655931785755113\n",
            "Training loss per 100 training steps: 0.024470150595983883\n",
            "Training loss per 100 training steps: 0.024209407940282816\n",
            "Training loss per 100 training steps: 0.02400050117311358\n",
            "Training loss per 100 training steps: 0.02386657740034248\n",
            "Training loss per 100 training steps: 0.02363029820707612\n",
            "Training loss per 100 training steps: 0.023460492976528243\n",
            "Training loss per 100 training steps: 0.023292456517415717\n",
            "Training loss per 100 training steps: 0.023115916525696823\n",
            "Training loss epoch: 0.023041035126009746\n",
            "Training accuracy epoch: 0.9237594449821898\n",
            "Training steps: 3747\n",
            "CPU times: user 3min 38s, sys: 1.32 s, total: 3min 40s\n",
            "Wall time: 3min 52s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ],
      "id": "7d46c2d4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9e097d3"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "            # compute the cohen kappa score\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "    print(f\"Validation steps: {nb_eval_steps}\")\n",
        "\n",
        "    return labels, predictions"
      ],
      "id": "b9e097d3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a520c16",
        "outputId": "301fd687-88c1-432d-ba84-18f80600ebd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss per 100 evaluation steps: 0.022053580731153488\n",
            "Validation loss per 100 evaluation steps: 0.017657223807594227\n",
            "Validation loss per 100 evaluation steps: 0.01684901797060191\n",
            "Validation loss per 100 evaluation steps: 0.017462209322654364\n",
            "Validation loss per 100 evaluation steps: 0.017983776635641754\n",
            "Validation loss per 100 evaluation steps: 0.0181743887582281\n",
            "Validation loss per 100 evaluation steps: 0.017921910232597687\n",
            "Validation loss per 100 evaluation steps: 0.017748743202701294\n",
            "Validation loss per 100 evaluation steps: 0.017825204064437994\n",
            "Validation loss per 100 evaluation steps: 0.01793540854285737\n",
            "Validation loss per 100 evaluation steps: 0.01790176626689192\n",
            "Validation loss per 100 evaluation steps: 0.01778188542069336\n",
            "Validation loss per 100 evaluation steps: 0.018083857660303276\n",
            "Validation loss per 100 evaluation steps: 0.018173147083980355\n",
            "Validation loss per 100 evaluation steps: 0.018145490790762425\n",
            "Validation loss per 100 evaluation steps: 0.01817946356406451\n",
            "Validation loss per 100 evaluation steps: 0.01815671887199527\n",
            "Validation loss per 100 evaluation steps: 0.01819201402353346\n",
            "Validation Loss: 0.018197638855621864\n",
            "Validation Accuracy: 0.9363071053052411\n",
            "Validation steps: 1733\n",
            "CPU times: user 21.7 s, sys: 79.9 ms, total: 21.8 s\n",
            "Wall time: 21.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "labels, predictions = valid(model, testing_loader)"
      ],
      "id": "3a520c16"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAgJ_udTaWRN",
        "outputId": "b441ccb4-f2a5-4c67-da3f-ae646b657eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m832.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.3.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=70c10885d4d48f6bcb702dfd779510c4508e6819234247b9ca2fc85e1712294d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval"
      ],
      "id": "LAgJ_udTaWRN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92b96e45",
        "outputId": "dfd36c80-3084-473e-8546-3379bcfcadab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.75      0.70      0.72      1837\n",
            "      B-MISC       0.59      0.37      0.46       922\n",
            "       B-ORG       0.65      0.73      0.69      1341\n",
            "       B-PER       0.84      0.78      0.81      1842\n",
            "       I-LOC       0.55      0.56      0.56       257\n",
            "      I-MISC       0.66      0.43      0.52       346\n",
            "       I-ORG       0.62      0.69      0.65       751\n",
            "       I-PER       0.86      0.85      0.86      1307\n",
            "           O       0.97      0.98      0.98     49907\n",
            "\n",
            "    accuracy                           0.94     58510\n",
            "   macro avg       0.72      0.68      0.69     58510\n",
            "weighted avg       0.94      0.94      0.94     58510\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(labels, predictions))"
      ],
      "id": "92b96e45"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d36b14b1",
        "outputId": "ff222d57-765c-4744-f1fe-be720de59d74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9401640745171765, 0.9401640745171765, 0.9401640745171765, None)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision_recall_fscore_support(labels, predictions, average = \"micro\")"
      ],
      "id": "d36b14b1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "282c7b9e",
        "outputId": "73c5ef7b-ba3d-4638-902d-08d24a511362"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7219840822429133, 0.6764159641276228, 0.6931664964853202, None)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"macro\")"
      ],
      "id": "282c7b9e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4d7879f",
        "outputId": "2439145e-6dc6-4e5f-a700-bfcf2b493ed2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9378319115964262, 0.9401640745171765, 0.938309440579291, None)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"weighted\")"
      ],
      "id": "e4d7879f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a28eb627"
      },
      "outputs": [],
      "source": [
        "# L1 loss function"
      ],
      "id": "a28eb627"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "558c12e8",
        "outputId": "1f5f0ee7-729d-4dfa-c663-8bc7d02588c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: 14987 sentences, 204567 tokens\n",
            "Dev data: 3466 sentences, 51578 tokens\n",
            "Test data: 3684 sentences, 46666 tokens\n",
            "\n",
            "NER tags: ['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Train data: 14987 sentences, 204567 tokens\n",
        "Dev data: 3466 sentences, 51578 tokens\n",
        "Test data: 3684 sentences, 46666 tokens\n",
        "\"\"\"\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "sys.path.append(\"../\")\n",
        "\n",
        "def flatten(l):\n",
        "    return [item for sublist in l for item in sublist]\n",
        "\n",
        "def read_CoNLL2003_format(filename, idx=3):\n",
        "    \"\"\"Read file in CoNLL-2003 shared task format\"\"\"\n",
        "\n",
        "    lines =  open(filename).read().strip()\n",
        "\n",
        "    # find sentence-like boundaries\n",
        "    lines = lines.split(\"\\n\\n\")\n",
        "\n",
        "    # throw out -DOCSTART- lines\n",
        "    #lines = [line for line in lines if not line.startswith(\"-DOCSTART-\")]\n",
        "\n",
        "     # split on newlines\n",
        "    lines = [line.split(\"\\n\") for line in lines]\n",
        "\n",
        "    # get tokens\n",
        "    tokens = [[l.split()[0] for l in line] for line in lines]\n",
        "\n",
        "    # get labels/tags\n",
        "    labels = [[l.split()[idx] for l in line] for line in lines]\n",
        "\n",
        "    data= {'tokens': tokens, 'labels': labels}\n",
        "    df=pd.DataFrame(data=data)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "DATADIR = \"./ner_english/\"\n",
        "\n",
        "def get_conll2003_data(trainfile=DATADIR + \"train.txt\",\n",
        "                  devfile=DATADIR + \"dev.txt\",\n",
        "                  testfile=DATADIR + \"test.txt\"):\n",
        "\n",
        "    train = read_CoNLL2003_format(trainfile)\n",
        "    print(\"Train data: %d sentences, %d tokens\"%(len(train),len(flatten(train.tokens))))\n",
        "\n",
        "    dev = read_CoNLL2003_format(devfile)\n",
        "    print(\"Dev data: %d sentences, %d tokens\"%(len(dev),len(flatten(dev.tokens))))\n",
        "\n",
        "    test = read_CoNLL2003_format(testfile)\n",
        "    print(\"Test data: %d sentences, %d tokens\"%(len(test),len(flatten(test.tokens))))\n",
        "\n",
        "    return train, dev, test\n",
        "\n",
        "train, dev, test = get_conll2003_data()\n",
        "\n",
        "X_train, y_train = train.tokens, train.labels\n",
        "X_dev, y_dev = dev.tokens, dev.labels\n",
        "X_test, y_test = test.tokens, test.labels\n",
        "\n",
        "\n",
        "label_list = np.unique(flatten(y_train))\n",
        "label_list = list(label_list)\n",
        "print(\"\\nNER tags:\",label_list)"
      ],
      "id": "558c12e8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d582914",
        "outputId": "6ac6e67a-e05a-448b-e4bf-b140fb7829bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN Dataset: (14987, 2)\n",
            "TEST Dataset: (3684, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 5e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenization (it is not needed in this case)\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "# Bert imput\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        tokens = self.data.tokens[index]\n",
        "        labels = self.data.labels[index]\n",
        "        tokenized_sentence, labels = tokens, labels\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# define training size 80/20 split\n",
        "\n",
        "\n",
        "train_dataset = train\n",
        "test_dataset = test\n",
        "\n",
        "\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "# pyTorch dataloaders\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id,\n",
        "                                                   output_hidden_states=True)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = len(id2label),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False)\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
      ],
      "id": "7d582914"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66fefe2b"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(targets, num_classes):\n",
        "    \"\"\"\n",
        "    One-hot encode a tensor of class indices.\n",
        "\n",
        "    Arguments:\n",
        "    - targets (torch.Tensor): A tensor of class indices, shape [N].\n",
        "    - num_classes (int): The number of classes.\n",
        "\n",
        "    Returns:\n",
        "    - torch.Tensor: The one-hot encoded tensor, shape [N, num_classes].\n",
        "    \"\"\"\n",
        "    return F.one_hot(targets, num_classes=num_classes).float()"
      ],
      "id": "66fefe2b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4db7e09f"
      },
      "outputs": [],
      "source": [
        "l1_loss_fn = nn.L1Loss()\n",
        "\n",
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "\n",
        "        # implement l1 loss function\n",
        "        flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        flatten_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "\n",
        "        targets_one_hot = one_hot_encode(flatten_targets, num_classes= flatten_logits.size(-1))\n",
        "        loss = l1_loss_fn(flatten_logits, targets_one_hot)\n",
        "\n",
        "\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training l1 loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "    print(f\"Training steps: {nb_tr_steps}\")"
      ],
      "id": "4db7e09f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9792cf7",
        "outputId": "126de0e8-bd84-4b2f-dcd0-49ab3d7f6838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training l1 loss per 100 training steps: 0.3400125503540039\n",
            "Training l1 loss per 100 training steps: 0.055244903292248744\n",
            "Training l1 loss per 100 training steps: 0.04365289834008288\n",
            "Training l1 loss per 100 training steps: 0.03844434545805486\n",
            "Training l1 loss per 100 training steps: 0.03531135969384204\n",
            "Training l1 loss per 100 training steps: 0.033025478126254386\n",
            "Training l1 loss per 100 training steps: 0.03109907973154809\n",
            "Training l1 loss per 100 training steps: 0.029583324664956577\n",
            "Training l1 loss per 100 training steps: 0.028233844932219882\n",
            "Training l1 loss per 100 training steps: 0.02707116606104685\n",
            "Training l1 loss per 100 training steps: 0.026012961338688207\n",
            "Training l1 loss per 100 training steps: 0.025061648673158847\n",
            "Training l1 loss per 100 training steps: 0.024196867319250435\n",
            "Training l1 loss per 100 training steps: 0.023406282762390526\n",
            "Training l1 loss per 100 training steps: 0.022697870099091428\n",
            "Training l1 loss per 100 training steps: 0.02206132522747566\n",
            "Training l1 loss per 100 training steps: 0.02146789653611827\n",
            "Training l1 loss per 100 training steps: 0.020891505819709773\n",
            "Training l1 loss per 100 training steps: 0.02039082317888687\n",
            "Training l1 loss per 100 training steps: 0.019922864406826713\n",
            "Training l1 loss per 100 training steps: 0.019465818726594957\n",
            "Training l1 loss per 100 training steps: 0.019049614756547626\n",
            "Training l1 loss per 100 training steps: 0.018646666886744472\n",
            "Training l1 loss per 100 training steps: 0.01827206850045404\n",
            "Training l1 loss per 100 training steps: 0.017923863907606464\n",
            "Training l1 loss per 100 training steps: 0.017588690812902444\n",
            "Training l1 loss per 100 training steps: 0.017282974788283886\n",
            "Training l1 loss per 100 training steps: 0.016994135966852047\n",
            "Training l1 loss per 100 training steps: 0.01672593265574363\n",
            "Training l1 loss per 100 training steps: 0.01646810393845961\n",
            "Training l1 loss per 100 training steps: 0.016219168700500008\n",
            "Training l1 loss per 100 training steps: 0.0159940478699483\n",
            "Training l1 loss per 100 training steps: 0.015769961531984223\n",
            "Training l1 loss per 100 training steps: 0.015548511367783253\n",
            "Training l1 loss per 100 training steps: 0.0153482321379238\n",
            "Training l1 loss per 100 training steps: 0.0151548305414915\n",
            "Training l1 loss per 100 training steps: 0.014958968497005827\n",
            "Training l1 loss per 100 training steps: 0.014768256854655468\n",
            "Training loss epoch: 0.014688739051019825\n",
            "Training accuracy epoch: 0.8532808799857473\n",
            "Training steps: 3747\n",
            "CPU times: user 3min 16s, sys: 816 ms, total: 3min 17s\n",
            "Wall time: 3min 29s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ],
      "id": "f9792cf7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e363015"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "\n",
        "            # implement l1 loss\n",
        "            flatten_targets = targets.view(-1)\n",
        "            flatten_logits = eval_logits.view(-1, model.num_labels)\n",
        "            targets_one_hot = one_hot_encode(flatten_targets, num_classes= flatten_logits.size(-1))\n",
        "            loss = l1_loss_fn(flatten_logits, targets_one_hot)\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation l1 loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "    print(f\"Validation steps: {nb_eval_steps}\")\n",
        "\n",
        "    return labels, predictions"
      ],
      "id": "0e363015"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f817764b",
        "outputId": "aecfdcdb-3a4f-45bd-f0f5-f2a17db314c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation l1 loss per 100 evaluation steps: 0.0048906696029007435\n",
            "Validation l1 loss per 100 evaluation steps: 0.0055676527173802405\n",
            "Validation l1 loss per 100 evaluation steps: 0.00527084444820955\n",
            "Validation l1 loss per 100 evaluation steps: 0.005433568789738159\n",
            "Validation l1 loss per 100 evaluation steps: 0.005476555027569321\n",
            "Validation l1 loss per 100 evaluation steps: 0.005434722074041675\n",
            "Validation l1 loss per 100 evaluation steps: 0.005386427089032685\n",
            "Validation l1 loss per 100 evaluation steps: 0.005399581895856859\n",
            "Validation l1 loss per 100 evaluation steps: 0.005367764547064937\n",
            "Validation l1 loss per 100 evaluation steps: 0.0053526789294173335\n",
            "Validation l1 loss per 100 evaluation steps: 0.005368904595576845\n",
            "Validation l1 loss per 100 evaluation steps: 0.005362114280108684\n",
            "Validation l1 loss per 100 evaluation steps: 0.005366984407396539\n",
            "Validation l1 loss per 100 evaluation steps: 0.005366057734134722\n",
            "Validation l1 loss per 100 evaluation steps: 0.005357419126344676\n",
            "Validation l1 loss per 100 evaluation steps: 0.005352318469158248\n",
            "Validation l1 loss per 100 evaluation steps: 0.005372584000640525\n",
            "Validation l1 loss per 100 evaluation steps: 0.005365057962003226\n",
            "Validation l1 loss per 100 evaluation steps: 0.005355750725758177\n",
            "Validation Loss: 0.005348476228363868\n",
            "Validation Accuracy: 0.8910488452022295\n",
            "Validation steps: 1842\n",
            "CPU times: user 24.2 s, sys: 71.1 ms, total: 24.3 s\n",
            "Wall time: 24.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "labels, predictions = valid(model, testing_loader)"
      ],
      "id": "f817764b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "889fd862",
        "outputId": "103fc71b-5cc0-404e-da64-4ed718a24394",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.61      0.38      0.47      1668\n",
            "      B-MISC       0.33      0.03      0.05       702\n",
            "       B-ORG       0.50      0.40      0.45      1661\n",
            "       B-PER       0.55      0.45      0.49      1617\n",
            "       I-LOC       0.00      0.00      0.00       257\n",
            "      I-MISC       0.00      0.00      0.00       216\n",
            "       I-ORG       0.00      0.00      0.00       835\n",
            "       I-PER       0.61      0.54      0.57      1156\n",
            "           O       0.92      0.99      0.95     45922\n",
            "\n",
            "    accuracy                           0.89     54034\n",
            "   macro avg       0.39      0.31      0.33     54034\n",
            "weighted avg       0.85      0.89      0.87     54034\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(labels, predictions))"
      ],
      "id": "889fd862"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd307163"
      },
      "source": [],
      "id": "bd307163"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb278f56",
        "outputId": "538a3927-4cef-4884-cb9c-343d780c37ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8901432431432061, 0.8901432431432061, 0.8901432431432061, None)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision_recall_fscore_support(labels, predictions, average = \"micro\", zero_division = 1)"
      ],
      "id": "eb278f56"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN5mqyLr32T8",
        "outputId": "3eb14819-1d06-4fb4-8029-84e025f37d5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6128010074298055, 0.30990451577317385, 0.3317289836825475, None)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"macro\", zero_division = 1)"
      ],
      "id": "PN5mqyLr32T8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn8BI3nC32ax",
        "outputId": "0c337e10-a683-40bc-8182-5efb6b3329ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8605589018231765, 0.8901432431432061, 0.8671435576149141, None)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"weighted\", zero_division = 1)"
      ],
      "id": "Qn8BI3nC32ax"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09AfTDPY32lO"
      },
      "outputs": [],
      "source": [],
      "id": "09AfTDPY32lO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMiTIDvs3-Hu"
      },
      "outputs": [],
      "source": [
        "# L2 function"
      ],
      "id": "gMiTIDvs3-Hu"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Train data: 14987 sentences, 204567 tokens\n",
        "Dev data: 3466 sentences, 51578 tokens\n",
        "Test data: 3684 sentences, 46666 tokens\n",
        "\"\"\"\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "sys.path.append(\"../\")\n",
        "\n",
        "\n",
        "def flatten(l):\n",
        "    return [item for sublist in l for item in sublist]\n",
        "\n",
        "def read_CoNLL2003_format(filename, idx=3):\n",
        "    \"\"\"Read file in CoNLL-2003 shared task format\"\"\"\n",
        "\n",
        "    lines =  open(filename).read().strip()\n",
        "\n",
        "    # find sentence-like boundaries\n",
        "    lines = lines.split(\"\\n\\n\")\n",
        "\n",
        "    # throw out -DOCSTART- lines\n",
        "    #lines = [line for line in lines if not line.startswith(\"-DOCSTART-\")]\n",
        "\n",
        "     # split on newlines\n",
        "    lines = [line.split(\"\\n\") for line in lines]\n",
        "\n",
        "    # get tokens\n",
        "    tokens = [[l.split()[0] for l in line] for line in lines]\n",
        "\n",
        "    # get labels/tags\n",
        "    labels = [[l.split()[idx] for l in line] for line in lines]\n",
        "\n",
        "    data= {'tokens': tokens, 'labels': labels}\n",
        "    df=pd.DataFrame(data=data)\n",
        "\n",
        "    return df\n",
        "\n",
        "DATADIR = \"./ner_english/\"\n",
        "\n",
        "def get_conll2003_data(trainfile=DATADIR + \"train.txt\",\n",
        "                  devfile=DATADIR + \"dev.txt\",\n",
        "                  testfile=DATADIR + \"test.txt\"):\n",
        "\n",
        "    train = read_CoNLL2003_format(trainfile)\n",
        "    print(\"Train data: %d sentences, %d tokens\"%(len(train),len(flatten(train.tokens))))\n",
        "\n",
        "    dev = read_CoNLL2003_format(devfile)\n",
        "    print(\"Dev data: %d sentences, %d tokens\"%(len(dev),len(flatten(dev.tokens))))\n",
        "\n",
        "    test = read_CoNLL2003_format(testfile)\n",
        "    print(\"Test data: %d sentences, %d tokens\"%(len(test),len(flatten(test.tokens))))\n",
        "\n",
        "    return train, dev, test\n",
        "\n",
        "train, dev, test = get_conll2003_data()\n",
        "\n",
        "X_train, y_train = train.tokens, train.labels\n",
        "X_dev, y_dev = dev.tokens, dev.labels\n",
        "X_test, y_test = test.tokens, test.labels\n",
        "\n",
        "\n",
        "label_list = np.unique(flatten(y_train))\n",
        "label_list = list(label_list)\n",
        "print(\"\\nNER tags:\",label_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0GGMutFrw3t",
        "outputId": "75ff9c5b-2ddb-4611-c5ec-ccf8e4913586"
      },
      "id": "R0GGMutFrw3t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: 14987 sentences, 204567 tokens\n",
            "Dev data: 3466 sentences, 51578 tokens\n",
            "Test data: 3684 sentences, 46666 tokens\n",
            "\n",
            "NER tags: ['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCLrNk7j3-Kc",
        "outputId": "32f9c3c1-6219-4cca-a01c-250a5f96094a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN Dataset: (14987, 2)\n",
            "TEST Dataset: (3684, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 5e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenization (it is not needed in this case)\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "# Bert imput\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        tokens = self.data.tokens[index]\n",
        "        labels = self.data.labels[index]\n",
        "        tokenized_sentence, labels = tokens, labels\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# define training size 80/20 split\n",
        "\n",
        "\n",
        "train_dataset = train\n",
        "test_dataset = test\n",
        "\n",
        "\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "# pyTorch dataloaders\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id,\n",
        "                                                   output_hidden_states=True)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = len(id2label),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
        "\n"
      ],
      "id": "nCLrNk7j3-Kc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoYhvE6F3-My"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(targets, num_classes):\n",
        "    \"\"\"\n",
        "    One-hot encode a tensor of class indices.\n",
        "\n",
        "    Arguments:\n",
        "    - targets (torch.Tensor): A tensor of class indices, shape [N].\n",
        "    - num_classes (int): The number of classes.\n",
        "\n",
        "    Returns:\n",
        "    - torch.Tensor: The one-hot encoded tensor, shape [N, num_classes].\n",
        "    \"\"\"\n",
        "    return F.one_hot(targets, num_classes=num_classes).float()"
      ],
      "id": "IoYhvE6F3-My"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT0Uw-Ip3-O7"
      },
      "outputs": [],
      "source": [
        "l2_loss_fn = nn.MSELoss()\n",
        "\n",
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "\n",
        "        # implement l2 loss function\n",
        "        flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        flatten_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "\n",
        "        targets_one_hot = one_hot_encode(flatten_targets, num_classes= flatten_logits.size(-1))\n",
        "        loss = l2_loss_fn(flatten_logits, targets_one_hot)\n",
        "\n",
        "\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training l1 loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "    print(f\"Training steps: {nb_tr_steps}\")"
      ],
      "id": "sT0Uw-Ip3-O7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpgyQoEv3-Qn",
        "outputId": "37538b5a-4a17-4bbf-b989-806cd6b0138b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training l1 loss per 100 training steps: 0.22480149567127228\n",
            "Training l1 loss per 100 training steps: 0.012046752177123534\n",
            "Training l1 loss per 100 training steps: 0.008279891093887055\n",
            "Training l1 loss per 100 training steps: 0.006842876340887599\n",
            "Training l1 loss per 100 training steps: 0.006024195501137237\n",
            "Training l1 loss per 100 training steps: 0.005438634885025179\n",
            "Training l1 loss per 100 training steps: 0.005049751479544378\n",
            "Training l1 loss per 100 training steps: 0.004707832827356335\n",
            "Training l1 loss per 100 training steps: 0.004426759258714899\n",
            "Training l1 loss per 100 training steps: 0.004183447655493478\n",
            "Training l1 loss per 100 training steps: 0.004002425583664674\n",
            "Training l1 loss per 100 training steps: 0.0038261556386529763\n",
            "Training l1 loss per 100 training steps: 0.003681079719388558\n",
            "Training l1 loss per 100 training steps: 0.003559566707950555\n",
            "Training l1 loss per 100 training steps: 0.003447711059125971\n",
            "Training l1 loss per 100 training steps: 0.003336768671878763\n",
            "Training l1 loss per 100 training steps: 0.0032470534415239365\n",
            "Training l1 loss per 100 training steps: 0.0031671661953640274\n",
            "Training l1 loss per 100 training steps: 0.0030939485472948887\n",
            "Training l1 loss per 100 training steps: 0.003021187552461339\n",
            "Training l1 loss per 100 training steps: 0.0029602593769858555\n",
            "Training l1 loss per 100 training steps: 0.0029062497918843125\n",
            "Training l1 loss per 100 training steps: 0.00284797016278987\n",
            "Training l1 loss per 100 training steps: 0.002789729091155463\n",
            "Training l1 loss per 100 training steps: 0.002742462712566972\n",
            "Training l1 loss per 100 training steps: 0.002695612315380736\n",
            "Training l1 loss per 100 training steps: 0.0026578607154884425\n",
            "Training l1 loss per 100 training steps: 0.0026192931727335453\n",
            "Training l1 loss per 100 training steps: 0.0025814751929622887\n",
            "Training l1 loss per 100 training steps: 0.0025483361289795775\n",
            "Training l1 loss per 100 training steps: 0.002517377523956659\n",
            "Training l1 loss per 100 training steps: 0.0024881234425147085\n",
            "Training l1 loss per 100 training steps: 0.0024544165869267737\n",
            "Training l1 loss per 100 training steps: 0.0024240496988407983\n",
            "Training l1 loss per 100 training steps: 0.002399375609716308\n",
            "Training l1 loss per 100 training steps: 0.002377870626875562\n",
            "Training l1 loss per 100 training steps: 0.0023605251342004646\n",
            "Training l1 loss per 100 training steps: 0.002332897995666494\n",
            "Training loss epoch: 0.00232242194249584\n",
            "Training accuracy epoch: 0.9119882352764306\n",
            "Training steps: 3747\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ],
      "id": "OpgyQoEv3-Qn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e6G4gEQ3-Sl"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "\n",
        "            # implement l2 loss\n",
        "            flatten_targets = targets.view(-1)\n",
        "            flatten_logits = eval_logits.view(-1, model.num_labels)\n",
        "            targets_one_hot = one_hot_encode(flatten_targets, num_classes= flatten_logits.size(-1))\n",
        "            loss = l2_loss_fn(flatten_logits, targets_one_hot)\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation l1 loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "    print(f\"Validation steps: {nb_eval_steps}\")\n",
        "\n",
        "    return labels, predictions"
      ],
      "id": "0e6G4gEQ3-Sl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDAasu8u3-VP",
        "outputId": "2ce22929-4de5-49d8-d9cb-dc44fa25b17f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation l1 loss per 100 evaluation steps: 0.0018311975290998816\n",
            "Validation l1 loss per 100 evaluation steps: 0.0012351325423500528\n",
            "Validation l1 loss per 100 evaluation steps: 0.00132480836874488\n",
            "Validation l1 loss per 100 evaluation steps: 0.0013538042142218756\n",
            "Validation l1 loss per 100 evaluation steps: 0.001457899386388223\n",
            "Validation l1 loss per 100 evaluation steps: 0.001477457344935284\n",
            "Validation l1 loss per 100 evaluation steps: 0.0014696420825106098\n",
            "Validation l1 loss per 100 evaluation steps: 0.0015116342482764536\n",
            "Validation l1 loss per 100 evaluation steps: 0.0014852633689764624\n",
            "Validation l1 loss per 100 evaluation steps: 0.0014870512753417668\n",
            "Validation l1 loss per 100 evaluation steps: 0.001487928490623072\n",
            "Validation l1 loss per 100 evaluation steps: 0.001492886331933064\n",
            "Validation l1 loss per 100 evaluation steps: 0.001474271961981456\n",
            "Validation l1 loss per 100 evaluation steps: 0.001487956603923773\n",
            "Validation l1 loss per 100 evaluation steps: 0.0014790275137802368\n",
            "Validation l1 loss per 100 evaluation steps: 0.001477673287085536\n",
            "Validation l1 loss per 100 evaluation steps: 0.0014836573992976334\n",
            "Validation l1 loss per 100 evaluation steps: 0.00147269651674226\n",
            "Validation l1 loss per 100 evaluation steps: 0.001471352661970137\n",
            "Validation Loss: 0.0014688629892902272\n",
            "Validation Accuracy: 0.9228020085593999\n",
            "Validation steps: 1842\n"
          ]
        }
      ],
      "source": [
        "labels, predictions = valid(model, testing_loader)"
      ],
      "id": "oDAasu8u3-VP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYJco3BT3-XH",
        "outputId": "a50c2771-7914-4406-e4fd-559942421b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.69      0.59      0.64      1668\n",
            "      B-MISC       0.53      0.32      0.40       702\n",
            "       B-ORG       0.73      0.55      0.63      1661\n",
            "       B-PER       0.72      0.80      0.76      1617\n",
            "       I-LOC       0.45      0.33      0.38       257\n",
            "      I-MISC       0.72      0.17      0.27       216\n",
            "       I-ORG       0.58      0.66      0.62       835\n",
            "       I-PER       0.80      0.87      0.83      1156\n",
            "           O       0.96      0.98      0.97     45922\n",
            "\n",
            "    accuracy                           0.93     54034\n",
            "   macro avg       0.69      0.59      0.61     54034\n",
            "weighted avg       0.92      0.93      0.92     54034\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(labels, predictions))"
      ],
      "id": "tYJco3BT3-XH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oRiPPPW3-ZB",
        "outputId": "629d2343-916a-4142-c3ac-b9835dbc55cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9271569752378133, 0.9271569752378133, 0.9271569752378133, None)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision_recall_fscore_support(labels, predictions, average = \"micro\", zero_division = 1)"
      ],
      "id": "7oRiPPPW3-ZB"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ai7hCU2mNZIp"
      },
      "id": "Ai7hCU2mNZIp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVeVq3xP3-bU",
        "outputId": "9a3d4fc4-ae2e-46f5-d0af-8efc59c8dc30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6878612320992653, 0.5856072608850558, 0.611148031589909, None)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"macro\", zero_division = 1)"
      ],
      "id": "mVeVq3xP3-bU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ocyr42rC4RrA",
        "outputId": "2f219d1b-6ccc-4722-b916-c96b0fc9135f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9224661302709939, 0.9271569752378133, 0.9230027370235004, None)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"weighted\", zero_division = 1)"
      ],
      "id": "Ocyr42rC4RrA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EfHPSFO4Rtg"
      },
      "outputs": [],
      "source": [],
      "id": "9EfHPSFO4Rtg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXah7sH14R1S"
      },
      "outputs": [],
      "source": [],
      "id": "VXah7sH14R1S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5659cba"
      },
      "outputs": [],
      "source": [
        "#Dlite loss function"
      ],
      "id": "b5659cba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "744f1bdb",
        "outputId": "9fc613a4-678b-4084-8980-387bf58c7e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: 14987 sentences, 204567 tokens\n",
            "Dev data: 3466 sentences, 51578 tokens\n",
            "Test data: 3684 sentences, 46666 tokens\n",
            "\n",
            "NER tags: ['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Train data: 14987 sentences, 204567 tokens\n",
        "Dev data: 3466 sentences, 51578 tokens\n",
        "Test data: 3684 sentences, 46666 tokens\n",
        "\"\"\"\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "sys.path.append(\"../\")\n",
        "\n",
        "def flatten(l):\n",
        "    return [item for sublist in l for item in sublist]\n",
        "\n",
        "def read_CoNLL2003_format(filename, idx=3):\n",
        "    \"\"\"Read file in CoNLL-2003 shared task format\"\"\"\n",
        "\n",
        "    lines =  open(filename).read().strip()\n",
        "\n",
        "    # find sentence-like boundaries\n",
        "    lines = lines.split(\"\\n\\n\")\n",
        "\n",
        "    # throw out -DOCSTART- lines\n",
        "    #lines = [line for line in lines if not line.startswith(\"-DOCSTART-\")]\n",
        "\n",
        "     # split on newlines\n",
        "    lines = [line.split(\"\\n\") for line in lines]\n",
        "\n",
        "    # get tokens\n",
        "    tokens = [[l.split()[0] for l in line] for line in lines]\n",
        "\n",
        "    # get labels/tags\n",
        "    labels = [[l.split()[idx] for l in line] for line in lines]\n",
        "\n",
        "    data= {'tokens': tokens, 'labels': labels}\n",
        "    df=pd.DataFrame(data=data)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "DATADIR = \"./ner_english/\"\n",
        "\n",
        "def get_conll2003_data(trainfile=DATADIR + \"train.txt\",\n",
        "                  devfile=DATADIR + \"dev.txt\",\n",
        "                  testfile=DATADIR + \"test.txt\"):\n",
        "\n",
        "    train = read_CoNLL2003_format(trainfile)\n",
        "    print(\"Train data: %d sentences, %d tokens\"%(len(train),len(flatten(train.tokens))))\n",
        "\n",
        "    dev = read_CoNLL2003_format(devfile)\n",
        "    print(\"Dev data: %d sentences, %d tokens\"%(len(dev),len(flatten(dev.tokens))))\n",
        "\n",
        "    test = read_CoNLL2003_format(testfile)\n",
        "    print(\"Test data: %d sentences, %d tokens\"%(len(test),len(flatten(test.tokens))))\n",
        "\n",
        "    return train, dev, test\n",
        "\n",
        "train, dev, test = get_conll2003_data()\n",
        "\n",
        "X_train, y_train = train.tokens, train.labels\n",
        "X_dev, y_dev = dev.tokens, dev.labels\n",
        "X_test, y_test = test.tokens, test.labels\n",
        "\n",
        "\n",
        "label_list = np.unique(flatten(y_train))\n",
        "label_list = list(label_list)\n",
        "print(\"\\nNER tags:\",label_list)"
      ],
      "id": "744f1bdb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be6377da",
        "outputId": "9e666dd6-aaf1-499d-aa89-523b9bdb8fbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN Dataset: (14987, 2)\n",
            "TEST Dataset: (3684, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 5e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenization (it is not needed in this case)\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "# Bert imput\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        tokens = self.data.tokens[index]\n",
        "        labels = self.data.labels[index]\n",
        "        tokenized_sentence, labels = tokens, labels\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# define training size 80/20 split\n",
        "\n",
        "\n",
        "train_dataset = train\n",
        "test_dataset = test\n",
        "\n",
        "\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "# pyTorch dataloaders\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id,\n",
        "                                                   output_hidden_states=True)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = len(id2label),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
      ],
      "id": "be6377da"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a113a92"
      },
      "outputs": [],
      "source": [
        "# DLITE Loss function\n",
        "class DLITELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DLITELoss, self).__init__()\n",
        "\n",
        "    def forward(self, logits, targets, epsilon=1e-10):\n",
        "        # Convert logits to probabilities using softmax\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        # One-hot encode the targets to get true probabilities\n",
        "        true_probs = F.one_hot(targets, num_classes=probs.size(-1)).float()\n",
        "\n",
        "        # Define the g function\n",
        "        g_values = torch.abs(probs * (1 - torch.log(probs + epsilon)) - true_probs * (1 - torch.log(true_probs + epsilon)))\n",
        "\n",
        "        # Define the delta_h function\n",
        "        delta_h_values = torch.abs(probs**2 * (1 - 2 * torch.log(probs + epsilon)) - true_probs**2 * (1 - 2 * torch.log(true_probs + epsilon))) / (2 * (probs + true_probs))\n",
        "\n",
        "        # Compute DLITE loss for each class\n",
        "        dl_values = g_values - delta_h_values\n",
        "\n",
        "        # Sum over all classes and average over batch size\n",
        "        loss = dl_values.sum(dim=-1).mean()\n",
        "\n",
        "        return loss"
      ],
      "id": "9a113a92"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56a99bb4"
      },
      "outputs": [],
      "source": [
        "dlite_loss_fn = DLITELoss()\n",
        "\n",
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "\n",
        "\n",
        "\n",
        "        # implement Dlite loss function\n",
        "        flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        flatten_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "\n",
        "        loss = dlite_loss_fn(flatten_logits, flatten_targets)\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training dlite loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "    print(f\"Training steps: {nb_tr_steps}\")"
      ],
      "id": "56a99bb4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb554fde",
        "outputId": "098dfb12-05b3-4c81-8be7-7d871d9029be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training dlite loss per 100 training steps: 0.679557204246521\n",
            "Training dlite loss per 100 training steps: 0.0333419585978557\n",
            "Training dlite loss per 100 training steps: 0.025475730960817997\n",
            "Training dlite loss per 100 training steps: 0.02333164553349819\n",
            "Training dlite loss per 100 training steps: 0.021747106747054948\n",
            "Training dlite loss per 100 training steps: 0.02093453503930904\n",
            "Training dlite loss per 100 training steps: 0.02014573694262173\n",
            "Training dlite loss per 100 training steps: 0.01974439222759869\n",
            "Training dlite loss per 100 training steps: 0.019451556662106295\n",
            "Training dlite loss per 100 training steps: 0.01933756405682759\n",
            "Training dlite loss per 100 training steps: 0.019103211071068927\n",
            "Training dlite loss per 100 training steps: 0.019029646172031945\n",
            "Training dlite loss per 100 training steps: 0.018925614431807708\n",
            "Training dlite loss per 100 training steps: 0.018903241310735553\n",
            "Training dlite loss per 100 training steps: 0.018730444270027416\n",
            "Training dlite loss per 100 training steps: 0.018596053425894137\n",
            "Training dlite loss per 100 training steps: 0.018520941621862564\n",
            "Training dlite loss per 100 training steps: 0.01855322222500725\n",
            "Training dlite loss per 100 training steps: 0.018447331524893716\n",
            "Training dlite loss per 100 training steps: 0.018388420588942522\n",
            "Training dlite loss per 100 training steps: 0.018476813768842887\n",
            "Training dlite loss per 100 training steps: 0.018473983613059273\n",
            "Training dlite loss per 100 training steps: 0.018392379131711104\n",
            "Training dlite loss per 100 training steps: 0.018385699750744867\n",
            "Training dlite loss per 100 training steps: 0.018353497844598034\n",
            "Training dlite loss per 100 training steps: 0.018315233669783135\n",
            "Training dlite loss per 100 training steps: 0.018334683704398516\n",
            "Training dlite loss per 100 training steps: 0.018292646289645893\n",
            "Training dlite loss per 100 training steps: 0.01829611239221246\n",
            "Training dlite loss per 100 training steps: 0.01824276236542776\n",
            "Training dlite loss per 100 training steps: 0.018223528845778054\n",
            "Training dlite loss per 100 training steps: 0.018228818594394763\n",
            "Training dlite loss per 100 training steps: 0.018216064648766052\n",
            "Training dlite loss per 100 training steps: 0.018195784334711095\n",
            "Training dlite loss per 100 training steps: 0.01817323654963712\n",
            "Training dlite loss per 100 training steps: 0.01821500102889689\n",
            "Training dlite loss per 100 training steps: 0.018212671509001358\n",
            "Training dlite loss per 100 training steps: 0.01818934881171531\n",
            "Training loss epoch: 0.018189383076347574\n",
            "Training accuracy epoch: 0.8489075180407578\n",
            "Training steps: 3747\n",
            "CPU times: user 3min 36s, sys: 925 ms, total: 3min 37s\n",
            "Wall time: 3min 52s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ],
      "id": "cb554fde"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb6661bf"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "            flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            flatten_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            # implement dlite loss\n",
        "            loss = dlite_loss_fn(flatten_logits, flatten_targets)\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation dlite loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "    print(f\"Validation steps: {nb_eval_steps}\")\n",
        "\n",
        "    return labels, predictions"
      ],
      "id": "fb6661bf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af598b56",
        "outputId": "83b42df7-862b-49e9-d4d7-488f1c15c68f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation dlite loss per 100 evaluation steps: 0.03906558081507683\n",
            "Validation dlite loss per 100 evaluation steps: 0.016324678749460964\n",
            "Validation dlite loss per 100 evaluation steps: 0.016891715581686416\n",
            "Validation dlite loss per 100 evaluation steps: 0.016653731781258386\n",
            "Validation dlite loss per 100 evaluation steps: 0.016544182826994342\n",
            "Validation dlite loss per 100 evaluation steps: 0.017187872051807628\n",
            "Validation dlite loss per 100 evaluation steps: 0.017383375177928997\n",
            "Validation dlite loss per 100 evaluation steps: 0.017706984837720707\n",
            "Validation dlite loss per 100 evaluation steps: 0.01768645588121326\n",
            "Validation dlite loss per 100 evaluation steps: 0.01741036070125846\n",
            "Validation dlite loss per 100 evaluation steps: 0.017376738568805443\n",
            "Validation dlite loss per 100 evaluation steps: 0.01732084131840446\n",
            "Validation dlite loss per 100 evaluation steps: 0.0173230390674768\n",
            "Validation dlite loss per 100 evaluation steps: 0.017279862742509863\n",
            "Validation dlite loss per 100 evaluation steps: 0.0173125531267198\n",
            "Validation dlite loss per 100 evaluation steps: 0.01729924940368822\n",
            "Validation dlite loss per 100 evaluation steps: 0.017214412613416934\n",
            "Validation dlite loss per 100 evaluation steps: 0.017167107560271528\n",
            "Validation dlite loss per 100 evaluation steps: 0.017153251794004808\n",
            "Validation Loss: 0.01720625906125949\n",
            "Validation Accuracy: 0.8416789871614987\n",
            "Validation steps: 1842\n",
            "CPU times: user 29.5 s, sys: 98 ms, total: 29.6 s\n",
            "Wall time: 32.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "labels, predictions = valid(model, testing_loader)"
      ],
      "id": "af598b56"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c838bbe",
        "outputId": "20bbe3cc-7a84-4b48-9bde-3a8ba2f86d9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.00      0.00      0.00      1668\n",
            "      B-MISC       0.00      0.00      0.00       702\n",
            "       B-ORG       0.00      0.00      0.00      1661\n",
            "       B-PER       0.00      0.00      0.00      1617\n",
            "       I-LOC       0.00      0.00      0.00       257\n",
            "      I-MISC       0.00      0.00      0.00       216\n",
            "       I-ORG       0.00      0.00      0.00       835\n",
            "       I-PER       0.00      0.00      0.00      1156\n",
            "           O       0.85      1.00      0.92     45922\n",
            "\n",
            "    accuracy                           0.85     54034\n",
            "   macro avg       0.09      0.11      0.10     54034\n",
            "weighted avg       0.72      0.85      0.78     54034\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(labels, predictions))"
      ],
      "id": "0c838bbe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6007f4f7"
      },
      "outputs": [],
      "source": [],
      "id": "6007f4f7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMEfalyT4b-4",
        "outputId": "b9ffe791-9399-4108-8820-9852c4ade7ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8498723026242736, 0.8498723026242736, 0.8498723026242736, None)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision_recall_fscore_support(labels, predictions, average = \"micro\", zero_division = 1)"
      ],
      "id": "sMEfalyT4b-4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5l7ueq24cBp",
        "outputId": "927215c3-3d21-43ae-c1e6-fdaf79be4607"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9833191447360304, 0.1111111111111111, 0.10209381016536165, None)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"macro\", zero_division = 1)"
      ],
      "id": "n5l7ueq24cBp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX29jTW54cDs",
        "outputId": "0c95e1df-9871-4605-ab19-56d549bc2c3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8724106281436113, 0.8498723026242736, 0.7809003137602923, None)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"weighted\", zero_division = 1)"
      ],
      "id": "yX29jTW54cDs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5FVsp554fDO"
      },
      "outputs": [],
      "source": [],
      "id": "i5FVsp554fDO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2531e79c"
      },
      "outputs": [],
      "source": [
        "# KL divergence"
      ],
      "id": "2531e79c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1796103",
        "outputId": "e9131a96-7b13-44d1-8f0e-2d6d0a187ce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: 14987 sentences, 204567 tokens\n",
            "Dev data: 3466 sentences, 51578 tokens\n",
            "Test data: 3684 sentences, 46666 tokens\n",
            "\n",
            "NER tags: ['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Train data: 14987 sentences, 204567 tokens\n",
        "Dev data: 3466 sentences, 51578 tokens\n",
        "Test data: 3684 sentences, 46666 tokens\n",
        "\"\"\"\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "sys.path.append(\"../\")\n",
        "\n",
        "def flatten(l):\n",
        "    return [item for sublist in l for item in sublist]\n",
        "\n",
        "def read_CoNLL2003_format(filename, idx=3):\n",
        "    \"\"\"Read file in CoNLL-2003 shared task format\"\"\"\n",
        "\n",
        "    lines =  open(filename).read().strip()\n",
        "\n",
        "    # find sentence-like boundaries\n",
        "    lines = lines.split(\"\\n\\n\")\n",
        "\n",
        "    # throw out -DOCSTART- lines\n",
        "    #lines = [line for line in lines if not line.startswith(\"-DOCSTART-\")]\n",
        "\n",
        "     # split on newlines\n",
        "    lines = [line.split(\"\\n\") for line in lines]\n",
        "\n",
        "    # get tokens\n",
        "    tokens = [[l.split()[0] for l in line] for line in lines]\n",
        "\n",
        "    # get labels/tags\n",
        "    labels = [[l.split()[idx] for l in line] for line in lines]\n",
        "\n",
        "    data= {'tokens': tokens, 'labels': labels}\n",
        "    df=pd.DataFrame(data=data)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "DATADIR = \"./ner_english/\"\n",
        "\n",
        "def get_conll2003_data(trainfile=DATADIR + \"train.txt\",\n",
        "                  devfile=DATADIR + \"dev.txt\",\n",
        "                  testfile=DATADIR + \"test.txt\"):\n",
        "\n",
        "    train = read_CoNLL2003_format(trainfile)\n",
        "    print(\"Train data: %d sentences, %d tokens\"%(len(train),len(flatten(train.tokens))))\n",
        "\n",
        "    dev = read_CoNLL2003_format(devfile)\n",
        "    print(\"Dev data: %d sentences, %d tokens\"%(len(dev),len(flatten(dev.tokens))))\n",
        "\n",
        "    test = read_CoNLL2003_format(testfile)\n",
        "    print(\"Test data: %d sentences, %d tokens\"%(len(test),len(flatten(test.tokens))))\n",
        "\n",
        "    return train, dev, test\n",
        "\n",
        "train, dev, test = get_conll2003_data()\n",
        "\n",
        "X_train, y_train = train.tokens, train.labels\n",
        "X_dev, y_dev = dev.tokens, dev.labels\n",
        "X_test, y_test = test.tokens, test.labels\n",
        "\n",
        "\n",
        "label_list = np.unique(flatten(y_train))\n",
        "label_list = list(label_list)\n",
        "print(\"\\nNER tags:\",label_list)"
      ],
      "id": "a1796103"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0446c802",
        "outputId": "5257c636-b7e8-41cb-e74b-d5e0f4b4eda6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN Dataset: (14987, 2)\n",
            "TEST Dataset: (3684, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 5e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenization (it is not needed in this case)\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "# Bert imput\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        tokens = self.data.tokens[index]\n",
        "        labels = self.data.labels[index]\n",
        "        tokenized_sentence, labels = tokens, labels\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# define training size 80/20 split\n",
        "\n",
        "\n",
        "train_dataset = train\n",
        "test_dataset = test\n",
        "\n",
        "\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "# pyTorch dataloaders\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id,\n",
        "                                                   output_hidden_states=True)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = len(id2label),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
      ],
      "id": "0446c802"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a6be8d7"
      },
      "outputs": [],
      "source": [
        "# KL implementation"
      ],
      "id": "8a6be8d7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3b3c538"
      },
      "outputs": [],
      "source": [
        "class KLDivergenceLoss(nn.Module):\n",
        "    def __init__(self, reduction='mean'):\n",
        "        super(KLDivergenceLoss, self).__init__()\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        # Convert logits to probabilities using softmax\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        # One-hot encode the targets to get true probabilities\n",
        "        true_probs = F.one_hot(targets, num_classes=probs.size(-1)).float()\n",
        "\n",
        "        # Masks for non-zero elements of probs and true_probs\n",
        "        mask_probs = probs > 0\n",
        "        mask_true_probs = true_probs > 0\n",
        "\n",
        "        # Calculate g function for non-zero elements using the mask\n",
        "        kl_values = torch.zeros_like(probs)\n",
        "        kl_values[mask_true_probs] = true_probs[mask_true_probs] * torch.log(true_probs[mask_true_probs]/probs[mask_true_probs])\n",
        "\n",
        "        # Sum over all classes and average over the batch size\n",
        "        loss = kl_values.sum(dim=-1).mean()\n",
        "\n",
        "        return loss\n"
      ],
      "id": "a3b3c538"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49a93ff9"
      },
      "outputs": [],
      "source": [
        "kl_loss_fn = KLDivergenceLoss()\n",
        "\n",
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "\n",
        "        # implement kL divergence loss function\n",
        "        flatten_targets = targets.view(-1)\n",
        "        flatten_logits = tr_logits.view(-1, model.num_labels)\n",
        "\n",
        "        loss = kl_loss_fn(flatten_logits, flatten_targets)\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training KL loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "    print(f\"Training steps: {nb_tr_steps}\")"
      ],
      "id": "49a93ff9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c9e6c90",
        "outputId": "da557884-c992-4dfe-8da6-8d190791d7b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training KL loss per 100 training steps: 2.013615608215332\n",
            "Training KL loss per 100 training steps: 0.11540140477147433\n",
            "Training KL loss per 100 training steps: 0.08540455459973853\n",
            "Training KL loss per 100 training steps: 0.07172085745167296\n",
            "Training KL loss per 100 training steps: 0.06502350443797628\n",
            "Training KL loss per 100 training steps: 0.05939675354679485\n",
            "Training KL loss per 100 training steps: 0.05528480958653778\n",
            "Training KL loss per 100 training steps: 0.05178971546927943\n",
            "Training KL loss per 100 training steps: 0.04929394458191523\n",
            "Training KL loss per 100 training steps: 0.04758490607443242\n",
            "Training KL loss per 100 training steps: 0.0459145980868042\n",
            "Training KL loss per 100 training steps: 0.04447095011099564\n",
            "Training KL loss per 100 training steps: 0.043161617073003235\n",
            "Training KL loss per 100 training steps: 0.042250845044225646\n",
            "Training KL loss per 100 training steps: 0.0409168250088332\n",
            "Training KL loss per 100 training steps: 0.04010391786319454\n",
            "Training KL loss per 100 training steps: 0.039345309127172774\n",
            "Training KL loss per 100 training steps: 0.03856201922761354\n",
            "Training KL loss per 100 training steps: 0.038036359677547336\n",
            "Training KL loss per 100 training steps: 0.03750382823370366\n",
            "Training KL loss per 100 training steps: 0.03681376254061997\n",
            "Training KL loss per 100 training steps: 0.03627196964144003\n",
            "Training KL loss per 100 training steps: 0.035801698507304\n",
            "Training KL loss per 100 training steps: 0.03535713626548198\n",
            "Training KL loss per 100 training steps: 0.03501827003474932\n",
            "Training KL loss per 100 training steps: 0.03464588667722702\n",
            "Training KL loss per 100 training steps: 0.03426977759408426\n",
            "Training KL loss per 100 training steps: 0.03390619433826114\n",
            "Training KL loss per 100 training steps: 0.03362524611318275\n",
            "Training KL loss per 100 training steps: 0.03339196653122775\n",
            "Training KL loss per 100 training steps: 0.03311251152687308\n",
            "Training KL loss per 100 training steps: 0.032909534163278645\n",
            "Training KL loss per 100 training steps: 0.032582173339265885\n",
            "Training KL loss per 100 training steps: 0.03229019900365316\n",
            "Training KL loss per 100 training steps: 0.03201718699791777\n",
            "Training KL loss per 100 training steps: 0.031803384512396275\n",
            "Training KL loss per 100 training steps: 0.031604017019876716\n",
            "Training KL loss per 100 training steps: 0.031350471973452844\n",
            "Training loss epoch: 0.031292065681458356\n",
            "Training accuracy epoch: 0.9205718935364247\n",
            "Training steps: 3747\n",
            "CPU times: user 3min 41s, sys: 940 ms, total: 3min 42s\n",
            "Wall time: 3min 59s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ],
      "id": "3c9e6c90"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4fce4dd"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "\n",
        "            # implement KL divergence loss\n",
        "            flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            flatten_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            loss = kl_loss_fn(flatten_logits, flatten_targets)\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation KL loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "    # compute the cohen kappa score\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "    print(f\"Validation steps: {nb_eval_steps}\")\n",
        "\n",
        "    return labels, predictions"
      ],
      "id": "f4fce4dd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a125de6f",
        "outputId": "a7677647-01b6-4b27-b593-83c378cd79d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation KL loss per 100 evaluation steps: 0.08835896104574203\n",
            "Validation KL loss per 100 evaluation steps: 0.028153014845487958\n",
            "Validation KL loss per 100 evaluation steps: 0.025673933854686855\n",
            "Validation KL loss per 100 evaluation steps: 0.02632330794735739\n",
            "Validation KL loss per 100 evaluation steps: 0.025107370784806383\n",
            "Validation KL loss per 100 evaluation steps: 0.025932033580020088\n",
            "Validation KL loss per 100 evaluation steps: 0.02537051426223421\n",
            "Validation KL loss per 100 evaluation steps: 0.025436891785683476\n",
            "Validation KL loss per 100 evaluation steps: 0.026302027431353445\n",
            "Validation KL loss per 100 evaluation steps: 0.02569492581850148\n",
            "Validation KL loss per 100 evaluation steps: 0.0261218834543202\n",
            "Validation KL loss per 100 evaluation steps: 0.026134935434045714\n",
            "Validation KL loss per 100 evaluation steps: 0.025963147337237574\n",
            "Validation KL loss per 100 evaluation steps: 0.0263162159200684\n",
            "Validation KL loss per 100 evaluation steps: 0.0259859977914863\n",
            "Validation KL loss per 100 evaluation steps: 0.025927130126733144\n",
            "Validation KL loss per 100 evaluation steps: 0.026144445442715766\n",
            "Validation KL loss per 100 evaluation steps: 0.026071577850405134\n",
            "Validation KL loss per 100 evaluation steps: 0.025981167961292035\n",
            "Validation Loss: 0.02602008350819612\n",
            "Validation Accuracy: 0.9236818103867009\n",
            "Validation steps: 1842\n",
            "CPU times: user 25.4 s, sys: 86.1 ms, total: 25.5 s\n",
            "Wall time: 25.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "labels, predictions = valid(model, testing_loader)"
      ],
      "id": "a125de6f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71a4cdad",
        "outputId": "950296d8-d5ed-4b47-ba45-9d597963a278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.77      0.58      0.66      1668\n",
            "      B-MISC       0.60      0.33      0.42       702\n",
            "       B-ORG       0.67      0.64      0.66      1661\n",
            "       B-PER       0.82      0.74      0.78      1617\n",
            "       I-LOC       0.44      0.39      0.41       257\n",
            "      I-MISC       0.47      0.38      0.42       216\n",
            "       I-ORG       0.51      0.70      0.59       835\n",
            "       I-PER       0.85      0.79      0.82      1156\n",
            "           O       0.96      0.98      0.97     45922\n",
            "\n",
            "    accuracy                           0.93     54034\n",
            "   macro avg       0.68      0.62      0.64     54034\n",
            "weighted avg       0.93      0.93      0.93     54034\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(labels, predictions))"
      ],
      "id": "71a4cdad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L09SHmpC4xiN"
      },
      "outputs": [],
      "source": [],
      "id": "L09SHmpC4xiN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh1-5Uo44xk5",
        "outputId": "b98b1ee0-6b5e-4417-f888-132eeb569882"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9276751674871377, 0.9276751674871377, 0.9276751674871377, None)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision_recall_fscore_support(labels, predictions, average = \"micro\", zero_division = 1)"
      ],
      "id": "kh1-5Uo44xk5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuWAi8oM4xoE",
        "outputId": "1bbc7976-f736-4f46-d929-3dd80d6d5b38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6755226255369471, 0.6152718068099925, 0.6369761796377479, None)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"macro\", zero_division = 1)"
      ],
      "id": "xuWAi8oM4xoE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaIHUiTf4xvC",
        "outputId": "14f21014-ed08-4c3d-cbab-d5c8a7863c83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9250781485378636, 0.9276751674871377, 0.9250553436905857, None)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "precision_recall_fscore_support(labels, predictions, average = \"weighted\", zero_division = 1)"
      ],
      "id": "RaIHUiTf4xvC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b814f5d7"
      },
      "source": [],
      "id": "b814f5d7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8300980"
      },
      "outputs": [],
      "source": [],
      "id": "e8300980"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3298bd34"
      },
      "outputs": [],
      "source": [],
      "id": "3298bd34"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6ecef01"
      },
      "outputs": [],
      "source": [],
      "id": "e6ecef01"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "307e131a7dbd4c71a5101f30ddeb830b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b54ef4426b148648a43e65df62fa8ae",
              "IPY_MODEL_629268c4bc2f448aa6a68db3e851649b",
              "IPY_MODEL_3836250ecac643cd90c3358b753cee26"
            ],
            "layout": "IPY_MODEL_39e354b8f898486998314da9e897be41"
          }
        },
        "9b54ef4426b148648a43e65df62fa8ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c333267d9ad48dd9e3f897c509d4a7f",
            "placeholder": "​",
            "style": "IPY_MODEL_2048f491f7d44a128beb635198c93349",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "629268c4bc2f448aa6a68db3e851649b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae089c7060354546b26519b76adff4d4",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df19fc9c62b344a7a108f81bce553cb2",
            "value": 48
          }
        },
        "3836250ecac643cd90c3358b753cee26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5036cf06da2c4072a6a2c9829f4b19e8",
            "placeholder": "​",
            "style": "IPY_MODEL_a8739a0b8a3e40cc8a8787d4a13da012",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.34kB/s]"
          }
        },
        "39e354b8f898486998314da9e897be41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c333267d9ad48dd9e3f897c509d4a7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2048f491f7d44a128beb635198c93349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae089c7060354546b26519b76adff4d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df19fc9c62b344a7a108f81bce553cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5036cf06da2c4072a6a2c9829f4b19e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8739a0b8a3e40cc8a8787d4a13da012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b8489f554804d4b99865f3e9e440c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bf65fd56ad74da2bc77852625c898ce",
              "IPY_MODEL_40efcd9f87c94b12a7daf38bd3455f5a",
              "IPY_MODEL_c8904cf564514afb96abc4301fb73daa"
            ],
            "layout": "IPY_MODEL_54d55c50888c4605843aa608201db62d"
          }
        },
        "9bf65fd56ad74da2bc77852625c898ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_010f3e3feca9465fa7a3e4433e9e52dd",
            "placeholder": "​",
            "style": "IPY_MODEL_f8dd686a634142719284b67d0ae4db41",
            "value": "vocab.txt: 100%"
          }
        },
        "40efcd9f87c94b12a7daf38bd3455f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb1e0ceff6b744cf9373f6d2782a500d",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbca5e2451e14bfab31612a36d31335d",
            "value": 231508
          }
        },
        "c8904cf564514afb96abc4301fb73daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_907525741dd9470a93539177ea6a422d",
            "placeholder": "​",
            "style": "IPY_MODEL_dd77d7066eb6411fae0442e6738a114d",
            "value": " 232k/232k [00:00&lt;00:00, 3.80MB/s]"
          }
        },
        "54d55c50888c4605843aa608201db62d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "010f3e3feca9465fa7a3e4433e9e52dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8dd686a634142719284b67d0ae4db41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb1e0ceff6b744cf9373f6d2782a500d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbca5e2451e14bfab31612a36d31335d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "907525741dd9470a93539177ea6a422d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd77d7066eb6411fae0442e6738a114d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae91d751795a4fd2b4d056eba6533605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7ae5f51267e41e09b47e58918dde082",
              "IPY_MODEL_d2f96090169849f28bf28865a77cfdb1",
              "IPY_MODEL_a7c15eeb0e9b458d8087fb67437d560e"
            ],
            "layout": "IPY_MODEL_32bd5c603deb4bb483874d67463e66f2"
          }
        },
        "f7ae5f51267e41e09b47e58918dde082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77bc33ba7df44827a6240be12f14a875",
            "placeholder": "​",
            "style": "IPY_MODEL_ca42d1a65565452cb18cc2466e4abb7b",
            "value": "tokenizer.json: 100%"
          }
        },
        "d2f96090169849f28bf28865a77cfdb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d4105727def471fbb7bd93898778106",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec49be2dc6d14acdb2c704c075f54870",
            "value": 466062
          }
        },
        "a7c15eeb0e9b458d8087fb67437d560e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c25ed2540cd402d9dbf21b892c8376c",
            "placeholder": "​",
            "style": "IPY_MODEL_74fa0b81c7474c0c8cc6f6b160cee131",
            "value": " 466k/466k [00:00&lt;00:00, 17.3MB/s]"
          }
        },
        "32bd5c603deb4bb483874d67463e66f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77bc33ba7df44827a6240be12f14a875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca42d1a65565452cb18cc2466e4abb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d4105727def471fbb7bd93898778106": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec49be2dc6d14acdb2c704c075f54870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c25ed2540cd402d9dbf21b892c8376c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74fa0b81c7474c0c8cc6f6b160cee131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e33c61c94dff419c8bffebb3b73a329e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a04a6cf1b95845ceaa47ce387e00097f",
              "IPY_MODEL_fb32aa5b834147c7b959b497fb97719a",
              "IPY_MODEL_26ca55ecf44749cb849e1135af72d9c2"
            ],
            "layout": "IPY_MODEL_fe8e32c17bdb487e94b210d7a0bd6fce"
          }
        },
        "a04a6cf1b95845ceaa47ce387e00097f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_572063b9bf274c18baf2cea616a9f491",
            "placeholder": "​",
            "style": "IPY_MODEL_69f845e5b05c4b53a2ff174f7584b99a",
            "value": "config.json: 100%"
          }
        },
        "fb32aa5b834147c7b959b497fb97719a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84c5f5b112f644a195f853eaf1c7e774",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4cba8b1447b4f3aae0280a9aefa87eb",
            "value": 570
          }
        },
        "26ca55ecf44749cb849e1135af72d9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bb45c09bdc340878108b63e7667619e",
            "placeholder": "​",
            "style": "IPY_MODEL_c478f797cd9c4477a8f111788cb6cf84",
            "value": " 570/570 [00:00&lt;00:00, 26.9kB/s]"
          }
        },
        "fe8e32c17bdb487e94b210d7a0bd6fce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "572063b9bf274c18baf2cea616a9f491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69f845e5b05c4b53a2ff174f7584b99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84c5f5b112f644a195f853eaf1c7e774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4cba8b1447b4f3aae0280a9aefa87eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bb45c09bdc340878108b63e7667619e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c478f797cd9c4477a8f111788cb6cf84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29e162b6d47b42e799ac3a2f3625182d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9aaf2698d2b4399b3a834f826b373af",
              "IPY_MODEL_b278e18a9f4546cbbd15f581125acef3",
              "IPY_MODEL_1e609721cbc54731b509133f49ab9e35"
            ],
            "layout": "IPY_MODEL_2264e3f14eae412591937905117840ee"
          }
        },
        "e9aaf2698d2b4399b3a834f826b373af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6e6afe431fb4bd0971c8024f80a8f7a",
            "placeholder": "​",
            "style": "IPY_MODEL_d727f0ce52e247c493a761e07b21b4dc",
            "value": "model.safetensors: 100%"
          }
        },
        "b278e18a9f4546cbbd15f581125acef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e72108dbb6e947879bd1fbce5af644c0",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4376bf5d62c64b8c9ee288457d9f334a",
            "value": 440449768
          }
        },
        "1e609721cbc54731b509133f49ab9e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_186431652c664778af10c479201d41ab",
            "placeholder": "​",
            "style": "IPY_MODEL_33c27e4c9b4f47609ffd4349a200a134",
            "value": " 440M/440M [00:03&lt;00:00, 125MB/s]"
          }
        },
        "2264e3f14eae412591937905117840ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6e6afe431fb4bd0971c8024f80a8f7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d727f0ce52e247c493a761e07b21b4dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e72108dbb6e947879bd1fbce5af644c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4376bf5d62c64b8c9ee288457d9f334a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "186431652c664778af10c479201d41ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33c27e4c9b4f47609ffd4349a200a134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}