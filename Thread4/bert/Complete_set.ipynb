{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "82fdcbca",
      "metadata": {
        "id": "82fdcbca"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertConfig, BertForTokenClassification\n",
        "# Using the dlite function\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7c8951f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c8951f4",
        "outputId": "e5af0951-8d5d-40fd-8741-d0fe6093eaa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8328f08",
      "metadata": {
        "id": "e8328f08"
      },
      "source": [
        "# Data preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0cf2e5b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "0cf2e5b7",
        "outputId": "4abab919-0ca7-4926-ac7f-05fa182b05c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tags: 17\n",
            "[('geo', 45058), ('org', 36927), ('per', 34241), ('tim', 26861), ('gpe', 16068), ('art', 699), ('eve', 561), ('nat', 252)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'B-gpe,O,O,B-tim,O,B-per,I-per,O,O,O,B-geo,O,O,O,O,O,O,O,O'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data = pd.read_csv(\"ner_datasetreference.csv\", encoding='unicode_escape')\n",
        "data.head()\n",
        "\n",
        "data.count()\n",
        "\n",
        "print(\"Number of tags: {}\".format(len(data.Tag.unique())))\n",
        "frequencies = data.Tag.value_counts()\n",
        "frequencies\n",
        "\n",
        "tags = {}\n",
        "for tag, count in zip(frequencies.index, frequencies):\n",
        "    if tag != \"O\":\n",
        "        if tag[2:5] not in tags.keys():\n",
        "            tags[tag[2:5]] = count\n",
        "        else:\n",
        "            tags[tag[2:5]] += count\n",
        "    continue\n",
        "\n",
        "print(sorted(tags.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "entities_to_remove = [\"B-art\", \"I-art\", \"B-eve\", \"I-eve\", \"B-nat\", \"I-nat\"]\n",
        "data = data[~data.Tag.isin(entities_to_remove)]\n",
        "data.head()\n",
        "\n",
        "# pandas has a very handy \"forward fill\" function to fill missing values based on the last upper non-nan value\n",
        "data = data.fillna(method='ffill')\n",
        "data.head()\n",
        "\n",
        "# let's create a new column called \"sentence\" which groups the words by sentence\n",
        "data['sentence'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Word'].transform(lambda x: ' '.join(x))\n",
        "# let's also create a new column called \"word_labels\" which groups the tags by sentence\n",
        "data['word_labels'] = data[['Sentence #','Word','Tag']].groupby(['Sentence #'])['Tag'].transform(lambda x: ','.join(x))\n",
        "data.head()\n",
        "\n",
        "label2id = {k: v for v, k in enumerate(data.Tag.unique())}\n",
        "id2label = {v: k for v, k in enumerate(data.Tag.unique())}\n",
        "label2id\n",
        "\n",
        "data = data[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n",
        "data.head()\n",
        "\n",
        "\n",
        "\n",
        "len(data)\n",
        "\n",
        "data.iloc[41].sentence\n",
        "\n",
        "data.iloc[41].word_labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b1ea60b",
      "metadata": {
        "id": "0b1ea60b"
      },
      "source": [
        "# Data preparing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4905bf7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284,
          "referenced_widgets": [
            "636b577fdb514e16be0728f5951e0393",
            "46d0ce3c77c148d3874831062674d1f3",
            "03907f2becdd4b12ae6b4416ece0b114",
            "2c198740c29f4c66908941e5f64a4379",
            "5c7de95e0e7142e5a304fdfdff42e53e",
            "172cc15cc3494ff18cbdb15134979265",
            "ddd5e777b74242c4a4cd60b8b36b7d94",
            "2e046b47f1c243bb874c400eb30de6b3",
            "d8f6392e39234ef6862cdb18454e87ae",
            "829158fe13ad4541a9844f08cdfeba01",
            "f81b5919b42c44cbb553a3c4a3d79310",
            "830f038d381548dd8477d99dfa72c02f",
            "455692e589f043aeb01f431d0c744a74",
            "8d48248bccb949be80ddc59c67d3418f",
            "46dedb4ca9d04f1ca0d1f27e79542e41",
            "347d67ad6473483da745bd209dd0c114",
            "a0e11f920d3e4643b54e7e7f75cc9795",
            "263dc4daf4ac42298fce3a764929149b",
            "61cf59214b674b90891053349e98df57",
            "b6617c52f387470eb3e94e4639c2ec25",
            "fc7cde1413dc4cc9979322b560fd0e85",
            "4c4fd5319bc047a4a8eb8fa3609be486",
            "33f83eae687547f8bf6867a26c580b7a",
            "4e324e7a464a46cea522c46661e1d999",
            "854f37304f584183a0fe823ec4f1b422",
            "d63b14d9e3ac456288f1df1fddaad54a",
            "ff3fc5058a674b71b77aaa9816ab4375",
            "5ccf450bdccc4aeaaaab418bdfb3730f",
            "fc326b61c86141f3bbc6c7ecb7a5a464",
            "efd4478c2f624ab4a6c2e48cb58a2ce9",
            "9442af9224df4d1481f4c2270c348853",
            "c2220e7d9c9f41d2af5dd7faf2f556e5",
            "8385c9bd721943a6a6e3303a0c7c45cb",
            "d2193ecab5534678b5c35b0bd79eb4c3",
            "95b3aa2547ea4256a876932221074c4f",
            "c920bb5c7f9f4dc6af9798854d57fa37",
            "06de1580543d4fb197493a21774376c1",
            "1d4059bd32a0462fa53bce23cd0e2c46",
            "c332377a134d4d4ea79518e3bed508ba",
            "68510587ef54426696dccba7574c7418",
            "ee25aae9ac744ab291618e3d5a00ed84",
            "a708074ed2c84384aff4983b38c14e62",
            "1256ef69288b4e1c9dd778733b683b8b",
            "6ea225efb1184159b127f680f459a591",
            "7ff1522e291d437e8016844b71f379d3",
            "1c7879e56842467a9b2ae60273e34c15",
            "96ec789815304f87a64112d72e2af4b9",
            "bc72688162e34b209569e2966f0e10db",
            "e31cc02cc3634d6f8d04027aba58d94b",
            "7bbd4f93e8e5410fa40abefb72465983",
            "7bd4ee29c8ba487bb46d3137e9cbea8d",
            "6d03cc3d66634828809fff81a4e238d6",
            "818d3cdd51064224856a7549551eeff2",
            "e739a059ac114b94a75031c317c57342",
            "6759ac2753564fdf81cea9dac8df7fbe"
          ]
        },
        "id": "4905bf7d",
        "outputId": "9f2760b4-2e51-4f41-d60a-3e6f8b674e3e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "636b577fdb514e16be0728f5951e0393"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "830f038d381548dd8477d99dfa72c02f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33f83eae687547f8bf6867a26c580b7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2193ecab5534678b5c35b0bd79eb4c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (47571, 2)\n",
            "TRAIN Dataset: (38057, 2)\n",
            "TEST Dataset: (9514, 2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ff1522e291d437e8016844b71f379d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 5e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenization\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "# Bert imput\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        sentence = self.data.sentence[index]\n",
        "        word_labels = self.data.word_labels[index]\n",
        "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# define training size 80/20 split\n",
        "\n",
        "train_size = 0.8\n",
        "train_dataset = data.sample(frac=train_size,random_state=200)\n",
        "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(data.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "# pyTorch dataloaders\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id)\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d7c632e",
      "metadata": {
        "id": "7d7c632e"
      },
      "source": [
        "# Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f9efa25b",
      "metadata": {
        "id": "f9efa25b"
      },
      "outputs": [],
      "source": [
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7d46c2d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d46c2d4",
        "outputId": "4761a2b6-f000-4853-db9e-ba4d913e44a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training loss per 100 training steps: 2.26269268989563\n",
            "Training loss per 100 training steps: 0.18580198961098005\n",
            "Training loss per 100 training steps: 0.1303291315194312\n",
            "Training loss per 100 training steps: 0.10425275738391271\n",
            "Training loss per 100 training steps: 0.0900488038236122\n",
            "Training loss per 100 training steps: 0.07994406149088741\n",
            "Training loss per 100 training steps: 0.07474045634010927\n",
            "Training loss per 100 training steps: 0.06971314357136629\n",
            "Training loss per 100 training steps: 0.06557909982946333\n",
            "Training loss per 100 training steps: 0.06262367371390662\n",
            "Training loss per 100 training steps: 0.06049454721055095\n",
            "Training loss per 100 training steps: 0.05844750732078143\n",
            "Training loss per 100 training steps: 0.0566398040037703\n",
            "Training loss per 100 training steps: 0.05476176636452807\n",
            "Training loss per 100 training steps: 0.05305613287224991\n",
            "Training loss per 100 training steps: 0.05178412836296937\n",
            "Training loss per 100 training steps: 0.05095813264558412\n",
            "Training loss per 100 training steps: 0.050167314867285914\n",
            "Training loss per 100 training steps: 0.049147609312181414\n",
            "Training loss per 100 training steps: 0.048511723590562064\n",
            "Training loss per 100 training steps: 0.04786335458122157\n",
            "Training loss per 100 training steps: 0.04703672825973188\n",
            "Training loss per 100 training steps: 0.04661716220380805\n",
            "Training loss per 100 training steps: 0.04624017612287764\n",
            "Training loss per 100 training steps: 0.04561611620517489\n",
            "Training loss per 100 training steps: 0.045253616630569655\n",
            "Training loss per 100 training steps: 0.04478602319343\n",
            "Training loss per 100 training steps: 0.04418797973497374\n",
            "Training loss per 100 training steps: 0.04371196932178649\n",
            "Training loss per 100 training steps: 0.043405422375748376\n",
            "Training loss per 100 training steps: 0.04303010012172423\n",
            "Training loss per 100 training steps: 0.04267489301004429\n",
            "Training loss per 100 training steps: 0.04230775141854174\n",
            "Training loss per 100 training steps: 0.04205275820848927\n",
            "Training loss per 100 training steps: 0.041715511211496144\n",
            "Training loss per 100 training steps: 0.04128120412087875\n",
            "Training loss per 100 training steps: 0.04093731368627738\n",
            "Training loss per 100 training steps: 0.04053426084400837\n",
            "Training loss per 100 training steps: 0.04028653148506127\n",
            "Training loss per 100 training steps: 0.039972089914193286\n",
            "Training loss per 100 training steps: 0.039719013365422356\n",
            "Training loss per 100 training steps: 0.039511401036241324\n",
            "Training loss per 100 training steps: 0.03930225362596296\n",
            "Training loss per 100 training steps: 0.039128475336651654\n",
            "Training loss per 100 training steps: 0.03889276786655218\n",
            "Training loss per 100 training steps: 0.03870183228449018\n",
            "Training loss per 100 training steps: 0.03861858682236319\n",
            "Training loss per 100 training steps: 0.038436701161045556\n",
            "Training loss per 100 training steps: 0.03826346933355518\n",
            "Training loss per 100 training steps: 0.03810329874180247\n",
            "Training loss per 100 training steps: 0.03791369180287344\n",
            "Training loss per 100 training steps: 0.03779106897794324\n",
            "Training loss per 100 training steps: 0.037600271721662554\n",
            "Training loss per 100 training steps: 0.03746026632641425\n",
            "Training loss per 100 training steps: 0.037329723265099445\n",
            "Training loss per 100 training steps: 0.03722025103614595\n",
            "Training loss per 100 training steps: 0.037016765048549664\n",
            "Training loss per 100 training steps: 0.036888124662178896\n",
            "Training loss per 100 training steps: 0.036767864672774174\n",
            "Training loss per 100 training steps: 0.03668469504960579\n",
            "Training loss per 100 training steps: 0.036624291464452924\n",
            "Training loss per 100 training steps: 0.03650972407231756\n",
            "Training loss per 100 training steps: 0.03642821954949856\n",
            "Training loss per 100 training steps: 0.036330386222749825\n",
            "Training loss per 100 training steps: 0.036226223574378415\n",
            "Training loss per 100 training steps: 0.036118495197587294\n",
            "Training loss per 100 training steps: 0.03600959003118178\n",
            "Training loss per 100 training steps: 0.03590991173535714\n",
            "Training loss per 100 training steps: 0.03579511893150956\n",
            "Training loss per 100 training steps: 0.035700189459345937\n",
            "Training loss per 100 training steps: 0.0356243072903119\n",
            "Training loss per 100 training steps: 0.035489930101081396\n",
            "Training loss per 100 training steps: 0.035409985955215495\n",
            "Training loss per 100 training steps: 0.035317908705255564\n",
            "Training loss per 100 training steps: 0.03523214490313944\n",
            "Training loss per 100 training steps: 0.035110552330022075\n",
            "Training loss per 100 training steps: 0.03498755991677028\n",
            "Training loss per 100 training steps: 0.03491747621517444\n",
            "Training loss per 100 training steps: 0.034825227704458346\n",
            "Training loss per 100 training steps: 0.03474741660995832\n",
            "Training loss per 100 training steps: 0.03469277065296447\n",
            "Training loss per 100 training steps: 0.03460316492744177\n",
            "Training loss per 100 training steps: 0.034557971422793994\n",
            "Training loss per 100 training steps: 0.03446228346778971\n",
            "Training loss per 100 training steps: 0.03441197720641074\n",
            "Training loss per 100 training steps: 0.03433017057912203\n",
            "Training loss per 100 training steps: 0.03423363795748783\n",
            "Training loss per 100 training steps: 0.03417324366476003\n",
            "Training loss per 100 training steps: 0.034114339401033276\n",
            "Training loss per 100 training steps: 0.03407259700185615\n",
            "Training loss per 100 training steps: 0.034034547725277454\n",
            "Training loss per 100 training steps: 0.03395676494937601\n",
            "Training loss per 100 training steps: 0.03383425876873672\n",
            "Training loss per 100 training steps: 0.03377812851140502\n",
            "Training loss per 100 training steps: 0.033776370224408755\n",
            "Training loss per 100 training steps: 0.03370883097070145\n",
            "Training loss epoch: 0.033694602155793556\n",
            "Training accuracy epoch: 0.9523727684183143\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b9e097d3",
      "metadata": {
        "id": "b9e097d3"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    return labels, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3a520c16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a520c16",
        "outputId": "aa0ac237-8840-404f-b346-fcdd1dcd00ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss per 100 evaluation steps: 0.008669273927807808\n",
            "Validation loss per 100 evaluation steps: 0.033252935524480096\n",
            "Validation loss per 100 evaluation steps: 0.028029420242453862\n",
            "Validation loss per 100 evaluation steps: 0.02803733856402977\n",
            "Validation loss per 100 evaluation steps: 0.027894649701512318\n",
            "Validation loss per 100 evaluation steps: 0.027555504653617592\n",
            "Validation loss per 100 evaluation steps: 0.027440005783099637\n",
            "Validation loss per 100 evaluation steps: 0.027234871215643604\n",
            "Validation loss per 100 evaluation steps: 0.02751514466479321\n",
            "Validation loss per 100 evaluation steps: 0.02767676208534287\n",
            "Validation loss per 100 evaluation steps: 0.0272679228605589\n",
            "Validation loss per 100 evaluation steps: 0.027767216561218916\n",
            "Validation loss per 100 evaluation steps: 0.027999266397734642\n",
            "Validation loss per 100 evaluation steps: 0.027628886433565213\n",
            "Validation loss per 100 evaluation steps: 0.027497260682441828\n",
            "Validation loss per 100 evaluation steps: 0.02753540812685785\n",
            "Validation loss per 100 evaluation steps: 0.027493820531643377\n",
            "Validation loss per 100 evaluation steps: 0.02761762931358515\n",
            "Validation loss per 100 evaluation steps: 0.02770401328243371\n",
            "Validation loss per 100 evaluation steps: 0.02786494018909052\n",
            "Validation loss per 100 evaluation steps: 0.027951207531617277\n",
            "Validation loss per 100 evaluation steps: 0.027968757412981212\n",
            "Validation loss per 100 evaluation steps: 0.027982052256277954\n",
            "Validation loss per 100 evaluation steps: 0.027814326186360608\n",
            "Validation loss per 100 evaluation steps: 0.028154883834586596\n",
            "Validation loss per 100 evaluation steps: 0.027939508386484055\n",
            "Validation loss per 100 evaluation steps: 0.0279149684971737\n",
            "Validation loss per 100 evaluation steps: 0.027864224306070495\n",
            "Validation loss per 100 evaluation steps: 0.0277212061591685\n",
            "Validation loss per 100 evaluation steps: 0.027763305533287905\n",
            "Validation loss per 100 evaluation steps: 0.02772781138800629\n",
            "Validation loss per 100 evaluation steps: 0.02765781393057104\n",
            "Validation loss per 100 evaluation steps: 0.027788278780623392\n",
            "Validation loss per 100 evaluation steps: 0.02782618171360404\n",
            "Validation loss per 100 evaluation steps: 0.02780448983210409\n",
            "Validation loss per 100 evaluation steps: 0.027792196467997462\n",
            "Validation loss per 100 evaluation steps: 0.027679968844251578\n",
            "Validation loss per 100 evaluation steps: 0.02762338775594523\n",
            "Validation loss per 100 evaluation steps: 0.027479660452006838\n",
            "Validation loss per 100 evaluation steps: 0.027402343645871498\n",
            "Validation loss per 100 evaluation steps: 0.027368779063175683\n",
            "Validation loss per 100 evaluation steps: 0.02743772935741013\n",
            "Validation loss per 100 evaluation steps: 0.027395579173244047\n",
            "Validation loss per 100 evaluation steps: 0.027236459228531983\n",
            "Validation loss per 100 evaluation steps: 0.027262325830338614\n",
            "Validation loss per 100 evaluation steps: 0.027285365447588802\n",
            "Validation loss per 100 evaluation steps: 0.027429333513229102\n",
            "Validation loss per 100 evaluation steps: 0.027419908310651175\n",
            "Validation Loss: 0.027378819253377408\n",
            "Validation Accuracy: 0.9602204427078\n"
          ]
        }
      ],
      "source": [
        "labels, predictions = valid(model, testing_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "92b96e45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "92b96e45",
        "outputId": "533f909c-5cb4-4863-fb68-78e6189d26ca"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0c8ba575cf48>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mseqeval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seqeval'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report([labels], [predictions]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e09cf3f",
      "metadata": {
        "id": "6e09cf3f"
      },
      "outputs": [],
      "source": [
        "sentence = \"India has a capital called Mumbai. On Wednesday, the president will give a presentation\"\n",
        "\n",
        "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "\n",
        "# move to gpu\n",
        "ids = inputs[\"input_ids\"].to(device)\n",
        "mask = inputs[\"attention_mask\"].to(device)\n",
        "# forward pass\n",
        "outputs = model(ids, mask)\n",
        "logits = outputs[0]\n",
        "\n",
        "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
        "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "word_level_predictions = []\n",
        "for pair in wp_preds:\n",
        "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
        "    # skip prediction\n",
        "    continue\n",
        "  else:\n",
        "    word_level_predictions.append(pair[1])\n",
        "\n",
        "# we join tokens, if they are not special ones\n",
        "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
        "print(str_rep)\n",
        "print(word_level_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a28eb627",
      "metadata": {
        "id": "a28eb627"
      },
      "outputs": [],
      "source": [
        "# L1 loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d582914",
      "metadata": {
        "id": "7d582914"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 5e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenization\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "# Bert imput\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        sentence = self.data.sentence[index]\n",
        "        word_labels = self.data.word_labels[index]\n",
        "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# define training size 80/20 split\n",
        "\n",
        "train_size = 0.8\n",
        "train_dataset = data.sample(frac=train_size,random_state=200)\n",
        "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(data.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "# pyTorch dataloaders\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id)\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66fefe2b",
      "metadata": {
        "id": "66fefe2b"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(targets, num_classes):\n",
        "    \"\"\"\n",
        "    One-hot encode a tensor of class indices.\n",
        "\n",
        "    Arguments:\n",
        "    - targets (torch.Tensor): A tensor of class indices, shape [N].\n",
        "    - num_classes (int): The number of classes.\n",
        "\n",
        "    Returns:\n",
        "    - torch.Tensor: The one-hot encoded tensor, shape [N, num_classes].\n",
        "    \"\"\"\n",
        "    return F.one_hot(targets, num_classes=num_classes).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db7e09f",
      "metadata": {
        "id": "4db7e09f"
      },
      "outputs": [],
      "source": [
        "l1_loss_fn = nn.L1Loss()\n",
        "\n",
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "\n",
        "        # implement l1 loss function\n",
        "        flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        flatten_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "\n",
        "        targets_one_hot = one_hot_encode(flatten_targets, num_classes= flatten_logits.size(-1))\n",
        "\n",
        "        loss = l1_loss_fn(flatten_logits, targets_one_hot)\n",
        "\n",
        "\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training l1 loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9792cf7",
      "metadata": {
        "id": "f9792cf7"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e363015",
      "metadata": {
        "id": "0e363015"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "\n",
        "            # implement l1 loss\n",
        "            flatten_targets = targets.view(-1)\n",
        "            flatten_logits = eval_logits.view(-1, model.num_labels)\n",
        "            targets_one_hot = one_hot_encode(flatten_targets, num_classes= flatten_logits.size(-1))\n",
        "            loss = l1_loss_fn(flatten_logits, targets_one_hot)\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation l1 loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    return labels, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f817764b",
      "metadata": {
        "id": "f817764b"
      },
      "outputs": [],
      "source": [
        "labels, predictions = valid(model, testing_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "889fd862",
      "metadata": {
        "id": "889fd862"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report([labels], [predictions]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd307163",
      "metadata": {
        "id": "bd307163"
      },
      "source": [
        "# Raw\n",
        "                 precision    recall  f1-score   support\n",
        "\n",
        "          geo       0.81      0.83      0.82      1138\n",
        "          gpe       0.91      0.84      0.88       336\n",
        "          org       0.51      0.61      0.56       652\n",
        "          per       0.61      0.73      0.66       566\n",
        "          tim       0.84      0.79      0.81       457\n",
        "    micro avg       0.71      0.76      0.74      3149\n",
        "    macro avg       0.74      0.76      0.75      3149\n",
        "    weigt avg       0.73      0.76      0.74      3149"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb278f56",
      "metadata": {
        "id": "eb278f56"
      },
      "outputs": [],
      "source": [
        "sentence = \"India has a capital called Mumbai. On Wednesday, the president will give a presentation\"\n",
        "\n",
        "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "\n",
        "# move to gpu\n",
        "ids = inputs[\"input_ids\"].to(device)\n",
        "mask = inputs[\"attention_mask\"].to(device)\n",
        "# forward pass\n",
        "outputs = model(ids, mask)\n",
        "logits = outputs[0]\n",
        "\n",
        "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
        "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "word_level_predictions = []\n",
        "for pair in wp_preds:\n",
        "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
        "    # skip prediction\n",
        "    continue\n",
        "  else:\n",
        "    word_level_predictions.append(pair[1])\n",
        "\n",
        "# we join tokens, if they are not special ones\n",
        "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
        "print(str_rep)\n",
        "print(word_level_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z2zseVQVFtVN"
      },
      "id": "z2zseVQVFtVN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5659cba",
      "metadata": {
        "id": "b5659cba"
      },
      "outputs": [],
      "source": [
        "#Dlite loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be6377da",
      "metadata": {
        "id": "be6377da"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 5e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenization\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "# Bert imput\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        sentence = self.data.sentence[index]\n",
        "        word_labels = self.data.word_labels[index]\n",
        "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# define training size 80/20 split\n",
        "\n",
        "train_size = 0.8\n",
        "train_dataset = data.sample(frac=train_size,random_state=200)\n",
        "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(data.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "# pyTorch dataloaders\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id)\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a113a92",
      "metadata": {
        "id": "9a113a92"
      },
      "outputs": [],
      "source": [
        "# DLITE Loss function\n",
        "class DLITELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DLITELoss, self).__init__()\n",
        "\n",
        "    def forward(self, logits, targets, epsilon=1e-10):\n",
        "        # Convert logits to probabilities using softmax\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        # One-hot encode the targets to get true probabilities\n",
        "        true_probs = F.one_hot(targets, num_classes=probs.size(-1)).float()\n",
        "\n",
        "        # Define the g function\n",
        "        g_values = torch.abs(probs * (1 - torch.log(probs + epsilon)) - true_probs * (1 - torch.log(true_probs + epsilon)))\n",
        "\n",
        "        # Define the delta_h function\n",
        "        delta_h_values = torch.abs(probs**2 * (1 - 2 * torch.log(probs + epsilon)) - true_probs**2 * (1 - 2 * torch.log(true_probs + epsilon))) / (2 * (probs + true_probs))\n",
        "\n",
        "        # Compute DLITE loss for each class\n",
        "        dl_values = g_values - delta_h_values\n",
        "\n",
        "        # Sum over all classes and average over batch size\n",
        "        loss = dl_values.sum(dim=-1).mean()\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56a99bb4",
      "metadata": {
        "id": "56a99bb4"
      },
      "outputs": [],
      "source": [
        "dlite_loss_fn = DLITELoss()\n",
        "\n",
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "\n",
        "        # implement dlite loss function\n",
        "        flatten_targets = targets.view(-1)\n",
        "        flatten_logits = tr_logits.view(-1, model.num_labels)\n",
        "\n",
        "        loss = dlite_loss_fn(flatten_logits, flatten_targets)\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training dlite loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb554fde",
      "metadata": {
        "id": "cb554fde"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb6661bf",
      "metadata": {
        "id": "fb6661bf"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "\n",
        "            # implement dlite loss\n",
        "            flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            flatten_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            loss = dlite_loss_fn(flatten_logits, flatten_targets)\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation dlite loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    return labels, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af598b56",
      "metadata": {
        "id": "af598b56"
      },
      "outputs": [],
      "source": [
        "labels, predictions = valid(model, testing_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c838bbe",
      "metadata": {
        "id": "0c838bbe"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report([labels], [predictions]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"India has a capital called Mumbai. On Wednesday, the president will give a presentation\"\n",
        "\n",
        "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "\n",
        "# move to gpu\n",
        "ids = inputs[\"input_ids\"].to(device)\n",
        "mask = inputs[\"attention_mask\"].to(device)\n",
        "# forward pass\n",
        "outputs = model(ids, mask)\n",
        "logits = outputs[0]\n",
        "\n",
        "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
        "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "word_level_predictions = []\n",
        "for pair in wp_preds:\n",
        "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
        "    # skip prediction\n",
        "    continue\n",
        "  else:\n",
        "    word_level_predictions.append(pair[1])\n",
        "\n",
        "# we join tokens, if they are not special ones\n",
        "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
        "print(str_rep)\n",
        "print(word_level_predictions)"
      ],
      "metadata": {
        "id": "FOZzv44SFqgt"
      },
      "id": "FOZzv44SFqgt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-KWCU7vbFqnA"
      },
      "id": "-KWCU7vbFqnA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c0812b0",
      "metadata": {
        "id": "3c0812b0"
      },
      "outputs": [],
      "source": [
        "# using preferred function, dlite loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e10b7ad3",
      "metadata": {
        "id": "e10b7ad3"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 5e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# tokenization\n",
        "\n",
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels\n",
        "\n",
        "# Bert imput\n",
        "\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        sentence = self.data.sentence[index]\n",
        "        word_labels = self.data.word_labels[index]\n",
        "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "# define training size 80/20 split\n",
        "\n",
        "train_size = 0.8\n",
        "train_dataset = data.sample(frac=train_size,random_state=200)\n",
        "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(data.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
        "\n",
        "# pyTorch dataloaders\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id)\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "\n",
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7df515e3",
      "metadata": {
        "id": "7df515e3"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DLITELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DLITELoss, self).__init__()\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        # Convert logits to probabilities using softmax\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        # One-hot encode the targets to get true probabilities\n",
        "        true_probs = F.one_hot(targets, num_classes=probs.size(-1)).float()\n",
        "\n",
        "        # Masks for non-zero elements of probs and true_probs\n",
        "        mask_probs = probs > 0\n",
        "        mask_true_probs = true_probs > 0\n",
        "\n",
        "        # Calculate g function for non-zero elements using the mask\n",
        "        g_probs = torch.zeros_like(probs)\n",
        "        g_true_probs = torch.zeros_like(true_probs)\n",
        "        g_probs[mask_probs] = probs[mask_probs] * (1 - torch.log(probs[mask_probs]))\n",
        "        g_true_probs[mask_true_probs] = true_probs[mask_true_probs] * (1 - torch.log(true_probs[mask_true_probs]))\n",
        "        g_values = torch.abs(g_probs - g_true_probs)\n",
        "\n",
        "        # Calculate delta_h function for non-zero elements using the mask\n",
        "        delta_h_probs = torch.zeros_like(probs)\n",
        "        delta_h_true_probs = torch.zeros_like(true_probs)\n",
        "        delta_h_probs[mask_probs] = probs[mask_probs]**2 * (1 - 2 * torch.log(probs[mask_probs]))\n",
        "        delta_h_true_probs[mask_true_probs] = true_probs[mask_true_probs]**2 * (1 - 2 * torch.log(true_probs[mask_true_probs]))\n",
        "        delta_h_values = torch.abs(delta_h_probs - delta_h_true_probs) / (2 * (probs + true_probs))\n",
        "\n",
        "        # Compute DLITE loss for each class\n",
        "        dl_values = g_values - delta_h_values\n",
        "\n",
        "        # Sum over all classes and average over the batch size\n",
        "        loss = dl_values.sum(dim=-1).mean()\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b3dfbbd",
      "metadata": {
        "id": "6b3dfbbd"
      },
      "outputs": [],
      "source": [
        "dlite_loss_fn = DLITELoss()\n",
        "\n",
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "\n",
        "        # implement dlite loss function\n",
        "        flatten_targets = targets.view(-1)\n",
        "        flatten_logits = tr_logits.view(-1, model.num_labels)\n",
        "\n",
        "        loss = dlite_loss_fn(flatten_logits, flatten_targets)\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training dlite loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa08c800",
      "metadata": {
        "id": "aa08c800"
      },
      "outputs": [],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11a7c9af",
      "metadata": {
        "id": "11a7c9af"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "\n",
        "            # implement dlite loss\n",
        "            flatten_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            flatten_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            loss = dlite_loss_fn(flatten_logits, flatten_targets)\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation dlite loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    return labels, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1af54ebb",
      "metadata": {
        "id": "1af54ebb"
      },
      "outputs": [],
      "source": [
        "labels, predictions = valid(model, testing_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8334c303",
      "metadata": {
        "id": "8334c303"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report([labels], [predictions]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"India has a capital called Mumbai. On Wednesday, the president will give a presentation\"\n",
        "\n",
        "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "\n",
        "# move to gpu\n",
        "ids = inputs[\"input_ids\"].to(device)\n",
        "mask = inputs[\"attention_mask\"].to(device)\n",
        "# forward pass\n",
        "outputs = model(ids, mask)\n",
        "logits = outputs[0]\n",
        "\n",
        "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
        "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "word_level_predictions = []\n",
        "for pair in wp_preds:\n",
        "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
        "    # skip prediction\n",
        "    continue\n",
        "  else:\n",
        "    word_level_predictions.append(pair[1])\n",
        "\n",
        "# we join tokens, if they are not special ones\n",
        "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
        "print(str_rep)\n",
        "print(word_level_predictions)"
      ],
      "metadata": {
        "id": "klGqQGMzFj7m"
      },
      "id": "klGqQGMzFj7m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f7d3aeb",
      "metadata": {
        "id": "2f7d3aeb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1282ab63",
      "metadata": {
        "id": "1282ab63"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2531e79c",
      "metadata": {
        "id": "2531e79c"
      },
      "outputs": [],
      "source": [
        "#supplementary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5ab8cbe",
      "metadata": {
        "id": "f5ab8cbe"
      },
      "outputs": [],
      "source": [
        "train_loss = [2.2325093746185303\n",
        ",0.1979579284307685\n",
        ",0.12895157340849142\n",
        ",0.10328258732736012\n",
        ",0.0878933280035203\n",
        ",0.0783737279979434\n",
        ",0.07320133446384153\n",
        ",0.06823869907501792\n",
        ",0.06492780488316952\n",
        ",0.06174008353984399\n",
        ",0.05902789908278218\n",
        ",0.056935268176432366\n",
        ",0.05499273609083268\n",
        ",0.0533133281321375\n",
        ",0.052311804418082815\n",
        ",0.05142250508731566\n",
        ",0.050630945896185636\n",
        ",0.049709162813297056\n",
        ",0.048903996835184545\n",
        ",0.048022510704321335\n",
        ",0.047283017834851414\n",
        ",0.046424678418659444\n",
        ",0.04591873265289385\n",
        ",0.04537974703723669\n",
        ",0.04482773856807001\n",
        ",0.044695471722741756\n",
        ",0.0442344236395045\n",
        ",0.04382670562562537\n",
        ",0.043526379945136834\n",
        ",0.042959065997332783\n",
        ",0.042615813321918244\n",
        ",0.04236366690313837\n",
        ",0.04194363717661335\n",
        ",0.041636375546184115\n",
        ",0.04127128278829146\n",
        ",0.040830182668952344\n",
        ",0.040511208626328704\n",
        ",0.04015171905060302\n",
        ",0.03998226949771771\n",
        ",0.03974237102390194\n",
        ",0.039552484788377966\n",
        ",0.03925740381365571\n",
        ",0.03909101153347049\n",
        ",0.03885572383529452\n",
        ",0.038653940598617584\n",
        ",0.038488645594775474\n",
        ",0.038240548501359634\n",
        ",0.03800850534515674\n",
        ",0.037811750453333466\n",
        ",0.03761026566804916\n",
        ",0.03742966236035337\n",
        ",0.037274709314759034\n",
        ",0.03722820342288905\n",
        ",0.03705529322322318\n",
        ",0.03687602514696104\n",
        ",0.036694977386151295\n",
        ",0.036629343080851216\n",
        ",0.03644962136436507\n",
        ",0.03636226016797601\n",
        ",0.03613686500790709\n",
        ",0.035993703895092134\n",
        ",0.035869906830048585\n",
        ",0.03573250684088324\n",
        ",0.03559945397448514\n",
        ",0.0354758132030313\n",
        ",0.03540891779299771\n",
        ",0.03532459841772547\n",
        ",0.03520177065284388\n",
        ",0.035112940754735596\n",
        ",0.034968782362413756\n",
        ",0.034851248161488387\n",
        ",0.03479361125706784\n",
        ",0.03466927684660891\n",
        ",0.03457833603794154\n",
        ",0.034532723558633203\n",
        ",0.03444788609688939\n",
        ",0.034326689096761995\n",
        ",0.03421140569255102\n",
        ",0.03412737015806481\n",
        ",0.034008684251748016\n",
        ",0.03394792483909402\n",
        ",0.03389268621911891\n",
        ",0.0338584198185477\n",
        ",0.033820015794525676\n",
        ",0.03375752592415768\n",
        ",0.03371273689236913\n",
        ",0.033630659235927354\n",
        ",0.0335223192349297\n",
        ",0.03347988172628834\n",
        ",0.03342515947154852\n",
        ",0.03338083248692902\n",
        ",0.03329662269781074\n",
        ",0.033256497778373945\n",
        ",0.03323929868624935\n",
        ",0.03318744341058361\n",
        ",0.033132966347406215\n",
        "]\n",
        "\n",
        "val_loss = [0.0004504175449255854\n",
        ",0.020999852330902232\n",
        ",0.024837858137963208\n",
        ",0.02643324451021778\n",
        ",0.02730427119373993\n",
        ",0.027486739688979134\n",
        ",0.02716654109358864\n",
        ",0.026838445321209162\n",
        ",0.02611335244361275\n",
        ",0.02633049204775431\n",
        ",0.025937548436633658\n",
        ",0.025770300013460923\n",
        ",0.026005364909461825\n",
        ",0.026456152055700594\n",
        ",0.02650550593533419\n",
        ",0.02615778042942174\n",
        ",0.026060040542358456\n",
        ",0.025959265149952983\n",
        ",0.026003249076909714\n",
        ",0.025804673071758936\n",
        ",0.02603425900868543\n",
        ",0.02640873462428003\n",
        ",0.02640183253427328\n",
        ",0.02626056144045647\n",
        ",0.025982746248886617\n",
        ",0.026291238948046514\n",
        ",0.026189267576610494\n",
        ",0.02632155728957276\n",
        ",0.026337634692630715\n",
        ",0.026306505561406422\n",
        ",0.02646202455662978\n",
        ",0.026598204387275774\n",
        ",0.02650092320310233\n",
        ",0.02659494341949986\n",
        ",0.026761365918512966\n",
        ",0.02679626689326632\n",
        ",0.026806609066234773\n",
        ",0.026728623379799494\n",
        ",0.02678413699066005\n",
        ",0.02677149474938725\n",
        ",0.026680416342943096\n",
        ",0.026583757406345828\n",
        ",0.02648283885511433\n",
        ",0.026358857102755123\n",
        ",0.026422911207087077\n",
        ",0.02649165671957513\n",
        ",0.02645034227771821\n",
        ",0.026437492430170365\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cd3b70b",
      "metadata": {
        "id": "8cd3b70b"
      },
      "outputs": [],
      "source": [
        "train_loss1 = [2.5125837326049805\n",
        ",0.18495027390815835\n",
        ",0.1260197929787769\n",
        ",0.10287963366135955\n",
        ",0.08980680358110743\n",
        ",0.07864732964674453\n",
        ",0.07286720020973902\n",
        ",0.0679733717316541\n",
        ",0.06474917087984154\n",
        ",0.06170449949946714\n",
        ",0.0585274608714132\n",
        ",0.0568599446287986\n",
        ",0.05517868011810667\n",
        ",0.053381042903191483\n",
        ",0.05212022383795548\n",
        ",0.05103034733411956\n",
        ",0.05007359942048003\n",
        ",0.04921441449109478\n",
        ",0.04848727054683505\n",
        ",0.047801279022933026\n",
        ",0.046846523765066844\n",
        ",0.046105911105422163\n",
        ",0.04533718291189613\n",
        ",0.04482896972519679\n",
        ",0.044304396230472394\n",
        ",0.04400880676996308\n",
        ",0.043659349859601564\n",
        ",0.043366642550747014\n",
        ",0.04283153417424466\n",
        ",0.04248384785821089\n",
        ",0.04209979105635969\n",
        ",0.0418293478965565\n",
        ",0.041488571700002704\n",
        ",0.04119593738525007\n",
        ",0.040843214627934644\n",
        ",0.040562539309893286\n",
        ",0.040294503173009165\n",
        ",0.03997987574220856\n",
        ",0.03967427169556858\n",
        ",0.03943999163827388\n",
        ",0.03929245764219798\n",
        ",0.03913553452312235\n",
        ",0.038924633530431615\n",
        ",0.03867104271354339\n",
        ",0.03847319712893771\n",
        ",0.03821012117788919\n",
        ",0.03811462049593155\n",
        ",0.03798709852122139\n",
        ",0.037854854175139334\n",
        ",0.037669485746302564\n",
        ",0.03759296579544777\n",
        ",0.037351109683174274\n",
        ",0.03719115494183808\n",
        ",0.037069306896644456\n",
        ",0.036854485109253106\n",
        ",0.03666568191148128\n",
        ",0.0365425059483579\n",
        ",0.03642314951458973\n",
        ",0.03631088431128819\n",
        ",0.03610955552272308\n",
        ",0.03608332045832553\n",
        ",0.03592896814518045\n",
        ",0.035820163685179145\n",
        ",0.03568763501286622\n",
        ",0.03555100793679036\n",
        ",0.035510147342936955\n",
        ",0.03545331921066251\n",
        ",0.03532558147283747\n",
        ",0.03525144194395188\n",
        ",0.03515092285867162\n",
        ",0.03511770487004451\n",
        ",0.03499624451666041\n",
        ",0.034896817224015775\n",
        ",0.03476217683463235\n",
        ",0.03465939276700504\n",
        ",0.03455587062289829\n",
        ",0.034460702522672144\n",
        ",0.034334936586999314\n",
        ",0.03427597760785932\n",
        ",0.03421890534452117\n",
        ",0.034206896386595964\n",
        ",0.034097469688177964\n",
        ",0.03403980722749401\n",
        ",0.03397811568438874\n",
        ",0.03387436536485025\n",
        ",0.03381546306758436\n",
        ",0.03371997943488411\n",
        ",0.03368235483623164\n",
        ",0.033646932265442374\n",
        ",0.033613810221844544\n",
        ",0.03357742478194162\n",
        ",0.03350178679616318\n",
        ",0.03342250592728775\n",
        ",0.033375230891496105\n",
        ",0.03328310861639536\n",
        ",0.033202405200214655\n",
        "]\n",
        "\n",
        "val_loss1 = [0.017590003088116646\n",
        ",0.02675862360803588\n",
        ",0.03159482722838591\n",
        ",0.03084583202226318\n",
        ",0.02898786961331939\n",
        ",0.02738359260827732\n",
        ",0.027094627684943504\n",
        ",0.02709027058754846\n",
        ",0.027994495634380057\n",
        ",0.02741310348702588\n",
        ",0.02761579330744299\n",
        ",0.02781156853523731\n",
        ",0.027182493401352127\n",
        ",0.027438449549604622\n",
        ",0.027884448385013298\n",
        ",0.027634959299268506\n",
        ",0.02754228485070776\n",
        ",0.02746705717095571\n",
        ",0.02741693189322655\n",
        ",0.02744888707405706\n",
        ",0.02747464233776402\n",
        ",0.027580890003794645\n",
        ",0.027258598224814433\n",
        ",0.027179132774608837\n",
        ",0.027273053928008415\n",
        ",0.027172842783134626\n",
        ",0.02736645159441055\n",
        ",0.027284132521992396\n",
        ",0.02712221650239909\n",
        ",0.02708375964100197\n",
        ",0.02706333861407238\n",
        ",0.027089703420553602\n",
        ",0.02711124042656694\n",
        ",0.02724569468029756\n",
        ",0.027299724766134726\n",
        ",0.027251111255788326\n",
        ",0.027312134299982516\n",
        ",0.027318999080233827\n",
        ",0.027316816045153566\n",
        ",0.027270148031844285\n",
        ",0.027224115678311085\n",
        ",0.027315830894194836\n",
        ",0.02735427692738019\n",
        ",0.0274134942769153\n",
        ",0.02737298361498944\n",
        ",0.027322298095235505\n",
        ",0.027245115432797624\n",
        ",0.02722037587502722\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c683cc29",
      "metadata": {
        "id": "c683cc29"
      },
      "outputs": [],
      "source": [
        "train_loss2 = [0.7031505107879639\n",
        ",0.05740733703801242\n",
        ",0.0473253355681229\n",
        ",0.04399225958510831\n",
        ",0.04183098877837621\n",
        ",0.04094505903695407\n",
        ",0.04045199655597261\n",
        ",0.03972181384758087\n",
        ",0.03964800694417447\n",
        ",0.039297096521344776\n",
        ",0.03930038988668044\n",
        ",0.03885559976299388\n",
        ",0.03864053552761402\n",
        ",0.03859179740160762\n",
        ",0.038579006425024764\n",
        ",0.03844150174701159\n",
        ",0.03828318008995146\n",
        ",0.038310948596106675\n",
        ",0.03820864622735393\n",
        ",0.03819713182816258\n",
        ",0.03815251966884678\n",
        ",0.038247790875852304\n",
        ",0.038119610761701554\n",
        ",0.03800761074956026\n",
        ",0.037945560200657424\n",
        ",0.03786500180067756\n",
        ",0.03789272194899275\n",
        ",0.037947280376118005\n",
        ",0.03787380185961647\n",
        ",0.03785450959432928\n",
        ",0.037828671335272866\n",
        ",0.03778180737015239\n",
        ",0.03774212558066753\n",
        ",0.03765631682996896\n",
        ",0.03766627247569779\n",
        ",0.03764831265800561\n",
        ",0.03770401645820492\n",
        ",0.03769548518586607\n",
        ",0.037627275290299474\n",
        ",0.037547033628253616\n",
        ",0.03754060079925228\n",
        ",0.037513043830954766\n",
        ",0.03748586284039183\n",
        ",0.037464027127843094\n",
        ",0.03745826741559379\n",
        ",0.037416309247728284\n",
        ",0.03743729774086905\n",
        ",0.037437031681921445\n",
        ",0.03739487158746336\n",
        ",0.037341277864638374\n",
        ",0.03728865300479613\n",
        ",0.037255318217658734\n",
        ",0.03723603038197444\n",
        ",0.03726278637297747\n",
        ",0.03730120614732068\n",
        ",0.0373243803193035\n",
        ",0.03733835628407951\n",
        ",0.03735149771148705\n",
        ",0.03732479246408156\n",
        ",0.03732215939616888\n",
        ",0.03734141879602917\n",
        ",0.03729345859374249\n",
        ",0.037277281081412726\n",
        ",0.037280523976738575\n",
        ",0.037216536719771945\n",
        ",0.03726177163504714\n",
        ",0.03722397180838852\n",
        ",0.03725375368961379\n",
        ",0.037247048598605344\n",
        ",0.037276480704400525\n",
        ",0.037248160077334\n",
        ",0.0372310882396616\n",
        ",0.03721774478711154\n",
        ",0.03718015507710423\n",
        ",0.03718369341331026\n",
        ",0.037166566869474206\n",
        ",0.037212073674159234\n",
        ",0.037204406451052344\n",
        ",0.03721020493125957\n",
        ",0.03721832830207442\n",
        ",0.03724821812324466\n",
        ",0.03723831218686171\n",
        ",0.0372808037432135\n",
        ",0.037253567409440004\n",
        ",0.03723000153407302\n",
        ",0.0372143419486291\n",
        ",0.03723333545942717\n",
        ",0.037255259246375086\n",
        ",0.03723252248193996\n",
        ",0.0372401385294287\n",
        ",0.03725366090660408\n",
        ",0.03723941650219853\n",
        ",0.03725498750640194\n",
        ",0.037241664826044234\n",
        ",0.037229248718724975\n",
        ",0.03720373181251393\n",
        "]\n",
        "\n",
        "val_loss2 = [0.011718887835741043\n",
        ",0.034808284924720725\n",
        ",0.036128069394574164\n",
        ",0.03574035671695919\n",
        ",0.03563368818849707\n",
        ",0.035101787941398135\n",
        ",0.035474845554163414\n",
        ",0.035747039658921016\n",
        ",0.03568792775506761\n",
        ",0.03519104969886379\n",
        ",0.03564806127220303\n",
        ",0.03578789359458274\n",
        ",0.03575807760657982\n",
        ",0.03591299487513343\n",
        ",0.03600118588018651\n",
        ",0.03608283080771746\n",
        ",0.036151836646261676\n",
        ",0.03611398195667589\n",
        ",0.03642952900258235\n",
        ",0.03659064267067222\n",
        ",0.036524821119612465\n",
        ",0.03663631463475025\n",
        ",0.036691533213124225\n",
        ",0.03650598171521872\n",
        ",0.03652786354710667\n",
        ",0.03657454740532526\n",
        ",0.03653504116245877\n",
        ",0.03653172337113875\n",
        ",0.036528642453288324\n",
        ",0.036614644068770144\n",
        ",0.03659078230558523\n",
        ",0.03656594018529557\n",
        ",0.036508481230024405\n",
        ",0.03641426960524744\n",
        ",0.03635660926981339\n",
        ",0.036312284625651774\n",
        ",0.03637564419424517\n",
        ",0.03631314683270395\n",
        ",0.03634848534150437\n",
        ",0.036390022833531654\n",
        ",0.036470489319197025\n",
        ",0.036443207887131776\n",
        ",0.03646650663983643\n",
        ",0.036476915145432\n",
        ",0.036572946061077666\n",
        ",0.03654234135247587\n",
        ",0.03650712400767543\n",
        ",0.03645429335268326\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "636b577fdb514e16be0728f5951e0393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46d0ce3c77c148d3874831062674d1f3",
              "IPY_MODEL_03907f2becdd4b12ae6b4416ece0b114",
              "IPY_MODEL_2c198740c29f4c66908941e5f64a4379"
            ],
            "layout": "IPY_MODEL_5c7de95e0e7142e5a304fdfdff42e53e"
          }
        },
        "46d0ce3c77c148d3874831062674d1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_172cc15cc3494ff18cbdb15134979265",
            "placeholder": "​",
            "style": "IPY_MODEL_ddd5e777b74242c4a4cd60b8b36b7d94",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "03907f2becdd4b12ae6b4416ece0b114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e046b47f1c243bb874c400eb30de6b3",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8f6392e39234ef6862cdb18454e87ae",
            "value": 28
          }
        },
        "2c198740c29f4c66908941e5f64a4379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_829158fe13ad4541a9844f08cdfeba01",
            "placeholder": "​",
            "style": "IPY_MODEL_f81b5919b42c44cbb553a3c4a3d79310",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.21kB/s]"
          }
        },
        "5c7de95e0e7142e5a304fdfdff42e53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "172cc15cc3494ff18cbdb15134979265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddd5e777b74242c4a4cd60b8b36b7d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e046b47f1c243bb874c400eb30de6b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f6392e39234ef6862cdb18454e87ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "829158fe13ad4541a9844f08cdfeba01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f81b5919b42c44cbb553a3c4a3d79310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "830f038d381548dd8477d99dfa72c02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_455692e589f043aeb01f431d0c744a74",
              "IPY_MODEL_8d48248bccb949be80ddc59c67d3418f",
              "IPY_MODEL_46dedb4ca9d04f1ca0d1f27e79542e41"
            ],
            "layout": "IPY_MODEL_347d67ad6473483da745bd209dd0c114"
          }
        },
        "455692e589f043aeb01f431d0c744a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0e11f920d3e4643b54e7e7f75cc9795",
            "placeholder": "​",
            "style": "IPY_MODEL_263dc4daf4ac42298fce3a764929149b",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "8d48248bccb949be80ddc59c67d3418f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61cf59214b674b90891053349e98df57",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6617c52f387470eb3e94e4639c2ec25",
            "value": 231508
          }
        },
        "46dedb4ca9d04f1ca0d1f27e79542e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc7cde1413dc4cc9979322b560fd0e85",
            "placeholder": "​",
            "style": "IPY_MODEL_4c4fd5319bc047a4a8eb8fa3609be486",
            "value": " 232k/232k [00:00&lt;00:00, 4.92MB/s]"
          }
        },
        "347d67ad6473483da745bd209dd0c114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0e11f920d3e4643b54e7e7f75cc9795": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "263dc4daf4ac42298fce3a764929149b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61cf59214b674b90891053349e98df57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6617c52f387470eb3e94e4639c2ec25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc7cde1413dc4cc9979322b560fd0e85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c4fd5319bc047a4a8eb8fa3609be486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33f83eae687547f8bf6867a26c580b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e324e7a464a46cea522c46661e1d999",
              "IPY_MODEL_854f37304f584183a0fe823ec4f1b422",
              "IPY_MODEL_d63b14d9e3ac456288f1df1fddaad54a"
            ],
            "layout": "IPY_MODEL_ff3fc5058a674b71b77aaa9816ab4375"
          }
        },
        "4e324e7a464a46cea522c46661e1d999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ccf450bdccc4aeaaaab418bdfb3730f",
            "placeholder": "​",
            "style": "IPY_MODEL_fc326b61c86141f3bbc6c7ecb7a5a464",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "854f37304f584183a0fe823ec4f1b422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efd4478c2f624ab4a6c2e48cb58a2ce9",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9442af9224df4d1481f4c2270c348853",
            "value": 466062
          }
        },
        "d63b14d9e3ac456288f1df1fddaad54a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2220e7d9c9f41d2af5dd7faf2f556e5",
            "placeholder": "​",
            "style": "IPY_MODEL_8385c9bd721943a6a6e3303a0c7c45cb",
            "value": " 466k/466k [00:00&lt;00:00, 19.3MB/s]"
          }
        },
        "ff3fc5058a674b71b77aaa9816ab4375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ccf450bdccc4aeaaaab418bdfb3730f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc326b61c86141f3bbc6c7ecb7a5a464": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efd4478c2f624ab4a6c2e48cb58a2ce9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9442af9224df4d1481f4c2270c348853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2220e7d9c9f41d2af5dd7faf2f556e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8385c9bd721943a6a6e3303a0c7c45cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2193ecab5534678b5c35b0bd79eb4c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95b3aa2547ea4256a876932221074c4f",
              "IPY_MODEL_c920bb5c7f9f4dc6af9798854d57fa37",
              "IPY_MODEL_06de1580543d4fb197493a21774376c1"
            ],
            "layout": "IPY_MODEL_1d4059bd32a0462fa53bce23cd0e2c46"
          }
        },
        "95b3aa2547ea4256a876932221074c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c332377a134d4d4ea79518e3bed508ba",
            "placeholder": "​",
            "style": "IPY_MODEL_68510587ef54426696dccba7574c7418",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "c920bb5c7f9f4dc6af9798854d57fa37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee25aae9ac744ab291618e3d5a00ed84",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a708074ed2c84384aff4983b38c14e62",
            "value": 570
          }
        },
        "06de1580543d4fb197493a21774376c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1256ef69288b4e1c9dd778733b683b8b",
            "placeholder": "​",
            "style": "IPY_MODEL_6ea225efb1184159b127f680f459a591",
            "value": " 570/570 [00:00&lt;00:00, 38.7kB/s]"
          }
        },
        "1d4059bd32a0462fa53bce23cd0e2c46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c332377a134d4d4ea79518e3bed508ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68510587ef54426696dccba7574c7418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee25aae9ac744ab291618e3d5a00ed84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a708074ed2c84384aff4983b38c14e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1256ef69288b4e1c9dd778733b683b8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ea225efb1184159b127f680f459a591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ff1522e291d437e8016844b71f379d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c7879e56842467a9b2ae60273e34c15",
              "IPY_MODEL_96ec789815304f87a64112d72e2af4b9",
              "IPY_MODEL_bc72688162e34b209569e2966f0e10db"
            ],
            "layout": "IPY_MODEL_e31cc02cc3634d6f8d04027aba58d94b"
          }
        },
        "1c7879e56842467a9b2ae60273e34c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bbd4f93e8e5410fa40abefb72465983",
            "placeholder": "​",
            "style": "IPY_MODEL_7bd4ee29c8ba487bb46d3137e9cbea8d",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "96ec789815304f87a64112d72e2af4b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d03cc3d66634828809fff81a4e238d6",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_818d3cdd51064224856a7549551eeff2",
            "value": 440449768
          }
        },
        "bc72688162e34b209569e2966f0e10db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e739a059ac114b94a75031c317c57342",
            "placeholder": "​",
            "style": "IPY_MODEL_6759ac2753564fdf81cea9dac8df7fbe",
            "value": " 440M/440M [00:02&lt;00:00, 188MB/s]"
          }
        },
        "e31cc02cc3634d6f8d04027aba58d94b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bbd4f93e8e5410fa40abefb72465983": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bd4ee29c8ba487bb46d3137e9cbea8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d03cc3d66634828809fff81a4e238d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "818d3cdd51064224856a7549551eeff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e739a059ac114b94a75031c317c57342": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6759ac2753564fdf81cea9dac8df7fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
