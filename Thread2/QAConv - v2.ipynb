{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e399d0b7",
   "metadata": {},
   "source": [
    "2024/1/2  \n",
    "Mengyang Xu  \n",
    "  \n",
    "### Updates\n",
    "In section 4, for the questions data of the QAconv data, the embedding methodology also be added to the retrieval system to see if it has positive impacts for the improvement of performance(f1). Moreover, the retrieval sentence is also being used to compare with the GPT4ALL model.  \n",
    "  \n",
    "### Findings\n",
    "1. After adding the embedding, the performance of the system did not make a big difference, perhaps there is still error with the embedding process  \n",
    "2. The retrieve sentence method did solve some prblems for the GPT4ALL model, it located some specific sentences that is related to the question while the GPT4ALL model can not answer. However, it also located some sentences that can not be used to answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b084a",
   "metadata": {},
   "source": [
    "## 1. Data pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0bada0",
   "metadata": {},
   "source": [
    "Combine the questions file and source text together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546510c8",
   "metadata": {},
   "source": [
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.chains import RetrievalQA\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d16c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.chains import RetrievalQA\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain.prompts import PromptTemplate\n",
    "import logging\n",
    "import time\n",
    "from langchain.embeddings.huggingface import HuggingFaceInstructEmbeddings\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0b51d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='E:/QA/article_segment.json'\n",
    "data = json.loads(Path(file_path).read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e457c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=''\n",
    "for i in data['newsdial-984'][\"seg_dialog\"]:\n",
    "    text+=i['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85c051ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data['newsdial-984']['prev_ctx']:\n",
    "    text+=i['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec5e385e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And one senator, for example today, Senator Bob Casey, a Democrat from Pennsylvania, sent a letter to the president urging him - I\\'m quoting from the letter - he says, \"to put an end to these practices immediately, to ensure that the investment decisions being made by Freddie Mac are in line with the intent of Congress and the greater needs of our economy.\" So we also spoke today with Senator Johnny Isakson, a Republican from Georgia, who\\'s also interested in reforming Freddie Mac and Fannie Mae. So I think there are people on Capitol Hill who are starting to really ponder, What is the structure of these organizations and what role do they play? What\\'s appropriate for them to do? And this is just sort of an interesting look at conflicts of interest. We are not, in any way - our story has not said that it is illegal, just that it raises questions about how it functions.Well, you did quote Alan Boyce in your story, a former bond trader who\\'s been involved in efforts to push for more refinancing of home loans. Freddie Mac, he said, prevented households from being able to take advantage of today\\'s mortgage rates and then bet on it. You say, well, Freddie Mac has two arms, one, the left hand, did not necessarily know what the right hand is doing. However, they seemed to be miraculously working in concert.And there are people in Congress now who are starting to wonder about whether or not this should be changed, at the moment, as the laws are structured, and as Freddie Mac\\'s mission is, which is to not go broke. You know, it\\'s supposed to be a solvent organization doing its business, but it\\'s also supposed to be helping homeowners. This structure could be called into question.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4d3068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee71f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv = pd.read_json(\"E:/QA/article_segment.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df4891b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsdial-984</th>\n",
       "      <th>newsdial-924</th>\n",
       "      <th>newsdial-599</th>\n",
       "      <th>newsdial-184</th>\n",
       "      <th>newsdial-144</th>\n",
       "      <th>newsdial-880</th>\n",
       "      <th>newsdial-983</th>\n",
       "      <th>newsdial-129</th>\n",
       "      <th>newsdial-956</th>\n",
       "      <th>newsdial-987</th>\n",
       "      <th>...</th>\n",
       "      <th>newsdial-4842</th>\n",
       "      <th>newsdial-1384</th>\n",
       "      <th>supreme_court-4434</th>\n",
       "      <th>enron_wisrlab-2432</th>\n",
       "      <th>newsdial-3004</th>\n",
       "      <th>enron_wisrlab-1707</th>\n",
       "      <th>newsdial-3646</th>\n",
       "      <th>supreme_court-1113</th>\n",
       "      <th>newsdial-3104</th>\n",
       "      <th>newsdial-3275</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prev_ctx</th>\n",
       "      <td>[{'id': 'newsidal-NPR-166-26', 'speaker': 'MAR...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-162-25', 'speaker': 'NEA...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-132-10', 'speaker': 'RAC...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-38-10', 'speaker': 'Ms. ...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-31-12', 'speaker': 'FARA...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-159-100', 'speaker': 'KA...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-166-23', 'speaker': 'NEA...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-28-25', 'speaker': 'Ms. ...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-163-145', 'speaker': 'SO...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-166-35', 'speaker': 'JEF...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-692-3', 'speaker': 'ELIZ...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-219-102', 'speaker': 'PE...</td>\n",
       "      <td>[{'id': 'court-04-698-28361', 'speaker': 'JUST...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'id': 'newsidal-NPR-486-57', 'speaker': 'NEA...</td>\n",
       "      <td>[{'id': 'enron-enron_wisrlab_60462-0', 'speake...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-554-23', 'speaker': 'I m...</td>\n",
       "      <td>[{'id': 'court-03-636-7031', 'speaker': 'JUSTI...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-491-208', 'speaker': 'ST...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-506-9', 'speaker': 'FARA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_dialog</th>\n",
       "      <td>[{'id': 'newsidal-NPR-166-27', 'speaker': 'MAR...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-162-26', 'speaker': 'AMY...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-132-11', 'speaker': 'URI...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-38-11', 'speaker': 'Ms. ...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-31-13', 'speaker': 'FARA...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-159-101', 'speaker': 'KA...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-166-24', 'speaker': 'CHR...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-28-26', 'speaker': 'MADE...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-163-146', 'speaker': 'NE...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-166-36', 'speaker': 'JEF...</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-692-4', 'speaker': 'MELI...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-219-103', 'speaker': 'JO...</td>\n",
       "      <td>[{'id': 'court-04-698-28362', 'speaker': 'MR. ...</td>\n",
       "      <td>[{'id': 'enron-enron_wisrlab_13011-0', 'speake...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-486-58', 'speaker': 'RIC...</td>\n",
       "      <td>[{'id': 'enron-enron_wisrlab_60462-1', 'speake...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-554-24', 'speaker': 'I m...</td>\n",
       "      <td>[{'id': 'court-03-636-7032', 'speaker': 'MR. D...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-491-209', 'speaker': 'NE...</td>\n",
       "      <td>[{'id': 'newsidal-NPR-506-10', 'speaker': 'Dr....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>237</td>\n",
       "      <td>226</td>\n",
       "      <td>221</td>\n",
       "      <td>248</td>\n",
       "      <td>272</td>\n",
       "      <td>217</td>\n",
       "      <td>213</td>\n",
       "      <td>333</td>\n",
       "      <td>204</td>\n",
       "      <td>263</td>\n",
       "      <td>...</td>\n",
       "      <td>236</td>\n",
       "      <td>228</td>\n",
       "      <td>222</td>\n",
       "      <td>246</td>\n",
       "      <td>240</td>\n",
       "      <td>245</td>\n",
       "      <td>239</td>\n",
       "      <td>284</td>\n",
       "      <td>295</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 18728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 newsdial-984  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-166-26', 'speaker': 'MAR...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-166-27', 'speaker': 'MAR...   \n",
       "word_count                                                237   \n",
       "\n",
       "                                                 newsdial-924  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-162-25', 'speaker': 'NEA...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-162-26', 'speaker': 'AMY...   \n",
       "word_count                                                226   \n",
       "\n",
       "                                                 newsdial-599  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-132-10', 'speaker': 'RAC...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-132-11', 'speaker': 'URI...   \n",
       "word_count                                                221   \n",
       "\n",
       "                                                 newsdial-184  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-38-10', 'speaker': 'Ms. ...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-38-11', 'speaker': 'Ms. ...   \n",
       "word_count                                                248   \n",
       "\n",
       "                                                 newsdial-144  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-31-12', 'speaker': 'FARA...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-31-13', 'speaker': 'FARA...   \n",
       "word_count                                                272   \n",
       "\n",
       "                                                 newsdial-880  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-159-100', 'speaker': 'KA...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-159-101', 'speaker': 'KA...   \n",
       "word_count                                                217   \n",
       "\n",
       "                                                 newsdial-983  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-166-23', 'speaker': 'NEA...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-166-24', 'speaker': 'CHR...   \n",
       "word_count                                                213   \n",
       "\n",
       "                                                 newsdial-129  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-28-25', 'speaker': 'Ms. ...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-28-26', 'speaker': 'MADE...   \n",
       "word_count                                                333   \n",
       "\n",
       "                                                 newsdial-956  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-163-145', 'speaker': 'SO...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-163-146', 'speaker': 'NE...   \n",
       "word_count                                                204   \n",
       "\n",
       "                                                 newsdial-987  ...  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-166-35', 'speaker': 'JEF...  ...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-166-36', 'speaker': 'JEF...  ...   \n",
       "word_count                                                263  ...   \n",
       "\n",
       "                                                newsdial-4842  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-692-3', 'speaker': 'ELIZ...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-692-4', 'speaker': 'MELI...   \n",
       "word_count                                                236   \n",
       "\n",
       "                                                newsdial-1384  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-219-102', 'speaker': 'PE...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-219-103', 'speaker': 'JO...   \n",
       "word_count                                                228   \n",
       "\n",
       "                                           supreme_court-4434  \\\n",
       "prev_ctx    [{'id': 'court-04-698-28361', 'speaker': 'JUST...   \n",
       "seg_dialog  [{'id': 'court-04-698-28362', 'speaker': 'MR. ...   \n",
       "word_count                                                222   \n",
       "\n",
       "                                           enron_wisrlab-2432  \\\n",
       "prev_ctx                                                   []   \n",
       "seg_dialog  [{'id': 'enron-enron_wisrlab_13011-0', 'speake...   \n",
       "word_count                                                246   \n",
       "\n",
       "                                                newsdial-3004  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-486-57', 'speaker': 'NEA...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-486-58', 'speaker': 'RIC...   \n",
       "word_count                                                240   \n",
       "\n",
       "                                           enron_wisrlab-1707  \\\n",
       "prev_ctx    [{'id': 'enron-enron_wisrlab_60462-0', 'speake...   \n",
       "seg_dialog  [{'id': 'enron-enron_wisrlab_60462-1', 'speake...   \n",
       "word_count                                                245   \n",
       "\n",
       "                                                newsdial-3646  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-554-23', 'speaker': 'I m...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-554-24', 'speaker': 'I m...   \n",
       "word_count                                                239   \n",
       "\n",
       "                                           supreme_court-1113  \\\n",
       "prev_ctx    [{'id': 'court-03-636-7031', 'speaker': 'JUSTI...   \n",
       "seg_dialog  [{'id': 'court-03-636-7032', 'speaker': 'MR. D...   \n",
       "word_count                                                284   \n",
       "\n",
       "                                                newsdial-3104  \\\n",
       "prev_ctx    [{'id': 'newsidal-NPR-491-208', 'speaker': 'ST...   \n",
       "seg_dialog  [{'id': 'newsidal-NPR-491-209', 'speaker': 'NE...   \n",
       "word_count                                                295   \n",
       "\n",
       "                                                newsdial-3275  \n",
       "prev_ctx    [{'id': 'newsidal-NPR-506-9', 'speaker': 'FARA...  \n",
       "seg_dialog  [{'id': 'newsidal-NPR-506-10', 'speaker': 'Dr....  \n",
       "word_count                                                215  \n",
       "\n",
       "[3 rows x 18728 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b3882c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA = pd.read_json(\"E:/QAConv-V1.0/QAConv-V1.0/sample.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b532d877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "QA['text']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5356862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'openslack-2635'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA.iloc[0]['article_segment_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08554956",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA.loc[0,'text']='dasdawd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a44c9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(QA)):\n",
    "    text=''\n",
    "    for j in data[QA.iloc[i]['article_segment_id']]['prev_ctx']:\n",
    "        text+=j['text']\n",
    "    for k in data[QA.iloc[i]['article_segment_id']][\"seg_dialog\"]:\n",
    "        text+=k['text']\n",
    "    QA.loc[i,'text']=text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f16e5558",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'QA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m QA\u001b[38;5;241m.\u001b[39mto_json(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQA_data_sample.json\u001b[39m\u001b[38;5;124m'\u001b[39m, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'QA' is not defined"
     ]
    }
   ],
   "source": [
    "QA.to_json('QA_data_sample.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12c6aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='E:/QA/QA_data_sample.json'\n",
    "combined_data = json.loads(Path(file_path).read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c10bcd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python']\n",
      "['Mr. Kneedler']\n",
      "['Al-Azhar University']\n",
      "['FARAI CHIDEYA']\n",
      "['\\\\epsilon']\n",
      "['Katherine Marshall Woods']\n",
      "['baby-shaking case']\n",
      "['CHIEF JUSTICE ROBERTS']\n",
      "['10 of 11']\n",
      "['Don Gonyea']\n"
     ]
    }
   ],
   "source": [
    "combined_data_test=combined_data[0:10]\n",
    "for i in combined_data_test:\n",
    "    print(i['answers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99310f",
   "metadata": {},
   "source": [
    "### The combined data saved to local environment for the later use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346560d6",
   "metadata": {},
   "source": [
    "## 2 Running the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5892e",
   "metadata": {},
   "source": [
    "### 2.1 Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e7f3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import collections\n",
    "\n",
    "def compute_f1(a_gold, a_pred):\n",
    "    gold_toks = word_tokenize(a_gold)\n",
    "    pred_toks = word_tokenize(a_pred)\n",
    "    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
    "    num_same = sum(common.values())\n",
    "    \n",
    "    if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
    "        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
    "        return int(gold_toks == pred_toks)\n",
    "    \n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    \n",
    "    precision = 1.0 * num_same / len(pred_toks)\n",
    "    recall = 1.0 * num_same / len(gold_toks)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd9eb283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible. \n",
    "Also provide me the source for your answer. Explain how to get the answer step by step.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "llm = GPT4All(model=\"E:/ggml-model-gpt4all-falcon-q4_0.bin\", max_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a325108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "CPU times: total: 1h 33min 10s\n",
      "Wall time: 23min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "answers_pairs=[]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0.1)\n",
    "\n",
    "\n",
    "for cov in combined_data:\n",
    "    all_splits = text_splitter.split_text(cov['text'])\n",
    "    vectorstore = Chroma.from_texts(texts=all_splits, embedding=GPT4AllEmbeddings())\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever(), return_source_documents=True)\n",
    "    \n",
    "    question = cov['question']\n",
    "    docs = vectorstore.similarity_search(question)\n",
    "    predict = qa_chain({\"query\": question})\n",
    "    answers_pairs.append((cov['answers'],predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a64054",
   "metadata": {},
   "source": [
    "### 2.1 Result Evaluation(F1 Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8e51af9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which program does Suellen reference that shares its name with a snake?\n",
      "Predicted Answer:  Sueellen references the program called `snake` in her code.\n",
      "Actual Answer: Python\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which person is talking to the Chief Justice?\n",
      "Predicted Answer:  The person talking to the Chief Justice is Ms. Lee.\n",
      "Actual Answer: Mr. Kneedler\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the most important center of learning of Sunni Islam in the country where the pope is going to celebrate a mass tomorrow ?\n",
      "Predicted Answer:  The most important center of learning of Sunni Islam in the country where the pope is going to celebrate a mass tomorrow is Al Azhar University.\n",
      "Actual Answer: Al-Azhar University\n",
      "F1 Score: 0.0690\n",
      "\n",
      "Question: Who hosts NEWS & NOTES?\n",
      "Predicted Answer:  The context does not provide information about who hosts NEWS & NOTEs.\n",
      "Actual Answer: FARAI CHIDEYA\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which feature in DrRacket inserts an epsilon?\n",
      "Predicted Answer:  The `equal+hash` feature in DrRacket inserts an epsilon.\n",
      "Actual Answer: \\epsilon\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the clinical psychologist with the Psychological Group of Washington?\n",
      "Predicted Answer:  Taniesha Woods.\n",
      "Actual Answer: Katherine Marshall Woods\n",
      "F1 Score: 0.3333\n",
      "\n",
      "Question: what was the name of the case?\n",
      "Predicted Answer:  The case being referred to is the Baby-Shaking case.\n",
      "Actual Answer: baby-shaking case\n",
      "F1 Score: 0.1667\n",
      "\n",
      "Question: Who is the Chief Justice of  United States ?\n",
      "Predicted Answer:  The Chief Justice of the United States is currently John G. Roberts Jr.\n",
      "Actual Answer: CHIEF JUSTICE ROBERTS\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What proportion of African American jurors were struck?\n",
      "Predicted Answer:  The proportion of African American jurors who were struck during the trial cannot be determined from the given context.\n",
      "Actual Answer: 10 of 11\n",
      "F1 Score: 0.0833\n",
      "\n",
      "Question: Which NPR reporter was traveling in South Carolina?\n",
      "Predicted Answer:  The context does not provide information about which NPR reporter was traveling in South Carolina.\n",
      "Actual Answer: Don Gonyea\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Who is the only person that needs Denis O'Connell to sign a bilateral NDA?\n",
      "Predicted Answer:  The only person who needs Denis O'Connell to sign a bilateral ND\n",
      "Actual Answer: Leslie.Hansen\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: In which industry lynda need the survey about developers?\n",
      "Predicted Answer:  The survey is for developers in the tech industry.\n",
      "Actual Answer: tech industry\n",
      "F1 Score: 0.3333\n",
      "\n",
      "Question: What is the name of the petitioner in the case?\n",
      "Predicted Answer:  The petitioner in the case is not provided in the given context.\n",
      "Actual Answer: Mr. Lamken\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which act has a piece missing from it, according to the Circuit court?\n",
      "Predicted Answer:  The Circuit court believes that the FCPA does not provide protection for speech that is part of an employee's normal duties.\n",
      "Actual Answer: Federal Whistle-blower Protection Act\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which restatement section was based on injured party?\n",
      "Predicted Answer:  The reliance section, section three-24 says reliance is from the other for the injured party.\n",
      "Actual Answer: Section 324\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: How many months of unpaid leave does anyone with a permanent position have in Sweden ?\n",
      "Predicted Answer:  Anyone with a permanent position has a legal right to take up to 6 months of unpaid leave in Sweden.\n",
      "Actual Answer: six\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the amendment that requires reliability in the determination that death is an appropriate sentence ?\n",
      "Predicted Answer:  The amendment that requires reliability in the determination that death is an appropriate sentence is the Eighth Amendment.\n",
      "Actual Answer: Eighth Amendment\n",
      "F1 Score: 0.1905\n",
      "\n",
      "Question: Which month does Kate think the price of $292.50 possibly sounds right for?\n",
      "Predicted Answer:  It's difficult to determine which month the price of $292.50 possibly sounds right for without further context or information.\n",
      "Actual Answer: May\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: In which case Judge Weis gave his opinion ?\n",
      "Predicted Answer:  Judge Wei's opinion can be found in the case of Meritcare v. St. Paul.\n",
      "Actual Answer: Meritcare v. St. Paul\n",
      "F1 Score: 0.4000\n",
      "\n",
      "Question: Which company is giving the official confirmation letter for not to use their representative name?\n",
      "Predicted Answer:  It is not clear from the given context which company is giving the official confirmation letter for not to use their representative name.\n",
      "Actual Answer: Lehman Brothers Inc\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Jason Rezaian wrote stories for which paper?\n",
      "Predicted Answer:  The context does not provide information about which paper Jason Rezaiana wrote stories for.\n",
      "Actual Answer: the Washington Post\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Where does Deeanna want to move 'blueprints' into?\n",
      "Predicted Answer:  Deeanna wants to move 'blueprint's into 'ko\n",
      "Actual Answer: `koyo-lib`\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What time is the OU-Enron game ?\n",
      "Predicted Answer:  The game starts at 7:00pm.\n",
      "Actual Answer: 700\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What type of spy would have rights under regulations for handling secret contracts , Justice Clemmler says ?\n",
      "Predicted Answer:  It is unclear from the given context what type of spy would have rights under regulations for handling secret contracts.\n",
      "Actual Answer: were a party to a secret contract or at least a secret relationship\n",
      "F1 Score: 0.0588\n",
      "\n",
      "Question: Which types of networks are involved?\n",
      "Predicted Answer:  The given context does not provide specific information about the type of networks involved. However, based on the mention of a spreading-activation network and a network by which nodes support industry, it can be inferred that these networks may involve some form of social or economic interactions between nodes.\n",
      "Actual Answer: a spreading-activation network and a network by which nodes support the continued existence of other nodes\n",
      "F1 Score: 0.3768\n",
      "\n",
      "Question: Transactions will be between which two entities?\n",
      "Predicted Answer:  The context does not provide specific information about the parties involved in the transactions. However, it is mentioned that EnrOnine operates as a marketplace operator and customers can display products on <url> using the remote stack manager. It is also mentioned that Enron does not stand in the middle for credit and that they are a marketplace operator.\n",
      "Actual Answer: company offering product and customer\n",
      "F1 Score: 0.0290\n",
      "\n",
      "Question: What program allows the user to parallelize the tests and is recommended by Karoline?\n",
      "Predicted Answer:  pytest-parallel is recommended by Karoline for parallelization of tests.\n",
      "Actual Answer: pytest-parallel\n",
      "F1 Score: 0.1818\n",
      "\n",
      "Question: What does the Court say imposes restrictions on the discretion of police?\n",
      "Predicted Answer:  The Fourth Amendment imposes restrictions on the discretion of police officers and parole officers that are meaningful, as the Reyes Court said, there are restrictions on the timing, the frequency, the duration, and the oppressiveness of the search.\n",
      "Actual Answer: restrictions on the timing, the frequency, the duration, and the oppressiveness of the search\n",
      "F1 Score: 0.5574\n",
      "\n",
      "Question: Who is restrained in the circumstances of the trial?\n",
      "Predicted Answer:  The traffic offender who is restrained with non-visible restraints.\n",
      "Actual Answer: Mr. Deck\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What kind of action is referenced by Scalia when the prosecutor has died?\n",
      "Predicted Answer:  The question does not provide specific information about the type of action being referred to.\n",
      "Actual Answer: habeas action\n",
      "F1 Score: 0.1111\n",
      "\n",
      "Question: Why will the process be legthier?\n",
      "Predicted Answer:  The process will be easier because it will be split into two separate approvals, one for Legal and another for MSRs Dilworth and Forshter. This will make it easier to move the process along without delays caused by overlapping approvals.\n",
      "Actual Answer: the legal due-diligence\n",
      "F1 Score: 0.0435\n",
      "\n",
      "Question: who is the first speaker?\n",
      "Predicted Answer:  The first speaker in the given context is Judge Wei Shing Lee.\n",
      "Actual Answer: MR. HURD\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which country has the new plane stuck?\n",
      "Predicted Answer:  The new plane is stuck in Iran.\n",
      "Actual Answer: Iran.\n",
      "F1 Score: 0.4000\n",
      "\n",
      "Question: Which names have Julia been experimenting more with capitalizing?\n",
      "Predicted Answer:  It is not clear from the given context which names Captain Obvious has experimented with capitalizing.\n",
      "Actual Answer: struct names\n",
      "F1 Score: 0.1053\n",
      "\n",
      "Question: What is the name of the casting director for the film Wendy Raquel Robinsondo worked on?\n",
      "Predicted Answer:  The name of the casting director for the film Wendy Raquel Robinson worked on is not provided in the given context.\n",
      "Actual Answer: Robi Reed\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which person is Neal hosting on the show?\n",
      "Predicted Answer:  Neal is hosting the show with Geoffrey Bennett, Tambae Obeinson, Katherine Marshall Woods, and Farai Chatzarakis.\n",
      "Actual Answer: Naomi Oreskes\n",
      "F1 Score: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in answers_pairs:\n",
    "    f1_score = compute_f1(i[0][0],i[1]['result'])\n",
    "    print(f\"Question: {i[1]['query']}\")\n",
    "    print(f\"Predicted Answer: {i[1]['result']}\")\n",
    "    print(f\"Actual Answer: {i[0][0]}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1176c108",
   "metadata": {},
   "source": [
    "## 3 Attempt at Instruct Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "026f7929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting InstructorEmbedding\n",
      "  Obtaining dependency information for InstructorEmbedding from https://files.pythonhosted.org/packages/6c/fc/64375441f43cc9ddc81f76a1a8f516e6d63f5b6ecb67fffdcddc0445f0d3/InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata\n",
      "  Using cached InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Using cached InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
      "Installing collected packages: InstructorEmbedding\n",
      "Successfully installed InstructorEmbedding-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install InstructorEmbedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0335bf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (2.1.2)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98f02eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (4.32.1)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (2.1.2)\n",
      "Collecting torchvision (from sentence-transformers)\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/f9/e6/3c821e7417acd82df89e39f09156ce80d58817b5b4b1ac5453b522bc5dd4/torchvision-0.16.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torchvision-0.16.2-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: nltk in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (3.8.1)\n",
      "Collecting sentencepiece (from sentence-transformers)\n",
      "  Using cached sentencepiece-0.1.99-cp311-cp311-win_amd64.whl (977 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in d:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.2)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda\\lib\\site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Using cached torchvision-0.16.2-cp311-cp311-win_amd64.whl (1.1 MB)\n",
      "Installing collected packages: sentencepiece, torchvision, sentence-transformers\n",
      "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99 torchvision-0.16.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cb336e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (2.1.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (0.16.2)\n",
      "Collecting torchaudio\n",
      "  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/c9/c0/b738db223b85c0096e2c3b1aaa647419f9af68331f8ad09dba6a2d38136c/torchaudio-2.1.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torchaudio-2.1.2-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torchaudio-2.1.2-cp311-cp311-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.3 MB 787.7 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.3/2.3 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.3 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.3/2.3 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 10.6 MB/s eta 0:00:00\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abcbab5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible. \n",
    "Also provide me the source for your answer. Explain how to get the answer step by step.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "llm = GPT4All(model=\"E:/ggml-model-gpt4all-falcon-q4_0.bin\", max_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c16e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct_embedding_model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "instruct_embedding_model_kwargs = {'device': 'cpu'}\n",
    "instruct_embedding_encode_kwargs = {'normalize_embeddings': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa0c89ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python311\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "CPU times: total: 1h 25min 42s\n",
      "Wall time: 21min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "answers_pairs=[]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0.1)\n",
    "\n",
    "word_embed = HuggingFaceInstructEmbeddings(\n",
    "    model_name=instruct_embedding_model_name,\n",
    "    model_kwargs=instruct_embedding_model_kwargs,\n",
    "    encode_kwargs=instruct_embedding_encode_kwargs,\n",
    "    embed_instruction=\"Represent the story for retrieval:\"\n",
    ")\n",
    "\n",
    "for cov in combined_data:\n",
    "    all_splits = text_splitter.split_text(cov['text'])\n",
    "    vectorstore = Chroma.from_texts(texts=all_splits, embedding=word_embed)\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever(), return_source_documents=True)\n",
    "    \n",
    "    question = cov['question']\n",
    "    docs = vectorstore.similarity_search(question)\n",
    "    predict = qa_chain({\"query\": question})\n",
    "    answers_pairs.append((cov['answers'],predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4e8d578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which program does Suellen reference that shares its name with a snake?\n",
      "Predicted Answer:  Sueltene does not mention any specific program with the same name as a snake.\n",
      "Actual Answer: Python\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which person is talking to the Chief Justice?\n",
      "Predicted Answer:  Ms. Lee is talking to the Chief Justice.\n",
      "Actual Answer: Mr. Kneedler\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the most important center of learning of Sunni Islam in the country where the pope is going to celebrate a mass tomorrow ?\n",
      "Predicted Answer:  The most important center of learning of Sunni Islam in the country where the pope is going to celebrate a mass tomorrow is Al Azhar University.\n",
      "Actual Answer: Al-Azhar University\n",
      "F1 Score: 0.0690\n",
      "\n",
      "Question: Who hosts NEWS & NOTES?\n",
      "Predicted Answer:  The context does not provide information on who hosts NEWS & NOTEs.\n",
      "Actual Answer: FARAI CHIDEYA\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which feature in DrRacket inserts an epsilon?\n",
      "Predicted Answer:  The feature in DrRacket that inserts an epsilon is the `@usefixures` fixture object.\n",
      "Actual Answer: \\epsilon\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the clinical psychologist with the Psychological Group of Washington?\n",
      "Predicted Answer:  Katherine Marshall Woods.\n",
      "Actual Answer: Katherine Marshall Woods\n",
      "F1 Score: 0.8571\n",
      "\n",
      "Question: what was the name of the case?\n",
      "Predicted Answer:  The case is called Davis v. United States.\n",
      "Actual Answer: baby-shaking case\n",
      "F1 Score: 0.1818\n",
      "\n",
      "Question: Who is the Chief Justice of  United States ?\n",
      "Predicted Answer:  The Chief Justice of the United States is currently John G. Roberts Jr.\n",
      "Actual Answer: CHIEF JUSTICE ROBERTS\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What proportion of African American jurors were struck?\n",
      "Predicted Answer:  The context does not provide information on the proportion of African American jurors who were struck.\n",
      "Actual Answer: 10 of 11\n",
      "F1 Score: 0.1000\n",
      "\n",
      "Question: Which NPR reporter was traveling in South Carolina?\n",
      "Predicted Answer:  The context does not provide information about which NPR reporter was traveling in South Carolina.\n",
      "Actual Answer: Don Gonyea\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Who is the only person that needs Denis O'Connell to sign a bilateral NDA?\n",
      "Predicted Answer:  The only person who needs Denis O'Connell to sign a bilateral ND\n",
      "Actual Answer: Leslie.Hansen\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: In which industry lynda need the survey about developers?\n",
      "Predicted Answer:  The survey about developers is relevant to the tech industry.\n",
      "Actual Answer: tech industry\n",
      "F1 Score: 0.3077\n",
      "\n",
      "Question: What is the name of the petitioner in the case?\n",
      "Predicted Answer:  The petitioner in the case is the person who initiated the appeal.\n",
      "Actual Answer: Mr. Lamken\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which act has a piece missing from it, according to the Circuit court?\n",
      "Predicted Answer:  The Circuit court believes that the Federal Employees Protection Act (FEPRA) has a gap in it, as interpreted by the Federal Circuit. This is because the Federal Circuit has construed the FEPRA to exclude protection for speech that is part of the employee's normal duties.\n",
      "Actual Answer: Federal Whistle-blower Protection Act\n",
      "F1 Score: 0.1091\n",
      "\n",
      "Question: Which restatement section was based on injured party?\n",
      "Predicted Answer:  The reliance section, section three-24 says reliance is from the other for the injured party.\n",
      "Actual Answer: Section 324\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: How many months of unpaid leave does anyone with a permanent position have in Sweden ?\n",
      "Predicted Answer:  Anyone with a permanent position in Sweden has the right to take up to 6 months of unpaid leave to launch a company without it affecting their employment.\n",
      "Actual Answer: six\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the amendment that requires reliability in the determination that death is an appropriate sentence ?\n",
      "Predicted Answer:  The Eighth Amendment requires reliability in the determination that death is an appropriate sentence.\n",
      "Actual Answer: Eighth Amendment\n",
      "F1 Score: 0.2353\n",
      "\n",
      "Question: Which month does Kate think the price of $292.50 possibly sounds right for?\n",
      "Predicted Answer:  It is unclear from the given context which month Kate thinks the price of $292.50 possibly sounds right for.\n",
      "Actual Answer: May\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: In which case Judge Weis gave his opinion ?\n",
      "Predicted Answer:  The case Judge Wei's opinion was given in is not provided in the given context.\n",
      "Actual Answer: Meritcare v. St. Paul\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which company is giving the official confirmation letter for not to use their representative name?\n",
      "Predicted Answer:  The company that is giving the official confirmation letter for not to use their representative name is \"Designa\".\n",
      "Actual Answer: Lehman Brothers Inc\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Jason Rezaian wrote stories for which paper?\n",
      "Predicted Answer:  Jason Rezaian wrote stories for The Washington Post.\n",
      "Actual Answer: the Washington Post\n",
      "F1 Score: 0.3333\n",
      "\n",
      "Question: Where does Deeanna want to move 'blueprints' into?\n",
      "Predicted Answer:  Deeanna wants to move 'blueprint's into 'ko\n",
      "Actual Answer: `koyo-lib`\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What time is the OU-Enron game ?\n",
      "Predicted Answer:  The game starts at 7:00pm.\n",
      "Actual Answer: 700\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What type of spy would have rights under regulations for handling secret contracts , Justice Clemmler says ?\n",
      "Predicted Answer:  It is unclear from the given context what specific type of spy Justice Clemmer believes would have rights under regulations for handling secret contracts.\n",
      "Actual Answer: were a party to a secret contract or at least a secret relationship\n",
      "F1 Score: 0.0526\n",
      "\n",
      "Question: Which types of networks are involved?\n",
      "Predicted Answer:  The context mentions several types of networks, including a spreading-activation network, a network by which nodes support adopted by the legislature and internal executive branch directives taking into account the relative costs and benefits of certain types of regulation. There is also a model.rkt layer on top of graph that provides knowledge about nodeclasses and other elements of the spec.\n",
      "Actual Answer: a spreading-activation network and a network by which nodes support the continued existence of other nodes\n",
      "F1 Score: 0.3250\n",
      "\n",
      "Question: Transactions will be between which two entities?\n",
      "Predicted Answer:  The context does not provide specific information on which two entities will be involved in the transactions.\n",
      "Actual Answer: company offering product and customer\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What program allows the user to parallelize the tests and is recommended by Karoline?\n",
      "Predicted Answer:  The program recommended by Karoline for parallelizing tests is pytest.\n",
      "Actual Answer: pytest-parallel\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What does the Court say imposes restrictions on the discretion of police?\n",
      "Predicted Answer:  The Fourth Amendment imposes restrictions on the discretion of police officers and parole officers in their use of surveillance techniques.\n",
      "Actual Answer: restrictions on the timing, the frequency, the duration, and the oppressiveness of the search\n",
      "F1 Score: 0.2632\n",
      "\n",
      "Question: Who is restrained in the circumstances of the trial?\n",
      "Predicted Answer:  The defendant is restrained in the circumstances of the trial.\n",
      "Actual Answer: Mr. Deck\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What kind of action is referenced by Scalia when the prosecutor has died?\n",
      "Predicted Answer:  The type of action referenced by Scalia when the prosecutor has died is a civil action for malicious prosecution.\n",
      "Actual Answer: habeas action\n",
      "F1 Score: 0.0909\n",
      "\n",
      "Question: Why will the process be legthier?\n",
      "Predicted Answer:  The process will be easier because it will be divided into two separate approval processes for legal and para-legal personnel, giving them more time to complete the process before a reference entity is used.\n",
      "Actual Answer: the legal due-diligence\n",
      "F1 Score: 0.1026\n",
      "\n",
      "Question: who is the first speaker?\n",
      "Predicted Answer:  The first speaker in the given context is not provided.\n",
      "Actual Answer: MR. HURD\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which country has the new plane stuck?\n",
      "Predicted Answer:  The new plane is stuck in Iran.\n",
      "Actual Answer: Iran.\n",
      "F1 Score: 0.4000\n",
      "\n",
      "Question: Which names have Julia been experimenting more with capitalizing?\n",
      "Predicted Answer:  It's unclear from the given context which names Captain Obvious has experimented with capitalizing.\n",
      "Actual Answer: struct names\n",
      "F1 Score: 0.1111\n",
      "\n",
      "Question: What is the name of the casting director for the film Wendy Raquel Robinsondo worked on?\n",
      "Predicted Answer:  The casting director for the film Wendy Raquel Robinson worked on is not provided in the given context.\n",
      "Actual Answer: Robi Reed\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which person is Neal hosting on the show?\n",
      "Predicted Answer:  Neal is hosting Geoffrey Bennett on the show.\n",
      "Actual Answer: Naomi Oreskes\n",
      "F1 Score: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in answers_pairs:\n",
    "    f1_score = compute_f1(i[0][0],i[1]['result'])\n",
    "    print(f\"Question: {i[1]['query']}\")\n",
    "    print(f\"Predicted Answer: {i[1]['result']}\")\n",
    "    print(f\"Actual Answer: {i[0][0]}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ed449",
   "metadata": {},
   "source": [
    "## 4 Adding question embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f13ad78",
   "metadata": {},
   "source": [
    "### 4.1 GPT4ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1752f52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible. \n",
    "Also provide me the source for your answer. Explain how to get the answer step by step.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "llm = GPT4All(model=\"E:/ggml-model-gpt4all-falcon-q4_0.bin\", max_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "544aeac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct_embedding_model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "instruct_embedding_model_kwargs = {'device': 'cpu'}\n",
    "instruct_embedding_encode_kwargs = {'normalize_embeddings': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a8fce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "answers_pairs=[]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0.1)\n",
    "model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "def process_story_questions(combined_data, model_name, instruction):\n",
    "    word_embed = HuggingFaceInstructEmbeddings(\n",
    "        model_name=instruct_embedding_model_name,\n",
    "        model_kwargs=instruct_embedding_model_kwargs,\n",
    "        encode_kwargs=instruct_embedding_encode_kwargs,\n",
    "        embed_instruction=\"Represent the story for retrieval:\"\n",
    "    )\n",
    "\n",
    "    for cov in combined_data:\n",
    "        all_splits = text_splitter.split_text(cov['text'])\n",
    "        vectorstore = Chroma.from_texts(texts=all_splits, embedding=word_embed)\n",
    "        qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever(), return_source_documents=True)\n",
    "\n",
    "        question = cov['question']\n",
    "        hf_query_embs = HuggingFaceInstructEmbeddings(\n",
    "            model_name=instruct_embedding_model_name,\n",
    "            model_kwargs=instruct_embedding_model_kwargs,\n",
    "            encode_kwargs=instruct_embedding_encode_kwargs,\n",
    "            query_instruction=instruction\n",
    "        )\n",
    "        question_emb = hf_query_embs.embed_query(question)\n",
    "        docs = vectorstore.similarity_search_by_vector(question_emb)\n",
    "        predict = qa_chain({\"query\": question})\n",
    "        answers_pairs.append((cov['answers'],predict))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f81beb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python311\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'compute_f1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:6\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compute_f1' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "instruction = \"Represent the story for retrieval:\" \n",
    "process_story_questions(combined_data, model_name, instruction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1211dbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which program does Suellen reference that shares its name with a snake?\n",
      "Predicted Answer:  Sueltene does not mention any specific program with the same name as a snake.\n",
      "Actual Answer: Python\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which person is talking to the Chief Justice?\n",
      "Predicted Answer:  Ms. Lee is talking to the Chief Justice.\n",
      "Actual Answer: Mr. Kneedler\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the most important center of learning of Sunni Islam in the country where the pope is going to celebrate a mass tomorrow ?\n",
      "Predicted Answer:  The most important center of learning of Sunni Islam in the country where the pope is going to celebrate a mass tomorrow is Al Azhar University.\n",
      "Actual Answer: Al-Azhar University\n",
      "F1 Score: 0.0690\n",
      "\n",
      "Question: Who hosts NEWS & NOTES?\n",
      "Predicted Answer:  The context does not provide information on who hosts NEWS & NOTEs.\n",
      "Actual Answer: FARAI CHIDEYA\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which feature in DrRacket inserts an epsilon?\n",
      "Predicted Answer:  The feature in DrRacket that inserts an epsilon is the `@usefixures` fixture object.\n",
      "Actual Answer: \\epsilon\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the clinical psychologist with the Psychological Group of Washington?\n",
      "Predicted Answer:  Katherine Marshall Woods.\n",
      "Actual Answer: Katherine Marshall Woods\n",
      "F1 Score: 0.8571\n",
      "\n",
      "Question: what was the name of the case?\n",
      "Predicted Answer:  The case is called Davis v. United States.\n",
      "Actual Answer: baby-shaking case\n",
      "F1 Score: 0.1818\n",
      "\n",
      "Question: Who is the Chief Justice of  United States ?\n",
      "Predicted Answer:  The Chief Justice of the United States is currently John G. Roberts Jr.\n",
      "Actual Answer: CHIEF JUSTICE ROBERTS\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What proportion of African American jurors were struck?\n",
      "Predicted Answer:  The context does not provide information on the proportion of African American jurors who were struck.\n",
      "Actual Answer: 10 of 11\n",
      "F1 Score: 0.1000\n",
      "\n",
      "Question: Which NPR reporter was traveling in South Carolina?\n",
      "Predicted Answer:  The context does not provide information about which NPR reporter was traveling in South Carolina.\n",
      "Actual Answer: Don Gonyea\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Who is the only person that needs Denis O'Connell to sign a bilateral NDA?\n",
      "Predicted Answer:  The only person who needs Denis O'Connell to sign a bilateral ND\n",
      "Actual Answer: Leslie.Hansen\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: In which industry lynda need the survey about developers?\n",
      "Predicted Answer:  The survey about developers is relevant to the tech industry.\n",
      "Actual Answer: tech industry\n",
      "F1 Score: 0.3077\n",
      "\n",
      "Question: What is the name of the petitioner in the case?\n",
      "Predicted Answer:  The petitioner in the case is the person who initiated the appeal.\n",
      "Actual Answer: Mr. Lamken\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which act has a piece missing from it, according to the Circuit court?\n",
      "Predicted Answer:  The Circuit court believes that the Federal Employees Protection Act (FEPRA) has a gap in it, as interpreted by the Federal Circuit. This is because the Federal Circuit has construed the FEPRA to exclude protection for speech that is part of the employee's normal duties.\n",
      "Actual Answer: Federal Whistle-blower Protection Act\n",
      "F1 Score: 0.1091\n",
      "\n",
      "Question: Which restatement section was based on injured party?\n",
      "Predicted Answer:  The reliance section, section three-24 says reliance is from the other for the injured party.\n",
      "Actual Answer: Section 324\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: How many months of unpaid leave does anyone with a permanent position have in Sweden ?\n",
      "Predicted Answer:  Anyone with a permanent position in Sweden has the right to take up to 6 months of unpaid leave to launch a company without it affecting their employment.\n",
      "Actual Answer: six\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the amendment that requires reliability in the determination that death is an appropriate sentence ?\n",
      "Predicted Answer:  The Eighth Amendment requires reliability in the determination that death is an appropriate sentence.\n",
      "Actual Answer: Eighth Amendment\n",
      "F1 Score: 0.2353\n",
      "\n",
      "Question: Which month does Kate think the price of $292.50 possibly sounds right for?\n",
      "Predicted Answer:  It's unclear which specific month Kate believes the price of $292.50 sounds right for.\n",
      "Actual Answer: May\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: In which case Judge Weis gave his opinion ?\n",
      "Predicted Answer:  The case Judge Wei's opinion was given in is not provided in the given context.\n",
      "Actual Answer: Meritcare v. St. Paul\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which company is giving the official confirmation letter for not to use their representative name?\n",
      "Predicted Answer:  The company that is giving the official confirmation letter for not to use their representative name is \"Designa\".\n",
      "Actual Answer: Lehman Brothers Inc\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Jason Rezaian wrote stories for which paper?\n",
      "Predicted Answer:  Jason Rezaian wrote stories for The Washington Post.\n",
      "Actual Answer: the Washington Post\n",
      "F1 Score: 0.3333\n",
      "\n",
      "Question: Where does Deeanna want to move 'blueprints' into?\n",
      "Predicted Answer:  Deeanna wants to move 'blueprint's into 'ko\n",
      "Actual Answer: `koyo-lib`\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What time is the OU-Enron game ?\n",
      "Predicted Answer:  The game starts at 7:00pm.\n",
      "Actual Answer: 700\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What type of spy would have rights under regulations for handling secret contracts , Justice Clemmler says ?\n",
      "Predicted Answer:  It is unclear from the given context what specific type of spy Justice Clemmer believes would have rights under regulations for handling secret contracts.\n",
      "Actual Answer: were a party to a secret contract or at least a secret relationship\n",
      "F1 Score: 0.0526\n",
      "\n",
      "Question: Which types of networks are involved?\n",
      "Predicted Answer:  The context mentions several types of networks, including a spreading-activation network, a network by which nodes support adopted by the legislature and internal executive branch directives taking into account the relative costs and benefits of certain types of regulation. There is also a model.rkt layer on top of graph that provides knowledge about nodeclasses and other elements of the spec.\n",
      "Actual Answer: a spreading-activation network and a network by which nodes support the continued existence of other nodes\n",
      "F1 Score: 0.3250\n",
      "\n",
      "Question: Transactions will be between which two entities?\n",
      "Predicted Answer:  The context does not provide specific information on which two entities will be involved in the transactions.\n",
      "Actual Answer: company offering product and customer\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What program allows the user to parallelize the tests and is recommended by Karoline?\n",
      "Predicted Answer:  The program recommended by Karoline for parallelizing tests is pytest.\n",
      "Actual Answer: pytest-parallel\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What does the Court say imposes restrictions on the discretion of police?\n",
      "Predicted Answer:  The Fourth Amendment imposes restrictions on the discretion of police officers and parole officers in their use of surveillance techniques.\n",
      "Actual Answer: restrictions on the timing, the frequency, the duration, and the oppressiveness of the search\n",
      "F1 Score: 0.2632\n",
      "\n",
      "Question: Who is restrained in the circumstances of the trial?\n",
      "Predicted Answer:  The defendant is restrained in the circumstances of the trial.\n",
      "Actual Answer: Mr. Deck\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What kind of action is referenced by Scalia when the prosecutor has died?\n",
      "Predicted Answer:  The type of action referenced by Scalia when the prosecutor has died is a civil action for malicious prosecution.\n",
      "Actual Answer: habeas action\n",
      "F1 Score: 0.0909\n",
      "\n",
      "Question: Why will the process be legthier?\n",
      "Predicted Answer:  The process will be easier because it will be divided into two separate approval processes for legal and para-legal personnel, giving them more time to complete the process before a reference entity is used.\n",
      "Actual Answer: the legal due-diligence\n",
      "F1 Score: 0.1026\n",
      "\n",
      "Question: who is the first speaker?\n",
      "Predicted Answer:  The first speaker in the given context is not provided.\n",
      "Actual Answer: MR. HURD\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which country has the new plane stuck?\n",
      "Predicted Answer:  The new plane is stuck in Iran.\n",
      "Actual Answer: Iran.\n",
      "F1 Score: 0.4000\n",
      "\n",
      "Question: Which names have Julia been experimenting more with capitalizing?\n",
      "Predicted Answer:  It's unclear from the given context which names Captain Obvious has experimented with capitalizing.\n",
      "Actual Answer: struct names\n",
      "F1 Score: 0.1111\n",
      "\n",
      "Question: What is the name of the casting director for the film Wendy Raquel Robinsondo worked on?\n",
      "Predicted Answer:  The casting director for the film Wendy Raquel Robinson worked on is not provided in the given context.\n",
      "Actual Answer: Robi Reed\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which person is Neal hosting on the show?\n",
      "Predicted Answer:  Neal is hosting Geoffrey Bennett on the show.\n",
      "Actual Answer: Naomi Oreskes\n",
      "F1 Score: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in answers_pairs:\n",
    "    f1_score = compute_f1(i[0][0],i[1]['result'])\n",
    "    print(f\"Question: {i[1]['query']}\")\n",
    "    print(f\"Predicted Answer: {i[1]['result']}\")\n",
    "    print(f\"Actual Answer: {i[0][0]}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d165b0",
   "metadata": {},
   "source": [
    "### 4.2 Retrieved Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4091b76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1962d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "answers_pairs=[]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0.1)\n",
    "model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "def process_story_questions(combined_data, model_name, instruction):\n",
    "    hf_story_embs = HuggingFaceInstructEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs,\n",
    "        embed_instruction=\"Use the following pieces of context to answer the question at the end:\"\n",
    "    )\n",
    "\n",
    "    for cov in combined_data:\n",
    "        sentences = sent_tokenize(cov['text'])\n",
    "        sentence_embs = hf_story_embs.embed_documents(sentences)\n",
    "        #all_splits = text_splitter.split_text(cov['text'])\n",
    "        #vectorstore = Chroma.from_texts(texts=all_splits, embedding=word_embed)\n",
    "        #qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever(), return_source_documents=True)\n",
    "\n",
    "        question = cov['question'] \n",
    "        hf_query_embs = HuggingFaceInstructEmbeddings(\n",
    "            model_name=model_name,\n",
    "            model_kwargs=instruct_embedding_model_kwargs,\n",
    "            encode_kwargs=instruct_embedding_encode_kwargs,\n",
    "            query_instruction=instruction\n",
    "        )\n",
    "        question_emb = hf_query_embs.embed_query(question)\n",
    "        scores = [torch.cosine_similarity(torch.tensor(sentence_emb).unsqueeze(0), torch.tensor(question_emb).unsqueeze(0))[0].item() for sentence_emb in sentence_embs]\n",
    "        \n",
    "        best_sentence_idx = scores.index(max(scores))\n",
    "        best_sentence = sentences[best_sentence_idx]\n",
    "        \n",
    "        \n",
    "        #docs = vectorstore.similarity_search_by_vector(question_emb)\n",
    "        #predict = qa_chain({\"query\": question})\n",
    "        answers_pairs.append((cov['question'],cov['answers'],best_sentence))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "325bb0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "instruction = \"Represent the story for retrieval:\" \n",
    "process_story_questions(combined_data, model_name, instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea7da7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which program does Suellen reference that shares its name with a snake?\n",
      "Predicted Answer: But I'm sure it can make for quick test development&gt; dislike because of the magicnessyeah, I hate python, where is my `malloc()` ,stuck_out_tongue,Not really the same thingIn this case I'm talking about decorators that magically rewrite things to inject arguments^ that's my biggest concern, too.why magically?\n",
      "Actual Answer: ['Python']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which person is talking to the Chief Justice?\n",
      "Predicted Answer: Chief Justice, and may it please the Court, Much of the work of public employees is performed by speaking or writing, and much of that work concerns matters of public interest.\n",
      "Actual Answer: ['Mr. Kneedler']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What is the name of the most important center of learning of Sunni Islam in the country where the pope is going to celebrate a mass tomorrow ?\n",
      "Predicted Answer: It's the most important center of learning of Sunni Islam.\n",
      "Actual Answer: ['Al-Azhar University']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Who hosts NEWS & NOTES?\n",
      "Predicted Answer: Here at NEWS & NOTES, we have our own 40 acres of the blogosphere, News & Views.\n",
      "Actual Answer: ['FARAI CHIDEYA']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which feature in DrRacket inserts an epsilon?\n",
      "Predicted Answer: Using \\epsilon in DrRacket inserts an epsilon as expected.\n",
      "Actual Answer: ['\\\\epsilon']\n",
      "F1 Score: 0.1818\n",
      "\n",
      "Question: What is the name of the clinical psychologist with the Psychological Group of Washington?\n",
      "Predicted Answer: Still with us here in the Studio 3A is Katherine Marshall Woods, who's a clinical psychologist with the Psychological Group of Washington.\n",
      "Actual Answer: ['Katherine Marshall Woods']\n",
      "F1 Score: 0.2143\n",
      "\n",
      "Question: what was the name of the case?\n",
      "Predicted Answer: He would be deciding an issue that normally would be submitted to the jury.It's not our position, Your Honor, that -- that the trial court can make credibility determinations, but --But the example that Justice Kennedy gave you was such a determination.I -- I think, though -- I -- I suppose that would depend on the nature of the specific evidence at issue.\n",
      "Actual Answer: ['baby-shaking case']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Who is the Chief Justice of  United States ?\n",
      "Predicted Answer: This was a case decided by this Court in 1944.\n",
      "Actual Answer: ['CHIEF JUSTICE ROBERTS']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What proportion of African American jurors were struck?\n",
      "Predicted Answer: There we have 10 of 11 African American jurors struck.\n",
      "Actual Answer: ['10 of 11']\n",
      "F1 Score: 0.4286\n",
      "\n",
      "Question: Which NPR reporter was traveling in South Carolina?\n",
      "Predicted Answer: Don, I have to cut you off to go to a break, but I want to thank NPR's Don Gonyea traveling in South Carolina.\n",
      "Actual Answer: ['Don Gonyea']\n",
      "F1 Score: 0.1333\n",
      "\n",
      "Question: Who is the only person that needs Denis O'Connell to sign a bilateral NDA?\n",
      "Predicted Answer: As provided in my first set\n",
      "of comments, the maximum term that I have authority to approve is 2 years for\n",
      "a bilateral NDA.\n",
      "Actual Answer: ['Leslie.Hansen']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: In which industry lynda need the survey about developers?\n",
      "Predicted Answer: Thanks for your help.Hi everyone, I’m a UX design student working on a developers’ career advice project and I would really appreciate if you could take 1 minute and help me participate in this survey about developers in tech industry.\n",
      "Actual Answer: ['tech industry']\n",
      "F1 Score: 0.0851\n",
      "\n",
      "Question: What is the name of the petitioner in the case?\n",
      "Predicted Answer: It is then appealable either to a zoning board of adjustment -- that's the -- the model act -- or in California, States -- localities have the option of having the appeal go to the local legislature.\n",
      "Actual Answer: ['Mr. Lamken']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which act has a piece missing from it, according to the Circuit court?\n",
      "Predicted Answer: And just to respond to something that was said about the Federal Whistle-blower Protection Act, that statute has a gaping hole in it, as construed by the Federal Circuit, because the Federal Circuit has construed it to exclude protection for speech that is part of the employee's normal duties.\n",
      "Actual Answer: ['Federal Whistle-blower Protection Act']\n",
      "F1 Score: 0.1379\n",
      "\n",
      "Question: Which restatement section was based on injured party?\n",
      "Predicted Answer: The restatement section, section three- -- or the restatement section 324 says reliance is from the other for the injured party.\n",
      "Actual Answer: ['Section 324']\n",
      "F1 Score: 0.0800\n",
      "\n",
      "Question: How many months of unpaid leave does anyone with a permanent position have in Sweden ?\n",
      "Predicted Answer: It's quite a risk to start all over, no income whatsoever at the beginning.Her story isn't unusual in Sweden, where anyone with a permanent position has a legal right to take unpaid leave for six months to launch a company, providing it doesn't compete with their usual employer.To find out more, I braved the snow and made a visit to Samuel Engblom at the Swedish Confederation for Professional Employees, which represents white-collar workers.\n",
      "Actual Answer: ['six']\n",
      "F1 Score: 0.0241\n",
      "\n",
      "Question: What is the name of the amendment that requires reliability in the determination that death is an appropriate sentence ?\n",
      "Predicted Answer: To pick up on some of the things that were said during Attorney General Kline's argument, the Eighth Amendment requires reliability in the determination that death is an appropriate sentence.\n",
      "Actual Answer: ['Eighth Amendment']\n",
      "F1 Score: 0.1143\n",
      "\n",
      "Question: Which month does Kate think the price of $292.50 possibly sounds right for?\n",
      "Predicted Answer: But he\n",
      "said a price like $292.50 doesn't sound right for Sept. - possibly May?This is what amerex is showing and this is what I have confirmed.This is what amerex is showing and this is what I have confirmed.Yep - the trade's there all right.\n",
      "Actual Answer: ['May']\n",
      "F1 Score: 0.0385\n",
      "\n",
      "Question: In which case Judge Weis gave his opinion ?\n",
      "Predicted Answer: But, Your Honor, respectfully, we now know, because they've all written Law Review articles, that the people that wrote the House report, because they've said it, wrote those law -- wrote those words because they knew that the language did overrule Zahn and they didn't want to achieve that outcome.I think -- I think you're overstating what they say in the article.Well, Your Honor, respectfully, what we do have is undisputed fact here because if you see Judge Weis' conclusion, for example, Judge Weis is one of the people who has adopted one of the opinions opposing our view of -- of this position.He was the chair of the --He was.\n",
      "Actual Answer: ['Meritcare v. St. Paul']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which company is giving the official confirmation letter for not to use their representative name?\n",
      "Predicted Answer: Paul S. Rosica\n",
      "Lehman Brothers\n",
      "212-526-8887 Phone\n",
      "212-526-2755 Fax\n",
      "917-822-9797 Cell\n",
      "<email>\n",
      "\n",
      "This message is intended only for the personal and confidential use of the\n",
      "designated recipient(s) named above.\n",
      "Actual Answer: ['Lehman Brothers Inc']\n",
      "F1 Score: 0.1053\n",
      "\n",
      "Question: Jason Rezaian wrote stories for which paper?\n",
      "Predicted Answer: So the Iranian power structure is broken up into different parts.\n",
      "Actual Answer: ['the Washington Post']\n",
      "F1 Score: 0.1333\n",
      "\n",
      "Question: Where does Deeanna want to move 'blueprints' into?\n",
      "Predicted Answer: It doesn't work when I deploy the package because the location of `blueprints` is outside of the package's installation path so I get this error after I install the package,\n",
      "\n",
      " <code_snippet> \n",
      "\n",
      "If I move blueprints inside `koyo-lib`, then that causes problems as well because `blueprints` contains racket code (and koyo-lib is declared as a multi-collection package (though I could change it to a single collection package, but I'm not sure that would help)).So what I would like to do is move `blueprints` into `koyo-lib` but somehow tell `raco pkg` that it should ignore the `blueprints` folder when `koyo-lib` is installed.I have read about the `source-omit-files` configuration value but I don't think that'll do what I want.\n",
      "Actual Answer: ['`koyo-lib`']\n",
      "F1 Score: 0.0392\n",
      "\n",
      "Question: What time is the OU-Enron game ?\n",
      "Predicted Answer: We play the other Enron team.\n",
      "Actual Answer: ['700']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What type of spy would have rights under regulations for handling secret contracts , Justice Clemmler says ?\n",
      "Predicted Answer: Alleged spies would have rights under those regulations, and the very idea of walking into court and asserting your rights as an alleged spy is inconsistent with the entire relationship and the contract that gave rise to it.\n",
      "Actual Answer: ['were a party to a secret contract or at least a secret relationship']\n",
      "F1 Score: 0.1132\n",
      "\n",
      "Question: Which types of networks are involved?\n",
      "Predicted Answer: There are some other things, too, involving a spreading-activation network and a network by which nodes support the continued existence of other nodes.So, tagswhat’s a `tag?` value?Each node has a bunch of attributes, just an arbitrary hash table.\n",
      "Actual Answer: ['a spreading-activation network and a network by which nodes support the continued existence of other nodes']\n",
      "F1 Score: 0.4545\n",
      "\n",
      "Question: Transactions will be between which two entities?\n",
      "Predicted Answer: Transactions will be between company offering product and customer; Enron does not stand in middle for credit.\n",
      "Actual Answer: ['company offering product and customer']\n",
      "F1 Score: 0.4167\n",
      "\n",
      "Question: What program allows the user to parallelize the tests and is recommended by Karoline?\n",
      "Predicted Answer: basically they allow you to paralelize your testsOkayWill definitely look into thoseThanks <@Eliana> <@Karoline> ,taco,Having a simple issue.\n",
      "Actual Answer: ['pytest-parallel']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What does the Court say imposes restrictions on the discretion of police?\n",
      "Predicted Answer: And we believe the Fourth Amendment does impose -- the Fourth Amendment itself imposes restrictions on the discretion of police officers and parole officers that are meaningful, that -- as the Reyes Court said, there are restrictions on the timing, the frequency, the duration, and the oppressiveness of the search.\n",
      "Actual Answer: ['restrictions on the timing, the frequency, the duration, and the oppressiveness of the search']\n",
      "F1 Score: 0.4658\n",
      "\n",
      "Question: Who is restrained in the circumstances of the trial?\n",
      "Predicted Answer: Again, it -- it depends upon the circumstances, but if they're not visible to the jury, the defendant has a difficult time --Well, the circumstances that you were given was a traffic offender.A traffic offender who is restrained where it's not visible --With -- with non-visible restraints.\n",
      "Actual Answer: ['Mr. Deck']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: What kind of action is referenced by Scalia when the prosecutor has died?\n",
      "Predicted Answer: The prosecutor is dead.That's about four questions, Your Honor.\n",
      "Actual Answer: ['habeas action']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Why will the process be legthier?\n",
      "Predicted Answer: That process is now underway.\n",
      "Actual Answer: ['the legal due-diligence']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: who is the first speaker?\n",
      "Predicted Answer: I'm worried, however, about the fact that this statute doesn't just cover the initial IEP.\n",
      "Actual Answer: ['MR. HURD']\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Question: Which country has the new plane stuck?\n",
      "Predicted Answer: But as we sit here today, Norwegian Air's plane is still in Iran.\n",
      "Actual Answer: ['Iran.']\n",
      "F1 Score: 0.2222\n",
      "\n",
      "Question: Which names have Julia been experimenting more with capitalizing?\n",
      "Predicted Answer: )This reminds me, lately I've been experimenting more with capitalizing struct names.\n",
      "Actual Answer: ['struct names']\n",
      "F1 Score: 0.2222\n",
      "\n",
      "Question: What is the name of the casting director for the film Wendy Raquel Robinsondo worked on?\n",
      "Predicted Answer: I knew Robi Reed who was also the casting director, and (unintelligible) who was actually working on it.\n",
      "Actual Answer: ['Robi Reed']\n",
      "F1 Score: 0.1667\n",
      "\n",
      "Question: Which person is Neal hosting on the show?\n",
      "Predicted Answer: I'm Neal Conan in Washington.\n",
      "Actual Answer: ['Naomi Oreskes']\n",
      "F1 Score: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in answers_pairs:\n",
    "    f1_score = compute_f1(i[1][0],i[2])\n",
    "    print(f\"Question: {i[0]}\")\n",
    "    print(f\"Predicted Answer: {i[2]}\")\n",
    "    print(f\"Actual Answer: {i[1]}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba914059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python']\n",
      "['Mr. Kneedler']\n",
      "['Al-Azhar University']\n",
      "['FARAI CHIDEYA']\n",
      "['\\\\epsilon']\n",
      "['Katherine Marshall Woods']\n",
      "['baby-shaking case']\n",
      "['CHIEF JUSTICE ROBERTS']\n",
      "['10 of 11']\n",
      "['Don Gonyea']\n",
      "['Leslie.Hansen']\n",
      "['tech industry']\n",
      "['Mr. Lamken']\n",
      "['Federal Whistle-blower Protection Act']\n",
      "['Section 324']\n",
      "['six']\n",
      "['Eighth Amendment']\n",
      "['May']\n",
      "['Meritcare v. St. Paul']\n",
      "['Lehman Brothers Inc']\n",
      "['the Washington Post']\n",
      "['`koyo-lib`']\n",
      "['700']\n",
      "['were a party to a secret contract or at least a secret relationship']\n",
      "['a spreading-activation network and a network by which nodes support the continued existence of other nodes']\n",
      "['company offering product and customer']\n",
      "['pytest-parallel']\n",
      "['restrictions on the timing, the frequency, the duration, and the oppressiveness of the search']\n",
      "['Mr. Deck']\n",
      "['habeas action']\n",
      "['the legal due-diligence']\n",
      "['MR. HURD']\n",
      "['Iran.']\n",
      "['struct names']\n",
      "['Robi Reed']\n",
      "['Naomi Oreskes']\n"
     ]
    }
   ],
   "source": [
    "for i in answers_pairs:\n",
    "    f1_score = compute_f1(i[0][0],i[1])\n",
    "    print(f\"Question: {i[1]['query']}\")\n",
    "    print(f\"Predicted Answer: {i[1]['result']}\")\n",
    "    print(f\"Actual Answer: {i[0][0]}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18200dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def process_story_questions(data, model_name, instruction):\n",
    "    model_kwargs = {'device': 'cpu'}\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "    # Segment story text into sentences and embed each sentence\n",
    "    sentences = sent_tokenize(story_text)  # Splitting into sentences\n",
    "    hf_story_embs = HuggingFaceInstructEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs,\n",
    "        embed_instruction=\"Use the following pieces of context to answer the question at the end:\"\n",
    "    )\n",
    "    sentence_embs = hf_story_embs.embed_documents(sentences)\n",
    "\n",
    "    # Process each question\n",
    "    for question_data in story_data['questions']:\n",
    "        question = question_data['q']\n",
    "\n",
    "        hf_query_embs = HuggingFaceInstructEmbeddings(\n",
    "            model_name=model_name,\n",
    "            model_kwargs=model_kwargs,\n",
    "            encode_kwargs=encode_kwargs,\n",
    "            query_instruction=instruction\n",
    "        )\n",
    "        question_emb = hf_query_embs.embed_documents([question])[0]\n",
    "\n",
    "        # Compute cosine similarity scores with each sentence\n",
    "        scores = [torch.cosine_similarity(torch.tensor(sentence_emb).unsqueeze(0), torch.tensor(question_emb).unsqueeze(0))[0].item() for sentence_emb in sentence_embs]\n",
    "\n",
    "        best_sentence_idx = scores.index(max(scores))\n",
    "        best_sentence = sentences[best_sentence_idx]\n",
    "\n",
    "        # Extract actual answer using the consensus range\n",
    "        consensus = question_data['consensus']\n",
    "        actual_answer = story_text[consensus['s']:consensus['e']]\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1_score = compute_f1(best_sentence, actual_answer)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Predicted Answer: {best_sentence}\")\n",
    "        print(f\"Actual Answer: {actual_answer}\")\n",
    "        print(f\"F1 Score: {f1_score:.4f}\")\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        # # Calculate F1 score for each sentence\n",
    "        # f1_scores = [compute_f1(sentence, question) for sentence in sentences]\n",
    "\n",
    "        # # Find the sentence with the highest F1 score\n",
    "        # best_sentence_idx = f1_scores.index(max(f1_scores))\n",
    "        # best_sentence = sentences[best_sentence_idx]\n",
    "\n",
    "        # # Extract actual answer using the consensus range\n",
    "        # consensus = question_data['consensus']\n",
    "        # actual_answer = story_text[consensus['s']:consensus['e']]\n",
    "        \n",
    "        # # Calculate F1 score\n",
    "        # f1_score = compute_f1(best_sentence, actual_answer)\n",
    "        \n",
    "        # # Print results\n",
    "        # print(f\"Question: {question}\")\n",
    "        # print(f\"Predicted Answer: {best_sentence}\")\n",
    "        # print(f\"Actual Answer: {actual_answer}\")\n",
    "        # print(f\"F1 Score: {f1_score:.4f}\")\n",
    "        # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a914da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\"\n",
    "instruction = \"Represent the story for retrieval:\" \n",
    "process_story_questions(combined_data, model_name, instruction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
