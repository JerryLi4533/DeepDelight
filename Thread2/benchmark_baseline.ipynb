{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87f7587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a890fb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting unstructured\n",
      "  Obtaining dependency information for unstructured from https://files.pythonhosted.org/packages/4b/4c/0ebe18639be2a6b8e74dc60bf81fd4532289c80a0feac88004c28c7f1e0d/unstructured-0.10.25-py3-none-any.whl.metadata\n",
      "  Downloading unstructured-0.10.25-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: chardet in d:\\anaconda\\lib\\site-packages (from unstructured) (4.0.0)\n",
      "Requirement already satisfied: filetype in d:\\anaconda\\lib\\site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in d:\\anaconda\\lib\\site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in d:\\anaconda\\lib\\site-packages (from unstructured) (4.9.3)\n",
      "Requirement already satisfied: nltk in d:\\anaconda\\lib\\site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: tabulate in d:\\anaconda\\lib\\site-packages (from unstructured) (0.8.10)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: emoji in d:\\anaconda\\lib\\site-packages (from unstructured) (2.8.0)\n",
      "Requirement already satisfied: dataclasses-json in d:\\anaconda\\lib\\site-packages (from unstructured) (0.6.1)\n",
      "Requirement already satisfied: python-iso639 in d:\\anaconda\\lib\\site-packages (from unstructured) (2023.6.15)\n",
      "Requirement already satisfied: langdetect in d:\\anaconda\\lib\\site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from unstructured) (1.24.3)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Obtaining dependency information for rapidfuzz from https://files.pythonhosted.org/packages/76/dc/158b4f30a50ef7c283c7834419928da6400ed299ccf69dfc653d5c4f20fa/rapidfuzz-3.4.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading rapidfuzz-3.4.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: backoff in d:\\anaconda\\lib\\site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->unstructured) (2.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\anaconda\\lib\\site-packages (from dataclasses-json->unstructured) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\anaconda\\lib\\site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from nltk->unstructured) (8.0.4)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from nltk->unstructured) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda\\lib\\site-packages (from nltk->unstructured) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from nltk->unstructured) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->unstructured) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->unstructured) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->unstructured) (2023.7.22)\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\anaconda\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\anaconda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in d:\\anaconda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (4.7.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click->nltk->unstructured) (0.4.6)\n",
      "Downloading unstructured-0.10.25-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/1.7 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.0/1.7 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 10.6 MB/s eta 0:00:00\n",
      "Downloading rapidfuzz-3.4.0-cp311-cp311-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.8/1.8 MB 38.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 38.6 MB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz, unstructured\n",
      "Successfully installed rapidfuzz-3.4.0 unstructured-0.10.25\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script unstructured-ingest.exe is installed in 'C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56d3c540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting jq\n",
      "  Using cached jq-1.6.0.tar.gz (2.9 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: jq\n",
      "  Building wheel for jq (pyproject.toml): started\n",
      "  Building wheel for jq (pyproject.toml): finished with status 'error'\n",
      "Failed to build jq\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for jq (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [5 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  Executing: ./configure CFLAGS=-fPIC --prefix=C:\\Users\\Administrator\\AppData\\Local\\Temp\\pip-install-6j82es9e\\jq_22d57f4bdc834884bbbb6e28467b8470\\_deps\\build\\onig-install-6.9.8\n",
      "  error: [WinError 2] 系统找不到指定的文件。\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for jq\n",
      "ERROR: Could not build wheels for jq, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "pip install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f7cbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.28s/it]\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader('E:/QA', glob=\"**/*.txt\",  show_progress=True,use_multithreading=True, loader_kwargs={'encoding': 'utf-8'})\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93cf052e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b58849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a4417ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=GPT4AllEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93f17fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n"
     ]
    }
   ],
   "source": [
    "embeddings = GPT4AllEmbeddings()\n",
    "\n",
    "gpt4all_falcon_model = \"E:/ggml-model-gpt4all-falcon-q4_0.bin\"\n",
    "\n",
    "llm = GPT4All(model=gpt4all_falcon_model ,max_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275ed61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Which program does Suellen reference that shares its name with a snake?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "987e0ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source documents: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever(),\n",
    "                                       return_source_documents=True)\n",
    "result = qa_chain({\"query\": question})\n",
    "\n",
    "print(f\"Number of source documents: {len(result['source_documents'])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e769fd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The program Sueleln references that shares its name with a snake is \"Snake Nation\".'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55d14bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Source: E:\\QA\\article_segment_sample.txt\n",
      "Content: \"id\": \"newsidal-NPR-162-27\",\n",
      "\n",
      "\"speaker\": \"NEAL CONAN, HOST\",\n",
      "\n",
      "\"text\": \"Tom Parkinson, you think a pattern would indicate - well, a pattern - if you're dispensing large numbers of pills to large numbers of people, maybe people should get suspicious.\"\n",
      "\n",
      "},\n",
      "\n",
      "{\n",
      "\n",
      "\"id\": \"newsidal-NPR-162-28\",\n",
      "\n",
      "\"speaker\": \"TOM PARKINSON, BYLINE\",\n",
      "\n",
      "Document 2:\n",
      "Source: E:\\QA\\article_segment_sample.txt\n",
      "Content: \"text\": \"But we're going to be joined, as well, by Greg McGuff. He's a division president for Southern California - in Southern California for Lennar Homes. The company saw this trend toward more family members living under the same roof as a bright spot in an otherwise gloomy housing market. Greg McGuff is with us now by phone from his office in Corona, California. Welcome to you.\"\n",
      "\n",
      "},\n",
      "\n",
      "{\n",
      "\n",
      "\"id\": \"newsidal-NPR-159-105\",\n",
      "\n",
      "\"speaker\": \"GREG MCGUFF\",\n",
      "\n",
      "Document 3:\n",
      "Source: E:\\QA\\article_segment_sample.txt\n",
      "Content: \"text\": \"And remind us about the National Enquirer's connection to the investigations into Donald Trump because David Pecker was granted immunity in the investigation into Trump's former lawyer Michael Cohen because Pecker was involved into those illicit payments to Karen McDougal, right?\"\n",
      "\n",
      "},\n",
      "\n",
      "{\n",
      "\n",
      "\"id\": \"newsidal-NPR-132-13\",\n",
      "\n",
      "\"speaker\": \"URI BERLINER, BYLINE\",\n",
      "\n",
      "Document 4:\n",
      "Source: E:\\QA\\article_segment_sample.txt\n",
      "Content: \"text\": \"Right. The National Enquirer acknowledged paying hush money to a former Playboy model who said she had an affair with Trump. She was paid 150,000 during the 2016 campaign. And so that's really what happened there.\"\n",
      "\n",
      "},\n",
      "\n",
      "{\n",
      "\n",
      "\"id\": \"newsidal-NPR-132-14\",\n",
      "\n",
      "\"speaker\": \"RACHEL MARTIN, HOST\",\n",
      "\n",
      "\"text\": \"He also refers to his ownership of the Post as being a complexifier for him, which is an odd word. But, I mean, what more does he say about his role as the owner of the Post?\"\n",
      "\n",
      "},\n",
      "\n",
      "{\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(result['source_documents'], 1):\n",
    "    print(f\"Document {i}:\")\n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print(f\"Content: {doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe0b8991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:\\\\\\\\Users\\\\\\\\Administrator\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n",
      "Found model file at  E:/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "\n",
      "F1 Results:\n",
      "Chunk Size: 200, Overlap: 0, F1: 0.0\n",
      "Chunk Size: 200, Overlap: 0.1, F1: 0.0\n",
      "Chunk Size: 200, Overlap: 0.2, F1: 0.0\n",
      "Chunk Size: 200, Overlap: 0.3, F1: 0.0\n",
      "Chunk Size: 400, Overlap: 0, F1: 0.0\n",
      "Chunk Size: 400, Overlap: 0.1, F1: 0.0\n",
      "Chunk Size: 400, Overlap: 0.2, F1: 0.0\n",
      "Chunk Size: 400, Overlap: 0.3, F1: 0.0\n",
      "Chunk Size: 800, Overlap: 0, F1: 0.0\n",
      "Chunk Size: 800, Overlap: 0.1, F1: 0.0\n",
      "Chunk Size: 800, Overlap: 0.2, F1: 0.0\n",
      "Chunk Size: 800, Overlap: 0.3, F1: 0.0\n",
      "Chunk Size: 1600, Overlap: 0, F1: 0.0\n",
      "Chunk Size: 1600, Overlap: 0.1, F1: 0.0\n",
      "Chunk Size: 1600, Overlap: 0.2, F1: 0.0\n",
      "Chunk Size: 1600, Overlap: 0.3, F1: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "chunk_sizes = [200, 400, 800, 1600]\n",
    "overlaps = [0, 0.1, 0.2, 0.3]\n",
    "\n",
    "def calculate_em(reference, prediction):\n",
    "    return int(reference == prediction)\n",
    "\n",
    "em_results = {}\n",
    "f1_results = {}\n",
    "text_results=[]\n",
    "\n",
    "loader = DirectoryLoader('E:/QA', glob=\"**/*.txt\", show_progress=True, use_multithreading=True, loader_kwargs={'encoding': 'utf-8'})\n",
    "docs = loader.load()\n",
    "\n",
    "question_list=[\"Which party does Obama belong to?\",\"Who is the Seattle lawyer and Democratic superdelegate?\",\"Who is a division president for Southern California?\",\"Amazon was founded by whom?\"]\n",
    "answer_list=[\"Democratic Party\",\"David McDonald\",\"Greg McGuff\",\"Jeff Bezos\"]\n",
    "\n",
    "for chunk_size in chunk_sizes:\n",
    "    for overlap in overlaps:   \n",
    "        result_list=[]\n",
    "        boolean_list=[]\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
    "        all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "        vectorstore = Chroma.from_documents(documents=all_splits, embedding=GPT4AllEmbeddings())\n",
    "        llm = GPT4All(model=\"E:/ggml-model-gpt4all-falcon-q4_0.bin\", max_tokens=2048)\n",
    "        qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever(), return_source_documents=True)\n",
    "        \n",
    "        for question in question_list:\n",
    "            result = qa_chain({\"query\": question})\n",
    "            result_list.append(result)\n",
    "\n",
    "        for i in range(4):\n",
    "            boolean_list.append(result_list[i]==answer_list[i])\n",
    "            \n",
    "        f1 = f1_score([1,1,1,1], boolean_list, average='micro')\n",
    "\n",
    "        em_results[(chunk_size, overlap)] = em\n",
    "        f1_results[(chunk_size, overlap)] = f1\n",
    "        text_results.append(result_list)\n",
    "\n",
    "print(\"\\nF1 Results:\")\n",
    "for config, f1 in f1_results.items():\n",
    "    print(f\"Chunk Size: {config[0]}, Overlap: {config[1]}, F1: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a110998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is David McDonald.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n",
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is David McDonald.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n",
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is David McDonald.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n",
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is David McDonald.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n",
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is David McDonald.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n",
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is Irene Stein.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n",
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is Irene Stein.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n",
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is Irene Stein.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n",
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is Irene Stein.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n",
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is Irene Stein.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n",
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is Irene Stein.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n",
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is Irene Stein.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n",
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is Irene Stein.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n",
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is Irene Stein.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n",
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is Irene Stein.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n",
      " Barack Obama belongs to the Democratic Party.\n",
      " The Seattle lawyer and Democratic superdelegate is Irene Stein.\n",
      " Greg McGuff is the division president for Southern California.\n",
      " Amazon was founded by Jeff Bezos.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(16):\n",
    "    for j in range(4):\n",
    "        print(text_results[i][j]['result'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b3307b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
