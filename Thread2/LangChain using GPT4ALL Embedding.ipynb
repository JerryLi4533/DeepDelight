{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cR88iie6af6"
   },
   "source": [
    "# LangChain using GPT4ALL Embedding\n",
    "\n",
    "Lixiao Yang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Xp6rVvNQTIQV",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "bae000d9-4037-4b71-d379-125446c64924",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gpt4all in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (1.0.8)\n",
      "Requirement already satisfied: langchain in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (0.0.277)\n",
      "Requirement already satisfied: chromadb in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (0.4.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: requests in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from gpt4all) (2.28.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\software\\anaconda\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (2.0.20)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (0.0.29)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (2.8.5)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from chromadb) (3.3.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from chromadb) (1.15.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from chromadb) (4.7.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from chromadb) (0.13.3)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.2 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from chromadb) (0.7.2)\n",
      "Requirement already satisfied: fastapi<0.100.0,>=0.95.2 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from chromadb) (0.99.1)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from chromadb) (6.0.1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from chromadb) (3.0.2)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from chromadb) (0.23.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\software\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\software\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from fastapi<0.100.0,>=0.95.2->chromadb) (0.27.0)\n",
      "Requirement already satisfied: packaging in c:\\software\\anaconda\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (21.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.24.2)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: sympy in c:\\software\\anaconda\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.10.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: python-dateutil>2.1 in c:\\software\\anaconda\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\software\\anaconda\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\software\\anaconda\\lib\\site-packages (from pulsar-client>=3.1.0->chromadb) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\software\\anaconda\\lib\\site-packages (from requests->gpt4all) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\software\\anaconda\\lib\\site-packages (from requests->gpt4all) (3.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\software\\anaconda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\software\\anaconda\\lib\\site-packages (from tqdm->gpt4all) (0.4.5)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\software\\anaconda\\lib\\site-packages (from importlib-resources->chromadb) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\software\\anaconda\\lib\\site-packages (from packaging->onnxruntime>=1.14.1->chromadb) (3.0.9)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\software\\anaconda\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (3.5.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\software\\anaconda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\software\\anaconda\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\software\\anaconda\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gpt4all langchain chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtO5ZTQA6tff"
   },
   "source": [
    "## Step 1. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WQAcyEedTROu"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/FIFA\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmdN9Bbg6zMg"
   },
   "source": [
    "## Step 2. Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "isJEN1FHTUS-"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HN_BeFn62dO"
   },
   "source": [
    "## Step 3. Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OcxDllkd61dc",
    "outputId": "ca666b82-ea90-4ccc-903b-43771789aa2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:\\\\\\\\Users\\\\\\\\24075\\\\\\\\.cache\\\\\\\\gpt4all\\\\ggml-all-MiniLM-L6-v2-f16.bin\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=GPT4AllEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnERuv7i7Y3D"
   },
   "source": [
    "## Step 4. Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "javZ4ruq66P8",
    "outputId": "289187a9-528f-42b4-bf5f-189abe52032b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Which team won the 2022 world cup?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYpAfkHp8hX7"
   },
   "source": [
    "Session will crash for \"go deeper\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehE-zxfd7cD0"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from langchain.retrievers import SVMRetriever\n",
    "\n",
    "svm_retriever = SVMRetriever.from_documents(all_splits,GPT4AllEmbeddings())\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "len(docs_svm)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "4m-qjrnU71VO",
    "outputId": "d8751fbe-ff73-4135-e0b9-1f5a1d1307b8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\nimport logging\\n\\nfrom langchain.chat_models import ChatOpenAI\\nfrom langchain.retrievers.multi_query import MultiQueryRetriever\\n\\nlogging.basicConfig()\\nlogging.getLogger('langchain.retrievers.multi_query').setLevel(logging.INFO)\\n\\nretriever_from_llm = MultiQueryRetriever.from_llm(retriever=vectorstore.as_retriever(),\\n                                                  llm=ChatOpenAI(temperature=0))\\nunique_docs = retriever_from_llm.get_relevant_documents(query=question)\\nlen(unique_docs)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import logging\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger('langchain.retrievers.multi_query').setLevel(logging.INFO)\n",
    "\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(retriever=vectorstore.as_retriever(),\n",
    "                                                  llm=ChatOpenAI(temperature=0))\n",
    "unique_docs = retriever_from_llm.get_relevant_documents(query=question)\n",
    "len(unique_docs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slWIM43h8v3t"
   },
   "source": [
    "## Step 5. Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "w5LTUV-u8tvz",
    "outputId": "41a88183-f084-4bd7-8972-f13f9aa7e9f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:/Users/24075/AppData/Local/nomic.ai/GPT4All/ggml-model-gpt4all-falcon-q4_0.bin\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import GPT4All\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "gpt4all_falcon_model = \"C:/Users/24075/AppData/Local/nomic.ai/GPT4All/ggml-model-gpt4all-falcon-q4_0.bin\"\n",
    "\n",
    "llm = GPT4All(model=gpt4all_falcon_model ,max_tokens=2048)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:/Users/24075/AppData/Local/nomic.ai/GPT4All/ggml-model-gpt4all-falcon-q4_0.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The 2022 World Cup was awarded to Qatar.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible. \n",
    "Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "llm = GPT4All(model=gpt4all_falcon_model ,max_tokens=2048)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return source documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Brazil\\n\\n2nd\\n\\n Spain\\n\\n2024 (final)\\n\\n\\nFIFA U-20 World Cup\\n\\n2023 (final)\\n\\n\\xa0Uruguay\\n\\n1st\\n\\n\\xa0Italy\\n\\n2025 (final)\\n\\n\\nFIFA U-17 World Cup\\n\\n2019 (final)\\n\\n\\xa0Brazil\\n\\n4th\\n\\n\\xa0Mexico\\n\\n2023 (final)\\n\\n\\nFIFA Futsal World Cup\\n\\n2021 (final)\\n\\n\\xa0Portugal\\n\\n1st\\n\\n\\xa0Argentina\\n\\n2024 (final)\\n\\n\\nMen's Youth Olympic Futsal Tournament (U-20)\\n\\n2018 (final)\\n\\n\\xa0Brazil\\n\\n1st\\n\\n\\xa0Russia\\n\\n2026\\n\\n\\nFIFA Beach Soccer World Cup (see the BSWW)\\n\\n2021 (final)\\n\\n\\xa0Russia\\n\\n3rd\\n\\n\\xa0Japan\\n\\n2023 (final)\", metadata={'language': 'en', 'source': 'https://en.wikipedia.org/wiki/FIFA', 'title': 'FIFA - Wikipedia'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=vectorstore.as_retriever(),\n",
    "                                       return_source_documents=True)\n",
    "result = qa_chain({\"query\": question})\n",
    "print(len(result['source_documents']))\n",
    "result['source_documents'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Which team won the 2022 world cup?',\n",
       " 'answer': 'ERROR: The prompt size exceeds the context window size and cannot be processed.',\n",
       " 'sources': ''}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_chain_type(llm,retriever=vectorstore.as_retriever())\n",
    "\n",
    "result = qa_chain({\"question\": question})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask another question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Who is the first president of FIFA?\"\n",
    "# Robert Guerin\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:/Users/24075/AppData/Local/nomic.ai/GPT4All/ggml-model-gpt4all-falcon-q4_0.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Robert Guérin was the first president of FIFA.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = GPT4All(model=gpt4all_falcon_model ,max_tokens=2048)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For specific questions, the model demonstrates good result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question2 = \"What is the Top 20 rankings as of 20 July 2023?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(question2)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The table above shows the Top 20 rankings as of 20 July 2023.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question2})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to answers that organized in table format, it can not show the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question3 = \"What is the No.2 women's team as of 20 July 2023?\"\n",
    "# Sweden\n",
    "docs = vectorstore.similarity_search(question3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Sweden.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question3})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Sweden.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question4 = \"What is the No.2 women's team as of 25 August 2023?\"\n",
    "# Spain\n",
    "docs = vectorstore.similarity_search(question3)\n",
    "result = qa_chain({\"query\": question3})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings and Discussions\n",
    "For the above model, I use the locally downloaded **GPT4ALL Falcon** model to replace the original **OpenAI GPT3.5-turbo** model, it has the following specifications:\n",
    "- This model has been finetuned from Falcon\n",
    "- Developed by: Nomic AI\n",
    "- Model Type: A finetuned Falcon 7B model on assistant style interaction data\n",
    "- Language(s) (NLP): English\n",
    "- License: Apache-2\n",
    "- Finetuned from model [optional]: Falcon\n",
    "\n",
    "Based on the FIFA Wikipedia website result, I have the following findings:\n",
    "1. When dealing with pure text data, the answer is mostly correct.\n",
    "2. When the answer of the data involves with other format (table, etc.), the result is not displaying (ERROR: The prompt size exceeds the context window size and cannot be processed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
