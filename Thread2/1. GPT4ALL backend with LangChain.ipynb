{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT4ALL backend for LangChain\n",
    "\n",
    "Lixiao Yang \\\n",
    "8/29/2023\n",
    "\n",
    "- GPT4ALL: https://gpt4all.io/index.html\n",
    "    - github: https://github.com/nomic-ai/gpt4all\n",
    "    - for langchain: https://python.langchain.com/docs/integrations/llms/gpt4all.html\n",
    "    - data like: https://github.com/nomic-ai/gpt4all-datalake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import GPT4ALL and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gpt4all\n",
      "  Downloading gpt4all-1.0.8-py3-none-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 26.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from gpt4all) (2.28.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from gpt4all) (4.65.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\software\\anaconda\\lib\\site-packages (from requests->gpt4all) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\software\\anaconda\\lib\\site-packages (from requests->gpt4all) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\software\\anaconda\\lib\\site-packages (from requests->gpt4all) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\software\\anaconda\\lib\\site-packages (from requests->gpt4all) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\software\\anaconda\\lib\\site-packages (from tqdm->gpt4all) (0.4.5)\n",
      "Installing collected packages: gpt4all\n",
      "Successfully installed gpt4all-1.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install gpt4all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.0.277-py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 14.5 MB/s eta 0:00:00\n",
      "Collecting langsmith<0.1.0,>=0.0.21\n",
      "  Downloading langsmith-0.0.29-py3-none-any.whl (34 kB)\n",
      "Collecting pydantic<3,>=1\n",
      "  Downloading pydantic-2.3.0-py3-none-any.whl (374 kB)\n",
      "     ------------------------------------- 374.5/374.5 kB 11.4 MB/s eta 0:00:00\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\software\\anaconda\\lib\\site-packages (from langchain) (6.0)\n",
      "Collecting numexpr<3.0.0,>=2.8.4\n",
      "  Downloading numexpr-2.8.5-cp39-cp39-win_amd64.whl (94 kB)\n",
      "     ---------------------------------------- 94.4/94.4 kB ? eta 0:00:00\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\software\\anaconda\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (4.0.2)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
      "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\software\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\software\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\24075\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 49.4/49.4 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting typing-extensions>=4.6.1\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Collecting pydantic-core==2.6.3\n",
      "  Downloading pydantic_core-2.6.3-cp39-none-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 18.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\software\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\software\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\software\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\software\\anaconda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\software\\anaconda\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\software\\anaconda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\software\\anaconda\\lib\\site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (3.0.9)\n",
      "Installing collected packages: typing-extensions, tenacity, numexpr, annotated-types, typing-inspect, pydantic-core, marshmallow, pydantic, dataclasses-json, langsmith, langchain\n",
      "Successfully installed annotated-types-0.5.0 dataclasses-json-0.5.14 langchain-0.0.277 langsmith-0.0.29 marshmallow-3.20.1 numexpr-2.8.5 pydantic-2.3.0 pydantic-core-2.6.3 tenacity-8.2.3 typing-extensions-4.7.1 typing-inspect-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.7.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Up Question to pass to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = (\n",
    "    \"C:/Users/24075/AppData/Local/nomic.ai/GPT4All/ggml-model-gpt4all-falcon-q4_0.bin\"  # replace with your desired local file path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  C:/Users/24075/AppData/Local/nomic.ai/GPT4All/ggml-model-gpt4all-falcon-q4_0.bin\n",
      "Found model file at  C:/Users/24075/AppData/Local/nomic.ai/GPT4All/ggml-model-gpt4all-falcon-q4_0.bin\n"
     ]
    }
   ],
   "source": [
    "# Callbacks support token-wise streaming\n",
    "callbacks = [StreamingStdOutCallbackHandler()]\n",
    "\n",
    "# Verbose is required to pass to the callback manager\n",
    "llm = GPT4All(model=local_path, callbacks=callbacks, verbose=True)\n",
    "\n",
    "# If you want to use a custom model add the backend parameter\n",
    "# Check https://docs.gpt4all.io/gpt4all_python.html for supported backends\n",
    "llm = GPT4All(model=local_path, backend=\"gptj\", callbacks=callbacks, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. World Cup is a football tournament.\n",
      "2. Football teams are from different countries.\n",
      "3. World Cup teams are from different continents.\n",
      "4. World Cup teams are from different leagues.\n",
      "5. World Cup teams are from different countries.\n",
      "6. World Cup teams are from different cultures.\n",
      "7. World Cup teams are from different backgrounds.\n",
      "\n",
      "Answer: The answer is \"Spain\"."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. World Cup is a football tournament.\\n2. Football teams are from different countries.\\n3. World Cup teams are from different continents.\\n4. World Cup teams are from different leagues.\\n5. World Cup teams are from different countries.\\n6. World Cup teams are from different cultures.\\n7. World Cup teams are from different backgrounds.\\n\\nAnswer: The answer is \"Spain\".'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Which team won the 2022 world cup\"\n",
    "\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Check the internet for the latest news on FIFA.\n",
      "2. Look at the current FIFA President's name.\n",
      "3. Check if the person who is the current FIFA President is still the same person as before.\n",
      "\n",
      "If you are referring to the most recent FIFA President, it is Gianni Infantino."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n1. Check the internet for the latest news on FIFA.\\n2. Look at the current FIFA President's name.\\n3. Check if the person who is the current FIFA President is still the same person as before.\\n\\nIf you are referring to the most recent FIFA President, it is Gianni Infantino.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Who is the president of FIFA now?\"\n",
    "# Gianni Infantino\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Step 1: Find out the teams that are in the FIFA World Ranking for Women's Football.\n",
      "\n",
      "Step 2: Check the teams that are in the top 10 of the FIFA World Ranking for Women's Football.\n",
      "\n",
      "Step 3: Look at the teams that are in the top 20 of the FIFA World Ranking for Women's Football.\n",
      "\n",
      "Step 4: Find out the teams that are in the top 30 of the FIFA World Ranking for Women's Football.\n",
      "\n",
      "Step 5: Check the teams that are in the top 50 of the FIFA World Ranking for Women's Football.\n",
      "\n",
      "Step 6: Look at the teams that are in the top 100 of the FIFA World Ranking for Women's Football.\n",
      "\n",
      "Step 7: Find out the teams that are in the top 150 of the FIFA World Ranking for Women's Football.\n",
      "\n",
      "Step 8: Check the teams that are in the top 200 of the FIFA World Ranking for Women's Football.\n",
      "\n",
      "Step 9: Look at the teams that are in the top 250 of the FIFA World Ranking for Women's Football.\n",
      "\n",
      "Step 10: Find out the teams that are"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nStep 1: Find out the teams that are in the FIFA World Ranking for Women's Football.\\n\\nStep 2: Check the teams that are in the top 10 of the FIFA World Ranking for Women's Football.\\n\\nStep 3: Look at the teams that are in the top 20 of the FIFA World Ranking for Women's Football.\\n\\nStep 4: Find out the teams that are in the top 30 of the FIFA World Ranking for Women's Football.\\n\\nStep 5: Check the teams that are in the top 50 of the FIFA World Ranking for Women's Football.\\n\\nStep 6: Look at the teams that are in the top 100 of the FIFA World Ranking for Women's Football.\\n\\nStep 7: Find out the teams that are in the top 150 of the FIFA World Ranking for Women's Football.\\n\\nStep 8: Check the teams that are in the top 200 of the FIFA World Ranking for Women's Football.\\n\\nStep 9: Look at the teams that are in the top 250 of the FIFA World Ranking for Women's Football.\\n\\nStep 10: Find out the teams that are\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Which team is the top 1 ranked women's football country?\"\n",
    "# Sweden\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
