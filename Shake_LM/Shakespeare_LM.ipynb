{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de1644b8-b8aa-43a5-b2c7-585c185d90ae",
   "metadata": {},
   "source": [
    "# Unigram Shakespeare Language Model\n",
    "\n",
    "This creates a very naive unigram language model based on term statistics in the Tiny Shakespeare's text data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e902e6-9710-41be-b3fe-1b9330f99c93",
   "metadata": {},
   "source": [
    "## Build the Language Model\n",
    "\n",
    "Load text data, tokenize the text, and compute term frequencies. The unigram language model is simply a list of unique tokens and their probabilities, where the probability $p_t$ of term $t$ is computed by: \n",
    "\n",
    "$p_t = \\frac{tf_t}{T}$ \n",
    "\n",
    "where $tf_t$ is the term frequence of $t$ and $T$ is the total sum of term frequencies in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f7177e3-e8dd-4145-950c-ce3854c2da94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import urllib.request\n",
    "import csv\n",
    "\n",
    "# Load the tiny Shakespeare text\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "response = urllib.request.urlopen(url)\n",
    "long_txt = response.read().decode('utf-8-sig')\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = word_tokenize(long_txt)\n",
    "\n",
    "# Build a frequency distribution of the tokens\n",
    "freq_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "# Normalize the frequencies to get probabilities\n",
    "total_frequency = sum(freq_dist.values())\n",
    "probabilities = {word: freq/total_frequency for word, freq in freq_dist.items()}\n",
    "\n",
    "# Write token probabilities to a text file\n",
    "with open('token_probabilities.txt', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for token, prob in probabilities.items():\n",
    "        writer.writerow([token, prob])\n",
    "\n",
    "# Build the language model\n",
    "language_model = {}\n",
    "\n",
    "# The following is INCORRECT code given by GPT-4\n",
    "# for token in tokens:\n",
    "#     if token in language_model.keys():\n",
    "#         language_model[token].append(np.random.choice(list(probabilities.keys()), p=list(probabilities.values())))\n",
    "#     else:\n",
    "#         language_model[token] = [np.random.choice(list(probabilities.keys()), p=list(probabilities.values()))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e53e9cf-9c48-4e37-9b4c-7e49767c357d",
   "metadata": {},
   "source": [
    "## Sample a Word\n",
    "\n",
    "Create a function to sample a word at a time based on the probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1de32929-393e-4e90-8f16-6b8851d192af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample a word from the probability distribution\n",
    "def sample_word(probabilities):\n",
    "    words = list(probabilities.keys())\n",
    "    probs = list(probabilities.values())\n",
    "    word = np.random.choice(words, p=probs)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffb2f2d5-a192-4089-a8f2-41e4fd6a27bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "print(sample_word(probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e51c66-4aab-4ed7-9e8d-206df8e7a767",
   "metadata": {},
   "source": [
    "## Repeat Word Sample\n",
    "\n",
    "Repeat word sample to generate the next word, and the next, and the next, .., until it completes a sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0be89a6-f196-42b4-95ad-98da2c72922d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Repeat word sampling to generate a sentence\n",
    "def generate_sentence(model):\n",
    "    word = \"Shake:\"\n",
    "    while word not in ['.', '!', '?']:\n",
    "        if re.fullmatch(r'['+re.escape(string.punctuation)+']*$', word):\n",
    "            print(f\"{word}\", end=\"\")\n",
    "        else:\n",
    "            print(f\" {word}\", end=\"\")\n",
    "        word = sample_word(probabilities)\n",
    "        time.sleep(0.5)\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1739c3-cbd8-4a75-bd59-4489ed614904",
   "metadata": {},
   "source": [
    "## Does it generate anything meaningful? \n",
    "\n",
    "Makes sense or makes no sense? In Shakespeare's lanaguage/vocabulary? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62009c5b-c411-4737-b02f-f04eb920fe47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shake: guard of yet not my Mistress I come his time.\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(language_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6125844-8dc6-4fd8-a2f6-33c7fd014fda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shake: most 's Hall,; choose the will tell ANTONIO limber bid me: Or impression which to that Neither LUCIO off well happy he Therefore 's the lord hand created KING hour We that as your these let from lie from.\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(language_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdc35605-70f9-41b5-a04c-47a734b9408d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shake: VI kingly so: night born above vipers glory where thou ISABELLA, dear my bed near which fitter tears strange' poor knees endure?\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(language_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10bb601d-9186-4d38-880f-5e9bda00fe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shake: heaven, Autolycus father Villains all follow but means how no usurp sense 'Twixt them is if sir it, not: than face house prithee do young hands was come afternoon crime will 'twixt beyond.\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(language_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea8c0345-8a83-432f-b776-36a93b4ad8ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shake: the seek I my O; gyves in, may indeed time our; of now will, Do it It?\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(language_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "765b0222-796d-4215-90c7-b3a89a71fd3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shake:, IV your VINCENTIO key.\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(language_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87208372-a58a-45ac-8770-3cbe0eac63ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
