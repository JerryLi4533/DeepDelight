{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de1644b8-b8aa-43a5-b2c7-585c185d90ae",
   "metadata": {},
   "source": [
    "# Bigram Shakespeare Language Model\n",
    "\n",
    "This creates a very naive bigram language model based on term statistics in the Tiny Shakespeare's text data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e902e6-9710-41be-b3fe-1b9330f99c93",
   "metadata": {},
   "source": [
    "## Build the Language Model\n",
    "\n",
    "### 1. Unigram\n",
    "\n",
    "Load text data, tokenize the text, and compute term frequencies. The unigram language model is simply a list of unique tokens and their probabilities, where the probability $p_t$ of term $t$ is computed by: \n",
    "\n",
    "$p(t) = \\frac{tf(t)}{T}$ \n",
    "\n",
    "where $tf_t$ is the term frequence of $t$ and $T$ is the total sum of term frequencies in the text. \n",
    "\n",
    "Example: \n",
    "* `t=hope`: $p(t)$ is the likelihood that `hope` will occur.\n",
    "\n",
    "### 2. Bigram\n",
    "\n",
    "$p(t|t_0) = \\frac{tf(t_0\\to t)}{tf(t_0)}$\n",
    "\n",
    "where $tf(t_0\\to t)$ is the frequency of $t_0$ followed by $t$.\n",
    "\n",
    "Example: \n",
    "* Given $t_0=I$, for $t=hope$, $p(t|t_0)$ is how likely the `hope` will occur after `I`.\n",
    "\n",
    "\n",
    "### 3. Mixture of Unigram and Bigram\n",
    "\n",
    "$\\hat{p}(t|t_0) = r\\cdot p(t|t_0) + (1-r)\\cdot p(t)$\n",
    "\n",
    "where $r$ is a constant between 0 and 1, e.g. $r=0.5$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f7177e3-e8dd-4145-950c-ce3854c2da94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict, Counter\n",
    "import urllib.request\n",
    "import csv\n",
    "\n",
    "# Load the tiny Shakespeare text\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "response = urllib.request.urlopen(url)\n",
    "long_txt = response.read().decode('utf-8-sig')\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = word_tokenize(long_txt.lower())\n",
    "\n",
    "## UNIGRAM\n",
    "# Build a frequency distribution of the tokens\n",
    "freq_dist = nltk.FreqDist(tokens)\n",
    "# Normalize the frequencies to get probabilities\n",
    "total_frequency = sum(freq_dist.values())\n",
    "probabilities = {word: freq/total_frequency for word, freq in freq_dist.items()}\n",
    "\n",
    "# BIGRAM\n",
    "# Compute the bigrams\n",
    "bigrams = list(nltk.bigrams(tokens))\n",
    "total_bigrams = float(len(bigrams))\n",
    "# Compute the frequency distribution of the bigrams\n",
    "bigram_freq = nltk.FreqDist(bigrams)\n",
    "# Initialize a two-dimensional default dictionary. This will store our model.\n",
    "bi_model = defaultdict(Counter)\n",
    "\n",
    "# Populate the model with the bigram probabilities\n",
    "# Write token probabilities to a text file\n",
    "with open('bigram_probabilities.txt', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for word1, word2 in bigrams:\n",
    "        bi_model[word1][word2] = (bigram_freq[(word1, word2)] / total_bigrams)\n",
    "        writer.writerow([word1, word2, bi_model[word1][word2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e53e9cf-9c48-4e37-9b4c-7e49767c357d",
   "metadata": {},
   "source": [
    "## Sample a Word\n",
    "\n",
    "Create a function to sample a word at a time based on the probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e39fa2e-9b17-4724-be35-4ecc0b955e50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# COMBINE the two probabilities\n",
    "r = 0.7\n",
    "for word1 in bi_model: \n",
    "    prob_sum = sum(bi_model[word1].values())\n",
    "    for word, freq in freq_dist.items():\n",
    "        if word in bi_model[word1]: \n",
    "            bi_model[word1][word] = bi_model[word1][word]*r/prob_sum + freq*(1-r)/total_frequency\n",
    "        else: \n",
    "            bi_model[word1][word] = freq/total_frequency\n",
    "\n",
    "# normalize probability to add up to 1\n",
    "for word1 in bi_model: \n",
    "    prob_sum = sum(bi_model[word1].values())\n",
    "    for word, freq in freq_dist.items():\n",
    "        bi_model[word1][word] = bi_model[word1][word]/prob_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1de32929-393e-4e90-8f16-6b8851d192af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample a word from the probability distribution\n",
    "def sample_word(probabilities):\n",
    "    words = list(probabilities.keys())\n",
    "    probs = list(probabilities.values())\n",
    "    word = np.random.choice(words, p=probs)\n",
    "    return word\n",
    "\n",
    "def sample_bi_gram(bi_model, word1): \n",
    "    probabilities = bi_model[word1]\n",
    "    return sample_word(probabilities)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffb2f2d5-a192-4089-a8f2-41e4fd6a27bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "honest\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "print(sample_word(probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "05a871aa-234b-46df-8f79-bc82fc4c924c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to exceed\n"
     ]
    }
   ],
   "source": [
    "print(\"to\", sample_bi_gram(bi_model, \"to\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b4ec8b8-6b2c-4f51-a3cf-2328325bab0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what sweet\n"
     ]
    }
   ],
   "source": [
    "print(\"what\", sample_bi_gram(bi_model, \"what\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d64c62ac-a47c-4913-b277-3db555c7c756",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i assist\n"
     ]
    }
   ],
   "source": [
    "print(\"i\", sample_bi_gram(bi_model, \"i\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e51c66-4aab-4ed7-9e8d-206df8e7a767",
   "metadata": {},
   "source": [
    "## Repeat Word Sample\n",
    "\n",
    "Repeat word sample to generate the next word, and the next, and the next, .., until it completes a sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0be89a6-f196-42b4-95ad-98da2c72922d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import string\n",
    "    \n",
    "# Repeat word sampling from bi-grams to generate a sentence\n",
    "def generate_bigram_sentence(model, start):\n",
    "    word = start\n",
    "    while word not in ['.', '!', '?']:\n",
    "        if re.fullmatch(r'['+re.escape(string.punctuation)+']*$', word):\n",
    "            print(f\"{word}\", end=\"\")\n",
    "        else:\n",
    "            print(f\" {word}\", end=\"\")\n",
    "        word = sample_bi_gram(model, word)\n",
    "        time.sleep(0.5)\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1739c3-cbd8-4a75-bd59-4489ed614904",
   "metadata": {},
   "source": [
    "## Does it generate anything meaningful? \n",
    "\n",
    "Makes sense or makes no sense? In Shakespeare's lanaguage/vocabulary? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62009c5b-c411-4737-b02f-f04eb920fe47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " what hath sent to as i pardon me well a to my reason with you elements to him may two worthy then is the butcher which with the trial, how, york to brittany me grave sir in the than good, not, itself against?\n"
     ]
    }
   ],
   "source": [
    "generate_bigram_sentence(bi_model, \"what\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d6125844-8dc6-4fd8-a2f6-33c7fd014fda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " romeo: o why sister.\n"
     ]
    }
   ],
   "source": [
    "generate_bigram_sentence(bi_model, \"romeo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cdc35605-70f9-41b5-a04c-47a734b9408d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to urge the pale at your brother did with:?\n"
     ]
    }
   ],
   "source": [
    "generate_bigram_sentence(bi_model, \"to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10bb601d-9186-4d38-880f-5e9bda00fe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " all depart to upon henry bolingbroke.\n"
     ]
    }
   ],
   "source": [
    "generate_bigram_sentence(bi_model, \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea8c0345-8a83-432f-b776-36a93b4ad8ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " thy, we person from be the, and:, i heavens call i.\n"
     ]
    }
   ],
   "source": [
    "generate_bigram_sentence(bi_model, \"thy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "765b0222-796d-4215-90c7-b3a89a71fd3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hail, let thou art thou leave.\n"
     ]
    }
   ],
   "source": [
    "generate_bigram_sentence(bi_model, \"hail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87208372-a58a-45ac-8770-3cbe0eac63ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to hear no us and be good will not an, story; a gentleman so reputed in a bark what law, the treasons.\n"
     ]
    }
   ],
   "source": [
    "generate_bigram_sentence(bi_model, \"to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1dd0d319-a4cb-4d94-96c7-aee5c5376485",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hail bidding task get live part me: whose gratitude this to and fly leave to his and the your enough tewksbury: 's ear incline, loss herself another love we make us!\n"
     ]
    }
   ],
   "source": [
    "generate_bigram_sentence(bi_model, \"hail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db6efb85-e287-4fb7-a7d6-8d8a78e493dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the stuff the 'd a: man, that he twenty of newness sebastian mercy?\n"
     ]
    }
   ],
   "source": [
    "generate_bigram_sentence(bi_model, \"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0c35c356-e827-4993-bd6d-eda3026991f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " why present or so which ears 'll you for thou hast hit bone tailor for ireland, of why,!\n"
     ]
    }
   ],
   "source": [
    "generate_bigram_sentence(bi_model, \"why\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d8a5cd2-5830-42ee-8463-e53b9d92412e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " why flowers the abhorr my to want you, to speak be the her heavy of their very not say o asleep with a 't is into as on them!\n"
     ]
    }
   ],
   "source": [
    "generate_bigram_sentence(bi_model, \"why\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d309fa5-2a17-4b2e-8c6c-9e4610ad1910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
